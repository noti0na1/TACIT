{"instance_id": "astropy__astropy-12907", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..f10a24025a 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -95,8 +95,7 @@ def separability_matrix(transform):\n \n     \"\"\"\n     if transform.n_inputs == 1 and transform.n_outputs > 1:\n-        return np.ones((transform.n_outputs, transform.n_inputs),\n-                       dtype=np.bool_)\n+        return np.ones((transform.n_outputs, transform.n_inputs), dtype=np.bool_)\n     separable_matrix = _separable(transform)\n     separable_matrix = np.where(separable_matrix != 0, True, False)\n     return separable_matrix\n@@ -145,6 +144,7 @@ def _arith_oper(left, right):\n     result : ndarray\n         Result from this operation.\n     \"\"\"\n+\n     # models have the same number of inputs and outputs\n     def _n_inputs_outputs(input):\n         if isinstance(input, Model):\n@@ -162,7 +162,9 @@ def _arith_oper(left, right):\n             \"n_outputs={}) and right (n_inputs={}, n_outputs={}); \"\n             \"models must have the same n_inputs and the same \"\n             \"n_outputs for this operator.\".format(\n-                left_inputs, left_outputs, right_inputs, right_outputs))\n+                left_inputs, left_outputs, right_inputs, right_outputs\n+            )\n+        )\n \n     result = np.ones((left_outputs, left_inputs))\n     return result\n@@ -194,24 +196,24 @@ def _coord_matrix(model, pos, noutp):\n             axes.append(axis)\n         m = np.vstack(axes)\n         mat = np.zeros((noutp, model.n_inputs))\n-        if pos == 'left':\n-            mat[: model.n_outputs, :model.n_inputs] = m\n+        if pos == \"left\":\n+            mat[: model.n_outputs, : model.n_inputs] = m\n         else:\n-            mat[-model.n_outputs:, -model.n_inputs:] = m\n+            mat[-model.n_outputs :, -model.n_inputs :] = m\n         return mat\n     if not model.separable:\n         # this does not work for more than 2 coordinates\n         mat = np.zeros((noutp, model.n_inputs))\n-        if pos == 'left':\n-            mat[:model.n_outputs, : model.n_inputs] = 1\n+        if pos == \"left\":\n+            mat[: model.n_outputs, : model.n_inputs] = 1\n         else:\n-            mat[-model.n_outputs:, -model.n_inputs:] = 1\n+            mat[-model.n_outputs :, -model.n_inputs :] = 1\n     else:\n         mat = np.zeros((noutp, model.n_inputs))\n \n         for i in range(model.n_inputs):\n             mat[i, i] = 1\n-        if pos == 'right':\n+        if pos == \"right\":\n             mat = np.roll(mat, (noutp - model.n_outputs))\n     return mat\n \n@@ -234,15 +236,15 @@ def _cstack(left, right):\n     noutp = _compute_n_outputs(left, right)\n \n     if isinstance(left, Model):\n-        cleft = _coord_matrix(left, 'left', noutp)\n+        cleft = _coord_matrix(left, \"left\", noutp)\n     else:\n         cleft = np.zeros((noutp, left.shape[1]))\n         cleft[: left.shape[0], : left.shape[1]] = left\n     if isinstance(right, Model):\n-        cright = _coord_matrix(right, 'right', noutp)\n+        cright = _coord_matrix(right, \"right\", noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0] :, -right.shape[1] :] = right\n \n     return np.hstack([cleft, cright])\n \n@@ -274,16 +276,16 @@ def _cdot(left, right):\n             coords = input\n         return coords\n \n-    cleft = _n_inputs_outputs(left, 'left')\n-    cright = _n_inputs_outputs(right, 'right')\n+    cleft = _n_inputs_outputs(left, \"left\")\n+    cright = _n_inputs_outputs(right, \"right\")\n \n     try:\n         result = np.dot(cleft, cright)\n     except ValueError:\n         raise ModelDefinitionError(\n             'Models cannot be combined with the \"|\" operator; '\n-            'left coord_matrix is {}, right coord_matrix is {}'.format(\n-                cright, cleft))\n+            \"left coord_matrix is {}, right coord_matrix is {}\".format(cright, cleft)\n+        )\n     return result\n \n \n@@ -301,17 +303,26 @@ def _separable(transform):\n         An array of shape (transform.n_outputs,) of boolean type\n         Each element represents the separablity of the corresponding output.\n     \"\"\"\n-    if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n+    if (\n+        transform_matrix := transform._calculate_separability_matrix()\n+    ) is not NotImplemented:\n         return transform_matrix\n     elif isinstance(transform, CompoundModel):\n         sepleft = _separable(transform.left)\n         sepright = _separable(transform.right)\n         return _operators[transform.op](sepleft, sepright)\n     elif isinstance(transform, Model):\n-        return _coord_matrix(transform, 'left', transform.n_outputs)\n+        return _coord_matrix(transform, \"left\", transform.n_outputs)\n \n \n # Maps modeling operators to a function computing and represents the\n # relationship of axes as an array of 0-es and 1-s\n-_operators = {'&': _cstack, '|': _cdot, '+': _arith_oper, '-': _arith_oper,\n-              '*': _arith_oper, '/': _arith_oper, '**': _arith_oper}\n+_operators = {\n+    \"&\": _cstack,\n+    \"|\": _cdot,\n+    \"+\": _arith_oper,\n+    \"-\": _arith_oper,\n+    \"*\": _arith_oper,\n+    \"/\": _arith_oper,\n+    \"**\": _arith_oper,\n+}\n"}
{"instance_id": "astropy__astropy-14182", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..4fad2c1398 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -3,7 +3,6 @@\n :Author: Simon Gibbons (simongibbons@gmail.com)\n \"\"\"\n \n-\n from .core import DefaultSplitter\n from .fixedwidth import (\n     FixedWidth,\n@@ -57,10 +56,11 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n \n     def write(self, lines):\n         lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n+        idx = len(self.header.header_rows)\n+        lines = [lines[idx]] + lines + [lines[idx]]\n         return lines\n"}
{"instance_id": "astropy__astropy-14365", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..4cb1a5bd65 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -4,6 +4,7 @@ This package contains functions for reading and writing QDP tables that are\n not meant to be used directly, but instead are available as readers/writers in\n `astropy.table`. See :ref:`astropy:table_io` for more details.\n \"\"\"\n+\n import copy\n import re\n import warnings\n@@ -68,7 +69,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n"}
{"instance_id": "astropy__astropy-14995", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..183022b4da 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -512,7 +512,6 @@ class NDArithmeticMixin:\n             If neither had a mask ``None`` is returned. Otherwise\n             ``handle_mask`` must create (and copy) the returned mask.\n         \"\"\"\n-        # If only one mask is present we need not bother about any type checks\n         if (\n             self.mask is None and operand is not None and operand.mask is None\n         ) or handle_mask is None:\n@@ -522,6 +521,8 @@ class NDArithmeticMixin:\n             return deepcopy(operand.mask)\n         elif operand is None:\n             return deepcopy(self.mask)\n+        elif operand.mask is None:\n+            return deepcopy(self.mask)\n         else:\n             # Now lets calculate the resulting mask (operation enforces copy)\n             return handle_mask(self.mask, operand.mask, **kwds)\n"}
{"instance_id": "astropy__astropy-6938", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\nindex 574b4073b1..778dcda740 100644\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -12,9 +12,22 @@ import numpy as np\n \n from numpy import char as chararray\n \n-from .column import (ASCIITNULL, FITS2NUMPY, ASCII2NUMPY, ASCII2STR, ColDefs,\n-                     _AsciiColDefs, _FormatX, _FormatP, _VLF, _get_index,\n-                     _wrapx, _unwrapx, _makep, Delayed)\n+from .column import (\n+    ASCIITNULL,\n+    FITS2NUMPY,\n+    ASCII2NUMPY,\n+    ASCII2STR,\n+    ColDefs,\n+    _AsciiColDefs,\n+    _FormatX,\n+    _FormatP,\n+    _VLF,\n+    _get_index,\n+    _wrapx,\n+    _unwrapx,\n+    _makep,\n+    Delayed,\n+)\n from .util import decode_ascii, encode_ascii, _rstrip_inplace\n from ...utils import lazyproperty\n \n@@ -29,8 +42,9 @@ class FITS_record:\n     class expects a `FITS_rec` object as input.\n     \"\"\"\n \n-    def __init__(self, input, row=0, start=None, end=None, step=None,\n-                 base=None, **kwargs):\n+    def __init__(\n+        self, input, row=0, start=None, end=None, step=None, base=None, **kwargs\n+    ):\n         \"\"\"\n         Parameters\n         ----------\n@@ -67,13 +81,12 @@ class FITS_record:\n             if indx < self.start or indx > self.end - 1:\n                 raise KeyError(\"Key '{}' does not exist.\".format(key))\n         elif isinstance(key, slice):\n-            return type(self)(self.array, self.row, key.start, key.stop,\n-                              key.step, self)\n+            return type(self)(self.array, self.row, key.start, key.stop, key.step, self)\n         else:\n             indx = self._get_index(key)\n \n             if indx > self.array._nfields - 1:\n-                raise IndexError('Index out of bounds')\n+                raise IndexError(\"Index out of bounds\")\n \n         return self.array.field(indx)[self.row]\n \n@@ -90,7 +103,7 @@ class FITS_record:\n         else:\n             indx = self._get_index(key)\n             if indx > self.array._nfields - 1:\n-                raise IndexError('Index out of bounds')\n+                raise IndexError(\"Index out of bounds\")\n \n         self.array.field(indx)[self.row] = value\n \n@@ -105,7 +118,7 @@ class FITS_record:\n         outlist = []\n         for idx in range(len(self)):\n             outlist.append(repr(self[idx]))\n-        return '({})'.format(', '.join(outlist))\n+        return \"({})\".format(\", \".join(outlist))\n \n     def field(self, field):\n         \"\"\"\n@@ -131,7 +144,7 @@ class FITS_record:\n         return bases\n \n     def _get_index(self, indx):\n-        indices = np.ogrid[:self.array._nfields]\n+        indices = np.ogrid[: self.array._nfields]\n         for base in reversed(self._bases):\n             if base.step < 1:\n                 s = slice(base.start, None, base.step)\n@@ -161,11 +174,13 @@ class FITS_rec(np.recarray):\n \n         # input should be a record array\n         if input.dtype.subdtype is None:\n-            self = np.recarray.__new__(subtype, input.shape, input.dtype,\n-                                       buf=input.data)\n+            self = np.recarray.__new__(\n+                subtype, input.shape, input.dtype, buf=input.data\n+            )\n         else:\n-            self = np.recarray.__new__(subtype, input.shape, input.dtype,\n-                                       buf=input.data, strides=input.strides)\n+            self = np.recarray.__new__(\n+                subtype, input.shape, input.dtype, buf=input.data, strides=input.strides\n+            )\n \n         self._init()\n         if self.dtype.fields:\n@@ -198,13 +213,20 @@ class FITS_rec(np.recarray):\n         column_state = []\n         meta = []\n \n-        for attrs in ['_converted', '_heapoffset', '_heapsize', '_nfields',\n-                      '_gap', '_uint', 'parnames', '_coldefs']:\n-\n+        for attrs in [\n+            \"_converted\",\n+            \"_heapoffset\",\n+            \"_heapsize\",\n+            \"_nfields\",\n+            \"_gap\",\n+            \"_uint\",\n+            \"parnames\",\n+            \"_coldefs\",\n+        ]:\n             with suppress(AttributeError):\n                 # _coldefs can be Delayed, and file objects cannot be\n                 # picked, it needs to be deepcopied first\n-                if attrs == '_coldefs':\n+                if attrs == \"_coldefs\":\n                     column_state.append(self._coldefs.__deepcopy__(None))\n                 else:\n                     column_state.append(getattr(self, attrs))\n@@ -236,11 +258,11 @@ class FITS_rec(np.recarray):\n             self._nfields = len(self.dtype.fields)\n             self._converted = {}\n \n-            self._heapoffset = getattr(obj, '_heapoffset', 0)\n-            self._heapsize = getattr(obj, '_heapsize', 0)\n+            self._heapoffset = getattr(obj, \"_heapoffset\", 0)\n+            self._heapsize = getattr(obj, \"_heapsize\", 0)\n \n-            self._gap = getattr(obj, '_gap', 0)\n-            self._uint = getattr(obj, '_uint', False)\n+            self._gap = getattr(obj, \"_gap\", 0)\n+            self._uint = getattr(obj, \"_uint\", False)\n             self._col_weakrefs = weakref.WeakSet()\n             self._coldefs = ColDefs(self)\n \n@@ -310,8 +332,7 @@ class FITS_rec(np.recarray):\n                 if arr.hdu.data is None:\n                     column.array = None\n                 else:\n-                    column.array = _get_recarray_field(arr.hdu.data,\n-                                                       arr.field)\n+                    column.array = _get_recarray_field(arr.hdu.data, arr.field)\n         # Reset columns._arrays (which we may want to just do away with\n         # altogether\n         del columns._arrays\n@@ -390,16 +411,15 @@ class FITS_rec(np.recarray):\n                     _wrapx(inarr, outarr, recformat.repeat)\n                     continue\n             elif isinstance(recformat, _FormatP):\n-                data._cache_field(name, _makep(inarr, field, recformat,\n-                                               nrows=nrows))\n+                data._cache_field(name, _makep(inarr, field, recformat, nrows=nrows))\n                 continue\n             # TODO: Find a better way of determining that the column is meant\n             # to be FITS L formatted\n-            elif recformat[-2:] == FITS2NUMPY['L'] and inarr.dtype == bool:\n+            elif recformat[-2:] == FITS2NUMPY[\"L\"] and inarr.dtype == bool:\n                 # column is boolean\n                 # The raw data field should be filled with either 'T' or 'F'\n                 # (not 0).  Use 'F' as a default\n-                field[:] = ord('F')\n+                field[:] = ord(\"F\")\n                 # Also save the original boolean array in data._converted so\n                 # that it doesn't have to be re-converted\n                 converted = np.zeros(field.shape, dtype=bool)\n@@ -407,9 +427,8 @@ class FITS_rec(np.recarray):\n                 data._cache_field(name, converted)\n                 # TODO: Maybe this step isn't necessary at all if _scale_back\n                 # will handle it?\n-                inarr = np.where(inarr == np.False_, ord('F'), ord('T'))\n-            elif (columns[idx]._physical_values and\n-                    columns[idx]._pseudo_unsigned_ints):\n+                inarr = np.where(inarr == np.False_, ord(\"F\"), ord(\"T\"))\n+            elif columns[idx]._physical_values and columns[idx]._pseudo_unsigned_ints:\n                 # Temporary hack...\n                 bzero = column.bzero\n                 converted = np.zeros(field.shape, dtype=inarr.dtype)\n@@ -430,7 +449,7 @@ class FITS_rec(np.recarray):\n                     # strings, but we need to view it as a normal ndarray of\n                     # 8-bit ints to fill it with ASCII codes for 'T' and 'F'\n                     outarr = field.view(np.uint8, np.ndarray)[:n]\n-                elif arr.dtype.kind not in ('S', 'U'):\n+                elif arr.dtype.kind not in (\"S\", \"U\"):\n                     # Set up views of numeric columns with the appropriate\n                     # numeric dtype\n                     # Fill with the appropriate blanks for the column format\n@@ -441,10 +460,11 @@ class FITS_rec(np.recarray):\n                 continue\n \n             if inarr.shape != outarr.shape:\n-                if (inarr.dtype.kind == outarr.dtype.kind and\n-                        inarr.dtype.kind in ('U', 'S') and\n-                        inarr.dtype != outarr.dtype):\n-\n+                if (\n+                    inarr.dtype.kind == outarr.dtype.kind\n+                    and inarr.dtype.kind in (\"U\", \"S\")\n+                    and inarr.dtype != outarr.dtype\n+                ):\n                     inarr_rowsize = inarr[0].size\n                     inarr = inarr.flatten().view(outarr.dtype)\n \n@@ -543,13 +563,17 @@ class FITS_rec(np.recarray):\n                 for idx in range(self._nfields):\n                     self.field(idx)[key] = value[idx]\n             else:\n-                raise ValueError('Input tuple or list required to have {} '\n-                                 'elements.'.format(self._nfields))\n+                raise ValueError(\n+                    \"Input tuple or list required to have {} elements.\".format(\n+                        self._nfields\n+                    )\n+                )\n         else:\n-            raise TypeError('Assignment requires a FITS_record, tuple, or '\n-                            'list as input.')\n+            raise TypeError(\n+                \"Assignment requires a FITS_record, tuple, or list as input.\"\n+            )\n \n-    def copy(self, order='C'):\n+    def copy(self, order=\"C\"):\n         \"\"\"\n         The Numpy documentation lies; `numpy.ndarray.copy` is not equivalent to\n         `numpy.copy`.  Differences include that it re-views the copied array as\n@@ -593,11 +617,11 @@ class FITS_rec(np.recarray):\n         # that information in __del__ to save off copies of the array data\n         # for those columns to their Column.array property before our memory\n         # is freed.\n-        return self.__dict__.get('_coldefs')\n+        return self.__dict__.get(\"_coldefs\")\n \n     @_coldefs.setter\n     def _coldefs(self, cols):\n-        self.__dict__['_coldefs'] = cols\n+        self.__dict__[\"_coldefs\"] = cols\n         if isinstance(cols, ColDefs):\n             for col in cols.columns:\n                 self._col_weakrefs.add(col)\n@@ -605,7 +629,7 @@ class FITS_rec(np.recarray):\n     @_coldefs.deleter\n     def _coldefs(self):\n         try:\n-            del self.__dict__['_coldefs']\n+            del self.__dict__[\"_coldefs\"]\n         except KeyError as exc:\n             raise AttributeError(exc.args[0])\n \n@@ -614,7 +638,6 @@ class FITS_rec(np.recarray):\n             del self._coldefs\n             if self.dtype.fields is not None:\n                 for col in self._col_weakrefs:\n-\n                     if col.array is not None:\n                         col.array = col.array.copy()\n \n@@ -628,7 +651,7 @@ class FITS_rec(np.recarray):\n \n         if self.dtype.fields:\n             return list(self.dtype.names)\n-        elif getattr(self, '_coldefs', None) is not None:\n+        elif getattr(self, \"_coldefs\", None) is not None:\n             return self._coldefs.names\n         else:\n             return None\n@@ -637,7 +660,7 @@ class FITS_rec(np.recarray):\n     def formats(self):\n         \"\"\"List of column FITS formats.\"\"\"\n \n-        if getattr(self, '_coldefs', None) is not None:\n+        if getattr(self, \"_coldefs\", None) is not None:\n             return self._coldefs.formats\n \n         return None\n@@ -656,7 +679,7 @@ class FITS_rec(np.recarray):\n             total_itemsize = 0\n             for field in self.dtype.fields.values():\n                 itemsize = field[0].itemsize\n-                if field[0].kind == 'U':\n+                if field[0].kind == \"U\":\n                     itemsize = itemsize // 4\n                 total_itemsize += itemsize\n             return total_itemsize\n@@ -677,16 +700,16 @@ class FITS_rec(np.recarray):\n \n         if format.dtype.itemsize == 0:\n             warnings.warn(\n-                'Field {!r} has a repeat count of 0 in its format code, '\n-                'indicating an empty field.'.format(key))\n+                \"Field {!r} has a repeat count of 0 in its format code, \"\n+                \"indicating an empty field.\".format(key)\n+            )\n             return np.array([], dtype=format.dtype)\n \n         # If field's base is a FITS_rec, we can run into trouble because it\n         # contains a reference to the ._coldefs object of the original data;\n         # this can lead to a circular reference; see ticket #49\n         base = self\n-        while (isinstance(base, FITS_rec) and\n-                isinstance(base.base, np.recarray)):\n+        while isinstance(base, FITS_rec) and isinstance(base.base, np.recarray):\n             base = base.base\n         # base could still be a FITS_rec in some cases, so take care to\n         # use rec.recarray.field to avoid a potential infinite\n@@ -730,20 +753,19 @@ class FITS_rec(np.recarray):\n                 if self_base is base:\n                     return\n \n-                if getattr(self_base, 'base', None) is not None:\n+                if getattr(self_base, \"base\", None) is not None:\n                     self_base = self_base.base\n                 else:\n                     break\n \n-            if getattr(base, 'base', None) is not None:\n+            if getattr(base, \"base\", None) is not None:\n                 base = base.base\n             else:\n                 break\n \n         self._converted[name] = field\n \n-    def _update_column_attribute_changed(self, column, idx, attr, old_value,\n-                                         new_value):\n+    def _update_column_attribute_changed(self, column, idx, attr, old_value, new_value):\n         \"\"\"\n         Update how the data is formatted depending on changes to column\n         attributes initiated by the user through the `Column` interface.\n@@ -752,7 +774,7 @@ class FITS_rec(np.recarray):\n         for each attribute ``_update_column_<attr>``\n         \"\"\"\n \n-        method_name = '_update_column_{0}'.format(attr)\n+        method_name = \"_update_column_{0}\".format(attr)\n         if hasattr(self, method_name):\n             # Right now this is so we can be lazy and not implement updaters\n             # for every attribute yet--some we may not need at all, TBD\n@@ -763,7 +785,7 @@ class FITS_rec(np.recarray):\n \n         dtype = self.dtype\n         # Updating the names on the dtype should suffice\n-        dtype.names = dtype.names[:idx] + (name,) + dtype.names[idx + 1:]\n+        dtype.names = dtype.names[:idx] + (name,) + dtype.names[idx + 1 :]\n \n     def _convert_x(self, field, recformat):\n         \"\"\"Convert a raw table column to a bit array as specified by the\n@@ -785,23 +807,24 @@ class FITS_rec(np.recarray):\n         if raw_data is None:\n             raise OSError(\n                 \"Could not find heap data for the {!r} variable-length \"\n-                \"array column.\".format(column.name))\n+                \"array column.\".format(column.name)\n+            )\n \n         for idx in range(len(self)):\n             offset = field[idx, 1] + self._heapoffset\n             count = field[idx, 0]\n \n-            if recformat.dtype == 'a':\n+            if recformat.dtype == \"a\":\n                 dt = np.dtype(recformat.dtype + str(1))\n                 arr_len = count * dt.itemsize\n-                da = raw_data[offset:offset + arr_len].view(dt)\n+                da = raw_data[offset : offset + arr_len].view(dt)\n                 da = np.char.array(da.view(dtype=dt), itemsize=count)\n                 dummy[idx] = decode_ascii(da)\n             else:\n                 dt = np.dtype(recformat.dtype)\n                 arr_len = count * dt.itemsize\n-                dummy[idx] = raw_data[offset:offset + arr_len].view(dt)\n-                dummy[idx].dtype = dummy[idx].dtype.newbyteorder('>')\n+                dummy[idx] = raw_data[offset : offset + arr_len].view(dt)\n+                dummy[idx].dtype = dummy[idx].dtype.newbyteorder(\">\")\n                 # Each array in the field may now require additional\n                 # scaling depending on the other scaling parameters\n                 # TODO: The same scaling parameters apply to every\n@@ -811,8 +834,7 @@ class FITS_rec(np.recarray):\n                 # TODO: Test that this works for X format; I don't think\n                 # that it does--the recformat variable only applies to the P\n                 # format not the X format\n-                dummy[idx] = self._convert_other(column, dummy[idx],\n-                                                 recformat)\n+                dummy[idx] = self._convert_other(column, dummy[idx], recformat)\n \n         return dummy\n \n@@ -825,16 +847,16 @@ class FITS_rec(np.recarray):\n         format = column.format\n         recformat = ASCII2NUMPY[format[0]]\n         # if the string = TNULL, return ASCIITNULL\n-        nullval = str(column.null).strip().encode('ascii')\n+        nullval = str(column.null).strip().encode(\"ascii\")\n         if len(nullval) > format.width:\n-            nullval = nullval[:format.width]\n+            nullval = nullval[: format.width]\n \n         # Before using .replace make sure that any trailing bytes in each\n         # column are filled with spaces, and *not*, say, nulls; this causes\n         # functions like replace to potentially leave gibberish bytes in the\n         # array buffer.\n         dummy = np.char.ljust(field, format.width)\n-        dummy = np.char.replace(dummy, encode_ascii('D'), encode_ascii('E'))\n+        dummy = np.char.replace(dummy, encode_ascii(\"D\"), encode_ascii(\"E\"))\n         null_fill = encode_ascii(str(ASCIITNULL).rjust(format.width))\n \n         # Convert all fields equal to the TNULL value (nullval) to empty fields.\n@@ -843,17 +865,17 @@ class FITS_rec(np.recarray):\n         dummy = np.where(np.char.strip(dummy) == nullval, null_fill, dummy)\n \n         # always replace empty fields, see https://github.com/astropy/astropy/pull/5394\n-        if nullval != b'':\n-            dummy = np.where(np.char.strip(dummy) == b'', null_fill, dummy)\n+        if nullval != b\"\":\n+            dummy = np.where(np.char.strip(dummy) == b\"\", null_fill, dummy)\n \n         try:\n             dummy = np.array(dummy, dtype=recformat)\n         except ValueError as exc:\n             indx = self.names.index(column.name)\n             raise ValueError(\n-                '{}; the header may be missing the necessary TNULL{} '\n-                'keyword or the table contains invalid data'.format(\n-                    exc, indx + 1))\n+                \"{}; the header may be missing the necessary TNULL{} \"\n+                \"keyword or the table contains invalid data\".format(exc, indx + 1)\n+            )\n \n         return dummy\n \n@@ -868,8 +890,9 @@ class FITS_rec(np.recarray):\n             # special handling for the X format\n             return self._convert_x(field, recformat)\n \n-        (_str, _bool, _number, _scale, _zero, bscale, bzero, dim) = \\\n+        (_str, _bool, _number, _scale, _zero, bscale, bzero, dim) = (\n             self._get_scale_factors(column)\n+        )\n \n         indx = self.names.index(column.name)\n \n@@ -903,16 +926,19 @@ class FITS_rec(np.recarray):\n                 nitems = reduce(operator.mul, dim)\n                 if _str:\n                     actual_nitems = field.itemsize\n-                elif len(field.shape) == 1:  # No repeat count in TFORMn, equivalent to 1\n+                elif (\n+                    len(field.shape) == 1\n+                ):  # No repeat count in TFORMn, equivalent to 1\n                     actual_nitems = 1\n                 else:\n                     actual_nitems = field.shape[1]\n                 if nitems > actual_nitems:\n                     warnings.warn(\n-                        'TDIM{} value {:d} does not fit with the size of '\n-                        'the array items ({:d}).  TDIM{:d} will be ignored.'\n-                        .format(indx + 1, self._coldefs[indx].dims,\n-                                actual_nitems, indx + 1))\n+                        \"TDIM{} value {:d} does not fit with the size of \"\n+                        \"the array items ({:d}).  TDIM{:d} will be ignored.\".format(\n+                            indx + 1, self._coldefs[indx].dims, actual_nitems, indx + 1\n+                        )\n+                    )\n                     dim = None\n \n         # further conversion for both ASCII and binary tables\n@@ -930,18 +956,18 @@ class FITS_rec(np.recarray):\n             # format is something like P or Q\n             format_code = column.format.format\n \n-        if (_number and (_scale or _zero) and not column._physical_values):\n+        if _number and (_scale or _zero) and not column._physical_values:\n             # This is to handle pseudo unsigned ints in table columns\n             # TODO: For now this only really works correctly for binary tables\n             # Should it work for ASCII tables as well?\n             if self._uint:\n-                if bzero == 2**15 and format_code == 'I':\n+                if bzero == 2**15 and format_code == \"I\":\n                     field = np.array(field, dtype=np.uint16)\n-                elif bzero == 2**31 and format_code == 'J':\n+                elif bzero == 2**31 and format_code == \"J\":\n                     field = np.array(field, dtype=np.uint32)\n-                elif bzero == 2**63 and format_code == 'K':\n+                elif bzero == 2**63 and format_code == \"K\":\n                     field = np.array(field, dtype=np.uint64)\n-                    bzero64 = np.uint64(2 ** 63)\n+                    bzero64 = np.uint64(2**63)\n                 else:\n                     field = np.array(field, dtype=np.float64)\n             else:\n@@ -950,7 +976,7 @@ class FITS_rec(np.recarray):\n             if _scale:\n                 np.multiply(field, bscale, field)\n             if _zero:\n-                if self._uint and format_code == 'K':\n+                if self._uint and format_code == \"K\":\n                     # There is a chance of overflow, so be careful\n                     test_overflow = field.copy()\n                     try:\n@@ -958,13 +984,14 @@ class FITS_rec(np.recarray):\n                     except OverflowError:\n                         warnings.warn(\n                             \"Overflow detected while applying TZERO{0:d}. \"\n-                            \"Returning unscaled data.\".format(indx + 1))\n+                            \"Returning unscaled data.\".format(indx + 1)\n+                        )\n                     else:\n                         field = test_overflow\n                 else:\n                     field += bzero\n         elif _bool and field.dtype != bool:\n-            field = np.equal(field, ord('T'))\n+            field = np.equal(field, ord(\"T\"))\n         elif _str:\n             if not self._character_as_bytes:\n                 with suppress(UnicodeDecodeError):\n@@ -977,7 +1004,7 @@ class FITS_rec(np.recarray):\n                 field = field[:, :nitems]\n             if _str:\n                 fmt = field.dtype.char\n-                dtype = ('|{}{}'.format(fmt, dim[-1]), dim[:-1])\n+                dtype = (\"|{}{}\".format(fmt, dim[-1]), dim[:-1])\n                 field.dtype = dtype\n             else:\n                 field.shape = (field.shape[0],) + dim\n@@ -994,7 +1021,7 @@ class FITS_rec(np.recarray):\n         if self._heapsize:\n             raw_data = self._get_raw_data().view(np.ubyte)\n             heap_end = self._heapoffset + self._heapsize\n-            return raw_data[self._heapoffset:heap_end]\n+            return raw_data[self._heapoffset : heap_end]\n         else:\n             return np.array([], dtype=np.ubyte)\n \n@@ -1017,9 +1044,9 @@ class FITS_rec(np.recarray):\n \n         raw_data_bytes = self.nbytes + self._heapsize\n         base = self\n-        while hasattr(base, 'base') and base.base is not None:\n+        while hasattr(base, \"base\") and base.base is not None:\n             base = base.base\n-            if hasattr(base, 'nbytes') and base.nbytes >= raw_data_bytes:\n+            if hasattr(base, \"nbytes\") and base.nbytes >= raw_data_bytes:\n                 return base\n \n     def _get_scale_factors(self, column):\n@@ -1027,15 +1054,15 @@ class FITS_rec(np.recarray):\n \n         # TODO: Maybe this should be a method/property on Column?  Or maybe\n         # it's not really needed at all...\n-        _str = column.format.format == 'A'\n-        _bool = column.format.format == 'L'\n+        _str = column.format.format == \"A\"\n+        _bool = column.format.format == \"L\"\n \n         _number = not (_bool or _str)\n         bscale = column.bscale\n         bzero = column.bzero\n \n-        _scale = bscale not in ('', None, 1)\n-        _zero = bzero not in ('', None, 0)\n+        _scale = bscale not in (\"\", None, 1)\n+        _zero = bzero not in (\"\", None, 0)\n \n         # ensure bscale/bzero are numbers\n         if not _scale:\n@@ -1084,9 +1111,10 @@ class FITS_rec(np.recarray):\n                     raw_field[:] = 0  # reset\n                     npts = [len(arr) for arr in self._converted[name]]\n \n-                    raw_field[:len(npts), 0] = npts\n-                    raw_field[1:, 1] = (np.add.accumulate(raw_field[:-1, 0]) *\n-                                        dtype.itemsize)\n+                    raw_field[: len(npts), 0] = npts\n+                    raw_field[1:, 1] = (\n+                        np.add.accumulate(raw_field[:-1, 0]) * dtype.itemsize\n+                    )\n                     raw_field[:, 1][:] += heapsize\n \n                 heapsize += raw_field[:, 0].sum() * dtype.itemsize\n@@ -1098,8 +1126,9 @@ class FITS_rec(np.recarray):\n                 _wrapx(self._converted[name], raw_field, recformat.repeat)\n                 continue\n \n-            _str, _bool, _number, _scale, _zero, bscale, bzero, _ = \\\n+            _str, _bool, _number, _scale, _zero, bscale, bzero, _ = (\n                 self._get_scale_factors(column)\n+            )\n \n             field = self._converted.get(name, raw_field)\n \n@@ -1128,8 +1157,7 @@ class FITS_rec(np.recarray):\n                     self._scale_back_strings(indx, dummy, raw_field)\n                 # all other binary table columns\n                 else:\n-                    if len(raw_field) and isinstance(raw_field[0],\n-                                                     np.integer):\n+                    if len(raw_field) and isinstance(raw_field[0], np.integer):\n                         dummy = np.around(dummy)\n \n                     if raw_field.shape == dummy.shape:\n@@ -1144,8 +1172,10 @@ class FITS_rec(np.recarray):\n \n             # ASCII table does not have Boolean type\n             elif _bool and name in self._converted:\n-                choices = (np.array([ord('F')], dtype=np.int8)[0],\n-                           np.array([ord('T')], dtype=np.int8)[0])\n+                choices = (\n+                    np.array([ord(\"F\")], dtype=np.int8)[0],\n+                    np.array([ord(\"T\")], dtype=np.int8)[0],\n+                )\n                 raw_field[:] = np.choose(field, choices)\n \n         # Store the updated heapsize\n@@ -1170,7 +1200,7 @@ class FITS_rec(np.recarray):\n \n         # If the output_field is non-ASCII we will worry about ASCII encoding\n         # later when writing; otherwise we can do it right here\n-        if input_field.dtype.kind == 'U' and output_field.dtype.kind == 'S':\n+        if input_field.dtype.kind == \"U\" and output_field.dtype.kind == \"S\":\n             try:\n                 _ascii_encode(input_field, out=output_field)\n             except _UnicodeArrayEncodeError as exc:\n@@ -1181,7 +1211,9 @@ class FITS_rec(np.recarray):\n                     \"the string at that location.\".format(\n                         self._coldefs[col_idx].name,\n                         exc.index[0] if len(exc.index) == 1 else exc.index,\n-                        exc.start))\n+                        exc.start,\n+                    )\n+                )\n         else:\n             # Otherwise go ahead and do a direct copy into--if both are type\n             # 'U' we'll handle encoding later\n@@ -1217,31 +1249,33 @@ class FITS_rec(np.recarray):\n             lead = 0\n \n         if lead < 0:\n-            warnings.warn('Column {!r} starting point overlaps the previous '\n-                          'column.'.format(col_idx + 1))\n+            warnings.warn(\n+                \"Column {!r} starting point overlaps the previous column.\".format(\n+                    col_idx + 1\n+                )\n+            )\n \n         trail = starts[col_idx + 1] - starts[col_idx] - spans[col_idx]\n \n         if trail < 0:\n-            warnings.warn('Column {!r} ending point overlaps the next '\n-                          'column.'.format(col_idx + 1))\n+            warnings.warn(\n+                \"Column {!r} ending point overlaps the next column.\".format(col_idx + 1)\n+            )\n \n         # TODO: It would be nice if these string column formatting\n         # details were left to a specialized class, as is the case\n         # with FormatX and FormatP\n-        if 'A' in format:\n-            _pc = '{:'\n+        if \"A\" in format:\n+            _pc = \"{:\"\n         else:\n-            _pc = '{:>'\n+            _pc = \"{:>\"\n \n-        fmt = ''.join([_pc, format[1:], ASCII2STR[format[0]], '}',\n-                       (' ' * trail)])\n+        fmt = \"\".join([_pc, format[1:], ASCII2STR[format[0]], \"}\", (\" \" * trail)])\n \n         # Even if the format precision is 0, we should output a decimal point\n         # as long as there is space to do so--not including a decimal point in\n         # a float value is discouraged by the FITS Standard\n-        trailing_decimal = (format.precision == 0 and\n-                            format.format in ('F', 'E', 'D'))\n+        trailing_decimal = format.precision == 0 and format.format in (\"F\", \"E\", \"D\")\n \n         # not using numarray.strings's num2char because the\n         # result is not allowed to expand (as C/Python does).\n@@ -1249,19 +1283,21 @@ class FITS_rec(np.recarray):\n             value = fmt.format(value)\n             if len(value) > starts[col_idx + 1] - starts[col_idx]:\n                 raise ValueError(\n-                    \"Value {!r} does not fit into the output's itemsize of \"\n-                    \"{}.\".format(value, spans[col_idx]))\n+                    \"Value {!r} does not fit into the output's itemsize of {}.\".format(\n+                        value, spans[col_idx]\n+                    )\n+                )\n \n-            if trailing_decimal and value[0] == ' ':\n+            if trailing_decimal and value[0] == \" \":\n                 # We have some extra space in the field for the trailing\n                 # decimal point\n-                value = value[1:] + '.'\n+                value = value[1:] + \".\"\n \n             output_field[jdx] = value\n \n         # Replace exponent separator in floating point numbers\n-        if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+        if \"D\" in format:\n+            output_field = output_field.replace(encode_ascii(\"E\"), encode_ascii(\"D\"))\n \n \n def _get_recarray_field(array, key):\n@@ -1275,8 +1311,7 @@ def _get_recarray_field(array, key):\n     # This is currently needed for backwards-compatibility and for\n     # automatic truncation of trailing whitespace\n     field = np.recarray.field(array, key)\n-    if (field.dtype.char in ('S', 'U') and\n-            not isinstance(field, chararray.chararray)):\n+    if field.dtype.char in (\"S\", \"U\") and not isinstance(field, chararray.chararray):\n         field = field.view(chararray.chararray)\n     return field\n \n@@ -1302,19 +1337,21 @@ def _ascii_encode(inarray, out=None):\n     the item that couldn't be encoded.\n     \"\"\"\n \n-    out_dtype = np.dtype(('S{0}'.format(inarray.dtype.itemsize // 4),\n-                         inarray.dtype.shape))\n+    out_dtype = np.dtype(\n+        (\"S{0}\".format(inarray.dtype.itemsize // 4), inarray.dtype.shape)\n+    )\n     if out is not None:\n         out = out.view(out_dtype)\n \n     op_dtypes = [inarray.dtype, out_dtype]\n-    op_flags = [['readonly'], ['writeonly', 'allocate']]\n-    it = np.nditer([inarray, out], op_dtypes=op_dtypes,\n-                   op_flags=op_flags, flags=['zerosize_ok'])\n+    op_flags = [[\"readonly\"], [\"writeonly\", \"allocate\"]]\n+    it = np.nditer(\n+        [inarray, out], op_dtypes=op_dtypes, op_flags=op_flags, flags=[\"zerosize_ok\"]\n+    )\n \n     try:\n         for initem, outitem in it:\n-            outitem[...] = initem.item().encode('ascii')\n+            outitem[...] = initem.item().encode(\"ascii\")\n     except UnicodeEncodeError as exc:\n         index = np.unravel_index(it.iterindex, inarray.shape)\n         raise _UnicodeArrayEncodeError(*(exc.args + (index,)))\n@@ -1328,4 +1365,4 @@ def _has_unicode_fields(array):\n     \"\"\"\n \n     dtypes = (d[0] for d in array.dtype.fields.values())\n-    return any(d.kind == 'U' for d in dtypes)\n+    return any(d.kind == \"U\" for d in dtypes)\n"}
{"instance_id": "astropy__astropy-7746", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\nindex d3a06f2b31..7d88dcf03b 100644\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -1218,6 +1218,9 @@ reduce these to 2 dimensions using the naxis kwarg.\n                 raise ValueError(\n                     \"Coordinate arrays are not broadcastable to each other\")\n \n+            if axes[0].size == 0:\n+                return [np.empty_like(ax) for ax in axes]\n+\n             xy = np.hstack([x.reshape((x.size, 1)) for x in axes])\n \n             if ra_dec_order and sky == 'input':\n@@ -1235,6 +1238,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n                     \"of shape (N, {0})\".format(self.naxis))\n+            if xy.size == 0:\n+                return np.empty_like(xy)\n             if ra_dec_order and sky == 'input':\n                 xy = self._denormalize_sky(xy)\n             result = func(xy, origin)\n"}
{"instance_id": "django__django-10914", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex acee9887d2..110282c792 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -38,107 +38,107 @@ ALLOWED_HOSTS = []\n # https://en.wikipedia.org/wiki/List_of_tz_zones_by_name (although not all\n # systems may support all possibilities). When USE_TZ is True, this is\n # interpreted as the default user time zone.\n-TIME_ZONE = 'America/Chicago'\n+TIME_ZONE = \"America/Chicago\"\n \n # If you set this to True, Django will use timezone-aware datetimes.\n USE_TZ = False\n \n # Language code for this installation. All choices can be found here:\n # http://www.i18nguy.com/unicode/language-identifiers.html\n-LANGUAGE_CODE = 'en-us'\n+LANGUAGE_CODE = \"en-us\"\n \n # Languages we provide translations for, out of the box.\n LANGUAGES = [\n-    ('af', gettext_noop('Afrikaans')),\n-    ('ar', gettext_noop('Arabic')),\n-    ('ast', gettext_noop('Asturian')),\n-    ('az', gettext_noop('Azerbaijani')),\n-    ('bg', gettext_noop('Bulgarian')),\n-    ('be', gettext_noop('Belarusian')),\n-    ('bn', gettext_noop('Bengali')),\n-    ('br', gettext_noop('Breton')),\n-    ('bs', gettext_noop('Bosnian')),\n-    ('ca', gettext_noop('Catalan')),\n-    ('cs', gettext_noop('Czech')),\n-    ('cy', gettext_noop('Welsh')),\n-    ('da', gettext_noop('Danish')),\n-    ('de', gettext_noop('German')),\n-    ('dsb', gettext_noop('Lower Sorbian')),\n-    ('el', gettext_noop('Greek')),\n-    ('en', gettext_noop('English')),\n-    ('en-au', gettext_noop('Australian English')),\n-    ('en-gb', gettext_noop('British English')),\n-    ('eo', gettext_noop('Esperanto')),\n-    ('es', gettext_noop('Spanish')),\n-    ('es-ar', gettext_noop('Argentinian Spanish')),\n-    ('es-co', gettext_noop('Colombian Spanish')),\n-    ('es-mx', gettext_noop('Mexican Spanish')),\n-    ('es-ni', gettext_noop('Nicaraguan Spanish')),\n-    ('es-ve', gettext_noop('Venezuelan Spanish')),\n-    ('et', gettext_noop('Estonian')),\n-    ('eu', gettext_noop('Basque')),\n-    ('fa', gettext_noop('Persian')),\n-    ('fi', gettext_noop('Finnish')),\n-    ('fr', gettext_noop('French')),\n-    ('fy', gettext_noop('Frisian')),\n-    ('ga', gettext_noop('Irish')),\n-    ('gd', gettext_noop('Scottish Gaelic')),\n-    ('gl', gettext_noop('Galician')),\n-    ('he', gettext_noop('Hebrew')),\n-    ('hi', gettext_noop('Hindi')),\n-    ('hr', gettext_noop('Croatian')),\n-    ('hsb', gettext_noop('Upper Sorbian')),\n-    ('hu', gettext_noop('Hungarian')),\n-    ('hy', gettext_noop('Armenian')),\n-    ('ia', gettext_noop('Interlingua')),\n-    ('id', gettext_noop('Indonesian')),\n-    ('io', gettext_noop('Ido')),\n-    ('is', gettext_noop('Icelandic')),\n-    ('it', gettext_noop('Italian')),\n-    ('ja', gettext_noop('Japanese')),\n-    ('ka', gettext_noop('Georgian')),\n-    ('kab', gettext_noop('Kabyle')),\n-    ('kk', gettext_noop('Kazakh')),\n-    ('km', gettext_noop('Khmer')),\n-    ('kn', gettext_noop('Kannada')),\n-    ('ko', gettext_noop('Korean')),\n-    ('lb', gettext_noop('Luxembourgish')),\n-    ('lt', gettext_noop('Lithuanian')),\n-    ('lv', gettext_noop('Latvian')),\n-    ('mk', gettext_noop('Macedonian')),\n-    ('ml', gettext_noop('Malayalam')),\n-    ('mn', gettext_noop('Mongolian')),\n-    ('mr', gettext_noop('Marathi')),\n-    ('my', gettext_noop('Burmese')),\n-    ('nb', gettext_noop('Norwegian Bokm\u00e5l')),\n-    ('ne', gettext_noop('Nepali')),\n-    ('nl', gettext_noop('Dutch')),\n-    ('nn', gettext_noop('Norwegian Nynorsk')),\n-    ('os', gettext_noop('Ossetic')),\n-    ('pa', gettext_noop('Punjabi')),\n-    ('pl', gettext_noop('Polish')),\n-    ('pt', gettext_noop('Portuguese')),\n-    ('pt-br', gettext_noop('Brazilian Portuguese')),\n-    ('ro', gettext_noop('Romanian')),\n-    ('ru', gettext_noop('Russian')),\n-    ('sk', gettext_noop('Slovak')),\n-    ('sl', gettext_noop('Slovenian')),\n-    ('sq', gettext_noop('Albanian')),\n-    ('sr', gettext_noop('Serbian')),\n-    ('sr-latn', gettext_noop('Serbian Latin')),\n-    ('sv', gettext_noop('Swedish')),\n-    ('sw', gettext_noop('Swahili')),\n-    ('ta', gettext_noop('Tamil')),\n-    ('te', gettext_noop('Telugu')),\n-    ('th', gettext_noop('Thai')),\n-    ('tr', gettext_noop('Turkish')),\n-    ('tt', gettext_noop('Tatar')),\n-    ('udm', gettext_noop('Udmurt')),\n-    ('uk', gettext_noop('Ukrainian')),\n-    ('ur', gettext_noop('Urdu')),\n-    ('vi', gettext_noop('Vietnamese')),\n-    ('zh-hans', gettext_noop('Simplified Chinese')),\n-    ('zh-hant', gettext_noop('Traditional Chinese')),\n+    (\"af\", gettext_noop(\"Afrikaans\")),\n+    (\"ar\", gettext_noop(\"Arabic\")),\n+    (\"ast\", gettext_noop(\"Asturian\")),\n+    (\"az\", gettext_noop(\"Azerbaijani\")),\n+    (\"bg\", gettext_noop(\"Bulgarian\")),\n+    (\"be\", gettext_noop(\"Belarusian\")),\n+    (\"bn\", gettext_noop(\"Bengali\")),\n+    (\"br\", gettext_noop(\"Breton\")),\n+    (\"bs\", gettext_noop(\"Bosnian\")),\n+    (\"ca\", gettext_noop(\"Catalan\")),\n+    (\"cs\", gettext_noop(\"Czech\")),\n+    (\"cy\", gettext_noop(\"Welsh\")),\n+    (\"da\", gettext_noop(\"Danish\")),\n+    (\"de\", gettext_noop(\"German\")),\n+    (\"dsb\", gettext_noop(\"Lower Sorbian\")),\n+    (\"el\", gettext_noop(\"Greek\")),\n+    (\"en\", gettext_noop(\"English\")),\n+    (\"en-au\", gettext_noop(\"Australian English\")),\n+    (\"en-gb\", gettext_noop(\"British English\")),\n+    (\"eo\", gettext_noop(\"Esperanto\")),\n+    (\"es\", gettext_noop(\"Spanish\")),\n+    (\"es-ar\", gettext_noop(\"Argentinian Spanish\")),\n+    (\"es-co\", gettext_noop(\"Colombian Spanish\")),\n+    (\"es-mx\", gettext_noop(\"Mexican Spanish\")),\n+    (\"es-ni\", gettext_noop(\"Nicaraguan Spanish\")),\n+    (\"es-ve\", gettext_noop(\"Venezuelan Spanish\")),\n+    (\"et\", gettext_noop(\"Estonian\")),\n+    (\"eu\", gettext_noop(\"Basque\")),\n+    (\"fa\", gettext_noop(\"Persian\")),\n+    (\"fi\", gettext_noop(\"Finnish\")),\n+    (\"fr\", gettext_noop(\"French\")),\n+    (\"fy\", gettext_noop(\"Frisian\")),\n+    (\"ga\", gettext_noop(\"Irish\")),\n+    (\"gd\", gettext_noop(\"Scottish Gaelic\")),\n+    (\"gl\", gettext_noop(\"Galician\")),\n+    (\"he\", gettext_noop(\"Hebrew\")),\n+    (\"hi\", gettext_noop(\"Hindi\")),\n+    (\"hr\", gettext_noop(\"Croatian\")),\n+    (\"hsb\", gettext_noop(\"Upper Sorbian\")),\n+    (\"hu\", gettext_noop(\"Hungarian\")),\n+    (\"hy\", gettext_noop(\"Armenian\")),\n+    (\"ia\", gettext_noop(\"Interlingua\")),\n+    (\"id\", gettext_noop(\"Indonesian\")),\n+    (\"io\", gettext_noop(\"Ido\")),\n+    (\"is\", gettext_noop(\"Icelandic\")),\n+    (\"it\", gettext_noop(\"Italian\")),\n+    (\"ja\", gettext_noop(\"Japanese\")),\n+    (\"ka\", gettext_noop(\"Georgian\")),\n+    (\"kab\", gettext_noop(\"Kabyle\")),\n+    (\"kk\", gettext_noop(\"Kazakh\")),\n+    (\"km\", gettext_noop(\"Khmer\")),\n+    (\"kn\", gettext_noop(\"Kannada\")),\n+    (\"ko\", gettext_noop(\"Korean\")),\n+    (\"lb\", gettext_noop(\"Luxembourgish\")),\n+    (\"lt\", gettext_noop(\"Lithuanian\")),\n+    (\"lv\", gettext_noop(\"Latvian\")),\n+    (\"mk\", gettext_noop(\"Macedonian\")),\n+    (\"ml\", gettext_noop(\"Malayalam\")),\n+    (\"mn\", gettext_noop(\"Mongolian\")),\n+    (\"mr\", gettext_noop(\"Marathi\")),\n+    (\"my\", gettext_noop(\"Burmese\")),\n+    (\"nb\", gettext_noop(\"Norwegian Bokm\u00e5l\")),\n+    (\"ne\", gettext_noop(\"Nepali\")),\n+    (\"nl\", gettext_noop(\"Dutch\")),\n+    (\"nn\", gettext_noop(\"Norwegian Nynorsk\")),\n+    (\"os\", gettext_noop(\"Ossetic\")),\n+    (\"pa\", gettext_noop(\"Punjabi\")),\n+    (\"pl\", gettext_noop(\"Polish\")),\n+    (\"pt\", gettext_noop(\"Portuguese\")),\n+    (\"pt-br\", gettext_noop(\"Brazilian Portuguese\")),\n+    (\"ro\", gettext_noop(\"Romanian\")),\n+    (\"ru\", gettext_noop(\"Russian\")),\n+    (\"sk\", gettext_noop(\"Slovak\")),\n+    (\"sl\", gettext_noop(\"Slovenian\")),\n+    (\"sq\", gettext_noop(\"Albanian\")),\n+    (\"sr\", gettext_noop(\"Serbian\")),\n+    (\"sr-latn\", gettext_noop(\"Serbian Latin\")),\n+    (\"sv\", gettext_noop(\"Swedish\")),\n+    (\"sw\", gettext_noop(\"Swahili\")),\n+    (\"ta\", gettext_noop(\"Tamil\")),\n+    (\"te\", gettext_noop(\"Telugu\")),\n+    (\"th\", gettext_noop(\"Thai\")),\n+    (\"tr\", gettext_noop(\"Turkish\")),\n+    (\"tt\", gettext_noop(\"Tatar\")),\n+    (\"udm\", gettext_noop(\"Udmurt\")),\n+    (\"uk\", gettext_noop(\"Ukrainian\")),\n+    (\"ur\", gettext_noop(\"Urdu\")),\n+    (\"vi\", gettext_noop(\"Vietnamese\")),\n+    (\"zh-hans\", gettext_noop(\"Simplified Chinese\")),\n+    (\"zh-hant\", gettext_noop(\"Traditional Chinese\")),\n ]\n \n # Languages using BiDi (right-to-left) layout\n@@ -150,10 +150,10 @@ USE_I18N = True\n LOCALE_PATHS = []\n \n # Settings for language cookie\n-LANGUAGE_COOKIE_NAME = 'django_language'\n+LANGUAGE_COOKIE_NAME = \"django_language\"\n LANGUAGE_COOKIE_AGE = None\n LANGUAGE_COOKIE_DOMAIN = None\n-LANGUAGE_COOKIE_PATH = '/'\n+LANGUAGE_COOKIE_PATH = \"/\"\n \n \n # If you set this to True, Django will format dates, numbers and calendars\n@@ -166,13 +166,13 @@ MANAGERS = ADMINS\n \n # Default charset to use for all HttpResponse objects, if a MIME type isn't\n # manually specified. It's used to construct the Content-Type header.\n-DEFAULT_CHARSET = 'utf-8'\n+DEFAULT_CHARSET = \"utf-8\"\n \n # Encoding of files read from disk (template and initial SQL files).\n-FILE_CHARSET = 'utf-8'\n+FILE_CHARSET = \"utf-8\"\n \n # Email address that error messages come from.\n-SERVER_EMAIL = 'root@localhost'\n+SERVER_EMAIL = \"root@localhost\"\n \n # Database connection info. If left empty, will default to the dummy backend.\n DATABASES = {}\n@@ -184,10 +184,10 @@ DATABASE_ROUTERS = []\n # The default is to use the SMTP backend.\n # Third-party backends can be specified by providing a Python path\n # to a module that defines an EmailBackend class.\n-EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\n+EMAIL_BACKEND = \"django.core.mail.backends.smtp.EmailBackend\"\n \n # Host for sending email.\n-EMAIL_HOST = 'localhost'\n+EMAIL_HOST = \"localhost\"\n \n # Port for sending email.\n EMAIL_PORT = 25\n@@ -196,8 +196,8 @@ EMAIL_PORT = 25\n EMAIL_USE_LOCALTIME = False\n \n # Optional SMTP authentication information for EMAIL_HOST.\n-EMAIL_HOST_USER = ''\n-EMAIL_HOST_PASSWORD = ''\n+EMAIL_HOST_USER = \"\"\n+EMAIL_HOST_PASSWORD = \"\"\n EMAIL_USE_TLS = False\n EMAIL_USE_SSL = False\n EMAIL_SSL_CERTFILE = None\n@@ -210,15 +210,15 @@ INSTALLED_APPS = []\n TEMPLATES = []\n \n # Default form rendering class.\n-FORM_RENDERER = 'django.forms.renderers.DjangoTemplates'\n+FORM_RENDERER = \"django.forms.renderers.DjangoTemplates\"\n \n # Default email address to use for various automated correspondence from\n # the site managers.\n-DEFAULT_FROM_EMAIL = 'webmaster@localhost'\n+DEFAULT_FROM_EMAIL = \"webmaster@localhost\"\n \n # Subject-line prefix for email messages send with django.core.mail.mail_admins\n # or ...mail_managers.  Make sure to include the trailing space.\n-EMAIL_SUBJECT_PREFIX = '[Django] '\n+EMAIL_SUBJECT_PREFIX = \"[Django] \"\n \n # Whether to append trailing slashes to URLs.\n APPEND_SLASH = True\n@@ -258,18 +258,18 @@ IGNORABLE_404_URLS = []\n # A secret key for this particular Django installation. Used in secret-key\n # hashing algorithms. Set this in your settings, or Django will complain\n # loudly.\n-SECRET_KEY = ''\n+SECRET_KEY = \"\"\n \n # Default file storage mechanism that holds media.\n-DEFAULT_FILE_STORAGE = 'django.core.files.storage.FileSystemStorage'\n+DEFAULT_FILE_STORAGE = \"django.core.files.storage.FileSystemStorage\"\n \n # Absolute filesystem path to the directory that will hold user-uploaded files.\n # Example: \"/var/www/example.com/media/\"\n-MEDIA_ROOT = ''\n+MEDIA_ROOT = \"\"\n \n # URL that handles the media served from MEDIA_ROOT.\n # Examples: \"http://example.com/media/\", \"http://media.example.com/\"\n-MEDIA_URL = ''\n+MEDIA_URL = \"\"\n \n # Absolute path to the directory static files should be collected to.\n # Example: \"/var/www/example.com/static/\"\n@@ -281,8 +281,8 @@ STATIC_URL = None\n \n # List of upload handler classes to be applied in order.\n FILE_UPLOAD_HANDLERS = [\n-    'django.core.files.uploadhandler.MemoryFileUploadHandler',\n-    'django.core.files.uploadhandler.TemporaryFileUploadHandler',\n+    \"django.core.files.uploadhandler.MemoryFileUploadHandler\",\n+    \"django.core.files.uploadhandler.TemporaryFileUploadHandler\",\n ]\n \n # Maximum size, in bytes, of a request before it will be streamed to the\n@@ -304,7 +304,7 @@ FILE_UPLOAD_TEMP_DIR = None\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n@@ -319,45 +319,51 @@ FORMAT_MODULE_PATH = None\n \n # Default formatting for date objects. See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-DATE_FORMAT = 'N j, Y'\n+DATE_FORMAT = \"N j, Y\"\n \n # Default formatting for datetime objects. See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-DATETIME_FORMAT = 'N j, Y, P'\n+DATETIME_FORMAT = \"N j, Y, P\"\n \n # Default formatting for time objects. See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-TIME_FORMAT = 'P'\n+TIME_FORMAT = \"P\"\n \n # Default formatting for date objects when only the year and month are relevant.\n # See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-YEAR_MONTH_FORMAT = 'F Y'\n+YEAR_MONTH_FORMAT = \"F Y\"\n \n # Default formatting for date objects when only the month and day are relevant.\n # See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-MONTH_DAY_FORMAT = 'F j'\n+MONTH_DAY_FORMAT = \"F j\"\n \n # Default short formatting for date objects. See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-SHORT_DATE_FORMAT = 'm/d/Y'\n+SHORT_DATE_FORMAT = \"m/d/Y\"\n \n # Default short formatting for datetime objects.\n # See all available format strings here:\n # https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\n-SHORT_DATETIME_FORMAT = 'm/d/Y P'\n+SHORT_DATETIME_FORMAT = \"m/d/Y P\"\n \n # Default formats to be used when parsing dates from input boxes, in order\n # See all available format string here:\n # https://docs.python.org/library/datetime.html#strftime-behavior\n # * Note that these format strings are different from the ones to display dates\n DATE_INPUT_FORMATS = [\n-    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',  # '2006-10-25', '10/25/2006', '10/25/06'\n-    '%b %d %Y', '%b %d, %Y',             # 'Oct 25 2006', 'Oct 25, 2006'\n-    '%d %b %Y', '%d %b, %Y',             # '25 Oct 2006', '25 Oct, 2006'\n-    '%B %d %Y', '%B %d, %Y',             # 'October 25 2006', 'October 25, 2006'\n-    '%d %B %Y', '%d %B, %Y',             # '25 October 2006', '25 October, 2006'\n+    \"%Y-%m-%d\",\n+    \"%m/%d/%Y\",\n+    \"%m/%d/%y\",  # '2006-10-25', '10/25/2006', '10/25/06'\n+    \"%b %d %Y\",\n+    \"%b %d, %Y\",  # 'Oct 25 2006', 'Oct 25, 2006'\n+    \"%d %b %Y\",\n+    \"%d %b, %Y\",  # '25 Oct 2006', '25 Oct, 2006'\n+    \"%B %d %Y\",\n+    \"%B %d, %Y\",  # 'October 25 2006', 'October 25, 2006'\n+    \"%d %B %Y\",\n+    \"%d %B, %Y\",  # '25 October 2006', '25 October, 2006'\n ]\n \n # Default formats to be used when parsing times from input boxes, in order\n@@ -365,9 +371,9 @@ DATE_INPUT_FORMATS = [\n # https://docs.python.org/library/datetime.html#strftime-behavior\n # * Note that these format strings are different from the ones to display dates\n TIME_INPUT_FORMATS = [\n-    '%H:%M:%S',     # '14:30:59'\n-    '%H:%M:%S.%f',  # '14:30:59.000200'\n-    '%H:%M',        # '14:30'\n+    \"%H:%M:%S\",  # '14:30:59'\n+    \"%H:%M:%S.%f\",  # '14:30:59.000200'\n+    \"%H:%M\",  # '14:30'\n ]\n \n # Default formats to be used when parsing dates and times from input boxes,\n@@ -376,18 +382,18 @@ TIME_INPUT_FORMATS = [\n # https://docs.python.org/library/datetime.html#strftime-behavior\n # * Note that these format strings are different from the ones to display dates\n DATETIME_INPUT_FORMATS = [\n-    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'\n-    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'\n-    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'\n-    '%Y-%m-%d',              # '2006-10-25'\n-    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'\n-    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'\n-    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'\n-    '%m/%d/%Y',              # '10/25/2006'\n-    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'\n-    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'\n-    '%m/%d/%y %H:%M',        # '10/25/06 14:30'\n-    '%m/%d/%y',              # '10/25/06'\n+    \"%Y-%m-%d %H:%M:%S\",  # '2006-10-25 14:30:59'\n+    \"%Y-%m-%d %H:%M:%S.%f\",  # '2006-10-25 14:30:59.000200'\n+    \"%Y-%m-%d %H:%M\",  # '2006-10-25 14:30'\n+    \"%Y-%m-%d\",  # '2006-10-25'\n+    \"%m/%d/%Y %H:%M:%S\",  # '10/25/2006 14:30:59'\n+    \"%m/%d/%Y %H:%M:%S.%f\",  # '10/25/2006 14:30:59.000200'\n+    \"%m/%d/%Y %H:%M\",  # '10/25/2006 14:30'\n+    \"%m/%d/%Y\",  # '10/25/2006'\n+    \"%m/%d/%y %H:%M:%S\",  # '10/25/06 14:30:59'\n+    \"%m/%d/%y %H:%M:%S.%f\",  # '10/25/06 14:30:59.000200'\n+    \"%m/%d/%y %H:%M\",  # '10/25/06 14:30'\n+    \"%m/%d/%y\",  # '10/25/06'\n ]\n \n # First day of week, to be used on calendars\n@@ -395,7 +401,7 @@ DATETIME_INPUT_FORMATS = [\n FIRST_DAY_OF_WEEK = 0\n \n # Decimal separator symbol\n-DECIMAL_SEPARATOR = '.'\n+DECIMAL_SEPARATOR = \".\"\n \n # Boolean that sets whether to add thousand separator when formatting numbers\n USE_THOUSAND_SEPARATOR = False\n@@ -405,14 +411,14 @@ USE_THOUSAND_SEPARATOR = False\n NUMBER_GROUPING = 0\n \n # Thousand separator symbol\n-THOUSAND_SEPARATOR = ','\n+THOUSAND_SEPARATOR = \",\"\n \n # The tablespaces to use for each model when not specified otherwise.\n-DEFAULT_TABLESPACE = ''\n-DEFAULT_INDEX_TABLESPACE = ''\n+DEFAULT_TABLESPACE = \"\"\n+DEFAULT_INDEX_TABLESPACE = \"\"\n \n # Default X-Frame-Options header value\n-X_FRAME_OPTIONS = 'SAMEORIGIN'\n+X_FRAME_OPTIONS = \"SAMEORIGIN\"\n \n USE_X_FORWARDED_HOST = False\n USE_X_FORWARDED_PORT = False\n@@ -447,9 +453,9 @@ MIDDLEWARE = []\n ############\n \n # Cache to store session data if using the cache session backend.\n-SESSION_CACHE_ALIAS = 'default'\n+SESSION_CACHE_ALIAS = \"default\"\n # Cookie name. This can be whatever you want.\n-SESSION_COOKIE_NAME = 'sessionid'\n+SESSION_COOKIE_NAME = \"sessionid\"\n # Age of cookie, in seconds (default: 2 weeks).\n SESSION_COOKIE_AGE = 60 * 60 * 24 * 7 * 2\n # A string like \"example.com\", or None for standard domain cookie.\n@@ -457,23 +463,23 @@ SESSION_COOKIE_DOMAIN = None\n # Whether the session cookie should be secure (https:// only).\n SESSION_COOKIE_SECURE = False\n # The path of the session cookie.\n-SESSION_COOKIE_PATH = '/'\n+SESSION_COOKIE_PATH = \"/\"\n # Whether to use the non-RFC standard httpOnly flag (IE, FF3+, others)\n SESSION_COOKIE_HTTPONLY = True\n # Whether to set the flag restricting cookie leaks on cross-site requests.\n # This can be 'Lax', 'Strict', or None to disable the flag.\n-SESSION_COOKIE_SAMESITE = 'Lax'\n+SESSION_COOKIE_SAMESITE = \"Lax\"\n # Whether to save the session data on every request.\n SESSION_SAVE_EVERY_REQUEST = False\n # Whether a user's session cookie expires when the Web browser is closed.\n SESSION_EXPIRE_AT_BROWSER_CLOSE = False\n # The module to store session data\n-SESSION_ENGINE = 'django.contrib.sessions.backends.db'\n+SESSION_ENGINE = \"django.contrib.sessions.backends.db\"\n # Directory to store session files if using the file session module. If None,\n # the backend will use a sensible default.\n SESSION_FILE_PATH = None\n # class to serialize session data\n-SESSION_SERIALIZER = 'django.contrib.sessions.serializers.JSONSerializer'\n+SESSION_SERIALIZER = \"django.contrib.sessions.serializers.JSONSerializer\"\n \n #########\n # CACHE #\n@@ -481,25 +487,25 @@ SESSION_SERIALIZER = 'django.contrib.sessions.serializers.JSONSerializer'\n \n # The cache backends to use.\n CACHES = {\n-    'default': {\n-        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',\n+    \"default\": {\n+        \"BACKEND\": \"django.core.cache.backends.locmem.LocMemCache\",\n     }\n }\n-CACHE_MIDDLEWARE_KEY_PREFIX = ''\n+CACHE_MIDDLEWARE_KEY_PREFIX = \"\"\n CACHE_MIDDLEWARE_SECONDS = 600\n-CACHE_MIDDLEWARE_ALIAS = 'default'\n+CACHE_MIDDLEWARE_ALIAS = \"default\"\n \n ##################\n # AUTHENTICATION #\n ##################\n \n-AUTH_USER_MODEL = 'auth.User'\n+AUTH_USER_MODEL = \"auth.User\"\n \n-AUTHENTICATION_BACKENDS = ['django.contrib.auth.backends.ModelBackend']\n+AUTHENTICATION_BACKENDS = [\"django.contrib.auth.backends.ModelBackend\"]\n \n-LOGIN_URL = '/accounts/login/'\n+LOGIN_URL = \"/accounts/login/\"\n \n-LOGIN_REDIRECT_URL = '/accounts/profile/'\n+LOGIN_REDIRECT_URL = \"/accounts/profile/\"\n \n LOGOUT_REDIRECT_URL = None\n \n@@ -510,10 +516,10 @@ PASSWORD_RESET_TIMEOUT_DAYS = 3\n # password using different algorithms will be converted automatically\n # upon login\n PASSWORD_HASHERS = [\n-    'django.contrib.auth.hashers.PBKDF2PasswordHasher',\n-    'django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher',\n-    'django.contrib.auth.hashers.Argon2PasswordHasher',\n-    'django.contrib.auth.hashers.BCryptSHA256PasswordHasher',\n+    \"django.contrib.auth.hashers.PBKDF2PasswordHasher\",\n+    \"django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher\",\n+    \"django.contrib.auth.hashers.Argon2PasswordHasher\",\n+    \"django.contrib.auth.hashers.BCryptSHA256PasswordHasher\",\n ]\n \n AUTH_PASSWORD_VALIDATORS = []\n@@ -522,7 +528,7 @@ AUTH_PASSWORD_VALIDATORS = []\n # SIGNING #\n ###########\n \n-SIGNING_BACKEND = 'django.core.signing.TimestampSigner'\n+SIGNING_BACKEND = \"django.core.signing.TimestampSigner\"\n \n ########\n # CSRF #\n@@ -530,17 +536,17 @@ SIGNING_BACKEND = 'django.core.signing.TimestampSigner'\n \n # Dotted path to callable to be used as view when a request is\n # rejected by the CSRF middleware.\n-CSRF_FAILURE_VIEW = 'django.views.csrf.csrf_failure'\n+CSRF_FAILURE_VIEW = \"django.views.csrf.csrf_failure\"\n \n # Settings for CSRF cookie.\n-CSRF_COOKIE_NAME = 'csrftoken'\n+CSRF_COOKIE_NAME = \"csrftoken\"\n CSRF_COOKIE_AGE = 60 * 60 * 24 * 7 * 52\n CSRF_COOKIE_DOMAIN = None\n-CSRF_COOKIE_PATH = '/'\n+CSRF_COOKIE_PATH = \"/\"\n CSRF_COOKIE_SECURE = False\n CSRF_COOKIE_HTTPONLY = False\n-CSRF_COOKIE_SAMESITE = 'Lax'\n-CSRF_HEADER_NAME = 'HTTP_X_CSRFTOKEN'\n+CSRF_COOKIE_SAMESITE = \"Lax\"\n+CSRF_HEADER_NAME = \"HTTP_X_CSRFTOKEN\"\n CSRF_TRUSTED_ORIGINS = []\n CSRF_USE_SESSIONS = False\n \n@@ -549,7 +555,7 @@ CSRF_USE_SESSIONS = False\n ############\n \n # Class to use as messages backend\n-MESSAGE_STORAGE = 'django.contrib.messages.storage.fallback.FallbackStorage'\n+MESSAGE_STORAGE = \"django.contrib.messages.storage.fallback.FallbackStorage\"\n \n # Default values of MESSAGE_LEVEL and MESSAGE_TAGS are defined within\n # django.contrib.messages to avoid imports in this settings file.\n@@ -559,21 +565,21 @@ MESSAGE_STORAGE = 'django.contrib.messages.storage.fallback.FallbackStorage'\n ###########\n \n # The callable to use to configure logging\n-LOGGING_CONFIG = 'logging.config.dictConfig'\n+LOGGING_CONFIG = \"logging.config.dictConfig\"\n \n # Custom logging configuration.\n LOGGING = {}\n \n # Default exception reporter filter class used in case none has been\n # specifically assigned to the HttpRequest instance.\n-DEFAULT_EXCEPTION_REPORTER_FILTER = 'django.views.debug.SafeExceptionReporterFilter'\n+DEFAULT_EXCEPTION_REPORTER_FILTER = \"django.views.debug.SafeExceptionReporterFilter\"\n \n ###########\n # TESTING #\n ###########\n \n # The name of the class to use to run the test suite\n-TEST_RUNNER = 'django.test.runner.DiscoverRunner'\n+TEST_RUNNER = \"django.test.runner.DiscoverRunner\"\n \n # Apps that don't need to be serialized at test database creation time\n # (only apps with migrations are to start with)\n@@ -594,13 +600,13 @@ FIXTURE_DIRS = []\n STATICFILES_DIRS = []\n \n # The default file storage backend used during the build process\n-STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.StaticFilesStorage'\n+STATICFILES_STORAGE = \"django.contrib.staticfiles.storage.StaticFilesStorage\"\n \n # List of finder classes that know how to find static files in\n # various locations.\n STATICFILES_FINDERS = [\n-    'django.contrib.staticfiles.finders.FileSystemFinder',\n-    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n+    \"django.contrib.staticfiles.finders.FileSystemFinder\",\n+    \"django.contrib.staticfiles.finders.AppDirectoriesFinder\",\n     # 'django.contrib.staticfiles.finders.DefaultStorageFinder',\n ]\n \n"}
{"instance_id": "django__django-10924", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0c64748ccd..1b155d8c4d 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -12,6 +12,7 @@ from django import forms\n from django.apps import apps\n from django.conf import settings\n from django.core import checks, exceptions, validators\n+\n # When the _meta object was formalized, this exception was moved to\n # django.core.exceptions. It is retained here for backwards compatibility\n # purposes.\n@@ -22,7 +23,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -32,14 +36,37 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FieldDoesNotExist', 'FilePathField',\n-    'FloatField', 'GenericIPAddressField', 'IPAddressField', 'IntegerField',\n-    'NOT_PROVIDED', 'NullBooleanField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallIntegerField', 'TextField',\n-    'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FieldDoesNotExist\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -75,6 +102,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -101,15 +129,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -125,18 +153,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -172,7 +219,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -182,19 +229,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -212,12 +259,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -225,15 +272,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % (LOOKUP_SEP,),\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -244,14 +291,16 @@ class Field(RegisterLookupMixin):\n             return []\n \n         def is_value(value, accept_promise=True):\n-            return isinstance(value, (str, Promise) if accept_promise else str) or not is_iterable(value)\n+            return isinstance(\n+                value, (str, Promise) if accept_promise else str\n+            ) or not is_iterable(value)\n \n         if is_value(self.choices, accept_promise=False):\n             return [\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -285,7 +334,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -295,25 +344,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -322,7 +376,9 @@ class Field(RegisterLookupMixin):\n     def _check_backend_specific_checks(self, **kwargs):\n         app_label = self.model._meta.app_label\n         for db in connections:\n-            if router.allow_migrate(db, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                db, app_label, model_name=self.model._meta.model_name\n+            ):\n                 return connections[db].validation.check_field(self, **kwargs)\n         return []\n \n@@ -336,11 +392,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -350,25 +407,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -378,6 +434,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -385,6 +442,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -444,7 +502,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -513,7 +571,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -532,7 +590,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -541,10 +599,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -582,7 +643,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -609,16 +670,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -632,7 +693,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -642,7 +703,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -704,7 +767,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -721,7 +784,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -740,8 +803,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, DeferredAttribute(self.attname))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            setattr(\n+                cls,\n+                \"get_%s_display\" % self.name,\n+                partialmethod(cls._get_FIELD_display, field=self),\n+            )\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n@@ -800,11 +866,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -812,7 +888,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -820,12 +898,14 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         return (blank_choice if include_blank else []) + [\n             (choice_func(x), str(x))\n-            for x in rel_model._default_manager.complex_filter(limit_choices_to).order_by(*ordering)\n+            for x in rel_model._default_manager.complex_filter(\n+                limit_choices_to\n+            ).order_by(*ordering)\n         ]\n \n     def value_to_string(self, obj):\n@@ -846,6 +926,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -854,24 +935,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -880,9 +962,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -899,11 +991,11 @@ class AutoField(Field):\n \n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be an integer.\"),\n+        \"invalid\": _(\"'%(value)s' value must be an integer.\"),\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -916,9 +1008,9 @@ class AutoField(Field):\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -926,8 +1018,8 @@ class AutoField(Field):\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -940,9 +1032,9 @@ class AutoField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def rel_db_type(self, connection):\n@@ -959,13 +1051,16 @@ class AutoField(Field):\n \n     def get_prep_value(self, value):\n         from django.db.models.expressions import OuterRef\n+\n         value = super().get_prep_value(value)\n         if value is None or isinstance(value, OuterRef):\n             return value\n         return int(value)\n \n     def contribute_to_class(self, cls, name, **kwargs):\n-        assert not cls._meta.auto_field, \"Model %s can't have more than one AutoField.\" % cls._meta.label\n+        assert not cls._meta.auto_field, (\n+            \"Model %s can't have more than one AutoField.\" % cls._meta.label\n+        )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n \n@@ -986,8 +1081,8 @@ class BigAutoField(AutoField):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be either True or False.\"),\n-        'invalid_nullable': _(\"'%(value)s' value must be either True, False, or None.\"),\n+        \"invalid\": _(\"'%(value)s' value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"'%(value)s' value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -1000,14 +1095,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -1018,14 +1113,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -1048,16 +1143,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1084,10 +1182,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1096,20 +1194,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1121,8 +1217,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1130,7 +1232,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1143,19 +1245,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid date format. It must be \"\n-                     \"in YYYY-MM-DD format.\"),\n-        'invalid_date': _(\"'%(value)s' value has the correct format (YYYY-MM-DD) \"\n-                          \"but it is an invalid date.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"'%(value)s' value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1186,13 +1293,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1201,12 +1308,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1231,15 +1338,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1254,12 +1361,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1274,25 +1387,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"),\n-        'invalid_date': _(\"'%(value)s' value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _(\"'%(value)s' value has the correct format \"\n-                              \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n-                              \"but it is an invalid date/time.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1329,13 +1450,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1356,10 +1477,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1370,9 +1493,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1381,15 +1504,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1411,13 +1534,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1430,24 +1554,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be a decimal number.\"),\n+        \"invalid\": _(\"'%(value)s' value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1474,7 +1606,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1482,7 +1614,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1498,7 +1630,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1506,7 +1638,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1518,7 +1650,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1536,9 +1668,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1553,25 +1685,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except decimal.InvalidOperation:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1581,10 +1717,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\")\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1605,9 +1744,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1625,13 +1764,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1640,7 +1781,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1652,20 +1793,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1680,23 +1832,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1708,15 +1860,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1725,7 +1879,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be a float.\"),\n+        \"invalid\": _(\"'%(value)s' value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1745,22 +1899,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be an integer.\"),\n+        \"invalid\": _(\"'%(value)s' value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1774,10 +1930,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1791,22 +1948,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1827,16 +1990,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1847,32 +2012,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1890,14 +2057,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1907,13 +2082,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1921,11 +2096,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1937,8 +2112,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1950,7 +2127,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1958,29 +2135,31 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be either None, True or False.\"),\n-        'invalid_nullable': _(\"'%(value)s' value must be either None, True or False.\"),\n+        \"invalid\": _(\"'%(value)s' value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"'%(value)s' value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1988,7 +2167,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -2011,10 +2189,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2024,17 +2204,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -2043,24 +2227,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2089,29 +2275,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"HH:MM[:ss[.uuuuuu]] format.\"),\n-        'invalid_time': _(\"'%(value)s' value has the correct format \"\n-                          \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2145,13 +2338,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2164,8 +2357,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2188,15 +2381,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2219,13 +2412,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2233,30 +2428,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2271,7 +2468,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2279,9 +2476,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2294,8 +2491,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2306,29 +2503,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' is not a valid UUID.\"),\n+        \"invalid\": _(\"'%(value)s' is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2350,19 +2547,21 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\ndiff --git a/django/forms/fields.py b/django/forms/fields.py\nindex a977256525..90da83cbe2 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -15,15 +15,29 @@ from urllib.parse import urlsplit, urlunsplit\n \n from django.core import validators\n from django.core.exceptions import ValidationError\n+\n # Provide this import for backwards compatibility.\n from django.core.validators import EMPTY_VALUES  # NOQA\n from django.forms.boundfield import BoundField\n from django.forms.utils import from_current_timezone, to_current_timezone\n from django.forms.widgets import (\n-    FILE_INPUT_CONTRADICTION, CheckboxInput, ClearableFileInput, DateInput,\n-    DateTimeInput, EmailInput, FileInput, HiddenInput, MultipleHiddenInput,\n-    NullBooleanSelect, NumberInput, Select, SelectMultiple,\n-    SplitDateTimeWidget, SplitHiddenDateTimeWidget, TextInput, TimeInput,\n+    FILE_INPUT_CONTRADICTION,\n+    CheckboxInput,\n+    ClearableFileInput,\n+    DateInput,\n+    DateTimeInput,\n+    EmailInput,\n+    FileInput,\n+    HiddenInput,\n+    MultipleHiddenInput,\n+    NullBooleanSelect,\n+    NumberInput,\n+    Select,\n+    SelectMultiple,\n+    SplitDateTimeWidget,\n+    SplitHiddenDateTimeWidget,\n+    TextInput,\n+    TimeInput,\n     URLInput,\n )\n from django.utils import formats\n@@ -33,30 +47,64 @@ from django.utils.ipv6 import clean_ipv6_address\n from django.utils.translation import gettext_lazy as _, ngettext_lazy\n \n __all__ = (\n-    'Field', 'CharField', 'IntegerField',\n-    'DateField', 'TimeField', 'DateTimeField', 'DurationField',\n-    'RegexField', 'EmailField', 'FileField', 'ImageField', 'URLField',\n-    'BooleanField', 'NullBooleanField', 'ChoiceField', 'MultipleChoiceField',\n-    'ComboField', 'MultiValueField', 'FloatField', 'DecimalField',\n-    'SplitDateTimeField', 'GenericIPAddressField', 'FilePathField',\n-    'SlugField', 'TypedChoiceField', 'TypedMultipleChoiceField', 'UUIDField',\n+    \"Field\",\n+    \"CharField\",\n+    \"IntegerField\",\n+    \"DateField\",\n+    \"TimeField\",\n+    \"DateTimeField\",\n+    \"DurationField\",\n+    \"RegexField\",\n+    \"EmailField\",\n+    \"FileField\",\n+    \"ImageField\",\n+    \"URLField\",\n+    \"BooleanField\",\n+    \"NullBooleanField\",\n+    \"ChoiceField\",\n+    \"MultipleChoiceField\",\n+    \"ComboField\",\n+    \"MultiValueField\",\n+    \"FloatField\",\n+    \"DecimalField\",\n+    \"SplitDateTimeField\",\n+    \"GenericIPAddressField\",\n+    \"FilePathField\",\n+    \"SlugField\",\n+    \"TypedChoiceField\",\n+    \"TypedMultipleChoiceField\",\n+    \"UUIDField\",\n )\n \n \n class Field:\n     widget = TextInput  # Default widget to use when rendering this type of Field.\n-    hidden_widget = HiddenInput  # Default widget to use when rendering this as \"hidden\".\n+    hidden_widget = (\n+        HiddenInput  # Default widget to use when rendering this as \"hidden\".\n+    )\n     default_validators = []  # Default set of validators\n     # Add an 'invalid' entry to default_error_message if you want a specific\n     # field error message not raised by the field validators.\n     default_error_messages = {\n-        'required': _('This field is required.'),\n+        \"required\": _(\"This field is required.\"),\n     }\n     empty_values = list(validators.EMPTY_VALUES)\n \n-    def __init__(self, *, required=True, widget=None, label=None, initial=None,\n-                 help_text='', error_messages=None, show_hidden_initial=False,\n-                 validators=(), localize=False, disabled=False, label_suffix=None):\n+    def __init__(\n+        self,\n+        *,\n+        required=True,\n+        widget=None,\n+        label=None,\n+        initial=None,\n+        help_text=\"\",\n+        error_messages=None,\n+        show_hidden_initial=False,\n+        validators=(),\n+        localize=False,\n+        disabled=False,\n+        label_suffix=None,\n+    ):\n         # required -- Boolean that specifies whether the field is required.\n         #             True by default.\n         # widget -- A Widget class, or instance of a Widget class, that should\n@@ -108,7 +156,7 @@ class Field:\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self.error_messages = messages\n \n@@ -124,7 +172,7 @@ class Field:\n \n     def validate(self, value):\n         if value in self.empty_values and self.required:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n \n     def run_validators(self, value):\n         if value in self.empty_values:\n@@ -134,7 +182,7 @@ class Field:\n             try:\n                 v(value)\n             except ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n         if errors:\n@@ -179,15 +227,15 @@ class Field:\n             return False\n         try:\n             data = self.to_python(data)\n-            if hasattr(self, '_coerce'):\n+            if hasattr(self, \"_coerce\"):\n                 return self._coerce(data) != self._coerce(initial)\n         except ValidationError:\n             return True\n         # For purposes of seeing whether something has changed, None is\n         # the same as an empty string, if the data or initial value we get\n         # is None, replace it with ''.\n-        initial_value = initial if initial is not None else ''\n-        data_value = data if data is not None else ''\n+        initial_value = initial if initial is not None else \"\"\n+        data_value = data if data is not None else \"\"\n         return initial_value != data_value\n \n     def get_bound_field(self, form, field_name):\n@@ -206,7 +254,9 @@ class Field:\n \n \n class CharField(Field):\n-    def __init__(self, *, max_length=None, min_length=None, strip=True, empty_value='', **kwargs):\n+    def __init__(\n+        self, *, max_length=None, min_length=None, strip=True, empty_value=\"\", **kwargs\n+    ):\n         self.max_length = max_length\n         self.min_length = min_length\n         self.strip = strip\n@@ -232,25 +282,25 @@ class CharField(Field):\n         attrs = super().widget_attrs(widget)\n         if self.max_length is not None and not widget.is_hidden:\n             # The HTML attribute is maxlength, not max_length.\n-            attrs['maxlength'] = str(self.max_length)\n+            attrs[\"maxlength\"] = str(self.max_length)\n         if self.min_length is not None and not widget.is_hidden:\n             # The HTML attribute is minlength, not min_length.\n-            attrs['minlength'] = str(self.min_length)\n+            attrs[\"minlength\"] = str(self.min_length)\n         return attrs\n \n \n class IntegerField(Field):\n     widget = NumberInput\n     default_error_messages = {\n-        'invalid': _('Enter a whole number.'),\n+        \"invalid\": _(\"Enter a whole number.\"),\n     }\n-    re_decimal = re.compile(r'\\.0*\\s*$')\n+    re_decimal = re.compile(r\"\\.0*\\s*$\")\n \n     def __init__(self, *, max_value=None, min_value=None, **kwargs):\n         self.max_value, self.min_value = max_value, min_value\n-        if kwargs.get('localize') and self.widget == NumberInput:\n+        if kwargs.get(\"localize\") and self.widget == NumberInput:\n             # Localized number input is not well supported on most browsers\n-            kwargs.setdefault('widget', super().widget)\n+            kwargs.setdefault(\"widget\", super().widget)\n         super().__init__(**kwargs)\n \n         if max_value is not None:\n@@ -270,24 +320,24 @@ class IntegerField(Field):\n             value = formats.sanitize_separators(value)\n         # Strip trailing decimal and zeros.\n         try:\n-            value = int(self.re_decimal.sub('', str(value)))\n+            value = int(self.re_decimal.sub(\"\", str(value)))\n         except (ValueError, TypeError):\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         return value\n \n     def widget_attrs(self, widget):\n         attrs = super().widget_attrs(widget)\n         if isinstance(widget, NumberInput):\n             if self.min_value is not None:\n-                attrs['min'] = self.min_value\n+                attrs[\"min\"] = self.min_value\n             if self.max_value is not None:\n-                attrs['max'] = self.max_value\n+                attrs[\"max\"] = self.max_value\n         return attrs\n \n \n class FloatField(IntegerField):\n     default_error_messages = {\n-        'invalid': _('Enter a number.'),\n+        \"invalid\": _(\"Enter a number.\"),\n     }\n \n     def to_python(self, value):\n@@ -303,7 +353,7 @@ class FloatField(IntegerField):\n         try:\n             value = float(value)\n         except (ValueError, TypeError):\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         return value\n \n     def validate(self, value):\n@@ -311,21 +361,29 @@ class FloatField(IntegerField):\n         if value in self.empty_values:\n             return\n         if not math.isfinite(value):\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n \n     def widget_attrs(self, widget):\n         attrs = super().widget_attrs(widget)\n-        if isinstance(widget, NumberInput) and 'step' not in widget.attrs:\n-            attrs.setdefault('step', 'any')\n+        if isinstance(widget, NumberInput) and \"step\" not in widget.attrs:\n+            attrs.setdefault(\"step\", \"any\")\n         return attrs\n \n \n class DecimalField(IntegerField):\n     default_error_messages = {\n-        'invalid': _('Enter a number.'),\n+        \"invalid\": _(\"Enter a number.\"),\n     }\n \n-    def __init__(self, *, max_value=None, min_value=None, max_digits=None, decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        *,\n+        max_value=None,\n+        min_value=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(max_value=max_value, min_value=min_value, **kwargs)\n         self.validators.append(validators.DecimalValidator(max_digits, decimal_places))\n@@ -345,7 +403,7 @@ class DecimalField(IntegerField):\n         try:\n             value = Decimal(value)\n         except DecimalException:\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         return value\n \n     def validate(self, value):\n@@ -353,23 +411,22 @@ class DecimalField(IntegerField):\n         if value in self.empty_values:\n             return\n         if not value.is_finite():\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n \n     def widget_attrs(self, widget):\n         attrs = super().widget_attrs(widget)\n-        if isinstance(widget, NumberInput) and 'step' not in widget.attrs:\n+        if isinstance(widget, NumberInput) and \"step\" not in widget.attrs:\n             if self.decimal_places is not None:\n                 # Use exponential notation for small values since they might\n                 # be parsed as 0 otherwise. ref #20765\n                 step = str(Decimal(1).scaleb(-self.decimal_places)).lower()\n             else:\n-                step = 'any'\n-            attrs.setdefault('step', step)\n+                step = \"any\"\n+            attrs.setdefault(\"step\", step)\n         return attrs\n \n \n class BaseTemporalField(Field):\n-\n     def __init__(self, *, input_formats=None, **kwargs):\n         super().__init__(**kwargs)\n         if input_formats is not None:\n@@ -383,17 +440,17 @@ class BaseTemporalField(Field):\n                 return self.strptime(value, format)\n             except (ValueError, TypeError):\n                 continue\n-        raise ValidationError(self.error_messages['invalid'], code='invalid')\n+        raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n \n     def strptime(self, value, format):\n-        raise NotImplementedError('Subclasses must define this method.')\n+        raise NotImplementedError(\"Subclasses must define this method.\")\n \n \n class DateField(BaseTemporalField):\n     widget = DateInput\n-    input_formats = formats.get_format_lazy('DATE_INPUT_FORMATS')\n+    input_formats = formats.get_format_lazy(\"DATE_INPUT_FORMATS\")\n     default_error_messages = {\n-        'invalid': _('Enter a valid date.'),\n+        \"invalid\": _(\"Enter a valid date.\"),\n     }\n \n     def to_python(self, value):\n@@ -415,10 +472,8 @@ class DateField(BaseTemporalField):\n \n class TimeField(BaseTemporalField):\n     widget = TimeInput\n-    input_formats = formats.get_format_lazy('TIME_INPUT_FORMATS')\n-    default_error_messages = {\n-        'invalid': _('Enter a valid time.')\n-    }\n+    input_formats = formats.get_format_lazy(\"TIME_INPUT_FORMATS\")\n+    default_error_messages = {\"invalid\": _(\"Enter a valid time.\")}\n \n     def to_python(self, value):\n         \"\"\"\n@@ -437,9 +492,9 @@ class TimeField(BaseTemporalField):\n \n class DateTimeField(BaseTemporalField):\n     widget = DateTimeInput\n-    input_formats = formats.get_format_lazy('DATETIME_INPUT_FORMATS')\n+    input_formats = formats.get_format_lazy(\"DATETIME_INPUT_FORMATS\")\n     default_error_messages = {\n-        'invalid': _('Enter a valid date/time.'),\n+        \"invalid\": _(\"Enter a valid date/time.\"),\n     }\n \n     def prepare_value(self, value):\n@@ -468,8 +523,8 @@ class DateTimeField(BaseTemporalField):\n \n class DurationField(Field):\n     default_error_messages = {\n-        'invalid': _('Enter a valid duration.'),\n-        'overflow': _('The number of days must be between {min_days} and {max_days}.')\n+        \"invalid\": _(\"Enter a valid duration.\"),\n+        \"overflow\": _(\"The number of days must be between {min_days} and {max_days}.\"),\n     }\n \n     def prepare_value(self, value):\n@@ -485,12 +540,15 @@ class DurationField(Field):\n         try:\n             value = parse_duration(str(value))\n         except OverflowError:\n-            raise ValidationError(self.error_messages['overflow'].format(\n-                min_days=datetime.timedelta.min.days,\n-                max_days=datetime.timedelta.max.days,\n-            ), code='overflow')\n+            raise ValidationError(\n+                self.error_messages[\"overflow\"].format(\n+                    min_days=datetime.timedelta.min.days,\n+                    max_days=datetime.timedelta.max.days,\n+                ),\n+                code=\"overflow\",\n+            )\n         if value is None:\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         return value\n \n \n@@ -499,7 +557,7 @@ class RegexField(CharField):\n         \"\"\"\n         regex can be either a string or a compiled regular expression object.\n         \"\"\"\n-        kwargs.setdefault('strip', False)\n+        kwargs.setdefault(\"strip\", False)\n         super().__init__(**kwargs)\n         self._set_regex(regex)\n \n@@ -510,7 +568,10 @@ class RegexField(CharField):\n         if isinstance(regex, str):\n             regex = re.compile(regex)\n         self._regex = regex\n-        if hasattr(self, '_regex_validator') and self._regex_validator in self.validators:\n+        if (\n+            hasattr(self, \"_regex_validator\")\n+            and self._regex_validator in self.validators\n+        ):\n             self.validators.remove(self._regex_validator)\n         self._regex_validator = validators.RegexValidator(regex=regex)\n         self.validators.append(self._regex_validator)\n@@ -529,14 +590,17 @@ class EmailField(CharField):\n class FileField(Field):\n     widget = ClearableFileInput\n     default_error_messages = {\n-        'invalid': _(\"No file was submitted. Check the encoding type on the form.\"),\n-        'missing': _(\"No file was submitted.\"),\n-        'empty': _(\"The submitted file is empty.\"),\n-        'max_length': ngettext_lazy(\n-            'Ensure this filename has at most %(max)d character (it has %(length)d).',\n-            'Ensure this filename has at most %(max)d characters (it has %(length)d).',\n-            'max'),\n-        'contradiction': _('Please either submit a file or check the clear checkbox, not both.')\n+        \"invalid\": _(\"No file was submitted. Check the encoding type on the form.\"),\n+        \"missing\": _(\"No file was submitted.\"),\n+        \"empty\": _(\"The submitted file is empty.\"),\n+        \"max_length\": ngettext_lazy(\n+            \"Ensure this filename has at most %(max)d character (it has %(length)d).\",\n+            \"Ensure this filename has at most %(max)d characters (it has %(length)d).\",\n+            \"max\",\n+        ),\n+        \"contradiction\": _(\n+            \"Please either submit a file or check the clear checkbox, not both.\"\n+        ),\n     }\n \n     def __init__(self, *, max_length=None, allow_empty_file=False, **kwargs):\n@@ -553,22 +617,26 @@ class FileField(Field):\n             file_name = data.name\n             file_size = data.size\n         except AttributeError:\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n \n         if self.max_length is not None and len(file_name) > self.max_length:\n-            params = {'max': self.max_length, 'length': len(file_name)}\n-            raise ValidationError(self.error_messages['max_length'], code='max_length', params=params)\n+            params = {\"max\": self.max_length, \"length\": len(file_name)}\n+            raise ValidationError(\n+                self.error_messages[\"max_length\"], code=\"max_length\", params=params\n+            )\n         if not file_name:\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         if not self.allow_empty_file and not file_size:\n-            raise ValidationError(self.error_messages['empty'], code='empty')\n+            raise ValidationError(self.error_messages[\"empty\"], code=\"empty\")\n \n         return data\n \n     def clean(self, data, initial=None):\n         # If the widget got contradictory inputs, we raise a validation error\n         if data is FILE_INPUT_CONTRADICTION:\n-            raise ValidationError(self.error_messages['contradiction'], code='contradiction')\n+            raise ValidationError(\n+                self.error_messages[\"contradiction\"], code=\"contradiction\"\n+            )\n         # False means the field value should be cleared; further validation is\n         # not needed.\n         if data is False:\n@@ -596,7 +664,7 @@ class FileField(Field):\n class ImageField(FileField):\n     default_validators = [validators.validate_image_file_extension]\n     default_error_messages = {\n-        'invalid_image': _(\n+        \"invalid_image\": _(\n             \"Upload a valid image. The file you uploaded was either not an \"\n             \"image or a corrupted image.\"\n         ),\n@@ -615,13 +683,13 @@ class ImageField(FileField):\n \n         # We need to get a file object for Pillow. We might have a path or we might\n         # have to read the data into memory.\n-        if hasattr(data, 'temporary_file_path'):\n+        if hasattr(data, \"temporary_file_path\"):\n             file = data.temporary_file_path()\n         else:\n-            if hasattr(data, 'read'):\n+            if hasattr(data, \"read\"):\n                 file = BytesIO(data.read())\n             else:\n-                file = BytesIO(data['content'])\n+                file = BytesIO(data[\"content\"])\n \n         try:\n             # load() could spot a truncated JPEG, but it loads the entire\n@@ -638,24 +706,24 @@ class ImageField(FileField):\n         except Exception as exc:\n             # Pillow doesn't recognize it as an image.\n             raise ValidationError(\n-                self.error_messages['invalid_image'],\n-                code='invalid_image',\n+                self.error_messages[\"invalid_image\"],\n+                code=\"invalid_image\",\n             ) from exc\n-        if hasattr(f, 'seek') and callable(f.seek):\n+        if hasattr(f, \"seek\") and callable(f.seek):\n             f.seek(0)\n         return f\n \n     def widget_attrs(self, widget):\n         attrs = super().widget_attrs(widget)\n-        if isinstance(widget, FileInput) and 'accept' not in widget.attrs:\n-            attrs.setdefault('accept', 'image/*')\n+        if isinstance(widget, FileInput) and \"accept\" not in widget.attrs:\n+            attrs.setdefault(\"accept\", \"image/*\")\n         return attrs\n \n \n class URLField(CharField):\n     widget = URLInput\n     default_error_messages = {\n-        'invalid': _('Enter a valid URL.'),\n+        \"invalid\": _(\"Enter a valid URL.\"),\n     }\n     default_validators = [validators.URLValidator()]\n \n@@ -663,7 +731,6 @@ class URLField(CharField):\n         super().__init__(strip=True, **kwargs)\n \n     def to_python(self, value):\n-\n         def split_url(url):\n             \"\"\"\n             Return a list of url parts via urlparse.urlsplit(), or raise\n@@ -674,19 +741,19 @@ class URLField(CharField):\n             except ValueError:\n                 # urlparse.urlsplit can raise a ValueError with some\n                 # misformatted URLs.\n-                raise ValidationError(self.error_messages['invalid'], code='invalid')\n+                raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n \n         value = super().to_python(value)\n         if value:\n             url_fields = split_url(value)\n             if not url_fields[0]:\n                 # If no URL scheme given, assume http://\n-                url_fields[0] = 'http'\n+                url_fields[0] = \"http\"\n             if not url_fields[1]:\n                 # Assume that if no domain is provided, that the path segment\n                 # contains the domain.\n                 url_fields[1] = url_fields[2]\n-                url_fields[2] = ''\n+                url_fields[2] = \"\"\n                 # Rebuild the url_fields list, since the domain segment may now\n                 # contain the path too.\n                 url_fields = split_url(urlunsplit(url_fields))\n@@ -703,7 +770,7 @@ class BooleanField(Field):\n         # will submit for False. Also check for '0', since this is what\n         # RadioSelect will provide. Because bool(\"True\") == bool('1') == True,\n         # we don't need to handle that explicitly.\n-        if isinstance(value, str) and value.lower() in ('false', '0'):\n+        if isinstance(value, str) and value.lower() in (\"false\", \"0\"):\n             value = False\n         else:\n             value = bool(value)\n@@ -711,7 +778,7 @@ class BooleanField(Field):\n \n     def validate(self, value):\n         if not value and self.required:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n \n     def has_changed(self, initial, data):\n         if self.disabled:\n@@ -726,6 +793,7 @@ class NullBooleanField(BooleanField):\n     A field whose valid values are None, True, and False. Clean invalid values\n     to None.\n     \"\"\"\n+\n     widget = NullBooleanSelect\n \n     def to_python(self, value):\n@@ -737,9 +805,9 @@ class NullBooleanField(BooleanField):\n         the Booleanfield, this field must check for True because it doesn't\n         use the bool() function.\n         \"\"\"\n-        if value in (True, 'True', 'true', '1'):\n+        if value in (True, \"True\", \"true\", \"1\"):\n             return True\n-        elif value in (False, 'False', 'false', '0'):\n+        elif value in (False, \"False\", \"false\", \"0\"):\n             return False\n         else:\n             return None\n@@ -759,7 +827,9 @@ class CallableChoiceIterator:\n class ChoiceField(Field):\n     widget = Select\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. %(value)s is not one of the available choices.'),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n     }\n \n     def __init__(self, *, choices=(), **kwargs):\n@@ -790,7 +860,7 @@ class ChoiceField(Field):\n     def to_python(self, value):\n         \"\"\"Return a string.\"\"\"\n         if value in self.empty_values:\n-            return ''\n+            return \"\"\n         return str(value)\n \n     def validate(self, value):\n@@ -798,9 +868,9 @@ class ChoiceField(Field):\n         super().validate(value)\n         if value and not self.valid_value(value):\n             raise ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n     def valid_value(self, value):\n@@ -819,7 +889,7 @@ class ChoiceField(Field):\n \n \n class TypedChoiceField(ChoiceField):\n-    def __init__(self, *, coerce=lambda val: val, empty_value='', **kwargs):\n+    def __init__(self, *, coerce=lambda val: val, empty_value=\"\", **kwargs):\n         self.coerce = coerce\n         self.empty_value = empty_value\n         super().__init__(**kwargs)\n@@ -834,9 +904,9 @@ class TypedChoiceField(ChoiceField):\n             value = self.coerce(value)\n         except (ValueError, TypeError, ValidationError):\n             raise ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n         return value\n \n@@ -849,28 +919,32 @@ class MultipleChoiceField(ChoiceField):\n     hidden_widget = MultipleHiddenInput\n     widget = SelectMultiple\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. %(value)s is not one of the available choices.'),\n-        'invalid_list': _('Enter a list of values.'),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n+        \"invalid_list\": _(\"Enter a list of values.\"),\n     }\n \n     def to_python(self, value):\n         if not value:\n             return []\n         elif not isinstance(value, (list, tuple)):\n-            raise ValidationError(self.error_messages['invalid_list'], code='invalid_list')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_list\"], code=\"invalid_list\"\n+            )\n         return [str(val) for val in value]\n \n     def validate(self, value):\n         \"\"\"Validate that the input is a list or tuple.\"\"\"\n         if self.required and not value:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n         # Validate that each value in the value list is in self.choices.\n         for val in value:\n             if not self.valid_value(val):\n                 raise ValidationError(\n-                    self.error_messages['invalid_choice'],\n-                    code='invalid_choice',\n-                    params={'value': val},\n+                    self.error_messages[\"invalid_choice\"],\n+                    code=\"invalid_choice\",\n+                    params={\"value\": val},\n                 )\n \n     def has_changed(self, initial, data):\n@@ -890,7 +964,7 @@ class MultipleChoiceField(ChoiceField):\n class TypedMultipleChoiceField(MultipleChoiceField):\n     def __init__(self, *, coerce=lambda val: val, **kwargs):\n         self.coerce = coerce\n-        self.empty_value = kwargs.pop('empty_value', [])\n+        self.empty_value = kwargs.pop(\"empty_value\", [])\n         super().__init__(**kwargs)\n \n     def _coerce(self, value):\n@@ -906,9 +980,9 @@ class TypedMultipleChoiceField(MultipleChoiceField):\n                 new_value.append(self.coerce(choice))\n             except (ValueError, TypeError, ValidationError):\n                 raise ValidationError(\n-                    self.error_messages['invalid_choice'],\n-                    code='invalid_choice',\n-                    params={'value': choice},\n+                    self.error_messages[\"invalid_choice\"],\n+                    code=\"invalid_choice\",\n+                    params={\"value\": choice},\n                 )\n         return new_value\n \n@@ -920,13 +994,14 @@ class TypedMultipleChoiceField(MultipleChoiceField):\n         if value != self.empty_value:\n             super().validate(value)\n         elif self.required:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n \n \n class ComboField(Field):\n     \"\"\"\n     A Field whose clean() method calls multiple Field clean() methods.\n     \"\"\"\n+\n     def __init__(self, fields, **kwargs):\n         super().__init__(**kwargs)\n         # Set 'required' to False on the individual fields, because the\n@@ -964,17 +1039,17 @@ class MultiValueField(Field):\n \n     You'll probably want to use this with MultiWidget.\n     \"\"\"\n+\n     default_error_messages = {\n-        'invalid': _('Enter a list of values.'),\n-        'incomplete': _('Enter a complete value.'),\n+        \"invalid\": _(\"Enter a list of values.\"),\n+        \"incomplete\": _(\"Enter a complete value.\"),\n     }\n \n     def __init__(self, fields, *, require_all_fields=True, **kwargs):\n         self.require_all_fields = require_all_fields\n         super().__init__(**kwargs)\n         for f in fields:\n-            f.error_messages.setdefault('incomplete',\n-                                        self.error_messages['incomplete'])\n+            f.error_messages.setdefault(\"incomplete\", self.error_messages[\"incomplete\"])\n             if self.disabled:\n                 f.disabled = True\n             if self.require_all_fields:\n@@ -1008,11 +1083,13 @@ class MultiValueField(Field):\n         if not value or isinstance(value, (list, tuple)):\n             if not value or not [v for v in value if v not in self.empty_values]:\n                 if self.required:\n-                    raise ValidationError(self.error_messages['required'], code='required')\n+                    raise ValidationError(\n+                        self.error_messages[\"required\"], code=\"required\"\n+                    )\n                 else:\n                     return self.compress([])\n         else:\n-            raise ValidationError(self.error_messages['invalid'], code='invalid')\n+            raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         for i, field in enumerate(self.fields):\n             try:\n                 field_value = value[i]\n@@ -1023,13 +1100,15 @@ class MultiValueField(Field):\n                     # Raise a 'required' error if the MultiValueField is\n                     # required and any field is empty.\n                     if self.required:\n-                        raise ValidationError(self.error_messages['required'], code='required')\n+                        raise ValidationError(\n+                            self.error_messages[\"required\"], code=\"required\"\n+                        )\n                 elif field.required:\n                     # Otherwise, add an 'incomplete' error to the list of\n                     # collected errors and skip field cleaning, if a required\n                     # field is empty.\n-                    if field.error_messages['incomplete'] not in errors:\n-                        errors.append(field.error_messages['incomplete'])\n+                    if field.error_messages[\"incomplete\"] not in errors:\n+                        errors.append(field.error_messages[\"incomplete\"])\n                     continue\n             try:\n                 clean_data.append(field.clean(field_value))\n@@ -1055,13 +1134,13 @@ class MultiValueField(Field):\n         fields=(DateField(), TimeField()), this might return a datetime\n         object created by combining the date and time in data_list.\n         \"\"\"\n-        raise NotImplementedError('Subclasses must implement this method.')\n+        raise NotImplementedError(\"Subclasses must implement this method.\")\n \n     def has_changed(self, initial, data):\n         if self.disabled:\n             return False\n         if initial is None:\n-            initial = ['' for x in range(0, len(data))]\n+            initial = [\"\" for x in range(0, len(data))]\n         else:\n             if not isinstance(initial, list):\n                 initial = self.widget.decompress(initial)\n@@ -1076,9 +1155,18 @@ class MultiValueField(Field):\n \n \n class FilePathField(ChoiceField):\n-    def __init__(self, path, *, match=None, recursive=False, allow_files=True,\n-                 allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+    def __init__(\n+        self,\n+        path,\n+        *,\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n+        self.path = path() if callable(path) else path\n+        self.match, self.recursive = match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n         super().__init__(choices=(), **kwargs)\n \n@@ -1099,7 +1187,7 @@ class FilePathField(ChoiceField):\n                             self.choices.append((f, f.replace(path, \"\", 1)))\n                 if self.allow_folders:\n                     for f in sorted(dirs):\n-                        if f == '__pycache__':\n+                        if f == \"__pycache__\":\n                             continue\n                         if self.match is None or self.match_re.search(f):\n                             f = os.path.join(root, f)\n@@ -1107,11 +1195,12 @@ class FilePathField(ChoiceField):\n         else:\n             choices = []\n             for f in os.scandir(self.path):\n-                if f.name == '__pycache__':\n+                if f.name == \"__pycache__\":\n                     continue\n-                if (((self.allow_files and f.is_file()) or\n-                        (self.allow_folders and f.is_dir())) and\n-                        (self.match is None or self.match_re.search(f.name))):\n+                if (\n+                    (self.allow_files and f.is_file())\n+                    or (self.allow_folders and f.is_dir())\n+                ) and (self.match is None or self.match_re.search(f.name)):\n                     choices.append((f.path, f.name))\n             choices.sort(key=operator.itemgetter(1))\n             self.choices.extend(choices)\n@@ -1123,22 +1212,26 @@ class SplitDateTimeField(MultiValueField):\n     widget = SplitDateTimeWidget\n     hidden_widget = SplitHiddenDateTimeWidget\n     default_error_messages = {\n-        'invalid_date': _('Enter a valid date.'),\n-        'invalid_time': _('Enter a valid time.'),\n+        \"invalid_date\": _(\"Enter a valid date.\"),\n+        \"invalid_time\": _(\"Enter a valid time.\"),\n     }\n \n     def __init__(self, *, input_date_formats=None, input_time_formats=None, **kwargs):\n         errors = self.default_error_messages.copy()\n-        if 'error_messages' in kwargs:\n-            errors.update(kwargs['error_messages'])\n-        localize = kwargs.get('localize', False)\n+        if \"error_messages\" in kwargs:\n+            errors.update(kwargs[\"error_messages\"])\n+        localize = kwargs.get(\"localize\", False)\n         fields = (\n-            DateField(input_formats=input_date_formats,\n-                      error_messages={'invalid': errors['invalid_date']},\n-                      localize=localize),\n-            TimeField(input_formats=input_time_formats,\n-                      error_messages={'invalid': errors['invalid_time']},\n-                      localize=localize),\n+            DateField(\n+                input_formats=input_date_formats,\n+                error_messages={\"invalid\": errors[\"invalid_date\"]},\n+                localize=localize,\n+            ),\n+            TimeField(\n+                input_formats=input_time_formats,\n+                error_messages={\"invalid\": errors[\"invalid_time\"]},\n+                localize=localize,\n+            ),\n         )\n         super().__init__(fields, **kwargs)\n \n@@ -1147,25 +1240,31 @@ class SplitDateTimeField(MultiValueField):\n             # Raise a validation error if time or date is empty\n             # (possible if SplitDateTimeField has required=False).\n             if data_list[0] in self.empty_values:\n-                raise ValidationError(self.error_messages['invalid_date'], code='invalid_date')\n+                raise ValidationError(\n+                    self.error_messages[\"invalid_date\"], code=\"invalid_date\"\n+                )\n             if data_list[1] in self.empty_values:\n-                raise ValidationError(self.error_messages['invalid_time'], code='invalid_time')\n+                raise ValidationError(\n+                    self.error_messages[\"invalid_time\"], code=\"invalid_time\"\n+                )\n             result = datetime.datetime.combine(*data_list)\n             return from_current_timezone(result)\n         return None\n \n \n class GenericIPAddressField(CharField):\n-    def __init__(self, *, protocol='both', unpack_ipv4=False, **kwargs):\n+    def __init__(self, *, protocol=\"both\", unpack_ipv4=False, **kwargs):\n         self.unpack_ipv4 = unpack_ipv4\n-        self.default_validators = validators.ip_address_validators(protocol, unpack_ipv4)[0]\n+        self.default_validators = validators.ip_address_validators(\n+            protocol, unpack_ipv4\n+        )[0]\n         super().__init__(**kwargs)\n \n     def to_python(self, value):\n         if value in self.empty_values:\n-            return ''\n+            return \"\"\n         value = value.strip()\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             return clean_ipv6_address(value, self.unpack_ipv4)\n         return value\n \n@@ -1182,7 +1281,7 @@ class SlugField(CharField):\n \n class UUIDField(CharField):\n     default_error_messages = {\n-        'invalid': _('Enter a valid UUID.'),\n+        \"invalid\": _(\"Enter a valid UUID.\"),\n     }\n \n     def prepare_value(self, value):\n@@ -1198,5 +1297,5 @@ class UUIDField(CharField):\n             try:\n                 value = uuid.UUID(value)\n             except ValueError:\n-                raise ValidationError(self.error_messages['invalid'], code='invalid')\n+                raise ValidationError(self.error_messages[\"invalid\"], code=\"invalid\")\n         return value\n"}
{"instance_id": "django__django-11001", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": ""}
{"instance_id": "django__django-11019", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 02aa32b207..3aaf202664 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -21,16 +21,35 @@ from django.utils.translation import gettext_lazy as _\n from .renderers import get_default_renderer\n \n __all__ = (\n-    'Media', 'MediaDefiningClass', 'Widget', 'TextInput', 'NumberInput',\n-    'EmailInput', 'URLInput', 'PasswordInput', 'HiddenInput',\n-    'MultipleHiddenInput', 'FileInput', 'ClearableFileInput', 'Textarea',\n-    'DateInput', 'DateTimeInput', 'TimeInput', 'CheckboxInput', 'Select',\n-    'NullBooleanSelect', 'SelectMultiple', 'RadioSelect',\n-    'CheckboxSelectMultiple', 'MultiWidget', 'SplitDateTimeWidget',\n-    'SplitHiddenDateTimeWidget', 'SelectDateWidget',\n+    \"Media\",\n+    \"MediaDefiningClass\",\n+    \"Widget\",\n+    \"TextInput\",\n+    \"NumberInput\",\n+    \"EmailInput\",\n+    \"URLInput\",\n+    \"PasswordInput\",\n+    \"HiddenInput\",\n+    \"MultipleHiddenInput\",\n+    \"FileInput\",\n+    \"ClearableFileInput\",\n+    \"Textarea\",\n+    \"DateInput\",\n+    \"DateTimeInput\",\n+    \"TimeInput\",\n+    \"CheckboxInput\",\n+    \"Select\",\n+    \"NullBooleanSelect\",\n+    \"SelectMultiple\",\n+    \"RadioSelect\",\n+    \"CheckboxSelectMultiple\",\n+    \"MultiWidget\",\n+    \"SplitDateTimeWidget\",\n+    \"SplitHiddenDateTimeWidget\",\n+    \"SelectDateWidget\",\n )\n \n-MEDIA_TYPES = ('css', 'js')\n+MEDIA_TYPES = (\"css\", \"js\")\n \n \n class MediaOrderConflictWarning(RuntimeWarning):\n@@ -41,8 +60,8 @@ class MediaOrderConflictWarning(RuntimeWarning):\n class Media:\n     def __init__(self, media=None, css=None, js=None):\n         if media is not None:\n-            css = getattr(media, 'css', {})\n-            js = getattr(media, 'js', [])\n+            css = getattr(media, \"css\", {})\n+            js = getattr(media, \"js\", [])\n         else:\n             if css is None:\n                 css = {}\n@@ -52,7 +71,7 @@ class Media:\n         self._js_lists = [js]\n \n     def __repr__(self):\n-        return 'Media(css=%r, js=%r)' % (self._css, self._js)\n+        return \"Media(css=%r, js=%r)\" % (self._css, self._js)\n \n     def __str__(self):\n         return self.render()\n@@ -77,26 +96,38 @@ class Media:\n         return js\n \n     def render(self):\n-        return mark_safe('\\n'.join(chain.from_iterable(getattr(self, 'render_' + name)() for name in MEDIA_TYPES)))\n+        return mark_safe(\n+            \"\\n\".join(\n+                chain.from_iterable(\n+                    getattr(self, \"render_\" + name)() for name in MEDIA_TYPES\n+                )\n+            )\n+        )\n \n     def render_js(self):\n         return [\n             format_html(\n                 '<script type=\"text/javascript\" src=\"{}\"></script>',\n-                self.absolute_path(path)\n-            ) for path in self._js\n+                self.absolute_path(path),\n+            )\n+            for path in self._js\n         ]\n \n     def render_css(self):\n         # To keep rendering order consistent, we can't just iterate over items().\n         # We need to sort the keys, and iterate over the sorted list.\n         media = sorted(self._css)\n-        return chain.from_iterable([\n-            format_html(\n-                '<link href=\"{}\" type=\"text/css\" media=\"{}\" rel=\"stylesheet\">',\n-                self.absolute_path(path), medium\n-            ) for path in self._css[medium]\n-        ] for medium in media)\n+        return chain.from_iterable(\n+            [\n+                format_html(\n+                    '<link href=\"{}\" type=\"text/css\" media=\"{}\" rel=\"stylesheet\">',\n+                    self.absolute_path(path),\n+                    medium,\n+                )\n+                for path in self._css[medium]\n+            ]\n+            for medium in media\n+        )\n \n     def absolute_path(self, path):\n         \"\"\"\n@@ -104,14 +135,14 @@ class Media:\n         path. An absolute path will be returned unchanged while a relative path\n         will be passed to django.templatetags.static.static().\n         \"\"\"\n-        if path.startswith(('http://', 'https://', '/')):\n+        if path.startswith((\"http://\", \"https://\", \"/\")):\n             return path\n         return static(path)\n \n     def __getitem__(self, name):\n         \"\"\"Return a Media object that only contains media of the given type.\"\"\"\n         if name in MEDIA_TYPES:\n-            return Media(**{str(name): getattr(self, '_' + name)})\n+            return Media(**{str(name): getattr(self, \"_\" + name)})\n         raise KeyError('Unknown media type \"%s\"' % name)\n \n     @staticmethod\n@@ -140,13 +171,19 @@ class Media:\n             else:\n                 if index > last_insert_index:\n                     warnings.warn(\n-                        'Detected duplicate Media files in an opposite order:\\n'\n-                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n+                        \"Detected duplicate Media files in an opposite order:\\n\"\n+                        \"%s\\n%s\"\n+                        % (combined_list[last_insert_index], combined_list[index]),\n                         MediaOrderConflictWarning,\n                     )\n                 # path already exists in the list. Update last_insert_index so\n                 # that the following elements are inserted in front of this one.\n-                last_insert_index = index\n+                # Only update last_insert_index if the path was not in list_1\n+                # (i.e., it was inserted from list_2 in a previous iteration),\n+                # to avoid incorrect conflict warnings when both lists contain\n+                # the same element.\n+                if path not in list_1:\n+                    last_insert_index = index\n         return combined_list\n \n     def __add__(self, other):\n@@ -166,9 +203,9 @@ def media_property(cls):\n             base = Media()\n \n         # Get the media definition for this class\n-        definition = getattr(cls, 'Media', None)\n+        definition = getattr(cls, \"Media\", None)\n         if definition:\n-            extend = getattr(definition, 'extend', True)\n+            extend = getattr(definition, \"extend\", True)\n             if extend:\n                 if extend is True:\n                     m = base\n@@ -179,6 +216,7 @@ def media_property(cls):\n                 return m + Media(definition)\n             return Media(definition)\n         return base\n+\n     return property(_media)\n \n \n@@ -186,10 +224,11 @@ class MediaDefiningClass(type):\n     \"\"\"\n     Metaclass for classes that can have media definitions.\n     \"\"\"\n+\n     def __new__(mcs, name, bases, attrs):\n         new_class = super(MediaDefiningClass, mcs).__new__(mcs, name, bases, attrs)\n \n-        if 'media' not in attrs:\n+        if \"media\" not in attrs:\n             new_class.media = media_property(new_class)\n \n         return new_class\n@@ -212,17 +251,17 @@ class Widget(metaclass=MediaDefiningClass):\n \n     @property\n     def is_hidden(self):\n-        return self.input_type == 'hidden' if hasattr(self, 'input_type') else False\n+        return self.input_type == \"hidden\" if hasattr(self, \"input_type\") else False\n \n     def subwidgets(self, name, value, attrs=None):\n         context = self.get_context(name, value, attrs)\n-        yield context['widget']\n+        yield context[\"widget\"]\n \n     def format_value(self, value):\n         \"\"\"\n         Return a value as it should appear when rendered in a template.\n         \"\"\"\n-        if value == '' or value is None:\n+        if value == \"\" or value is None:\n             return None\n         if self.is_localized:\n             return formats.localize_input(value)\n@@ -230,13 +269,13 @@ class Widget(metaclass=MediaDefiningClass):\n \n     def get_context(self, name, value, attrs):\n         context = {}\n-        context['widget'] = {\n-            'name': name,\n-            'is_hidden': self.is_hidden,\n-            'required': self.is_required,\n-            'value': self.format_value(value),\n-            'attrs': self.build_attrs(self.attrs, attrs),\n-            'template_name': self.template_name,\n+        context[\"widget\"] = {\n+            \"name\": name,\n+            \"is_hidden\": self.is_hidden,\n+            \"required\": self.is_required,\n+            \"value\": self.format_value(value),\n+            \"attrs\": self.build_attrs(self.attrs, attrs),\n+            \"template_name\": self.template_name,\n         }\n         return context\n \n@@ -284,44 +323,45 @@ class Input(Widget):\n     \"\"\"\n     Base class for all <input> widgets.\n     \"\"\"\n+\n     input_type = None  # Subclasses must define this.\n-    template_name = 'django/forms/widgets/input.html'\n+    template_name = \"django/forms/widgets/input.html\"\n \n     def __init__(self, attrs=None):\n         if attrs is not None:\n             attrs = attrs.copy()\n-            self.input_type = attrs.pop('type', self.input_type)\n+            self.input_type = attrs.pop(\"type\", self.input_type)\n         super().__init__(attrs)\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        context['widget']['type'] = self.input_type\n+        context[\"widget\"][\"type\"] = self.input_type\n         return context\n \n \n class TextInput(Input):\n-    input_type = 'text'\n-    template_name = 'django/forms/widgets/text.html'\n+    input_type = \"text\"\n+    template_name = \"django/forms/widgets/text.html\"\n \n \n class NumberInput(Input):\n-    input_type = 'number'\n-    template_name = 'django/forms/widgets/number.html'\n+    input_type = \"number\"\n+    template_name = \"django/forms/widgets/number.html\"\n \n \n class EmailInput(Input):\n-    input_type = 'email'\n-    template_name = 'django/forms/widgets/email.html'\n+    input_type = \"email\"\n+    template_name = \"django/forms/widgets/email.html\"\n \n \n class URLInput(Input):\n-    input_type = 'url'\n-    template_name = 'django/forms/widgets/url.html'\n+    input_type = \"url\"\n+    template_name = \"django/forms/widgets/url.html\"\n \n \n class PasswordInput(Input):\n-    input_type = 'password'\n-    template_name = 'django/forms/widgets/password.html'\n+    input_type = \"password\"\n+    template_name = \"django/forms/widgets/password.html\"\n \n     def __init__(self, attrs=None, render_value=False):\n         super().__init__(attrs)\n@@ -334,8 +374,8 @@ class PasswordInput(Input):\n \n \n class HiddenInput(Input):\n-    input_type = 'hidden'\n-    template_name = 'django/forms/widgets/hidden.html'\n+    input_type = \"hidden\"\n+    template_name = \"django/forms/widgets/hidden.html\"\n \n \n class MultipleHiddenInput(HiddenInput):\n@@ -343,25 +383,26 @@ class MultipleHiddenInput(HiddenInput):\n     Handle <input type=\"hidden\"> for fields that have a list\n     of values.\n     \"\"\"\n-    template_name = 'django/forms/widgets/multiple_hidden.html'\n+\n+    template_name = \"django/forms/widgets/multiple_hidden.html\"\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        final_attrs = context['widget']['attrs']\n-        id_ = context['widget']['attrs'].get('id')\n+        final_attrs = context[\"widget\"][\"attrs\"]\n+        id_ = context[\"widget\"][\"attrs\"].get(\"id\")\n \n         subwidgets = []\n-        for index, value_ in enumerate(context['widget']['value']):\n+        for index, value_ in enumerate(context[\"widget\"][\"value\"]):\n             widget_attrs = final_attrs.copy()\n             if id_:\n                 # An ID attribute was given. Add a numeric index as a suffix\n                 # so that the inputs don't all have the same ID attribute.\n-                widget_attrs['id'] = '%s_%s' % (id_, index)\n+                widget_attrs[\"id\"] = \"%s_%s\" % (id_, index)\n             widget = HiddenInput()\n             widget.is_required = self.is_required\n-            subwidgets.append(widget.get_context(name, value_, widget_attrs)['widget'])\n+            subwidgets.append(widget.get_context(name, value_, widget_attrs)[\"widget\"])\n \n-        context['widget']['subwidgets'] = subwidgets\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n     def value_from_datadict(self, data, files, name):\n@@ -376,9 +417,9 @@ class MultipleHiddenInput(HiddenInput):\n \n \n class FileInput(Input):\n-    input_type = 'file'\n+    input_type = \"file\"\n     needs_multipart_form = True\n-    template_name = 'django/forms/widgets/file.html'\n+    template_name = \"django/forms/widgets/file.html\"\n \n     def format_value(self, value):\n         \"\"\"File input never renders a value.\"\"\"\n@@ -396,29 +437,29 @@ FILE_INPUT_CONTRADICTION = object()\n \n \n class ClearableFileInput(FileInput):\n-    clear_checkbox_label = _('Clear')\n-    initial_text = _('Currently')\n-    input_text = _('Change')\n-    template_name = 'django/forms/widgets/clearable_file_input.html'\n+    clear_checkbox_label = _(\"Clear\")\n+    initial_text = _(\"Currently\")\n+    input_text = _(\"Change\")\n+    template_name = \"django/forms/widgets/clearable_file_input.html\"\n \n     def clear_checkbox_name(self, name):\n         \"\"\"\n         Given the name of the file input, return the name of the clear checkbox\n         input.\n         \"\"\"\n-        return name + '-clear'\n+        return name + \"-clear\"\n \n     def clear_checkbox_id(self, name):\n         \"\"\"\n         Given the name of the clear checkbox input, return the HTML id for it.\n         \"\"\"\n-        return name + '_id'\n+        return name + \"_id\"\n \n     def is_initial(self, value):\n         \"\"\"\n         Return whether value is considered to be initial value.\n         \"\"\"\n-        return bool(value and getattr(value, 'url', False))\n+        return bool(value and getattr(value, \"url\", False))\n \n     def format_value(self, value):\n         \"\"\"\n@@ -431,21 +472,23 @@ class ClearableFileInput(FileInput):\n         context = super().get_context(name, value, attrs)\n         checkbox_name = self.clear_checkbox_name(name)\n         checkbox_id = self.clear_checkbox_id(checkbox_name)\n-        context['widget'].update({\n-            'checkbox_name': checkbox_name,\n-            'checkbox_id': checkbox_id,\n-            'is_initial': self.is_initial(value),\n-            'input_text': self.input_text,\n-            'initial_text': self.initial_text,\n-            'clear_checkbox_label': self.clear_checkbox_label,\n-        })\n+        context[\"widget\"].update(\n+            {\n+                \"checkbox_name\": checkbox_name,\n+                \"checkbox_id\": checkbox_id,\n+                \"is_initial\": self.is_initial(value),\n+                \"input_text\": self.input_text,\n+                \"initial_text\": self.initial_text,\n+                \"clear_checkbox_label\": self.clear_checkbox_label,\n+            }\n+        )\n         return context\n \n     def value_from_datadict(self, data, files, name):\n         upload = super().value_from_datadict(data, files, name)\n         if not self.is_required and CheckboxInput().value_from_datadict(\n-                data, files, self.clear_checkbox_name(name)):\n-\n+            data, files, self.clear_checkbox_name(name)\n+        ):\n             if upload:\n                 # If the user contradicts themselves (uploads a new file AND\n                 # checks the \"clear\" checkbox), we return a unique marker\n@@ -460,24 +503,24 @@ class ClearableFileInput(FileInput):\n \n     def value_omitted_from_data(self, data, files, name):\n         return (\n-            super().value_omitted_from_data(data, files, name) and\n-            self.clear_checkbox_name(name) not in data\n+            super().value_omitted_from_data(data, files, name)\n+            and self.clear_checkbox_name(name) not in data\n         )\n \n \n class Textarea(Widget):\n-    template_name = 'django/forms/widgets/textarea.html'\n+    template_name = \"django/forms/widgets/textarea.html\"\n \n     def __init__(self, attrs=None):\n         # Use slightly better defaults than HTML's 20x2 box\n-        default_attrs = {'cols': '40', 'rows': '10'}\n+        default_attrs = {\"cols\": \"40\", \"rows\": \"10\"}\n         if attrs:\n             default_attrs.update(attrs)\n         super().__init__(default_attrs)\n \n \n class DateTimeBaseInput(TextInput):\n-    format_key = ''\n+    format_key = \"\"\n     supports_microseconds = False\n \n     def __init__(self, attrs=None, format=None):\n@@ -485,32 +528,34 @@ class DateTimeBaseInput(TextInput):\n         self.format = format or None\n \n     def format_value(self, value):\n-        return formats.localize_input(value, self.format or formats.get_format(self.format_key)[0])\n+        return formats.localize_input(\n+            value, self.format or formats.get_format(self.format_key)[0]\n+        )\n \n \n class DateInput(DateTimeBaseInput):\n-    format_key = 'DATE_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/date.html'\n+    format_key = \"DATE_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/date.html\"\n \n \n class DateTimeInput(DateTimeBaseInput):\n-    format_key = 'DATETIME_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/datetime.html'\n+    format_key = \"DATETIME_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/datetime.html\"\n \n \n class TimeInput(DateTimeBaseInput):\n-    format_key = 'TIME_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/time.html'\n+    format_key = \"TIME_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/time.html\"\n \n \n # Defined at module level so that CheckboxInput is picklable (#17976)\n def boolean_check(v):\n-    return not (v is False or v is None or v == '')\n+    return not (v is False or v is None or v == \"\")\n \n \n class CheckboxInput(Input):\n-    input_type = 'checkbox'\n-    template_name = 'django/forms/widgets/checkbox.html'\n+    input_type = \"checkbox\"\n+    template_name = \"django/forms/widgets/checkbox.html\"\n \n     def __init__(self, attrs=None, check_test=None):\n         super().__init__(attrs)\n@@ -520,7 +565,7 @@ class CheckboxInput(Input):\n \n     def format_value(self, value):\n         \"\"\"Only return the 'value' attribute if value isn't empty.\"\"\"\n-        if value is True or value is False or value is None or value == '':\n+        if value is True or value is False or value is None or value == \"\":\n             return\n         return str(value)\n \n@@ -528,7 +573,7 @@ class CheckboxInput(Input):\n         if self.check_test(value):\n             if attrs is None:\n                 attrs = {}\n-            attrs['checked'] = True\n+            attrs[\"checked\"] = True\n         return super().get_context(name, value, attrs)\n \n     def value_from_datadict(self, data, files, name):\n@@ -538,7 +583,7 @@ class CheckboxInput(Input):\n             return False\n         value = data.get(name)\n         # Translate true and false strings to boolean values.\n-        values = {'true': True, 'false': False}\n+        values = {\"true\": True, \"false\": False}\n         if isinstance(value, str):\n             value = values.get(value.lower(), value)\n         return bool(value)\n@@ -555,7 +600,7 @@ class ChoiceWidget(Widget):\n     template_name = None\n     option_template_name = None\n     add_id_index = True\n-    checked_attribute = {'checked': True}\n+    checked_attribute = {\"checked\": True}\n     option_inherits_attrs = True\n \n     def __init__(self, attrs=None, choices=()):\n@@ -592,7 +637,7 @@ class ChoiceWidget(Widget):\n \n         for index, (option_value, option_label) in enumerate(self.choices):\n             if option_value is None:\n-                option_value = ''\n+                option_value = \"\"\n \n             subgroup = []\n             if isinstance(option_label, (list, tuple)):\n@@ -606,52 +651,64 @@ class ChoiceWidget(Widget):\n             groups.append((group_name, subgroup, index))\n \n             for subvalue, sublabel in choices:\n-                selected = (\n-                    str(subvalue) in value and\n-                    (not has_selected or self.allow_multiple_selected)\n+                selected = str(subvalue) in value and (\n+                    not has_selected or self.allow_multiple_selected\n                 )\n                 has_selected |= selected\n-                subgroup.append(self.create_option(\n-                    name, subvalue, sublabel, selected, index,\n-                    subindex=subindex, attrs=attrs,\n-                ))\n+                subgroup.append(\n+                    self.create_option(\n+                        name,\n+                        subvalue,\n+                        sublabel,\n+                        selected,\n+                        index,\n+                        subindex=subindex,\n+                        attrs=attrs,\n+                    )\n+                )\n                 if subindex is not None:\n                     subindex += 1\n         return groups\n \n-    def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n+    def create_option(\n+        self, name, value, label, selected, index, subindex=None, attrs=None\n+    ):\n         index = str(index) if subindex is None else \"%s_%s\" % (index, subindex)\n         if attrs is None:\n             attrs = {}\n-        option_attrs = self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n+        option_attrs = (\n+            self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n+        )\n         if selected:\n             option_attrs.update(self.checked_attribute)\n-        if 'id' in option_attrs:\n-            option_attrs['id'] = self.id_for_label(option_attrs['id'], index)\n+        if \"id\" in option_attrs:\n+            option_attrs[\"id\"] = self.id_for_label(option_attrs[\"id\"], index)\n         return {\n-            'name': name,\n-            'value': value,\n-            'label': label,\n-            'selected': selected,\n-            'index': index,\n-            'attrs': option_attrs,\n-            'type': self.input_type,\n-            'template_name': self.option_template_name,\n-            'wrap_label': True,\n+            \"name\": name,\n+            \"value\": value,\n+            \"label\": label,\n+            \"selected\": selected,\n+            \"index\": index,\n+            \"attrs\": option_attrs,\n+            \"type\": self.input_type,\n+            \"template_name\": self.option_template_name,\n+            \"wrap_label\": True,\n         }\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        context['widget']['optgroups'] = self.optgroups(name, context['widget']['value'], attrs)\n+        context[\"widget\"][\"optgroups\"] = self.optgroups(\n+            name, context[\"widget\"][\"value\"], attrs\n+        )\n         return context\n \n-    def id_for_label(self, id_, index='0'):\n+    def id_for_label(self, id_, index=\"0\"):\n         \"\"\"\n         Use an incremented id for each option where the main widget\n         references the zero index.\n         \"\"\"\n         if id_ and self.add_id_index:\n-            id_ = '%s_%s' % (id_, index)\n+            id_ = \"%s_%s\" % (id_, index)\n         return id_\n \n     def value_from_datadict(self, data, files, name):\n@@ -669,28 +726,28 @@ class ChoiceWidget(Widget):\n             return []\n         if not isinstance(value, (tuple, list)):\n             value = [value]\n-        return [str(v) if v is not None else '' for v in value]\n+        return [str(v) if v is not None else \"\" for v in value]\n \n \n class Select(ChoiceWidget):\n-    input_type = 'select'\n-    template_name = 'django/forms/widgets/select.html'\n-    option_template_name = 'django/forms/widgets/select_option.html'\n+    input_type = \"select\"\n+    template_name = \"django/forms/widgets/select.html\"\n+    option_template_name = \"django/forms/widgets/select_option.html\"\n     add_id_index = False\n-    checked_attribute = {'selected': True}\n+    checked_attribute = {\"selected\": True}\n     option_inherits_attrs = False\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         if self.allow_multiple_selected:\n-            context['widget']['attrs']['multiple'] = True\n+            context[\"widget\"][\"attrs\"][\"multiple\"] = True\n         return context\n \n     @staticmethod\n     def _choice_has_empty_value(choice):\n         \"\"\"Return True if the choice's value is empty string or None.\"\"\"\n         value, _ = choice\n-        return value is None or value == ''\n+        return value is None or value == \"\"\n \n     def use_required_attribute(self, initial):\n         \"\"\"\n@@ -703,44 +760,52 @@ class Select(ChoiceWidget):\n             return use_required_attribute\n \n         first_choice = next(iter(self.choices), None)\n-        return use_required_attribute and first_choice is not None and self._choice_has_empty_value(first_choice)\n+        return (\n+            use_required_attribute\n+            and first_choice is not None\n+            and self._choice_has_empty_value(first_choice)\n+        )\n \n \n class NullBooleanSelect(Select):\n     \"\"\"\n     A Select Widget intended to be used with NullBooleanField.\n     \"\"\"\n+\n     def __init__(self, attrs=None):\n         choices = (\n-            ('unknown', _('Unknown')),\n-            ('true', _('Yes')),\n-            ('false', _('No')),\n+            (\"unknown\", _(\"Unknown\")),\n+            (\"true\", _(\"Yes\")),\n+            (\"false\", _(\"No\")),\n         )\n         super().__init__(attrs, choices)\n \n     def format_value(self, value):\n         try:\n             return {\n-                True: 'true', False: 'false',\n-                'true': 'true', 'false': 'false',\n+                True: \"true\",\n+                False: \"false\",\n+                \"true\": \"true\",\n+                \"false\": \"false\",\n                 # For backwards compatibility with Django < 2.2.\n-                '2': 'true', '3': 'false',\n+                \"2\": \"true\",\n+                \"3\": \"false\",\n             }[value]\n         except KeyError:\n-            return 'unknown'\n+            return \"unknown\"\n \n     def value_from_datadict(self, data, files, name):\n         value = data.get(name)\n         return {\n             True: True,\n-            'True': True,\n-            'False': False,\n+            \"True\": True,\n+            \"False\": False,\n             False: False,\n-            'true': True,\n-            'false': False,\n+            \"true\": True,\n+            \"false\": False,\n             # For backwards compatibility with Django < 2.2.\n-            '2': True,\n-            '3': False,\n+            \"2\": True,\n+            \"3\": False,\n         }.get(value)\n \n \n@@ -761,16 +826,16 @@ class SelectMultiple(Select):\n \n \n class RadioSelect(ChoiceWidget):\n-    input_type = 'radio'\n-    template_name = 'django/forms/widgets/radio.html'\n-    option_template_name = 'django/forms/widgets/radio_option.html'\n+    input_type = \"radio\"\n+    template_name = \"django/forms/widgets/radio.html\"\n+    option_template_name = \"django/forms/widgets/radio_option.html\"\n \n \n class CheckboxSelectMultiple(ChoiceWidget):\n     allow_multiple_selected = True\n-    input_type = 'checkbox'\n-    template_name = 'django/forms/widgets/checkbox_select.html'\n-    option_template_name = 'django/forms/widgets/checkbox_option.html'\n+    input_type = \"checkbox\"\n+    template_name = \"django/forms/widgets/checkbox_select.html\"\n+    option_template_name = \"django/forms/widgets/checkbox_option.html\"\n \n     def use_required_attribute(self, initial):\n         # Don't use the 'required' attribute because browser validation would\n@@ -783,12 +848,12 @@ class CheckboxSelectMultiple(ChoiceWidget):\n         return False\n \n     def id_for_label(self, id_, index=None):\n-        \"\"\"\"\n+        \"\"\" \"\n         Don't include for=\"field_0\" in <label> because clicking such a label\n         would toggle the first checkbox.\n         \"\"\"\n         if index is None:\n-            return ''\n+            return \"\"\n         return super().id_for_label(id_, index)\n \n \n@@ -802,7 +867,8 @@ class MultiWidget(Widget):\n \n     You'll probably want to use this class with MultiValueField.\n     \"\"\"\n-    template_name = 'django/forms/widgets/multiwidget.html'\n+\n+    template_name = \"django/forms/widgets/multiwidget.html\"\n \n     def __init__(self, widgets, attrs=None):\n         self.widgets = [w() if isinstance(w, type) else w for w in widgets]\n@@ -822,38 +888,43 @@ class MultiWidget(Widget):\n         if not isinstance(value, list):\n             value = self.decompress(value)\n \n-        final_attrs = context['widget']['attrs']\n-        input_type = final_attrs.pop('type', None)\n-        id_ = final_attrs.get('id')\n+        final_attrs = context[\"widget\"][\"attrs\"]\n+        input_type = final_attrs.pop(\"type\", None)\n+        id_ = final_attrs.get(\"id\")\n         subwidgets = []\n         for i, widget in enumerate(self.widgets):\n             if input_type is not None:\n                 widget.input_type = input_type\n-            widget_name = '%s_%s' % (name, i)\n+            widget_name = \"%s_%s\" % (name, i)\n             try:\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n             if id_:\n                 widget_attrs = final_attrs.copy()\n-                widget_attrs['id'] = '%s_%s' % (id_, i)\n+                widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)\n             else:\n                 widget_attrs = final_attrs\n-            subwidgets.append(widget.get_context(widget_name, widget_value, widget_attrs)['widget'])\n-        context['widget']['subwidgets'] = subwidgets\n+            subwidgets.append(\n+                widget.get_context(widget_name, widget_value, widget_attrs)[\"widget\"]\n+            )\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n     def id_for_label(self, id_):\n         if id_:\n-            id_ += '_0'\n+            id_ += \"_0\"\n         return id_\n \n     def value_from_datadict(self, data, files, name):\n-        return [widget.value_from_datadict(data, files, name + '_%s' % i) for i, widget in enumerate(self.widgets)]\n+        return [\n+            widget.value_from_datadict(data, files, name + \"_%s\" % i)\n+            for i, widget in enumerate(self.widgets)\n+        ]\n \n     def value_omitted_from_data(self, data, files, name):\n         return all(\n-            widget.value_omitted_from_data(data, files, name + '_%s' % i)\n+            widget.value_omitted_from_data(data, files, name + \"_%s\" % i)\n             for i, widget in enumerate(self.widgets)\n         )\n \n@@ -863,7 +934,7 @@ class MultiWidget(Widget):\n         The given value can be assumed to be valid, but not necessarily\n         non-empty.\n         \"\"\"\n-        raise NotImplementedError('Subclasses must implement this method.')\n+        raise NotImplementedError(\"Subclasses must implement this method.\")\n \n     def _get_media(self):\n         \"\"\"\n@@ -874,6 +945,7 @@ class MultiWidget(Widget):\n         for w in self.widgets:\n             media = media + w.media\n         return media\n+\n     media = property(_get_media)\n \n     def __deepcopy__(self, memo):\n@@ -890,10 +962,18 @@ class SplitDateTimeWidget(MultiWidget):\n     \"\"\"\n     A widget that splits datetime input into two <input type=\"text\"> boxes.\n     \"\"\"\n-    supports_microseconds = False\n-    template_name = 'django/forms/widgets/splitdatetime.html'\n \n-    def __init__(self, attrs=None, date_format=None, time_format=None, date_attrs=None, time_attrs=None):\n+    supports_microseconds = False\n+    template_name = \"django/forms/widgets/splitdatetime.html\"\n+\n+    def __init__(\n+        self,\n+        attrs=None,\n+        date_format=None,\n+        time_format=None,\n+        date_attrs=None,\n+        time_attrs=None,\n+    ):\n         widgets = (\n             DateInput(\n                 attrs=attrs if date_attrs is None else date_attrs,\n@@ -917,12 +997,20 @@ class SplitHiddenDateTimeWidget(SplitDateTimeWidget):\n     \"\"\"\n     A widget that splits datetime input into two <input type=\"hidden\"> inputs.\n     \"\"\"\n-    template_name = 'django/forms/widgets/splithiddendatetime.html'\n \n-    def __init__(self, attrs=None, date_format=None, time_format=None, date_attrs=None, time_attrs=None):\n+    template_name = \"django/forms/widgets/splithiddendatetime.html\"\n+\n+    def __init__(\n+        self,\n+        attrs=None,\n+        date_format=None,\n+        time_format=None,\n+        date_attrs=None,\n+        time_attrs=None,\n+    ):\n         super().__init__(attrs, date_format, time_format, date_attrs, time_attrs)\n         for widget in self.widgets:\n-            widget.input_type = 'hidden'\n+            widget.input_type = \"hidden\"\n \n \n class SelectDateWidget(Widget):\n@@ -932,14 +1020,15 @@ class SelectDateWidget(Widget):\n     This also serves as an example of a Widget that has more than one HTML\n     element and hence implements value_from_datadict.\n     \"\"\"\n-    none_value = ('', '---')\n-    month_field = '%s_month'\n-    day_field = '%s_day'\n-    year_field = '%s_year'\n-    template_name = 'django/forms/widgets/select_date.html'\n-    input_type = 'select'\n+\n+    none_value = (\"\", \"---\")\n+    month_field = \"%s_month\"\n+    day_field = \"%s_day\"\n+    year_field = \"%s_year\"\n+    template_name = \"django/forms/widgets/select_date.html\"\n+    input_type = \"select\"\n     select_widget = Select\n-    date_re = re.compile(r'(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$')\n+    date_re = re.compile(r\"(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$\")\n \n     def __init__(self, attrs=None, years=None, months=None, empty_label=None):\n         self.attrs = attrs or {}\n@@ -960,14 +1049,14 @@ class SelectDateWidget(Widget):\n         # Optional string, list, or tuple to use as empty_label.\n         if isinstance(empty_label, (list, tuple)):\n             if not len(empty_label) == 3:\n-                raise ValueError('empty_label list/tuple must have 3 elements.')\n+                raise ValueError(\"empty_label list/tuple must have 3 elements.\")\n \n-            self.year_none_value = ('', empty_label[0])\n-            self.month_none_value = ('', empty_label[1])\n-            self.day_none_value = ('', empty_label[2])\n+            self.year_none_value = (\"\", empty_label[0])\n+            self.month_none_value = (\"\", empty_label[1])\n+            self.day_none_value = (\"\", empty_label[2])\n         else:\n             if empty_label is not None:\n-                self.none_value = ('', empty_label)\n+                self.none_value = (\"\", empty_label)\n \n             self.year_none_value = self.none_value\n             self.month_none_value = self.none_value\n@@ -980,33 +1069,40 @@ class SelectDateWidget(Widget):\n         if not self.is_required:\n             year_choices.insert(0, self.year_none_value)\n         year_name = self.year_field % name\n-        date_context['year'] = self.select_widget(attrs, choices=year_choices).get_context(\n+        date_context[\"year\"] = self.select_widget(\n+            attrs, choices=year_choices\n+        ).get_context(\n             name=year_name,\n-            value=context['widget']['value']['year'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % year_name},\n+            value=context[\"widget\"][\"value\"][\"year\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % year_name},\n         )\n         month_choices = list(self.months.items())\n         if not self.is_required:\n             month_choices.insert(0, self.month_none_value)\n         month_name = self.month_field % name\n-        date_context['month'] = self.select_widget(attrs, choices=month_choices).get_context(\n+        date_context[\"month\"] = self.select_widget(\n+            attrs, choices=month_choices\n+        ).get_context(\n             name=month_name,\n-            value=context['widget']['value']['month'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % month_name},\n+            value=context[\"widget\"][\"value\"][\"month\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % month_name},\n         )\n         day_choices = [(i, i) for i in range(1, 32)]\n         if not self.is_required:\n             day_choices.insert(0, self.day_none_value)\n         day_name = self.day_field % name\n-        date_context['day'] = self.select_widget(attrs, choices=day_choices,).get_context(\n+        date_context[\"day\"] = self.select_widget(\n+            attrs,\n+            choices=day_choices,\n+        ).get_context(\n             name=day_name,\n-            value=context['widget']['value']['day'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % day_name},\n+            value=context[\"widget\"][\"value\"][\"day\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % day_name},\n         )\n         subwidgets = []\n         for field in self._parse_date_fmt():\n-            subwidgets.append(date_context[field]['widget'])\n-        context['widget']['subwidgets'] = subwidgets\n+            subwidgets.append(date_context[field][\"widget\"])\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n     def format_value(self, value):\n@@ -1023,47 +1119,47 @@ class SelectDateWidget(Widget):\n             if match:\n                 # Convert any zeros in the date to empty strings to match the\n                 # empty option value.\n-                year, month, day = [int(val) or '' for val in match.groups()]\n+                year, month, day = [int(val) or \"\" for val in match.groups()]\n             elif settings.USE_L10N:\n-                input_format = get_format('DATE_INPUT_FORMATS')[0]\n+                input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n                 try:\n                     d = datetime.datetime.strptime(value, input_format)\n                 except ValueError:\n                     pass\n                 else:\n                     year, month, day = d.year, d.month, d.day\n-        return {'year': year, 'month': month, 'day': day}\n+        return {\"year\": year, \"month\": month, \"day\": day}\n \n     @staticmethod\n     def _parse_date_fmt():\n-        fmt = get_format('DATE_FORMAT')\n+        fmt = get_format(\"DATE_FORMAT\")\n         escaped = False\n         for char in fmt:\n             if escaped:\n                 escaped = False\n-            elif char == '\\\\':\n+            elif char == \"\\\\\":\n                 escaped = True\n-            elif char in 'Yy':\n-                yield 'year'\n-            elif char in 'bEFMmNn':\n-                yield 'month'\n-            elif char in 'dj':\n-                yield 'day'\n+            elif char in \"Yy\":\n+                yield \"year\"\n+            elif char in \"bEFMmNn\":\n+                yield \"month\"\n+            elif char in \"dj\":\n+                yield \"day\"\n \n     def id_for_label(self, id_):\n         for first_select in self._parse_date_fmt():\n-            return '%s_%s' % (id_, first_select)\n-        return '%s_month' % id_\n+            return \"%s_%s\" % (id_, first_select)\n+        return \"%s_month\" % id_\n \n     def value_from_datadict(self, data, files, name):\n         y = data.get(self.year_field % name)\n         m = data.get(self.month_field % name)\n         d = data.get(self.day_field % name)\n-        if y == m == d == '':\n+        if y == m == d == \"\":\n             return None\n         if y is not None and m is not None and d is not None:\n             if settings.USE_L10N:\n-                input_format = get_format('DATE_INPUT_FORMATS')[0]\n+                input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n                 try:\n                     date_value = datetime.date(int(y), int(m), int(d))\n                 except ValueError:\n@@ -1073,11 +1169,11 @@ class SelectDateWidget(Widget):\n                     return date_value.strftime(input_format)\n             # Return pseudo-ISO dates with zeros for any unselected values,\n             # e.g. '2017-0-23'.\n-            return '%s-%s-%s' % (y or 0, m or 0, d or 0)\n+            return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n         return data.get(name)\n \n     def value_omitted_from_data(self, data, files, name):\n         return not any(\n-            ('{}_{}'.format(name, interval) in data)\n-            for interval in ('year', 'month', 'day')\n+            (\"{}_{}\".format(name, interval) in data)\n+            for interval in (\"year\", \"month\", \"day\")\n         )\n"}
{"instance_id": "django__django-11039", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex f0b663222a..01e262abbe 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -11,33 +11,39 @@ class Command(BaseCommand):\n     output_transaction = True\n \n     def add_arguments(self, parser):\n-        parser.add_argument('app_label', help='App label of the application containing the migration.')\n-        parser.add_argument('migration_name', help='Migration name to print the SQL for.')\n         parser.add_argument(\n-            '--database', default=DEFAULT_DB_ALIAS,\n+            \"app_label\", help=\"App label of the application containing the migration.\"\n+        )\n+        parser.add_argument(\n+            \"migration_name\", help=\"Migration name to print the SQL for.\"\n+        )\n+        parser.add_argument(\n+            \"--database\",\n+            default=DEFAULT_DB_ALIAS,\n             help='Nominates a database to create SQL for. Defaults to the \"default\" database.',\n         )\n         parser.add_argument(\n-            '--backwards', action='store_true',\n-            help='Creates SQL to unapply the migration, rather than to apply it',\n+            \"--backwards\",\n+            action=\"store_true\",\n+            help=\"Creates SQL to unapply the migration, rather than to apply it\",\n         )\n \n     def execute(self, *args, **options):\n         # sqlmigrate doesn't support coloring its output but we need to force\n         # no_color=True so that the BEGIN/COMMIT statements added by\n         # output_transaction don't get colored either.\n-        options['no_color'] = True\n+        options[\"no_color\"] = True\n         return super().execute(*args, **options)\n \n     def handle(self, *args, **options):\n         # Get the database we're operating from\n-        connection = connections[options['database']]\n+        connection = connections[options[\"database\"]]\n \n         # Load up an executor to get all the migration data\n         executor = MigrationExecutor(connection)\n \n         # Resolve command-line arguments into a migration\n-        app_label, migration_name = options['app_label'], options['migration_name']\n+        app_label, migration_name = options[\"app_label\"], options[\"migration_name\"]\n         # Validate app_label\n         try:\n             apps.get_app_config(app_label)\n@@ -46,20 +52,28 @@ class Command(BaseCommand):\n         if app_label not in executor.loader.migrated_apps:\n             raise CommandError(\"App '%s' does not have migrations\" % app_label)\n         try:\n-            migration = executor.loader.get_migration_by_prefix(app_label, migration_name)\n+            migration = executor.loader.get_migration_by_prefix(\n+                app_label, migration_name\n+            )\n         except AmbiguityError:\n-            raise CommandError(\"More than one migration matches '%s' in app '%s'. Please be more specific.\" % (\n-                migration_name, app_label))\n+            raise CommandError(\n+                \"More than one migration matches '%s' in app '%s'. Please be more specific.\"\n+                % (migration_name, app_label)\n+            )\n         except KeyError:\n-            raise CommandError(\"Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?\" % (\n-                migration_name, app_label))\n+            raise CommandError(\n+                \"Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?\"\n+                % (migration_name, app_label)\n+            )\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = (\n+            migration.atomic and connection.features.can_rollback_ddl\n+        )\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n-        plan = [(executor.loader.graph.nodes[targets[0]], options['backwards'])]\n+        plan = [(executor.loader.graph.nodes[targets[0]], options[\"backwards\"])]\n         sql_statements = executor.collect_sql(plan)\n-        return '\\n'.join(sql_statements)\n+        return \"\\n\".join(sql_statements)\n"}
{"instance_id": "django__django-11049", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/conf/locale/en/LC_MESSAGES/django.po b/django/conf/locale/en/LC_MESSAGES/django.po\nindex 2c52175822..e95f84be75 100644\n--- a/django/conf/locale/en/LC_MESSAGES/django.po\n+++ b/django/conf/locale/en/LC_MESSAGES/django.po\n@@ -645,7 +645,7 @@ msgstr \"\"\n #: db/models/fields/__init__.py:1587\n #, python-format\n msgid \"\"\n-\"'%(value)s' value has an invalid format. It must be in [DD] [HH:[MM:]]ss[.\"\n+\"'%(value)s' value has an invalid format. It must be in [DD] [[HH:]MM:]ss[.\"\n \"uuuuuu] format.\"\n msgstr \"\"\n \ndiff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f32ce64629..b7705f0f94 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -12,6 +12,7 @@ from django import forms\n from django.apps import apps\n from django.conf import settings\n from django.core import checks, exceptions, validators\n+\n # When the _meta object was formalized, this exception was moved to\n # django.core.exceptions. It is retained here for backwards compatibility\n # purposes.\n@@ -22,7 +23,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -32,14 +36,37 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FieldDoesNotExist', 'FilePathField',\n-    'FloatField', 'GenericIPAddressField', 'IPAddressField', 'IntegerField',\n-    'NOT_PROVIDED', 'NullBooleanField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallIntegerField', 'TextField',\n-    'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FieldDoesNotExist\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -75,6 +102,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -101,15 +129,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -125,18 +153,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -172,7 +219,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -182,19 +229,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -212,12 +259,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -225,15 +272,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % (LOOKUP_SEP,),\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -244,14 +291,16 @@ class Field(RegisterLookupMixin):\n             return []\n \n         def is_value(value, accept_promise=True):\n-            return isinstance(value, (str, Promise) if accept_promise else str) or not is_iterable(value)\n+            return isinstance(\n+                value, (str, Promise) if accept_promise else str\n+            ) or not is_iterable(value)\n \n         if is_value(self.choices, accept_promise=False):\n             return [\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -285,7 +334,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -295,25 +344,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -322,7 +376,9 @@ class Field(RegisterLookupMixin):\n     def _check_backend_specific_checks(self, **kwargs):\n         app_label = self.model._meta.app_label\n         for db in connections:\n-            if router.allow_migrate(db, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                db, app_label, model_name=self.model._meta.model_name\n+            ):\n                 return connections[db].validation.check_field(self, **kwargs)\n         return []\n \n@@ -336,11 +392,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -350,25 +407,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -378,6 +434,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -385,6 +442,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -444,7 +502,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -513,7 +571,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -532,7 +590,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -541,10 +599,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -582,7 +643,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -609,16 +670,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -632,7 +693,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -642,7 +703,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -704,7 +767,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -721,7 +784,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -743,8 +806,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, DeferredAttribute(self.attname))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            setattr(\n+                cls,\n+                \"get_%s_display\" % self.name,\n+                partialmethod(cls._get_FIELD_display, field=self),\n+            )\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n@@ -803,11 +869,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -815,7 +891,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -823,12 +901,14 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         return (blank_choice if include_blank else []) + [\n             (choice_func(x), str(x))\n-            for x in rel_model._default_manager.complex_filter(limit_choices_to).order_by(*ordering)\n+            for x in rel_model._default_manager.complex_filter(\n+                limit_choices_to\n+            ).order_by(*ordering)\n         ]\n \n     def value_to_string(self, obj):\n@@ -849,6 +929,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -857,24 +938,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -883,9 +965,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -902,11 +994,11 @@ class AutoField(Field):\n \n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be an integer.\"),\n+        \"invalid\": _(\"'%(value)s' value must be an integer.\"),\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -919,9 +1011,9 @@ class AutoField(Field):\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -929,8 +1021,8 @@ class AutoField(Field):\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -943,9 +1035,9 @@ class AutoField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def rel_db_type(self, connection):\n@@ -962,13 +1054,16 @@ class AutoField(Field):\n \n     def get_prep_value(self, value):\n         from django.db.models.expressions import OuterRef\n+\n         value = super().get_prep_value(value)\n         if value is None or isinstance(value, OuterRef):\n             return value\n         return int(value)\n \n     def contribute_to_class(self, cls, name, **kwargs):\n-        assert not cls._meta.auto_field, \"Model %s can't have more than one AutoField.\" % cls._meta.label\n+        assert not cls._meta.auto_field, (\n+            \"Model %s can't have more than one AutoField.\" % cls._meta.label\n+        )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n \n@@ -989,8 +1084,8 @@ class BigAutoField(AutoField):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be either True or False.\"),\n-        'invalid_nullable': _(\"'%(value)s' value must be either True, False, or None.\"),\n+        \"invalid\": _(\"'%(value)s' value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"'%(value)s' value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -1003,14 +1098,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -1021,14 +1116,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -1051,16 +1146,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1087,10 +1185,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1099,20 +1197,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1124,8 +1220,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1133,7 +1235,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1146,19 +1248,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid date format. It must be \"\n-                     \"in YYYY-MM-DD format.\"),\n-        'invalid_date': _(\"'%(value)s' value has the correct format (YYYY-MM-DD) \"\n-                          \"but it is an invalid date.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"'%(value)s' value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1189,13 +1296,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1204,12 +1311,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1234,15 +1341,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1257,12 +1364,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1277,25 +1390,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"),\n-        'invalid_date': _(\"'%(value)s' value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _(\"'%(value)s' value has the correct format \"\n-                              \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n-                              \"but it is an invalid date/time.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1332,13 +1453,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1359,10 +1480,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1373,9 +1496,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1384,15 +1507,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1414,13 +1537,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1433,24 +1557,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be a decimal number.\"),\n+        \"invalid\": _(\"'%(value)s' value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1477,7 +1609,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1485,7 +1617,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1501,7 +1633,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1509,7 +1641,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1521,7 +1653,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1539,9 +1671,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1556,25 +1688,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except decimal.InvalidOperation:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1584,10 +1720,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1608,9 +1747,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1628,13 +1767,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1643,7 +1784,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1655,20 +1796,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1683,23 +1835,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1711,15 +1863,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1728,7 +1882,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be a float.\"),\n+        \"invalid\": _(\"'%(value)s' value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1748,22 +1902,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be an integer.\"),\n+        \"invalid\": _(\"'%(value)s' value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1777,10 +1933,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1792,13 +1949,17 @@ class IntegerField(Field):\n         validators_ = super().validators\n         internal_type = self.get_internal_type()\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n-        if (min_value is not None and not\n-            any(isinstance(validator, validators.MinValueValidator) and\n-                validator.limit_value >= min_value for validator in validators_)):\n+        if min_value is not None and not any(\n+            isinstance(validator, validators.MinValueValidator)\n+            and validator.limit_value >= min_value\n+            for validator in validators_\n+        ):\n             validators_.append(validators.MinValueValidator(min_value))\n-        if (max_value is not None and not\n-            any(isinstance(validator, validators.MaxValueValidator) and\n-                validator.limit_value <= max_value for validator in validators_)):\n+        if max_value is not None and not any(\n+            isinstance(validator, validators.MaxValueValidator)\n+            and validator.limit_value <= max_value\n+            for validator in validators_\n+        ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n \n@@ -1818,16 +1979,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1838,32 +2001,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1881,14 +2046,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1898,13 +2071,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1912,11 +2085,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1928,8 +2101,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1941,7 +2116,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1949,29 +2124,31 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value must be either None, True or False.\"),\n-        'invalid_nullable': _(\"'%(value)s' value must be either None, True or False.\"),\n+        \"invalid\": _(\"'%(value)s' value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"'%(value)s' value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1979,7 +2156,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -2002,10 +2178,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2015,17 +2193,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -2034,24 +2216,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2080,29 +2264,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"HH:MM[:ss[.uuuuuu]] format.\"),\n-        'invalid_time': _(\"'%(value)s' value has the correct format \"\n-                          \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"),\n+        \"invalid\": _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"'%(value)s' value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2136,13 +2327,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2155,8 +2346,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2179,15 +2370,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2210,13 +2401,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2224,30 +2417,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2255,9 +2450,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2270,8 +2465,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2282,29 +2477,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' is not a valid UUID.\"),\n+        \"invalid\": _(\"'%(value)s' is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2322,19 +2517,21 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n"}
{"instance_id": "django__django-11099", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..9571d49d66 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,19 +7,19 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r\"\\A[\\w.@+-]+\\Z\"\n     message = _(\n-        'Enter a valid username. This value may contain only English letters, '\n-        'numbers, and @/./+/-/_ characters.'\n+        \"Enter a valid username. This value may contain only English letters, \"\n+        \"numbers, and @/./+/-/_ characters.\"\n     )\n     flags = re.ASCII\n \n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r\"\\A[\\w.@+-]+\\Z\"\n     message = _(\n-        'Enter a valid username. This value may contain only letters, '\n-        'numbers, and @/./+/-/_ characters.'\n+        \"Enter a valid username. This value may contain only letters, \"\n+        \"numbers, and @/./+/-/_ characters.\"\n     )\n     flags = 0\n"}
{"instance_id": "django__django-11133", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..49927d50e4 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -18,7 +18,7 @@ from django.utils import timezone\n from django.utils.encoding import iri_to_uri\n from django.utils.http import http_date\n \n-_charset_from_content_type_re = re.compile(r';\\s*charset=(?P<charset>[^\\s;]+)', re.I)\n+_charset_from_content_type_re = re.compile(r\";\\s*charset=(?P<charset>[^\\s;]+)\", re.I)\n \n \n class BadHeaderError(ValueError):\n@@ -50,15 +50,15 @@ class HttpResponseBase:\n             try:\n                 self.status_code = int(status)\n             except (ValueError, TypeError):\n-                raise TypeError('HTTP status code must be an integer.')\n+                raise TypeError(\"HTTP status code must be an integer.\")\n \n             if not 100 <= self.status_code <= 599:\n-                raise ValueError('HTTP status code must be an integer from 100 to 599.')\n+                raise ValueError(\"HTTP status code must be an integer from 100 to 599.\")\n         self._reason_phrase = reason\n         self._charset = charset\n         if content_type is None:\n-            content_type = 'text/html; charset=%s' % self.charset\n-        self['Content-Type'] = content_type\n+            content_type = \"text/html; charset=%s\" % self.charset\n+        self[\"Content-Type\"] = content_type\n \n     @property\n     def reason_phrase(self):\n@@ -66,7 +66,7 @@ class HttpResponseBase:\n             return self._reason_phrase\n         # Leave self._reason_phrase unset in order to use the default\n         # reason phrase for status code.\n-        return responses.get(self.status_code, 'Unknown Status Code')\n+        return responses.get(self.status_code, \"Unknown Status Code\")\n \n     @reason_phrase.setter\n     def reason_phrase(self, value):\n@@ -76,11 +76,11 @@ class HttpResponseBase:\n     def charset(self):\n         if self._charset is not None:\n             return self._charset\n-        content_type = self.get('Content-Type', '')\n+        content_type = self.get(\"Content-Type\", \"\")\n         matched = _charset_from_content_type_re.search(content_type)\n         if matched:\n             # Extract the charset and strip its double quotes\n-            return matched.group('charset').replace('\"', '')\n+            return matched.group(\"charset\").replace('\"', \"\")\n         return settings.DEFAULT_CHARSET\n \n     @charset.setter\n@@ -89,20 +89,21 @@ class HttpResponseBase:\n \n     def serialize_headers(self):\n         \"\"\"HTTP headers as a bytestring.\"\"\"\n+\n         def to_bytes(val, encoding):\n             return val if isinstance(val, bytes) else val.encode(encoding)\n \n         headers = [\n-            (to_bytes(key, 'ascii') + b': ' + to_bytes(value, 'latin-1'))\n+            (to_bytes(key, \"ascii\") + b\": \" + to_bytes(value, \"latin-1\"))\n             for key, value in self._headers.values()\n         ]\n-        return b'\\r\\n'.join(headers)\n+        return b\"\\r\\n\".join(headers)\n \n     __bytes__ = serialize_headers\n \n     @property\n     def _content_type_for_repr(self):\n-        return ', \"%s\"' % self['Content-Type'] if 'Content-Type' in self else ''\n+        return ', \"%s\"' % self[\"Content-Type\"] if \"Content-Type\" in self else \"\"\n \n     def _convert_to_charset(self, value, charset, mime_encode=False):\n         \"\"\"\n@@ -113,9 +114,14 @@ class HttpResponseBase:\n         \"\"\"\n         if not isinstance(value, (bytes, str)):\n             value = str(value)\n-        if ((isinstance(value, bytes) and (b'\\n' in value or b'\\r' in value)) or\n-                isinstance(value, str) and ('\\n' in value or '\\r' in value)):\n-            raise BadHeaderError(\"Header values can't contain newlines (got %r)\" % value)\n+        if (\n+            (isinstance(value, bytes) and (b\"\\n\" in value or b\"\\r\" in value))\n+            or isinstance(value, str)\n+            and (\"\\n\" in value or \"\\r\" in value)\n+        ):\n+            raise BadHeaderError(\n+                \"Header values can't contain newlines (got %r)\" % value\n+            )\n         try:\n             if isinstance(value, str):\n                 # Ensure string is valid in given charset\n@@ -125,15 +131,15 @@ class HttpResponseBase:\n                 value = value.decode(charset)\n         except UnicodeError as e:\n             if mime_encode:\n-                value = Header(value, 'utf-8', maxlinelen=sys.maxsize).encode()\n+                value = Header(value, \"utf-8\", maxlinelen=sys.maxsize).encode()\n             else:\n-                e.reason += ', HTTP response headers must be in %s format' % charset\n+                e.reason += \", HTTP response headers must be in %s format\" % charset\n                 raise\n         return value\n \n     def __setitem__(self, header, value):\n-        header = self._convert_to_charset(header, 'ascii')\n-        value = self._convert_to_charset(value, 'latin-1', mime_encode=True)\n+        header = self._convert_to_charset(header, \"ascii\")\n+        value = self._convert_to_charset(value, \"latin-1\", mime_encode=True)\n         self._headers[header.lower()] = (header, value)\n \n     def __delitem__(self, header):\n@@ -154,8 +160,18 @@ class HttpResponseBase:\n     def get(self, header, alternate=None):\n         return self._headers.get(header.lower(), (None, alternate))[1]\n \n-    def set_cookie(self, key, value='', max_age=None, expires=None, path='/',\n-                   domain=None, secure=False, httponly=False, samesite=None):\n+    def set_cookie(\n+        self,\n+        key,\n+        value=\"\",\n+        max_age=None,\n+        expires=None,\n+        path=\"/\",\n+        domain=None,\n+        secure=False,\n+        httponly=False,\n+        samesite=None,\n+    ):\n         \"\"\"\n         Set a cookie.\n \n@@ -179,43 +195,47 @@ class HttpResponseBase:\n                 expires = None\n                 max_age = max(0, delta.days * 86400 + delta.seconds)\n             else:\n-                self.cookies[key]['expires'] = expires\n+                self.cookies[key][\"expires\"] = expires\n         else:\n-            self.cookies[key]['expires'] = ''\n+            self.cookies[key][\"expires\"] = \"\"\n         if max_age is not None:\n-            self.cookies[key]['max-age'] = max_age\n+            self.cookies[key][\"max-age\"] = max_age\n             # IE requires expires, so set it if hasn't been already.\n             if not expires:\n-                self.cookies[key]['expires'] = http_date(time.time() + max_age)\n+                self.cookies[key][\"expires\"] = http_date(time.time() + max_age)\n         if path is not None:\n-            self.cookies[key]['path'] = path\n+            self.cookies[key][\"path\"] = path\n         if domain is not None:\n-            self.cookies[key]['domain'] = domain\n+            self.cookies[key][\"domain\"] = domain\n         if secure:\n-            self.cookies[key]['secure'] = True\n+            self.cookies[key][\"secure\"] = True\n         if httponly:\n-            self.cookies[key]['httponly'] = True\n+            self.cookies[key][\"httponly\"] = True\n         if samesite:\n-            if samesite.lower() not in ('lax', 'strict'):\n+            if samesite.lower() not in (\"lax\", \"strict\"):\n                 raise ValueError('samesite must be \"lax\" or \"strict\".')\n-            self.cookies[key]['samesite'] = samesite\n+            self.cookies[key][\"samesite\"] = samesite\n \n     def setdefault(self, key, value):\n         \"\"\"Set a header unless it has already been set.\"\"\"\n         if key not in self:\n             self[key] = value\n \n-    def set_signed_cookie(self, key, value, salt='', **kwargs):\n+    def set_signed_cookie(self, key, value, salt=\"\", **kwargs):\n         value = signing.get_cookie_signer(salt=key + salt).sign(value)\n         return self.set_cookie(key, value, **kwargs)\n \n-    def delete_cookie(self, key, path='/', domain=None):\n+    def delete_cookie(self, key, path=\"/\", domain=None):\n         # Most browsers ignore the Set-Cookie header if the cookie name starts\n         # with __Host- or __Secure- and the cookie doesn't use the secure flag.\n-        secure = key.startswith(('__Secure-', '__Host-'))\n+        secure = key.startswith((\"__Secure-\", \"__Host-\"))\n         self.set_cookie(\n-            key, max_age=0, path=path, domain=domain, secure=secure,\n-            expires='Thu, 01 Jan 1970 00:00:00 GMT',\n+            key,\n+            max_age=0,\n+            path=path,\n+            domain=domain,\n+            secure=secure,\n+            expires=\"Thu, 01 Jan 1970 00:00:00 GMT\",\n         )\n \n     # Common methods used by subclasses\n@@ -229,7 +249,7 @@ class HttpResponseBase:\n         # Handle string types -- we can't rely on force_bytes here because:\n         # - Python attempts str conversion first\n         # - when self._charset != 'utf-8' it re-encodes the content\n-        if isinstance(value, bytes):\n+        if isinstance(value, (bytes, memoryview)):\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n@@ -251,13 +271,15 @@ class HttpResponseBase:\n         signals.request_finished.send(sender=self._handler_class)\n \n     def write(self, content):\n-        raise OSError('This %s instance is not writable' % self.__class__.__name__)\n+        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n \n     def flush(self):\n         pass\n \n     def tell(self):\n-        raise OSError('This %s instance cannot tell its position' % self.__class__.__name__)\n+        raise OSError(\n+            \"This %s instance cannot tell its position\" % self.__class__.__name__\n+        )\n \n     # These methods partially implement a stream-like object interface.\n     # See https://docs.python.org/library/io.html#io.IOBase\n@@ -272,7 +294,7 @@ class HttpResponseBase:\n         return False\n \n     def writelines(self, lines):\n-        raise OSError('This %s instance is not writable' % self.__class__.__name__)\n+        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n \n \n class HttpResponse(HttpResponseBase):\n@@ -284,34 +306,36 @@ class HttpResponse(HttpResponseBase):\n \n     streaming = False\n \n-    def __init__(self, content=b'', *args, **kwargs):\n+    def __init__(self, content=b\"\", *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         # Content is a bytestring. See the `content` property methods.\n         self.content = content\n \n     def __repr__(self):\n-        return '<%(cls)s status_code=%(status_code)d%(content_type)s>' % {\n-            'cls': self.__class__.__name__,\n-            'status_code': self.status_code,\n-            'content_type': self._content_type_for_repr,\n+        return \"<%(cls)s status_code=%(status_code)d%(content_type)s>\" % {\n+            \"cls\": self.__class__.__name__,\n+            \"status_code\": self.status_code,\n+            \"content_type\": self._content_type_for_repr,\n         }\n \n     def serialize(self):\n         \"\"\"Full HTTP message, including headers, as a bytestring.\"\"\"\n-        return self.serialize_headers() + b'\\r\\n\\r\\n' + self.content\n+        return self.serialize_headers() + b\"\\r\\n\\r\\n\" + self.content\n \n     __bytes__ = serialize\n \n     @property\n     def content(self):\n-        return b''.join(self._container)\n+        return b\"\".join(self._container)\n \n     @content.setter\n     def content(self, value):\n         # Consume iterators upon assignment to allow repeated iteration.\n-        if hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n-            content = b''.join(self.make_bytes(chunk) for chunk in value)\n-            if hasattr(value, 'close'):\n+        if hasattr(value, \"__iter__\") and not isinstance(\n+            value, (bytes, str, memoryview)\n+        ):\n+            content = b\"\".join(self.make_bytes(chunk) for chunk in value)\n+            if hasattr(value, \"close\"):\n                 try:\n                     value.close()\n                 except Exception:\n@@ -376,36 +400,37 @@ class StreamingHttpResponse(HttpResponseBase):\n     def _set_streaming_content(self, value):\n         # Ensure we can never iterate on \"value\" more than once.\n         self._iterator = iter(value)\n-        if hasattr(value, 'close'):\n+        if hasattr(value, \"close\"):\n             self._closable_objects.append(value)\n \n     def __iter__(self):\n         return self.streaming_content\n \n     def getvalue(self):\n-        return b''.join(self.streaming_content)\n+        return b\"\".join(self.streaming_content)\n \n \n class FileResponse(StreamingHttpResponse):\n     \"\"\"\n     A streaming HTTP response class optimized for files.\n     \"\"\"\n+\n     block_size = 4096\n \n-    def __init__(self, *args, as_attachment=False, filename='', **kwargs):\n+    def __init__(self, *args, as_attachment=False, filename=\"\", **kwargs):\n         self.as_attachment = as_attachment\n         self.filename = filename\n         super().__init__(*args, **kwargs)\n \n     def _set_streaming_content(self, value):\n-        if not hasattr(value, 'read'):\n+        if not hasattr(value, \"read\"):\n             self.file_to_stream = None\n             return super()._set_streaming_content(value)\n \n         self.file_to_stream = filelike = value\n-        if hasattr(filelike, 'close'):\n+        if hasattr(filelike, \"close\"):\n             self._closable_objects.append(filelike)\n-        value = iter(lambda: filelike.read(self.block_size), b'')\n+        value = iter(lambda: filelike.read(self.block_size), b\"\")\n         self.set_headers(filelike)\n         super()._set_streaming_content(value)\n \n@@ -415,57 +440,64 @@ class FileResponse(StreamingHttpResponse):\n         Content-Disposition) based on the `filelike` response content.\n         \"\"\"\n         encoding_map = {\n-            'bzip2': 'application/x-bzip',\n-            'gzip': 'application/gzip',\n-            'xz': 'application/x-xz',\n+            \"bzip2\": \"application/x-bzip\",\n+            \"gzip\": \"application/gzip\",\n+            \"xz\": \"application/x-xz\",\n         }\n-        filename = getattr(filelike, 'name', None)\n-        filename = filename if (isinstance(filename, str) and filename) else self.filename\n+        filename = getattr(filelike, \"name\", None)\n+        filename = (\n+            filename if (isinstance(filename, str) and filename) else self.filename\n+        )\n         if os.path.isabs(filename):\n-            self['Content-Length'] = os.path.getsize(filelike.name)\n-        elif hasattr(filelike, 'getbuffer'):\n-            self['Content-Length'] = filelike.getbuffer().nbytes\n+            self[\"Content-Length\"] = os.path.getsize(filelike.name)\n+        elif hasattr(filelike, \"getbuffer\"):\n+            self[\"Content-Length\"] = filelike.getbuffer().nbytes\n \n-        if self.get('Content-Type', '').startswith('text/html'):\n+        if self.get(\"Content-Type\", \"\").startswith(\"text/html\"):\n             if filename:\n                 content_type, encoding = mimetypes.guess_type(filename)\n                 # Encoding isn't set to prevent browsers from automatically\n                 # uncompressing files.\n                 content_type = encoding_map.get(encoding, content_type)\n-                self['Content-Type'] = content_type or 'application/octet-stream'\n+                self[\"Content-Type\"] = content_type or \"application/octet-stream\"\n             else:\n-                self['Content-Type'] = 'application/octet-stream'\n+                self[\"Content-Type\"] = \"application/octet-stream\"\n \n         if self.as_attachment:\n             filename = self.filename or os.path.basename(filename)\n             if filename:\n                 try:\n-                    filename.encode('ascii')\n+                    filename.encode(\"ascii\")\n                     file_expr = 'filename=\"{}\"'.format(filename)\n                 except UnicodeEncodeError:\n                     file_expr = \"filename*=utf-8''{}\".format(quote(filename))\n-                self['Content-Disposition'] = 'attachment; {}'.format(file_expr)\n+                self[\"Content-Disposition\"] = \"attachment; {}\".format(file_expr)\n \n \n class HttpResponseRedirectBase(HttpResponse):\n-    allowed_schemes = ['http', 'https', 'ftp']\n+    allowed_schemes = [\"http\", \"https\", \"ftp\"]\n \n     def __init__(self, redirect_to, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self['Location'] = iri_to_uri(redirect_to)\n+        self[\"Location\"] = iri_to_uri(redirect_to)\n         parsed = urlparse(str(redirect_to))\n         if parsed.scheme and parsed.scheme not in self.allowed_schemes:\n-            raise DisallowedRedirect(\"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme)\n+            raise DisallowedRedirect(\n+                \"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme\n+            )\n \n-    url = property(lambda self: self['Location'])\n+    url = property(lambda self: self[\"Location\"])\n \n     def __repr__(self):\n-        return '<%(cls)s status_code=%(status_code)d%(content_type)s, url=\"%(url)s\">' % {\n-            'cls': self.__class__.__name__,\n-            'status_code': self.status_code,\n-            'content_type': self._content_type_for_repr,\n-            'url': self.url,\n-        }\n+        return (\n+            '<%(cls)s status_code=%(status_code)d%(content_type)s, url=\"%(url)s\">'\n+            % {\n+                \"cls\": self.__class__.__name__,\n+                \"status_code\": self.status_code,\n+                \"content_type\": self._content_type_for_repr,\n+                \"url\": self.url,\n+            }\n+        )\n \n \n class HttpResponseRedirect(HttpResponseRedirectBase):\n@@ -481,12 +513,14 @@ class HttpResponseNotModified(HttpResponse):\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        del self['content-type']\n+        del self[\"content-type\"]\n \n     @HttpResponse.content.setter\n     def content(self, value):\n         if value:\n-            raise AttributeError(\"You cannot set content to a 304 (Not Modified) response\")\n+            raise AttributeError(\n+                \"You cannot set content to a 304 (Not Modified) response\"\n+            )\n         self._container = []\n \n \n@@ -507,14 +541,14 @@ class HttpResponseNotAllowed(HttpResponse):\n \n     def __init__(self, permitted_methods, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self['Allow'] = ', '.join(permitted_methods)\n+        self[\"Allow\"] = \", \".join(permitted_methods)\n \n     def __repr__(self):\n-        return '<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>' % {\n-            'cls': self.__class__.__name__,\n-            'status_code': self.status_code,\n-            'content_type': self._content_type_for_repr,\n-            'methods': self['Allow'],\n+        return \"<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>\" % {\n+            \"cls\": self.__class__.__name__,\n+            \"status_code\": self.status_code,\n+            \"content_type\": self._content_type_for_repr,\n+            \"methods\": self[\"Allow\"],\n         }\n \n \n@@ -544,15 +578,21 @@ class JsonResponse(HttpResponse):\n     :param json_dumps_params: A dictionary of kwargs passed to json.dumps().\n     \"\"\"\n \n-    def __init__(self, data, encoder=DjangoJSONEncoder, safe=True,\n-                 json_dumps_params=None, **kwargs):\n+    def __init__(\n+        self,\n+        data,\n+        encoder=DjangoJSONEncoder,\n+        safe=True,\n+        json_dumps_params=None,\n+        **kwargs,\n+    ):\n         if safe and not isinstance(data, dict):\n             raise TypeError(\n-                'In order to allow non-dict objects to be serialized set the '\n-                'safe parameter to False.'\n+                \"In order to allow non-dict objects to be serialized set the \"\n+                \"safe parameter to False.\"\n             )\n         if json_dumps_params is None:\n             json_dumps_params = {}\n-        kwargs.setdefault('content_type', 'application/json')\n+        kwargs.setdefault(\"content_type\", \"application/json\")\n         data = json.dumps(data, cls=encoder, **json_dumps_params)\n         super().__init__(content=data, **kwargs)\n"}
{"instance_id": "django__django-11179", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..9d37a73af4 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -12,8 +12,12 @@ class ProtectedError(IntegrityError):\n \n \n def CASCADE(collector, field, sub_objs, using):\n-    collector.collect(sub_objs, source=field.remote_field.model,\n-                      source_attr=field.name, nullable=field.null)\n+    collector.collect(\n+        sub_objs,\n+        source=field.remote_field.model,\n+        source_attr=field.name,\n+        nullable=field.null,\n+    )\n     if field.null and not connections[using].features.can_defer_constraint_checks:\n         collector.add_field_update(field, None, sub_objs)\n \n@@ -21,21 +25,27 @@ def CASCADE(collector, field, sub_objs, using):\n def PROTECT(collector, field, sub_objs, using):\n     raise ProtectedError(\n         \"Cannot delete some instances of model '%s' because they are \"\n-        \"referenced through a protected foreign key: '%s.%s'\" % (\n-            field.remote_field.model.__name__, sub_objs[0].__class__.__name__, field.name\n+        \"referenced through a protected foreign key: '%s.%s'\"\n+        % (\n+            field.remote_field.model.__name__,\n+            sub_objs[0].__class__.__name__,\n+            field.name,\n         ),\n-        sub_objs\n+        sub_objs,\n     )\n \n \n def SET(value):\n     if callable(value):\n+\n         def set_on_delete(collector, field, sub_objs, using):\n             collector.add_field_update(field, value(), sub_objs)\n     else:\n+\n         def set_on_delete(collector, field, sub_objs, using):\n             collector.add_field_update(field, value, sub_objs)\n-    set_on_delete.deconstruct = lambda: ('django.db.models.SET', (value,), {})\n+\n+    set_on_delete.deconstruct = lambda: (\"django.db.models.SET\", (value,), {})\n     return set_on_delete\n \n \n@@ -55,7 +65,8 @@ def get_candidate_relations_to_delete(opts):\n     # The candidate relations are the ones that come from N-1 and 1-1 relations.\n     # N-N  (i.e., many-to-many) relations aren't candidates for deletion.\n     return (\n-        f for f in opts.get_fields(include_hidden=True)\n+        f\n+        for f in opts.get_fields(include_hidden=True)\n         if f.auto_created and not f.concrete and (f.one_to_one or f.one_to_many)\n     )\n \n@@ -100,8 +111,9 @@ class Collector:\n         if source is not None and not nullable:\n             if reverse_dependency:\n                 source, model = model, source\n-            self.dependencies.setdefault(\n-                source._meta.concrete_model, set()).add(model._meta.concrete_model)\n+            self.dependencies.setdefault(source._meta.concrete_model, set()).add(\n+                model._meta.concrete_model\n+            )\n         return new_objs\n \n     def add_field_update(self, field, value, objs):\n@@ -112,9 +124,9 @@ class Collector:\n         if not objs:\n             return\n         model = objs[0].__class__\n-        self.field_updates.setdefault(\n-            model, {}).setdefault(\n-            (field, value), set()).update(objs)\n+        self.field_updates.setdefault(model, {}).setdefault(\n+            (field, value), set()\n+        ).update(objs)\n \n     def can_fast_delete(self, objs, from_field=None):\n         \"\"\"\n@@ -129,28 +141,38 @@ class Collector:\n         \"\"\"\n         if from_field and from_field.remote_field.on_delete is not CASCADE:\n             return False\n-        if hasattr(objs, '_meta'):\n+        if hasattr(objs, \"_meta\"):\n             model = type(objs)\n-        elif hasattr(objs, 'model') and hasattr(objs, '_raw_delete'):\n+        elif hasattr(objs, \"model\") and hasattr(objs, \"_raw_delete\"):\n             model = objs.model\n         else:\n             return False\n-        if (signals.pre_delete.has_listeners(model) or\n-                signals.post_delete.has_listeners(model) or\n-                signals.m2m_changed.has_listeners(model)):\n+        if (\n+            signals.pre_delete.has_listeners(model)\n+            or signals.post_delete.has_listeners(model)\n+            or signals.m2m_changed.has_listeners(model)\n+        ):\n             return False\n         # The use of from_field comes from the need to avoid cascade back to\n         # parent when parent delete is cascading to child.\n         opts = model._meta\n         return (\n-            all(link == from_field for link in opts.concrete_model._meta.parents.values()) and\n+            all(\n+                link == from_field\n+                for link in opts.concrete_model._meta.parents.values()\n+            )\n+            and\n             # Foreign keys pointing to this model.\n             all(\n                 related.field.remote_field.on_delete is DO_NOTHING\n                 for related in get_candidate_relations_to_delete(opts)\n-            ) and (\n+            )\n+            and (\n                 # Something like generic foreign key.\n-                not any(hasattr(field, 'bulk_related_objects') for field in opts.private_fields)\n+                not any(\n+                    hasattr(field, \"bulk_related_objects\")\n+                    for field in opts.private_fields\n+                )\n             )\n         )\n \n@@ -159,15 +181,26 @@ class Collector:\n         Return the objs in suitably sized batches for the used connection.\n         \"\"\"\n         conn_batch_size = max(\n-            connections[self.using].ops.bulk_batch_size([field.name], objs), 1)\n+            connections[self.using].ops.bulk_batch_size([field.name], objs), 1\n+        )\n         if len(objs) > conn_batch_size:\n-            return [objs[i:i + conn_batch_size]\n-                    for i in range(0, len(objs), conn_batch_size)]\n+            return [\n+                objs[i : i + conn_batch_size]\n+                for i in range(0, len(objs), conn_batch_size)\n+            ]\n         else:\n             return [objs]\n \n-    def collect(self, objs, source=None, nullable=False, collect_related=True,\n-                source_attr=None, reverse_dependency=False, keep_parents=False):\n+    def collect(\n+        self,\n+        objs,\n+        source=None,\n+        nullable=False,\n+        collect_related=True,\n+        source_attr=None,\n+        reverse_dependency=False,\n+        keep_parents=False,\n+    ):\n         \"\"\"\n         Add 'objs' to the collection of objects to be deleted as well as all\n         parent instances.  'objs' must be a homogeneous iterable collection of\n@@ -188,8 +221,9 @@ class Collector:\n         if self.can_fast_delete(objs):\n             self.fast_deletes.append(objs)\n             return\n-        new_objs = self.add(objs, source, nullable,\n-                            reverse_dependency=reverse_dependency)\n+        new_objs = self.add(\n+            objs, source, nullable, reverse_dependency=reverse_dependency\n+        )\n         if not new_objs:\n             return\n \n@@ -202,10 +236,13 @@ class Collector:\n             for ptr in concrete_model._meta.parents.values():\n                 if ptr:\n                     parent_objs = [getattr(obj, ptr.name) for obj in new_objs]\n-                    self.collect(parent_objs, source=model,\n-                                 source_attr=ptr.remote_field.related_name,\n-                                 collect_related=False,\n-                                 reverse_dependency=True)\n+                    self.collect(\n+                        parent_objs,\n+                        source=model,\n+                        source_attr=ptr.remote_field.related_name,\n+                        collect_related=False,\n+                        reverse_dependency=True,\n+                    )\n         if collect_related:\n             parents = model._meta.parents\n             for related in get_candidate_relations_to_delete(model._meta):\n@@ -223,7 +260,7 @@ class Collector:\n                     elif sub_objs:\n                         field.remote_field.on_delete(self, field, sub_objs, self.using)\n             for field in model._meta.private_fields:\n-                if hasattr(field, 'bulk_related_objects'):\n+                if hasattr(field, \"bulk_related_objects\"):\n                     # It's something like generic foreign key.\n                     sub_objs = field.bulk_related_objects(new_objs, self.using)\n                     self.collect(sub_objs, source=model, nullable=True)\n@@ -276,7 +313,10 @@ class Collector:\n             instance = list(instances)[0]\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n-                    count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                    count = sql.DeleteQuery(model).delete_batch(\n+                        [instance.pk], self.using\n+                    )\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n@@ -296,8 +336,9 @@ class Collector:\n             for model, instances_for_fieldvalues in self.field_updates.items():\n                 for (field, value), instances in instances_for_fieldvalues.items():\n                     query = sql.UpdateQuery(model)\n-                    query.update_batch([obj.pk for obj in instances],\n-                                       {field.name: value}, self.using)\n+                    query.update_batch(\n+                        [obj.pk for obj in instances], {field.name: value}, self.using\n+                    )\n \n             # reverse instance collections\n             for instances in self.data.values():\n"}
{"instance_id": "django__django-11283", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\nindex 0e66649695..f1720e211a 100644\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -7,26 +7,32 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n     Update the content_type of proxy model permissions to use the ContentType\n     of the proxy model.\n     \"\"\"\n-    Permission = apps.get_model('auth', 'Permission')\n-    ContentType = apps.get_model('contenttypes', 'ContentType')\n+    Permission = apps.get_model(\"auth\", \"Permission\")\n+    ContentType = apps.get_model(\"contenttypes\", \"ContentType\")\n     for Model in apps.get_models():\n         opts = Model._meta\n         if not opts.proxy:\n             continue\n         proxy_default_permissions_codenames = [\n-            '%s_%s' % (action, opts.model_name)\n-            for action in opts.default_permissions\n+            \"%s_%s\" % (action, opts.model_name) for action in opts.default_permissions\n         ]\n         permissions_query = Q(codename__in=proxy_default_permissions_codenames)\n         for codename, name in opts.permissions:\n             permissions_query = permissions_query | Q(codename=codename, name=name)\n-        concrete_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=True)\n-        proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n+        concrete_content_type = ContentType.objects.get_for_model(\n+            Model, for_concrete_model=True\n+        )\n+        proxy_content_type = ContentType.objects.get_for_model(\n+            Model, for_concrete_model=False\n+        )\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n         Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n+        ).exclude(\n+            Q(codename__in=proxy_default_permissions_codenames)\n+            & Q(content_type=new_content_type)\n         ).update(content_type=new_content_type)\n \n \n@@ -40,9 +46,11 @@ def revert_proxy_model_permissions(apps, schema_editor):\n \n class Migration(migrations.Migration):\n     dependencies = [\n-        ('auth', '0010_alter_group_name_max_length'),\n-        ('contenttypes', '0002_remove_content_type_name'),\n+        (\"auth\", \"0010_alter_group_name_max_length\"),\n+        (\"contenttypes\", \"0002_remove_content_type_name\"),\n     ]\n     operations = [\n-        migrations.RunPython(update_proxy_model_permissions, revert_proxy_model_permissions),\n+        migrations.RunPython(\n+            update_proxy_model_permissions, revert_proxy_model_permissions\n+        ),\n     ]\n"}
{"instance_id": "django__django-11422", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 7ca0d68fae..9097607c1f 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -114,14 +114,14 @@ def iter_modules_and_files(modules, extra_files):\n         # During debugging (with PyDev) the 'typing.io' and 'typing.re' objects\n         # are added to sys.modules, however they are types not modules and so\n         # cause issues here.\n-        if not isinstance(module, ModuleType) or getattr(module, '__spec__', None) is None:\n+        if not isinstance(module, ModuleType):\n             continue\n-        spec = module.__spec__\n-        # Modules could be loaded from places without a concrete location. If\n-        # this is the case, skip them.\n-        if spec.has_location:\n+        spec = getattr(module, '__spec__', None)\n+        if spec is not None and spec.has_location:\n             origin = spec.loader.archive if isinstance(spec.loader, zipimporter) else spec.origin\n             sys_file_paths.append(origin)\n+        elif getattr(module, '__file__', None):\n+            sys_file_paths.append(module.__file__)\n \n     results = set()\n     for filename in itertools.chain(sys_file_paths, extra_files):\n"}
{"instance_id": "django__django-11564", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 4c27fce605..6ab5d3116b 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -3,6 +3,7 @@ from datetime import datetime\n from urllib.parse import urljoin\n \n from django.conf import settings\n+from django.urls import get_script_prefix\n from django.core.exceptions import SuspiciousFileOperation\n from django.core.files import File, locks\n from django.core.files.move import file_move_safe\n@@ -17,8 +18,11 @@ from django.utils.module_loading import import_string\n from django.utils.text import get_valid_filename\n \n __all__ = (\n-    'Storage', 'FileSystemStorage', 'DefaultStorage', 'default_storage',\n-    'get_storage_class',\n+    \"Storage\",\n+    \"FileSystemStorage\",\n+    \"DefaultStorage\",\n+    \"default_storage\",\n+    \"get_storage_class\",\n )\n \n \n@@ -31,7 +35,7 @@ class Storage:\n     # The following methods represent a public interface to private methods.\n     # These shouldn't be overridden by subclasses unless absolutely necessary.\n \n-    def open(self, name, mode='rb'):\n+    def open(self, name, mode=\"rb\"):\n         \"\"\"Retrieve the specified file from storage.\"\"\"\n         return self._open(name, mode)\n \n@@ -45,7 +49,7 @@ class Storage:\n         if name is None:\n             name = content.name\n \n-        if not hasattr(content, 'chunks'):\n+        if not hasattr(content, \"chunks\"):\n             content = File(content, name)\n \n         name = self.get_available_name(name, max_length=max_length)\n@@ -66,7 +70,7 @@ class Storage:\n         character alphanumeric string (before the file extension, if one\n         exists) to the filename.\n         \"\"\"\n-        return '%s_%s%s' % (file_root, get_random_string(7), file_ext)\n+        return \"%s_%s%s\" % (file_root, get_random_string(7), file_ext)\n \n     def get_available_name(self, name, max_length=None):\n         \"\"\"\n@@ -81,7 +85,9 @@ class Storage:\n         # exceed the max_length.\n         while self.exists(name) or (max_length and len(name) > max_length):\n             # file_ext includes the dot.\n-            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n+            name = os.path.join(\n+                dir_name, self.get_alternative_name(file_root, file_ext)\n+            )\n             if max_length is None:\n                 continue\n             # Truncate file_root if max_length exceeded.\n@@ -92,10 +98,12 @@ class Storage:\n                 if not file_root:\n                     raise SuspiciousFileOperation(\n                         'Storage can not find an available filename for \"%s\". '\n-                        'Please make sure that the corresponding file field '\n+                        \"Please make sure that the corresponding file field \"\n                         'allows sufficient \"max_length\".' % name\n                     )\n-                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n+                name = os.path.join(\n+                    dir_name, self.get_alternative_name(file_root, file_ext)\n+                )\n         return name\n \n     def generate_filename(self, filename):\n@@ -122,55 +130,67 @@ class Storage:\n         \"\"\"\n         Delete the specified file from the storage system.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a delete() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide a delete() method\"\n+        )\n \n     def exists(self, name):\n         \"\"\"\n         Return True if a file referenced by the given name already exists in the\n         storage system, or False if the name is available for a new file.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide an exists() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide an exists() method\"\n+        )\n \n     def listdir(self, path):\n         \"\"\"\n         List the contents of the specified path. Return a 2-tuple of lists:\n         the first item being directories, the second item being files.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a listdir() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide a listdir() method\"\n+        )\n \n     def size(self, name):\n         \"\"\"\n         Return the total size, in bytes, of the file specified by name.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a size() method')\n+        raise NotImplementedError(\"subclasses of Storage must provide a size() method\")\n \n     def url(self, name):\n         \"\"\"\n         Return an absolute URL where the file's contents can be accessed\n         directly by a Web browser.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a url() method')\n+        raise NotImplementedError(\"subclasses of Storage must provide a url() method\")\n \n     def get_accessed_time(self, name):\n         \"\"\"\n         Return the last accessed time (as a datetime) of the file specified by\n         name. The datetime will be timezone-aware if USE_TZ=True.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a get_accessed_time() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide a get_accessed_time() method\"\n+        )\n \n     def get_created_time(self, name):\n         \"\"\"\n         Return the creation time (as a datetime) of the file specified by name.\n         The datetime will be timezone-aware if USE_TZ=True.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a get_created_time() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide a get_created_time() method\"\n+        )\n \n     def get_modified_time(self, name):\n         \"\"\"\n         Return the last modified time (as a datetime) of the file specified by\n         name. The datetime will be timezone-aware if USE_TZ=True.\n         \"\"\"\n-        raise NotImplementedError('subclasses of Storage must provide a get_modified_time() method')\n+        raise NotImplementedError(\n+            \"subclasses of Storage must provide a get_modified_time() method\"\n+        )\n \n \n @deconstructible\n@@ -178,12 +198,18 @@ class FileSystemStorage(Storage):\n     \"\"\"\n     Standard filesystem storage\n     \"\"\"\n+\n     # The combination of O_CREAT and O_EXCL makes os.open() raise OSError if\n     # the file already exists before it's opened.\n-    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)\n-\n-    def __init__(self, location=None, base_url=None, file_permissions_mode=None,\n-                 directory_permissions_mode=None):\n+    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, \"O_BINARY\", 0)\n+\n+    def __init__(\n+        self,\n+        location=None,\n+        base_url=None,\n+        file_permissions_mode=None,\n+        directory_permissions_mode=None,\n+    ):\n         self._location = location\n         self._base_url = base_url\n         self._file_permissions_mode = file_permissions_mode\n@@ -192,15 +218,15 @@ class FileSystemStorage(Storage):\n \n     def _clear_cached_properties(self, setting, **kwargs):\n         \"\"\"Reset setting based property values.\"\"\"\n-        if setting == 'MEDIA_ROOT':\n-            self.__dict__.pop('base_location', None)\n-            self.__dict__.pop('location', None)\n-        elif setting == 'MEDIA_URL':\n-            self.__dict__.pop('base_url', None)\n-        elif setting == 'FILE_UPLOAD_PERMISSIONS':\n-            self.__dict__.pop('file_permissions_mode', None)\n-        elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS':\n-            self.__dict__.pop('directory_permissions_mode', None)\n+        if setting == \"MEDIA_ROOT\":\n+            self.__dict__.pop(\"base_location\", None)\n+            self.__dict__.pop(\"location\", None)\n+        elif setting == \"MEDIA_URL\":\n+            self.__dict__.pop(\"base_url\", None)\n+        elif setting == \"FILE_UPLOAD_PERMISSIONS\":\n+            self.__dict__.pop(\"file_permissions_mode\", None)\n+        elif setting == \"FILE_UPLOAD_DIRECTORY_PERMISSIONS\":\n+            self.__dict__.pop(\"directory_permissions_mode\", None)\n \n     def _value_or_setting(self, value, setting):\n         return setting if value is None else value\n@@ -215,19 +241,23 @@ class FileSystemStorage(Storage):\n \n     @cached_property\n     def base_url(self):\n-        if self._base_url is not None and not self._base_url.endswith('/'):\n-            self._base_url += '/'\n+        if self._base_url is not None and not self._base_url.endswith(\"/\"):\n+            self._base_url += \"/\"\n         return self._value_or_setting(self._base_url, settings.MEDIA_URL)\n \n     @cached_property\n     def file_permissions_mode(self):\n-        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n+        return self._value_or_setting(\n+            self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS\n+        )\n \n     @cached_property\n     def directory_permissions_mode(self):\n-        return self._value_or_setting(self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS)\n+        return self._value_or_setting(\n+            self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS\n+        )\n \n-    def _open(self, name, mode='rb'):\n+    def _open(self, name, mode=\"rb\"):\n         return File(open(self.path(name), mode))\n \n     def _save(self, name, content):\n@@ -241,13 +271,15 @@ class FileSystemStorage(Storage):\n                 # for consistency with file_permissions_mode behavior.\n                 old_umask = os.umask(0)\n                 try:\n-                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n+                    os.makedirs(\n+                        directory, self.directory_permissions_mode, exist_ok=True\n+                    )\n                 finally:\n                     os.umask(old_umask)\n             else:\n                 os.makedirs(directory, exist_ok=True)\n         except FileExistsError:\n-            raise FileExistsError('%s exists and is not a directory.' % directory)\n+            raise FileExistsError(\"%s exists and is not a directory.\" % directory)\n \n         # There's a potential race condition between get_available_name and\n         # saving the file; it's possible that two threads might return the\n@@ -258,7 +290,7 @@ class FileSystemStorage(Storage):\n         while True:\n             try:\n                 # This file has a file path that we can move.\n-                if hasattr(content, 'temporary_file_path'):\n+                if hasattr(content, \"temporary_file_path\"):\n                     file_move_safe(content.temporary_file_path(), full_path)\n \n                 # This is a normal uploadedfile that we can stream.\n@@ -270,7 +302,7 @@ class FileSystemStorage(Storage):\n                         locks.lock(fd, locks.LOCK_EX)\n                         for chunk in content.chunks():\n                             if _file is None:\n-                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n+                                mode = \"wb\" if isinstance(chunk, bytes) else \"wt\"\n                                 _file = os.fdopen(fd, mode)\n                             _file.write(chunk)\n                     finally:\n@@ -291,7 +323,7 @@ class FileSystemStorage(Storage):\n             os.chmod(full_path, self.file_permissions_mode)\n \n         # Store filenames with forward slashes, even on Windows.\n-        return name.replace('\\\\', '/')\n+        return name.replace(\"\\\\\", \"/\")\n \n     def delete(self, name):\n         assert name, \"The name argument is not allowed to be empty.\"\n@@ -331,7 +363,10 @@ class FileSystemStorage(Storage):\n             raise ValueError(\"This file is not accessible via a URL.\")\n         url = filepath_to_uri(name)\n         if url is not None:\n-            url = url.lstrip('/')\n+            url = url.lstrip(\"/\")\n+        prefix = get_script_prefix()\n+        if prefix != \"/\":\n+            return prefix + self.base_url + url\n         return urljoin(self.base_url, url)\n \n     def _datetime_from_timestamp(self, ts):\ndiff --git a/django/templatetags/static.py b/django/templatetags/static.py\nindex 39712aaba0..b84a20c021 100644\n--- a/django/templatetags/static.py\n+++ b/django/templatetags/static.py\n@@ -2,6 +2,7 @@ from urllib.parse import quote, urljoin\n \n from django import template\n from django.apps import apps\n+from django.urls import get_script_prefix\n from django.utils.encoding import iri_to_uri\n from django.utils.html import conditional_escape\n \n@@ -9,14 +10,14 @@ register = template.Library()\n \n \n class PrefixNode(template.Node):\n-\n     def __repr__(self):\n         return \"<PrefixNode for %r>\" % self.name\n \n     def __init__(self, varname=None, name=None):\n         if name is None:\n             raise template.TemplateSyntaxError(\n-                \"Prefix nodes must be given a name to return.\")\n+                \"Prefix nodes must be given a name to return.\"\n+            )\n         self.varname = varname\n         self.name = name\n \n@@ -27,9 +28,10 @@ class PrefixNode(template.Node):\n         \"\"\"\n         # token.split_contents() isn't useful here because tags using this method don't accept variable as arguments\n         tokens = token.contents.split()\n-        if len(tokens) > 1 and tokens[1] != 'as':\n+        if len(tokens) > 1 and tokens[1] != \"as\":\n             raise template.TemplateSyntaxError(\n-                \"First argument in '%s' must be 'as'\" % tokens[0])\n+                \"First argument in '%s' must be 'as'\" % tokens[0]\n+            )\n         if len(tokens) > 1:\n             varname = tokens[2]\n         else:\n@@ -41,9 +43,10 @@ class PrefixNode(template.Node):\n         try:\n             from django.conf import settings\n         except ImportError:\n-            prefix = ''\n+            prefix = \"\"\n         else:\n-            prefix = iri_to_uri(getattr(settings, name, ''))\n+            prefix = iri_to_uri(getattr(settings, name, \"\"))\n+        prefix = get_script_prefix() + prefix\n         return prefix\n \n     def render(self, context):\n@@ -51,7 +54,7 @@ class PrefixNode(template.Node):\n         if self.varname is None:\n             return prefix\n         context[self.varname] = prefix\n-        return ''\n+        return \"\"\n \n \n @register.tag\n@@ -94,7 +97,8 @@ class StaticNode(template.Node):\n     def __init__(self, varname=None, path=None):\n         if path is None:\n             raise template.TemplateSyntaxError(\n-                \"Static template nodes must be given a path to return.\")\n+                \"Static template nodes must be given a path to return.\"\n+            )\n         self.path = path\n         self.varname = varname\n \n@@ -109,12 +113,13 @@ class StaticNode(template.Node):\n         if self.varname is None:\n             return url\n         context[self.varname] = url\n-        return ''\n+        return \"\"\n \n     @classmethod\n     def handle_simple(cls, path):\n-        if apps.is_installed('django.contrib.staticfiles'):\n+        if apps.is_installed(\"django.contrib.staticfiles\"):\n             from django.contrib.staticfiles.storage import staticfiles_storage\n+\n             return staticfiles_storage.url(path)\n         else:\n             return urljoin(PrefixNode.handle_simple(\"STATIC_URL\"), quote(path))\n@@ -128,11 +133,12 @@ class StaticNode(template.Node):\n \n         if len(bits) < 2:\n             raise template.TemplateSyntaxError(\n-                \"'%s' takes at least one argument (path to file)\" % bits[0])\n+                \"'%s' takes at least one argument (path to file)\" % bits[0]\n+            )\n \n         path = parser.compile_filter(bits[1])\n \n-        if len(bits) >= 2 and bits[-2] == 'as':\n+        if len(bits) >= 2 and bits[-2] == \"as\":\n             varname = bits[3]\n         else:\n             varname = None\n@@ -140,7 +146,7 @@ class StaticNode(template.Node):\n         return cls(varname, path)\n \n \n-@register.tag('static')\n+@register.tag(\"static\")\n def do_static(parser, token):\n     \"\"\"\n     Join the given path with the STATIC_URL setting.\n"}
{"instance_id": "django__django-11583", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 25c3b44250..bce311ca97 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -21,11 +21,11 @@ from django.utils.functional import cached_property\n from django.utils.version import get_version_tuple\n \n autoreload_started = Signal()\n-file_changed = Signal(providing_args=['file_path', 'kind'])\n+file_changed = Signal(providing_args=[\"file_path\", \"kind\"])\n \n-DJANGO_AUTORELOAD_ENV = 'RUN_MAIN'\n+DJANGO_AUTORELOAD_ENV = \"RUN_MAIN\"\n \n-logger = logging.getLogger('django.utils.autoreload')\n+logger = logging.getLogger(\"django.utils.autoreload\")\n \n # If an error is raised while importing a file, it's not placed in sys.modules.\n # This means that any future modifications aren't caught. Keep a list of these\n@@ -56,7 +56,7 @@ def check_errors(fn):\n \n             et, ev, tb = _exception\n \n-            if getattr(ev, 'filename', None) is None:\n+            if getattr(ev, \"filename\", None) is None:\n                 # get the filename from the last item in the stack\n                 filename = traceback.extract_tb(tb)[-1][0]\n             else:\n@@ -86,7 +86,7 @@ def ensure_echo_on():\n     attr_list = termios.tcgetattr(sys.stdin)\n     if not attr_list[3] & termios.ECHO:\n         attr_list[3] |= termios.ECHO\n-        if hasattr(signal, 'SIGTTOU'):\n+        if hasattr(signal, \"SIGTTOU\"):\n             old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)\n         else:\n             old_handler = None\n@@ -101,7 +101,11 @@ def iter_all_python_module_files():\n     # This ensures cached results are returned in the usual case that modules\n     # aren't loaded on the fly.\n     keys = sorted(sys.modules)\n-    modules = tuple(m for m in map(sys.modules.__getitem__, keys) if not isinstance(m, weakref.ProxyTypes))\n+    modules = tuple(\n+        m\n+        for m in map(sys.modules.__getitem__, keys)\n+        if not isinstance(m, weakref.ProxyTypes)\n+    )\n     return iter_modules_and_files(modules, frozenset(_error_files))\n \n \n@@ -115,21 +119,25 @@ def iter_modules_and_files(modules, extra_files):\n         # cause issues here.\n         if not isinstance(module, ModuleType):\n             continue\n-        if module.__name__ == '__main__':\n+        if module.__name__ == \"__main__\":\n             # __main__ (usually manage.py) doesn't always have a __spec__ set.\n             # Handle this by falling back to using __file__, resolved below.\n             # See https://docs.python.org/reference/import.html#main-spec\n             # __file__ may not exists, e.g. when running ipdb debugger.\n-            if hasattr(module, '__file__'):\n+            if hasattr(module, \"__file__\"):\n                 sys_file_paths.append(module.__file__)\n             continue\n-        if getattr(module, '__spec__', None) is None:\n+        if getattr(module, \"__spec__\", None) is None:\n             continue\n         spec = module.__spec__\n         # Modules could be loaded from places without a concrete location. If\n         # this is the case, skip them.\n         if spec.has_location:\n-            origin = spec.loader.archive if isinstance(spec.loader, zipimporter) else spec.origin\n+            origin = (\n+                spec.loader.archive\n+                if isinstance(spec.loader, zipimporter)\n+                else spec.origin\n+            )\n             sys_file_paths.append(origin)\n \n     results = set()\n@@ -139,7 +147,7 @@ def iter_modules_and_files(modules, extra_files):\n         path = Path(filename)\n         try:\n             resolved_path = path.resolve(strict=True).absolute()\n-        except FileNotFoundError:\n+        except (FileNotFoundError, ValueError):\n             # The module could have been removed, don't fail loudly if this\n             # is the case.\n             continue\n@@ -187,7 +195,7 @@ def sys_path_directories():\n         path = Path(path)\n         try:\n             resolved_path = path.resolve(strict=True).absolute()\n-        except FileNotFoundError:\n+        except (FileNotFoundError, ValueError):\n             continue\n         # If the path is a file (like a zip file), watch the parent directory.\n         if resolved_path.is_file():\n@@ -204,10 +212,10 @@ def get_child_arguments():\n     \"\"\"\n     import django.__main__\n \n-    args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n+    args = [sys.executable] + [\"-W%s\" % o for o in sys.warnoptions]\n     if sys.argv[0] == django.__main__.__file__:\n         # The server was started with `python -m django runserver`.\n-        args += ['-m', 'django']\n+        args += [\"-m\", \"django\"]\n         args += sys.argv[1:]\n     else:\n         args += sys.argv\n@@ -215,12 +223,12 @@ def get_child_arguments():\n \n \n def trigger_reload(filename):\n-    logger.info('%s changed, reloading.', filename)\n+    logger.info(\"%s changed, reloading.\", filename)\n     sys.exit(3)\n \n \n def restart_with_reloader():\n-    new_environ = {**os.environ, DJANGO_AUTORELOAD_ENV: 'true'}\n+    new_environ = {**os.environ, DJANGO_AUTORELOAD_ENV: \"true\"}\n     args = get_child_arguments()\n     while True:\n         exit_code = subprocess.call(args, env=new_environ, close_fds=False)\n@@ -237,15 +245,15 @@ class BaseReloader:\n     def watch_dir(self, path, glob):\n         path = Path(path)\n         if not path.is_absolute():\n-            raise ValueError('%s must be absolute.' % path)\n-        logger.debug('Watching dir %s with glob %s.', path, glob)\n+            raise ValueError(\"%s must be absolute.\" % path)\n+        logger.debug(\"Watching dir %s with glob %s.\", path, glob)\n         self.directory_globs[path].add(glob)\n \n     def watch_file(self, path):\n         path = Path(path)\n         if not path.is_absolute():\n-            raise ValueError('%s must be absolute.' % path)\n-        logger.debug('Watching file %s.', path)\n+            raise ValueError(\"%s must be absolute.\" % path)\n+        logger.debug(\"Watching file %s.\", path)\n         self.extra_files.add(path)\n \n     def watched_files(self, include_globs=True):\n@@ -275,13 +283,14 @@ class BaseReloader:\n             if app_reg.ready_event.wait(timeout=0.1):\n                 return True\n         else:\n-            logger.debug('Main Django thread has terminated before apps are ready.')\n+            logger.debug(\"Main Django thread has terminated before apps are ready.\")\n             return False\n \n     def run(self, django_main_thread):\n-        logger.debug('Waiting for apps ready_event.')\n+        logger.debug(\"Waiting for apps ready_event.\")\n         self.wait_for_apps_ready(apps, django_main_thread)\n         from django.urls import get_resolver\n+\n         # Prevent a race condition where URL modules aren't loaded when the\n         # reloader starts by accessing the urlconf_module property.\n         try:\n@@ -290,7 +299,7 @@ class BaseReloader:\n             # Loading the urlconf can result in errors during development.\n             # If this occurs then swallow the error and continue.\n             pass\n-        logger.debug('Apps ready_event triggered. Sending autoreload_started signal.')\n+        logger.debug(\"Apps ready_event triggered. Sending autoreload_started signal.\")\n         autoreload_started.send(sender=self)\n         self.run_loop()\n \n@@ -311,15 +320,15 @@ class BaseReloader:\n         testability of the reloader implementations by decoupling the work they\n         do from the loop.\n         \"\"\"\n-        raise NotImplementedError('subclasses must implement tick().')\n+        raise NotImplementedError(\"subclasses must implement tick().\")\n \n     @classmethod\n     def check_availability(cls):\n-        raise NotImplementedError('subclasses must implement check_availability().')\n+        raise NotImplementedError(\"subclasses must implement check_availability().\")\n \n     def notify_file_changed(self, path):\n         results = file_changed.send(sender=self, file_path=path)\n-        logger.debug('%s notified as changed. Signal results: %s.', path, results)\n+        logger.debug(\"%s notified as changed. Signal results: %s.\", path, results)\n         if not any(res[1] for res in results):\n             trigger_reload(path)\n \n@@ -342,10 +351,15 @@ class StatReloader(BaseReloader):\n                 old_time = mtimes.get(filepath)\n                 mtimes[filepath] = mtime\n                 if old_time is None:\n-                    logger.debug('File %s first seen with mtime %s', filepath, mtime)\n+                    logger.debug(\"File %s first seen with mtime %s\", filepath, mtime)\n                     continue\n                 elif mtime > old_time:\n-                    logger.debug('File %s previous mtime: %s, current mtime: %s', filepath, old_time, mtime)\n+                    logger.debug(\n+                        \"File %s previous mtime: %s, current mtime: %s\",\n+                        filepath,\n+                        old_time,\n+                        mtime,\n+                    )\n                     self.notify_file_changed(filepath)\n \n             time.sleep(self.SLEEP_TIME)\n@@ -378,7 +392,7 @@ class WatchmanReloader(BaseReloader):\n     def __init__(self):\n         self.roots = defaultdict(set)\n         self.processed_request = threading.Event()\n-        self.client_timeout = int(os.environ.get('DJANGO_WATCHMAN_TIMEOUT', 5))\n+        self.client_timeout = int(os.environ.get(\"DJANGO_WATCHMAN_TIMEOUT\", 5))\n         super().__init__()\n \n     @cached_property\n@@ -397,45 +411,56 @@ class WatchmanReloader(BaseReloader):\n         # now, watching its parent, if possible, is sufficient.\n         if not root.exists():\n             if not root.parent.exists():\n-                logger.warning('Unable to watch root dir %s as neither it or its parent exist.', root)\n+                logger.warning(\n+                    \"Unable to watch root dir %s as neither it or its parent exist.\",\n+                    root,\n+                )\n                 return\n             root = root.parent\n-        result = self.client.query('watch-project', str(root.absolute()))\n-        if 'warning' in result:\n-            logger.warning('Watchman warning: %s', result['warning'])\n-        logger.debug('Watchman watch-project result: %s', result)\n-        return result['watch'], result.get('relative_path')\n+        result = self.client.query(\"watch-project\", str(root.absolute()))\n+        if \"warning\" in result:\n+            logger.warning(\"Watchman warning: %s\", result[\"warning\"])\n+        logger.debug(\"Watchman watch-project result: %s\", result)\n+        return result[\"watch\"], result.get(\"relative_path\")\n \n     @functools.lru_cache()\n     def _get_clock(self, root):\n-        return self.client.query('clock', root)['clock']\n+        return self.client.query(\"clock\", root)[\"clock\"]\n \n     def _subscribe(self, directory, name, expression):\n         root, rel_path = self._watch_root(directory)\n         query = {\n-            'expression': expression,\n-            'fields': ['name'],\n-            'since': self._get_clock(root),\n-            'dedup_results': True,\n+            \"expression\": expression,\n+            \"fields\": [\"name\"],\n+            \"since\": self._get_clock(root),\n+            \"dedup_results\": True,\n         }\n         if rel_path:\n-            query['relative_root'] = rel_path\n-        logger.debug('Issuing watchman subscription %s, for root %s. Query: %s', name, root, query)\n-        self.client.query('subscribe', root, name, query)\n+            query[\"relative_root\"] = rel_path\n+        logger.debug(\n+            \"Issuing watchman subscription %s, for root %s. Query: %s\",\n+            name,\n+            root,\n+            query,\n+        )\n+        self.client.query(\"subscribe\", root, name, query)\n \n     def _subscribe_dir(self, directory, filenames):\n         if not directory.exists():\n             if not directory.parent.exists():\n-                logger.warning('Unable to watch directory %s as neither it or its parent exist.', directory)\n+                logger.warning(\n+                    \"Unable to watch directory %s as neither it or its parent exist.\",\n+                    directory,\n+                )\n                 return\n-            prefix = 'files-parent-%s' % directory.name\n-            filenames = ['%s/%s' % (directory.name, filename) for filename in filenames]\n+            prefix = \"files-parent-%s\" % directory.name\n+            filenames = [\"%s/%s\" % (directory.name, filename) for filename in filenames]\n             directory = directory.parent\n-            expression = ['name', filenames, 'wholename']\n+            expression = [\"name\", filenames, \"wholename\"]\n         else:\n-            prefix = 'files'\n-            expression = ['name', filenames]\n-        self._subscribe(directory, '%s:%s' % (prefix, directory), expression)\n+            prefix = \"files\"\n+            expression = [\"name\", filenames]\n+        self._subscribe(directory, \"%s:%s\" % (prefix, directory), expression)\n \n     def _watch_glob(self, directory, patterns):\n         \"\"\"\n@@ -446,19 +471,22 @@ class WatchmanReloader(BaseReloader):\n         overwrite the named subscription, so it must include all possible glob\n         expressions.\n         \"\"\"\n-        prefix = 'glob'\n+        prefix = \"glob\"\n         if not directory.exists():\n             if not directory.parent.exists():\n-                logger.warning('Unable to watch directory %s as neither it or its parent exist.', directory)\n+                logger.warning(\n+                    \"Unable to watch directory %s as neither it or its parent exist.\",\n+                    directory,\n+                )\n                 return\n-            prefix = 'glob-parent-%s' % directory.name\n-            patterns = ['%s/%s' % (directory.name, pattern) for pattern in patterns]\n+            prefix = \"glob-parent-%s\" % directory.name\n+            patterns = [\"%s/%s\" % (directory.name, pattern) for pattern in patterns]\n             directory = directory.parent\n \n-        expression = ['anyof']\n+        expression = [\"anyof\"]\n         for pattern in patterns:\n-            expression.append(['match', pattern, 'wholename'])\n-        self._subscribe(directory, '%s:%s' % (prefix, directory), expression)\n+            expression.append([\"match\", pattern, \"wholename\"])\n+        self._subscribe(directory, \"%s:%s\" % (prefix, directory), expression)\n \n     def watched_roots(self, watched_files):\n         extra_directories = self.directory_globs.keys()\n@@ -469,8 +497,8 @@ class WatchmanReloader(BaseReloader):\n     def _update_watches(self):\n         watched_files = list(self.watched_files(include_globs=False))\n         found_roots = common_roots(self.watched_roots(watched_files))\n-        logger.debug('Watching %s files', len(watched_files))\n-        logger.debug('Found common roots: %s', found_roots)\n+        logger.debug(\"Watching %s files\", len(watched_files))\n+        logger.debug(\"Found common roots: %s\", found_roots)\n         # Setup initial roots for performance, shortest roots first.\n         for root in sorted(found_roots):\n             self._watch_root(root)\n@@ -480,7 +508,9 @@ class WatchmanReloader(BaseReloader):\n         sorted_files = sorted(watched_files, key=lambda p: p.parent)\n         for directory, group in itertools.groupby(sorted_files, key=lambda p: p.parent):\n             # These paths need to be relative to the parent directory.\n-            self._subscribe_dir(directory, [str(p.relative_to(directory)) for p in group])\n+            self._subscribe_dir(\n+                directory, [str(p.relative_to(directory)) for p in group]\n+            )\n \n     def update_watches(self):\n         try:\n@@ -494,19 +524,19 @@ class WatchmanReloader(BaseReloader):\n         subscription = self.client.getSubscription(sub)\n         if not subscription:\n             return\n-        logger.debug('Watchman subscription %s has results.', sub)\n+        logger.debug(\"Watchman subscription %s has results.\", sub)\n         for result in subscription:\n             # When using watch-project, it's not simple to get the relative\n             # directory without storing some specific state. Store the full\n             # path to the directory in the subscription name, prefixed by its\n             # type (glob, files).\n-            root_directory = Path(result['subscription'].split(':', 1)[1])\n-            logger.debug('Found root directory %s', root_directory)\n-            for file in result.get('files', []):\n+            root_directory = Path(result[\"subscription\"].split(\":\", 1)[1])\n+            logger.debug(\"Found root directory %s\", root_directory)\n+            for file in result.get(\"files\", []):\n                 self.notify_file_changed(root_directory / file)\n \n     def request_processed(self, **kwargs):\n-        logger.debug('Request processed. Setting update_watches event.')\n+        logger.debug(\"Request processed. Setting update_watches event.\")\n         self.processed_request.set()\n \n     def tick(self):\n@@ -521,7 +551,7 @@ class WatchmanReloader(BaseReloader):\n             except pywatchman.SocketTimeout:\n                 pass\n             except pywatchman.WatchmanError as ex:\n-                logger.debug('Watchman error: %s, checking server status.', ex)\n+                logger.debug(\"Watchman error: %s, checking server status.\", ex)\n                 self.check_server_status(ex)\n             else:\n                 for sub in list(self.client.subs.keys()):\n@@ -535,7 +565,7 @@ class WatchmanReloader(BaseReloader):\n     def check_server_status(self, inner_ex=None):\n         \"\"\"Return True if the server is available.\"\"\"\n         try:\n-            self.client.query('version')\n+            self.client.query(\"version\")\n         except Exception:\n             raise WatchmanUnavailable(str(inner_ex)) from inner_ex\n         return True\n@@ -543,19 +573,19 @@ class WatchmanReloader(BaseReloader):\n     @classmethod\n     def check_availability(cls):\n         if not pywatchman:\n-            raise WatchmanUnavailable('pywatchman not installed.')\n+            raise WatchmanUnavailable(\"pywatchman not installed.\")\n         client = pywatchman.client(timeout=0.1)\n         try:\n             result = client.capabilityCheck()\n         except Exception:\n             # The service is down?\n-            raise WatchmanUnavailable('Cannot connect to the watchman service.')\n-        version = get_version_tuple(result['version'])\n+            raise WatchmanUnavailable(\"Cannot connect to the watchman service.\")\n+        version = get_version_tuple(result[\"version\"])\n         # Watchman 4.9 includes multiple improvements to watching project\n         # directories as well as case insensitive filesystems.\n-        logger.debug('Watchman version %s', version)\n+        logger.debug(\"Watchman version %s\", version)\n         if version < (4, 9):\n-            raise WatchmanUnavailable('Watchman 4.9 or later is required.')\n+            raise WatchmanUnavailable(\"Watchman 4.9 or later is required.\")\n \n \n def get_reloader():\n@@ -571,7 +601,9 @@ def start_django(reloader, main_func, *args, **kwargs):\n     ensure_echo_on()\n \n     main_func = check_errors(main_func)\n-    django_main_thread = threading.Thread(target=main_func, args=args, kwargs=kwargs, name='django-main-thread')\n+    django_main_thread = threading.Thread(\n+        target=main_func, args=args, kwargs=kwargs, name=\"django-main-thread\"\n+    )\n     django_main_thread.setDaemon(True)\n     django_main_thread.start()\n \n@@ -582,16 +614,20 @@ def start_django(reloader, main_func, *args, **kwargs):\n             # It's possible that the watchman service shuts down or otherwise\n             # becomes unavailable. In that case, use the StatReloader.\n             reloader = StatReloader()\n-            logger.error('Error connecting to Watchman: %s', ex)\n-            logger.info('Watching for file changes with %s', reloader.__class__.__name__)\n+            logger.error(\"Error connecting to Watchman: %s\", ex)\n+            logger.info(\n+                \"Watching for file changes with %s\", reloader.__class__.__name__\n+            )\n \n \n def run_with_reloader(main_func, *args, **kwargs):\n     signal.signal(signal.SIGTERM, lambda *args: sys.exit(0))\n     try:\n-        if os.environ.get(DJANGO_AUTORELOAD_ENV) == 'true':\n+        if os.environ.get(DJANGO_AUTORELOAD_ENV) == \"true\":\n             reloader = get_reloader()\n-            logger.info('Watching for file changes with %s', reloader.__class__.__name__)\n+            logger.info(\n+                \"Watching for file changes with %s\", reloader.__class__.__name__\n+            )\n             start_django(reloader, main_func, *args, **kwargs)\n         else:\n             exit_code = restart_with_reloader()\n"}
{"instance_id": "django__django-11620", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 2154a46320..ed0f84d65c 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -5,6 +5,7 @@ URLResolver is the main class here. Its resolve() method takes a URL (as\n a string) and returns a ResolverMatch object which provides access to all\n attributes of the resolved URL match.\n \"\"\"\n+\n import functools\n import inspect\n import re\n@@ -17,6 +18,7 @@ from django.conf import settings\n from django.core.checks import Error, Warning\n from django.core.checks.urls import check_resolver\n from django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\n+from django.http import Http404\n from django.utils.datastructures import MultiValueDict\n from django.utils.functional import cached_property\n from django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\n@@ -29,7 +31,16 @@ from .utils import get_callable\n \n \n class ResolverMatch:\n-    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None):\n+    def __init__(\n+        self,\n+        func,\n+        args,\n+        kwargs,\n+        url_name=None,\n+        app_names=None,\n+        namespaces=None,\n+        route=None,\n+    ):\n         self.func = func\n         self.args = args\n         self.kwargs = kwargs\n@@ -39,27 +50,35 @@ class ResolverMatch:\n         # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n         # in an empty value.\n         self.app_names = [x for x in app_names if x] if app_names else []\n-        self.app_name = ':'.join(self.app_names)\n+        self.app_name = \":\".join(self.app_names)\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n-        self.namespace = ':'.join(self.namespaces)\n+        self.namespace = \":\".join(self.namespaces)\n \n-        if not hasattr(func, '__name__'):\n+        if not hasattr(func, \"__name__\"):\n             # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+            self._func_path = func.__class__.__module__ + \".\" + func.__class__.__name__\n         else:\n             # A function-based view\n-            self._func_path = func.__module__ + '.' + func.__name__\n+            self._func_path = func.__module__ + \".\" + func.__name__\n \n         view_path = url_name or self._func_path\n-        self.view_name = ':'.join(self.namespaces + [view_path])\n+        self.view_name = \":\".join(self.namespaces + [view_path])\n \n     def __getitem__(self, index):\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n-        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n-            self._func_path, self.args, self.kwargs, self.url_name,\n-            self.app_names, self.namespaces, self.route,\n+        return (\n+            \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\"\n+            % (\n+                self._func_path,\n+                self.args,\n+                self.kwargs,\n+                self.url_name,\n+                self.app_names,\n+                self.namespaces,\n+                self.route,\n+            )\n         )\n \n \n@@ -71,7 +90,7 @@ def get_resolver(urlconf=None):\n \n @functools.lru_cache(maxsize=None)\n def _get_cached_resolver(urlconf=None):\n-    return URLResolver(RegexPattern(r'^/'), urlconf)\n+    return URLResolver(RegexPattern(r\"^/\"), urlconf)\n \n \n @functools.lru_cache(maxsize=None)\n@@ -82,7 +101,7 @@ def get_ns_resolver(ns_pattern, resolver, converters):\n     pattern = RegexPattern(ns_pattern)\n     pattern.converters = dict(converters)\n     ns_resolver = URLResolver(pattern, resolver.url_patterns)\n-    return URLResolver(RegexPattern(r'^/'), [ns_resolver])\n+    return URLResolver(RegexPattern(r\"^/\"), [ns_resolver])\n \n \n class LocaleRegexDescriptor:\n@@ -100,8 +119,8 @@ class LocaleRegexDescriptor:\n         # avoid per-language compilation.\n         pattern = getattr(instance, self.attr)\n         if isinstance(pattern, str):\n-            instance.__dict__['regex'] = instance._compile(pattern)\n-            return instance.__dict__['regex']\n+            instance.__dict__[\"regex\"] = instance._compile(pattern)\n+            return instance.__dict__[\"regex\"]\n         language_code = get_language()\n         if language_code not in instance._regex_dict:\n             instance._regex_dict[language_code] = instance._compile(str(pattern))\n@@ -127,7 +146,9 @@ class CheckURLMixin:\n             # Skip check as it can be useful to start a URL pattern with a slash\n             # when APPEND_SLASH=False.\n             return []\n-        if regex_pattern.startswith(('/', '^/', '^\\\\/')) and not regex_pattern.endswith('/'):\n+        if regex_pattern.startswith((\"/\", \"^/\", \"^\\\\/\")) and not regex_pattern.endswith(\n+            \"/\"\n+        ):\n             warning = Warning(\n                 \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                 \"slash as it is unnecessary. If this pattern is targeted in an \"\n@@ -142,7 +163,7 @@ class CheckURLMixin:\n \n \n class RegexPattern(CheckURLMixin):\n-    regex = LocaleRegexDescriptor('_regex')\n+    regex = LocaleRegexDescriptor(\"_regex\")\n \n     def __init__(self, regex, name=None, is_endpoint=False):\n         self._regex = regex\n@@ -159,7 +180,7 @@ class RegexPattern(CheckURLMixin):\n             # positional arguments.\n             kwargs = {k: v for k, v in match.groupdict().items() if v is not None}\n             args = () if kwargs else match.groups()\n-            return path[match.end():], args, kwargs\n+            return path[match.end() :], args, kwargs\n         return None\n \n     def check(self):\n@@ -171,13 +192,15 @@ class RegexPattern(CheckURLMixin):\n \n     def _check_include_trailing_dollar(self):\n         regex_pattern = self.regex.pattern\n-        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):\n-            return [Warning(\n-                \"Your URL pattern {} uses include with a route ending with a '$'. \"\n-                \"Remove the dollar from the route to avoid problems including \"\n-                \"URLs.\".format(self.describe()),\n-                id='urls.W001',\n-            )]\n+        if regex_pattern.endswith(\"$\") and not regex_pattern.endswith(r\"\\$\"):\n+            return [\n+                Warning(\n+                    \"Your URL pattern {} uses include with a route ending with a '$'. \"\n+                    \"Remove the dollar from the route to avoid problems including \"\n+                    \"URLs.\".format(self.describe()),\n+                    id=\"urls.W001\",\n+                )\n+            ]\n         else:\n             return []\n \n@@ -195,7 +218,7 @@ class RegexPattern(CheckURLMixin):\n \n \n _PATH_PARAMETER_COMPONENT_RE = re.compile(\n-    r'<(?:(?P<converter>[^>:]+):)?(?P<parameter>\\w+)>'\n+    r\"<(?:(?P<converter>[^>:]+):)?(?P<parameter>\\w+)>\"\n )\n \n \n@@ -207,25 +230,25 @@ def _route_to_regex(route, is_endpoint=False):\n     and {'pk': <django.urls.converters.IntConverter>}.\n     \"\"\"\n     original_route = route\n-    parts = ['^']\n+    parts = [\"^\"]\n     converters = {}\n     while True:\n         match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n         if not match:\n             parts.append(re.escape(route))\n             break\n-        parts.append(re.escape(route[:match.start()]))\n-        route = route[match.end():]\n-        parameter = match.group('parameter')\n+        parts.append(re.escape(route[: match.start()]))\n+        route = route[match.end() :]\n+        parameter = match.group(\"parameter\")\n         if not parameter.isidentifier():\n             raise ImproperlyConfigured(\n                 \"URL route '%s' uses parameter name %r which isn't a valid \"\n                 \"Python identifier.\" % (original_route, parameter)\n             )\n-        raw_converter = match.group('converter')\n+        raw_converter = match.group(\"converter\")\n         if raw_converter is None:\n             # If a converter isn't specified, the default is `str`.\n-            raw_converter = 'str'\n+            raw_converter = \"str\"\n         try:\n             converter = get_converter(raw_converter)\n         except KeyError as e:\n@@ -233,14 +256,14 @@ def _route_to_regex(route, is_endpoint=False):\n                 \"URL route '%s' uses invalid converter %s.\" % (original_route, e)\n             )\n         converters[parameter] = converter\n-        parts.append('(?P<' + parameter + '>' + converter.regex + ')')\n+        parts.append(\"(?P<\" + parameter + \">\" + converter.regex + \")\")\n     if is_endpoint:\n-        parts.append('$')\n-    return ''.join(parts), converters\n+        parts.append(\"$\")\n+    return \"\".join(parts), converters\n \n \n class RoutePattern(CheckURLMixin):\n-    regex = LocaleRegexDescriptor('_route')\n+    regex = LocaleRegexDescriptor(\"_route\")\n \n     def __init__(self, route, name=None, is_endpoint=False):\n         self._route = route\n@@ -258,21 +281,23 @@ class RoutePattern(CheckURLMixin):\n                 converter = self.converters[key]\n                 try:\n                     kwargs[key] = converter.to_python(value)\n-                except ValueError:\n+                except (ValueError, Http404):\n                     return None\n-            return path[match.end():], (), kwargs\n+            return path[match.end() :], (), kwargs\n         return None\n \n     def check(self):\n         warnings = self._check_pattern_startswith_slash()\n         route = self._route\n-        if '(?P<' in route or route.startswith('^') or route.endswith('$'):\n-            warnings.append(Warning(\n-                \"Your URL pattern {} has a route that contains '(?P<', begins \"\n-                \"with a '^', or ends with a '$'. This was likely an oversight \"\n-                \"when migrating to django.urls.path().\".format(self.describe()),\n-                id='2_0.W001',\n-            ))\n+        if \"(?P<\" in route or route.startswith(\"^\") or route.endswith(\"$\"):\n+            warnings.append(\n+                Warning(\n+                    \"Your URL pattern {} has a route that contains '(?P<', begins \"\n+                    \"with a '^', or ends with a '$'. This was likely an oversight \"\n+                    \"when migrating to django.urls.path().\".format(self.describe()),\n+                    id=\"2_0.W001\",\n+                )\n+            )\n         return warnings\n \n     def _compile(self, route):\n@@ -296,14 +321,14 @@ class LocalePrefixPattern:\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n         if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n-            return ''\n+            return \"\"\n         else:\n-            return '%s/' % language_code\n+            return \"%s/\" % language_code\n \n     def match(self, path):\n         language_prefix = self.language_prefix\n         if path.startswith(language_prefix):\n-            return path[len(language_prefix):], (), {}\n+            return path[len(language_prefix) :], (), {}\n         return None\n \n     def check(self):\n@@ -324,7 +349,7 @@ class URLPattern:\n         self.name = name\n \n     def __repr__(self):\n-        return '<%s %s>' % (self.__class__.__name__, self.pattern.describe())\n+        return \"<%s %s>\" % (self.__class__.__name__, self.pattern.describe())\n \n     def check(self):\n         warnings = self._check_pattern_name()\n@@ -351,7 +376,9 @@ class URLPattern:\n             new_path, args, kwargs = match\n             # Pass any extra_kwargs as **kwargs.\n             kwargs.update(self.default_args)\n-            return ResolverMatch(self.callback, args, kwargs, self.pattern.name, route=str(self.pattern))\n+            return ResolverMatch(\n+                self.callback, args, kwargs, self.pattern.name, route=str(self.pattern)\n+            )\n \n     @cached_property\n     def lookup_str(self):\n@@ -362,13 +389,15 @@ class URLPattern:\n         callback = self.callback\n         if isinstance(callback, functools.partial):\n             callback = callback.func\n-        if not hasattr(callback, '__name__'):\n+        if not hasattr(callback, \"__name__\"):\n             return callback.__module__ + \".\" + callback.__class__.__name__\n         return callback.__module__ + \".\" + callback.__qualname__\n \n \n class URLResolver:\n-    def __init__(self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None):\n+    def __init__(\n+        self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None\n+    ):\n         self.pattern = pattern\n         # urlconf_name is the dotted Python path to the module defining\n         # urlpatterns. It may also be an object with an urlpatterns attribute\n@@ -390,12 +419,15 @@ class URLResolver:\n     def __repr__(self):\n         if isinstance(self.urlconf_name, list) and self.urlconf_name:\n             # Don't bother to output the whole list, it can be huge\n-            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__\n+            urlconf_repr = \"<%s list>\" % self.urlconf_name[0].__class__.__name__\n         else:\n             urlconf_repr = repr(self.urlconf_name)\n-        return '<%s %s (%s:%s) %s>' % (\n-            self.__class__.__name__, urlconf_repr, self.app_name,\n-            self.namespace, self.pattern.describe(),\n+        return \"<%s %s (%s:%s) %s>\" % (\n+            self.__class__.__name__,\n+            urlconf_repr,\n+            self.app_name,\n+            self.namespace,\n+            self.pattern.describe(),\n         )\n \n     def check(self):\n@@ -413,11 +445,11 @@ class URLResolver:\n             try:\n                 handler, param_dict = self.resolve_error_handler(status_code)\n             except (ImportError, ViewDoesNotExist) as e:\n-                path = getattr(self.urlconf_module, 'handler%s' % status_code)\n+                path = getattr(self.urlconf_module, \"handler%s\" % status_code)\n                 msg = (\n                     \"The custom handler{status_code} view '{path}' could not be imported.\"\n                 ).format(status_code=status_code, path=path)\n-                messages.append(Error(msg, hint=str(e), id='urls.E008'))\n+                messages.append(Error(msg, hint=str(e), id=\"urls.E008\"))\n                 continue\n             signature = inspect.signature(handler)\n             args = [None] * num_parameters\n@@ -429,10 +461,10 @@ class URLResolver:\n                     \"take the correct number of arguments ({args}).\"\n                 ).format(\n                     status_code=status_code,\n-                    path=handler.__module__ + '.' + handler.__qualname__,\n-                    args='request, exception' if num_parameters == 2 else 'request',\n+                    path=handler.__module__ + \".\" + handler.__qualname__,\n+                    args=\"request, exception\" if num_parameters == 2 else \"request\",\n                 )\n-                messages.append(Error(msg, id='urls.E007'))\n+                messages.append(Error(msg, id=\"urls.E007\"))\n         return messages\n \n     def _populate(self):\n@@ -440,7 +472,7 @@ class URLResolver:\n         # infinite recursion. Concurrent threads may call this at the same\n         # time and will need to continue, so set 'populating' on a\n         # thread-local variable.\n-        if getattr(self._local, 'populating', False):\n+        if getattr(self._local, \"populating\", False):\n             return\n         try:\n             self._local.populating = True\n@@ -450,28 +482,45 @@ class URLResolver:\n             language_code = get_language()\n             for url_pattern in reversed(self.url_patterns):\n                 p_pattern = url_pattern.pattern.regex.pattern\n-                if p_pattern.startswith('^'):\n+                if p_pattern.startswith(\"^\"):\n                     p_pattern = p_pattern[1:]\n                 if isinstance(url_pattern, URLPattern):\n                     self._callback_strs.add(url_pattern.lookup_str)\n                     bits = normalize(url_pattern.pattern.regex.pattern)\n                     lookups.appendlist(\n                         url_pattern.callback,\n-                        (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n+                        (\n+                            bits,\n+                            p_pattern,\n+                            url_pattern.default_args,\n+                            url_pattern.pattern.converters,\n+                        ),\n                     )\n                     if url_pattern.name is not None:\n                         lookups.appendlist(\n                             url_pattern.name,\n-                            (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n+                            (\n+                                bits,\n+                                p_pattern,\n+                                url_pattern.default_args,\n+                                url_pattern.pattern.converters,\n+                            ),\n                         )\n                 else:  # url_pattern is a URLResolver.\n                     url_pattern._populate()\n                     if url_pattern.app_name:\n-                        apps.setdefault(url_pattern.app_name, []).append(url_pattern.namespace)\n+                        apps.setdefault(url_pattern.app_name, []).append(\n+                            url_pattern.namespace\n+                        )\n                         namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                     else:\n                         for name in url_pattern.reverse_dict:\n-                            for matches, pat, defaults, converters in url_pattern.reverse_dict.getlist(name):\n+                            for (\n+                                matches,\n+                                pat,\n+                                defaults,\n+                                converters,\n+                            ) in url_pattern.reverse_dict.getlist(name):\n                                 new_matches = normalize(p_pattern + pat)\n                                 lookups.appendlist(\n                                     name,\n@@ -479,10 +528,17 @@ class URLResolver:\n                                         new_matches,\n                                         p_pattern + pat,\n                                         {**defaults, **url_pattern.default_kwargs},\n-                                        {**self.pattern.converters, **url_pattern.pattern.converters, **converters}\n-                                    )\n+                                        {\n+                                            **self.pattern.converters,\n+                                            **url_pattern.pattern.converters,\n+                                            **converters,\n+                                        },\n+                                    ),\n                                 )\n-                        for namespace, (prefix, sub_pattern) in url_pattern.namespace_dict.items():\n+                        for namespace, (\n+                            prefix,\n+                            sub_pattern,\n+                        ) in url_pattern.namespace_dict.items():\n                             current_converters = url_pattern.pattern.converters\n                             sub_pattern.pattern.converters.update(current_converters)\n                             namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n@@ -522,7 +578,7 @@ class URLResolver:\n         \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n         if not route1:\n             return route2\n-        if route2.startswith('^'):\n+        if route2.startswith(\"^\"):\n             route2 = route2[1:]\n         return route1 + route2\n \n@@ -541,7 +597,7 @@ class URLResolver:\n                 try:\n                     sub_match = pattern.resolve(new_path)\n                 except Resolver404 as e:\n-                    sub_tried = e.args[0].get('tried')\n+                    sub_tried = e.args[0].get(\"tried\")\n                     if sub_tried is not None:\n                         tried.extend([pattern] + t for t in sub_tried)\n                     else:\n@@ -557,7 +613,11 @@ class URLResolver:\n                         sub_match_args = sub_match.args\n                         if not sub_match_dict:\n                             sub_match_args = args + sub_match.args\n-                        current_route = '' if isinstance(pattern, URLPattern) else str(pattern.pattern)\n+                        current_route = (\n+                            \"\"\n+                            if isinstance(pattern, URLPattern)\n+                            else str(pattern.pattern)\n+                        )\n                         return ResolverMatch(\n                             sub_match.func,\n                             sub_match_args,\n@@ -568,8 +628,8 @@ class URLResolver:\n                             self._join_route(current_route, sub_match.route),\n                         )\n                     tried.append([pattern])\n-            raise Resolver404({'tried': tried, 'path': new_path})\n-        raise Resolver404({'path': path})\n+            raise Resolver404({\"tried\": tried, \"path\": new_path})\n+        raise Resolver404({\"path\": path})\n \n     @cached_property\n     def urlconf_module(self):\n@@ -594,16 +654,17 @@ class URLResolver:\n         return patterns\n \n     def resolve_error_handler(self, view_type):\n-        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)\n+        callback = getattr(self.urlconf_module, \"handler%s\" % view_type, None)\n         if not callback:\n             # No handler specified in file; use lazy import, since\n             # django.conf.urls imports this file.\n             from django.conf import urls\n-            callback = getattr(urls, 'handler%s' % view_type)\n+\n+            callback = getattr(urls, \"handler%s\" % view_type)\n         return get_callable(callback), {}\n \n     def reverse(self, lookup_view, *args, **kwargs):\n-        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)\n+        return self._reverse_with_prefix(lookup_view, \"\", *args, **kwargs)\n \n     def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n         if args and kwargs:\n@@ -638,16 +699,22 @@ class URLResolver:\n                 # without quoting to build a decoded URL and look for a match.\n                 # Then, if we have a match, redo the substitution with quoted\n                 # arguments in order to return a properly encoded URL.\n-                candidate_pat = _prefix.replace('%', '%%') + result\n-                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % text_candidate_subs):\n+                candidate_pat = _prefix.replace(\"%\", \"%%\") + result\n+                if re.search(\n+                    \"^%s%s\" % (re.escape(_prefix), pattern),\n+                    candidate_pat % text_candidate_subs,\n+                ):\n                     # safe characters from `pchar` definition of RFC 3986\n-                    url = quote(candidate_pat % text_candidate_subs, safe=RFC3986_SUBDELIMS + '/~:@')\n+                    url = quote(\n+                        candidate_pat % text_candidate_subs,\n+                        safe=RFC3986_SUBDELIMS + \"/~:@\",\n+                    )\n                     # Don't allow construction of scheme relative urls.\n                     return escape_leading_slashes(url)\n         # lookup_view can be URL name or callable, but callables are not\n         # friendly in error messages.\n-        m = getattr(lookup_view, '__module__', None)\n-        n = getattr(lookup_view, '__name__', None)\n+        m = getattr(lookup_view, \"__module__\", None)\n+        n = getattr(lookup_view, \"__name__\", None)\n         if m is not None and n is not None:\n             lookup_view_s = \"%s.%s\" % (m, n)\n         else:\n@@ -661,13 +728,15 @@ class URLResolver:\n                 arg_msg = \"keyword arguments '%s'\" % (kwargs,)\n             else:\n                 arg_msg = \"no arguments\"\n-            msg = (\n-                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %\n-                (lookup_view_s, arg_msg, len(patterns), patterns)\n+            msg = \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" % (\n+                lookup_view_s,\n+                arg_msg,\n+                len(patterns),\n+                patterns,\n             )\n         else:\n             msg = (\n                 \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n-                \"a valid view function or pattern name.\" % {'view': lookup_view_s}\n+                \"a valid view function or pattern name.\" % {\"view\": lookup_view_s}\n             )\n         raise NoReverseMatch(msg)\n"}
{"instance_id": "django__django-11630", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/checks/model_checks.py b/django/core/checks/model_checks.py\nindex 5c2266ca1d..fa7f49f5a6 100644\n--- a/django/core/checks/model_checks.py\n+++ b/django/core/checks/model_checks.py\n@@ -5,6 +5,7 @@ from itertools import chain\n \n from django.apps import apps\n from django.core.checks import Error, Tags, register\n+from django.db import router\n \n \n @register(Tags.models)\n@@ -19,7 +20,7 @@ def check_all_models(app_configs=None, **kwargs):\n         models = chain.from_iterable(app_config.get_models() for app_config in app_configs)\n     for model in models:\n         if model._meta.managed and not model._meta.proxy:\n-            db_table_models[model._meta.db_table].append(model._meta.label)\n+            db_table_models[(model._meta.db_table, router.db_for_read(model))].append(model._meta.label)\n         if not inspect.ismethod(model.check):\n             errors.append(\n                 Error(\n@@ -35,12 +36,13 @@ def check_all_models(app_configs=None, **kwargs):\n             indexes[model_index.name].append(model._meta.label)\n         for model_constraint in model._meta.constraints:\n             constraints[model_constraint.name].append(model._meta.label)\n-    for db_table, model_labels in db_table_models.items():\n+    for db_table_and_model, model_labels in db_table_models.items():\n         if len(model_labels) != 1:\n+            db_table = db_table_and_model[0]\n             errors.append(\n                 Error(\n                     \"db_table '%s' is used by multiple models: %s.\"\n-                    % (db_table, ', '.join(db_table_models[db_table])),\n+                    % (db_table, ', '.join(db_table_models[db_table_and_model])),\n                     obj=db_table,\n                     id='models.E028',\n                 )\n"}
{"instance_id": "django__django-11742", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 9ce46e3f73..fb2805d6e5 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -12,6 +12,7 @@ from django import forms\n from django.apps import apps\n from django.conf import settings\n from django.core import checks, exceptions, validators\n+\n # When the _meta object was formalized, this exception was moved to\n # django.core.exceptions. It is retained here for backwards compatibility\n # purposes.\n@@ -22,7 +23,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -32,14 +36,38 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FieldDoesNotExist', 'FilePathField',\n-    'FloatField', 'GenericIPAddressField', 'IPAddressField', 'IntegerField',\n-    'NOT_PROVIDED', 'NullBooleanField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallAutoField',\n-    'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FieldDoesNotExist\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -75,6 +103,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -101,15 +130,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -127,18 +156,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -174,7 +222,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -184,19 +232,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -214,12 +262,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -227,15 +275,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % (LOOKUP_SEP,),\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -246,14 +294,16 @@ class Field(RegisterLookupMixin):\n             return []\n \n         def is_value(value, accept_promise=True):\n-            return isinstance(value, (str, Promise) if accept_promise else str) or not is_iterable(value)\n+            return isinstance(\n+                value, (str, Promise) if accept_promise else str\n+            ) or not is_iterable(value)\n \n         if is_value(self.choices, accept_promise=False):\n             return [\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -287,7 +337,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -297,25 +347,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -324,7 +379,9 @@ class Field(RegisterLookupMixin):\n     def _check_backend_specific_checks(self, **kwargs):\n         app_label = self.model._meta.app_label\n         for db in connections:\n-            if router.allow_migrate(db, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                db, app_label, model_name=self.model._meta.model_name\n+            ):\n                 return connections[db].validation.check_field(self, **kwargs)\n         return []\n \n@@ -338,11 +395,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -352,25 +410,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -380,6 +437,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -387,6 +445,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -446,7 +505,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -515,7 +574,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -534,7 +593,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -543,10 +602,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -584,7 +646,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -611,16 +673,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -634,7 +696,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -644,7 +706,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -706,7 +770,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -723,7 +787,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -742,8 +806,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            setattr(\n+                cls,\n+                \"get_%s_display\" % self.name,\n+                partialmethod(cls._get_FIELD_display, field=self),\n+            )\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n@@ -802,11 +869,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -814,7 +891,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -822,8 +901,8 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n@@ -850,6 +929,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -858,24 +938,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -884,9 +965,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -901,8 +992,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -915,14 +1006,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -933,14 +1024,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -955,6 +1046,7 @@ class CharField(Field):\n         return [\n             *super().check(**kwargs),\n             *self._check_max_length_attribute(**kwargs),\n+            *self._check_max_length_choices(),\n         ]\n \n     def _check_max_length_attribute(self, **kwargs):\n@@ -963,21 +1055,87 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n             return []\n \n+    def _check_max_length_choices(self):\n+        if not self.choices:\n+            return []\n+        if self.max_length is None:\n+            return []\n+\n+        try:\n+            max_length_choice = max(\n+                len(str(value)) for value, _ in self.flatten_choices(self.choices)\n+            )\n+        except (TypeError, ValueError):\n+            return []\n+\n+        if max_length_choice > self.max_length:\n+            return [\n+                checks.Error(\n+                    \"max_length is too small to fit the longest choice value \"\n+                    \"(%s > %s).\" % (max_length_choice, self.max_length),\n+                    obj=self,\n+                    id=\"fields.E122\",\n+                )\n+            ]\n+        return []\n+        if self.max_length is None:\n+            return []\n+\n+        # Validate that max_length can accommodate the longest choice value\n+        try:\n+            max_length_choice = max(\n+                len(str(value)) if not isinstance(value, Promise) else len(str(value))\n+                for value, _ in self.flatten_choices(self.choices)\n+            )\n+        except (TypeError, ValueError):\n+            return []\n+\n+        if max_length_choice > self.max_length:\n+            return [\n+                checks.Error(\n+                    \"max_length is too small to fit the longest choice value \"\n+                    \"(%s > %s).\" % (max_length_choice, self.max_length),\n+                    obj=self,\n+                    id=\"fields.E122\",\n+                )\n+            ]\n+        return []\n+\n+    def flatten_choices(self, choices):\n+        \"\"\"\n+        Flatten choices to yield (value, label) pairs.\n+        Handles both simple choices and grouped choices.\n+        \"\"\"\n+        for choice in choices:\n+            if len(choice) == 2:\n+                group_name, group_choices = choice\n+                try:\n+                    for value, label in group_choices:\n+                        yield (value, label)\n+                except (TypeError, ValueError):\n+                    yield (group_name, group_choices)\n+            else:\n+                value, label = choice\n+                yield (value, label)\n+\n     def cast_db_type(self, connection):\n         if self.max_length is None:\n             return connection.ops.cast_char_field_without_max_length\n@@ -999,10 +1157,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1011,20 +1169,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1036,8 +1192,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1045,7 +1207,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1058,19 +1220,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1101,13 +1268,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1116,12 +1283,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1146,15 +1313,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1169,12 +1336,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1189,25 +1362,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1244,13 +1425,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1271,10 +1452,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1285,9 +1468,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1296,15 +1479,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1326,13 +1509,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1345,24 +1529,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1389,7 +1581,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1397,7 +1589,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1413,7 +1605,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1421,7 +1613,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1433,7 +1625,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1451,9 +1643,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1468,25 +1660,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except decimal.InvalidOperation:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1496,10 +1692,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1520,9 +1719,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1540,13 +1739,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1555,7 +1756,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1567,20 +1768,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1595,23 +1807,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1623,15 +1835,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1640,7 +1854,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1665,22 +1879,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1694,10 +1910,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1711,22 +1928,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1752,16 +1975,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1772,32 +1997,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1815,14 +2042,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1832,13 +2067,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1846,11 +2081,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1862,8 +2097,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1875,7 +2112,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1883,29 +2120,31 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1913,7 +2152,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -1936,10 +2174,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -1949,17 +2189,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -1968,24 +2212,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2014,29 +2260,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2070,13 +2323,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2089,8 +2342,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2113,15 +2366,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2144,13 +2397,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2158,30 +2413,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2196,7 +2453,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2204,9 +2461,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2219,8 +2476,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2231,29 +2488,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2275,28 +2532,29 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n-\n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2309,9 +2567,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2319,8 +2577,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2334,8 +2592,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2366,34 +2623,33 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n         return subclass in self._subclasses or super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\n"}
{"instance_id": "django__django-11797", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": ""}
{"instance_id": "django__django-11815", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..3030eb8cea 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -23,12 +23,16 @@ class BaseSerializer:\n         self.value = value\n \n     def serialize(self):\n-        raise NotImplementedError('Subclasses of BaseSerializer must implement the serialize() method.')\n+        raise NotImplementedError(\n+            \"Subclasses of BaseSerializer must implement the serialize() method.\"\n+        )\n \n \n class BaseSequenceSerializer(BaseSerializer):\n     def _format(self):\n-        raise NotImplementedError('Subclasses of BaseSequenceSerializer must implement the _format() method.')\n+        raise NotImplementedError(\n+            \"Subclasses of BaseSequenceSerializer must implement the _format() method.\"\n+        )\n \n     def serialize(self):\n         imports = set()\n@@ -53,19 +57,21 @@ class ChoicesSerializer(BaseSerializer):\n \n class DateTimeSerializer(BaseSerializer):\n     \"\"\"For datetime.*, except datetime.datetime.\"\"\"\n+\n     def serialize(self):\n-        return repr(self.value), {'import datetime'}\n+        return repr(self.value), {\"import datetime\"}\n \n \n class DatetimeDatetimeSerializer(BaseSerializer):\n     \"\"\"For datetime.datetime.\"\"\"\n+\n     def serialize(self):\n         if self.value.tzinfo is not None and self.value.tzinfo != utc:\n             self.value = self.value.astimezone(utc)\n         imports = [\"import datetime\"]\n         if self.value.tzinfo is not None:\n             imports.append(\"from django.utils.timezone import utc\")\n-        return repr(self.value).replace('<UTC>', 'utc'), set(imports)\n+        return repr(self.value).replace(\"<UTC>\", \"utc\"), set(imports)\n \n \n class DecimalSerializer(BaseSerializer):\n@@ -120,9 +126,9 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        return \"%s.%s[%r]\" % (module, enum_class.__name__, self.value.name), {\n+            \"import %s\" % module\n+        }\n \n \n class FloatSerializer(BaseSimpleSerializer):\n@@ -139,23 +145,29 @@ class FrozensetSerializer(BaseSequenceSerializer):\n \n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n-        if getattr(self.value, \"__self__\", None) and isinstance(self.value.__self__, type):\n+        if getattr(self.value, \"__self__\", None) and isinstance(\n+            self.value.__self__, type\n+        ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\"import %s\" % module}\n+            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+                \"import %s\" % module\n+            }\n         # Further error checking\n-        if self.value.__name__ == '<lambda>':\n+        if self.value.__name__ == \"<lambda>\":\n             raise ValueError(\"Cannot serialize function: lambda\")\n         if self.value.__module__ is None:\n             raise ValueError(\"Cannot serialize function %r: No module\" % self.value)\n \n         module_name = self.value.__module__\n \n-        if '<' not in self.value.__qualname__:  # Qualname can include <locals>\n-            return '%s.%s' % (module_name, self.value.__qualname__), {'import %s' % self.value.__module__}\n+        if \"<\" not in self.value.__qualname__:  # Qualname can include <locals>\n+            return \"%s.%s\" % (module_name, self.value.__qualname__), {\n+                \"import %s\" % self.value.__module__\n+            }\n \n         raise ValueError(\n-            'Could not find function %s in %s.\\n' % (self.value.__name__, module_name)\n+            \"Could not find function %s in %s.\\n\" % (self.value.__name__, module_name)\n         )\n \n \n@@ -164,11 +176,14 @@ class FunctoolsPartialSerializer(BaseSerializer):\n         # Serialize functools.partial() arguments\n         func_string, func_imports = serializer_factory(self.value.func).serialize()\n         args_string, args_imports = serializer_factory(self.value.args).serialize()\n-        keywords_string, keywords_imports = serializer_factory(self.value.keywords).serialize()\n+        keywords_string, keywords_imports = serializer_factory(\n+            self.value.keywords\n+        ).serialize()\n         # Add any imports needed by arguments\n-        imports = {'import functools', *func_imports, *args_imports, *keywords_imports}\n+        imports = {\"import functools\", *func_imports, *args_imports, *keywords_imports}\n         return (\n-            'functools.%s(%s, *%s, **%s)' % (\n+            \"functools.%s(%s, *%s, **%s)\"\n+            % (\n                 self.value.__class__.__name__,\n                 func_string,\n                 args_string,\n@@ -211,23 +226,26 @@ class ModelManagerSerializer(DeconstructableSerializer):\n class OperationSerializer(BaseSerializer):\n     def serialize(self):\n         from django.db.migrations.writer import OperationWriter\n+\n         string, imports = OperationWriter(self.value, indentation=0).serialize()\n         # Nested operation, trailing comma is handled in upper OperationWriter._write()\n-        return string.rstrip(','), imports\n+        return string.rstrip(\",\"), imports\n \n \n class RegexSerializer(BaseSerializer):\n     def serialize(self):\n-        regex_pattern, pattern_imports = serializer_factory(self.value.pattern).serialize()\n+        regex_pattern, pattern_imports = serializer_factory(\n+            self.value.pattern\n+        ).serialize()\n         # Turn off default implicit flags (e.g. re.U) because regexes with the\n         # same implicit and explicit flags aren't equal.\n-        flags = self.value.flags ^ re.compile('').flags\n+        flags = self.value.flags ^ re.compile(\"\").flags\n         regex_flags, flag_imports = serializer_factory(flags).serialize()\n-        imports = {'import re', *pattern_imports, *flag_imports}\n+        imports = {\"import re\", *pattern_imports, *flag_imports}\n         args = [regex_pattern]\n         if flags:\n             args.append(regex_flags)\n-        return \"re.compile(%s)\" % ', '.join(args), imports\n+        return \"re.compile(%s)\" % \", \".join(args), imports\n \n \n class SequenceSerializer(BaseSequenceSerializer):\n@@ -239,12 +257,14 @@ class SetSerializer(BaseSequenceSerializer):\n     def _format(self):\n         # Serialize as a set literal except when value is empty because {}\n         # is an empty dict.\n-        return '{%s}' if self.value else 'set(%s)'\n+        return \"{%s}\" if self.value else \"set(%s)\"\n \n \n class SettingsReferenceSerializer(BaseSerializer):\n     def serialize(self):\n-        return \"settings.%s\" % self.value.setting_name, {\"from django.conf import settings\"}\n+        return \"settings.%s\" % self.value.setting_name, {\n+            \"from django.conf import settings\"\n+        }\n \n \n class TupleSerializer(BaseSequenceSerializer):\n@@ -258,7 +278,7 @@ class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n             (models.Model, \"models.Model\", []),\n-            (type(None), 'type(None)', []),\n+            (type(None), \"type(None)\", []),\n         ]\n         for case, string, imports in special_cases:\n             if case is self.value:\n@@ -293,7 +313,11 @@ class Serializer:\n         (bool, int, type(None), bytes, str, range): BaseSimpleSerializer,\n         decimal.Decimal: DecimalSerializer,\n         (functools.partial, functools.partialmethod): FunctoolsPartialSerializer,\n-        (types.FunctionType, types.BuiltinFunctionType, types.MethodType): FunctionTypeSerializer,\n+        (\n+            types.FunctionType,\n+            types.BuiltinFunctionType,\n+            types.MethodType,\n+        ): FunctionTypeSerializer,\n         collections.abc.Iterable: IterableSerializer,\n         (COMPILED_REGEX_TYPE, RegexObject): RegexSerializer,\n         uuid.UUID: UUIDSerializer,\n@@ -302,7 +326,9 @@ class Serializer:\n     @classmethod\n     def register(cls, type_, serializer):\n         if not issubclass(serializer, BaseSerializer):\n-            raise ValueError(\"'%s' must inherit from 'BaseSerializer'.\" % serializer.__name__)\n+            raise ValueError(\n+                \"'%s' must inherit from 'BaseSerializer'.\" % serializer.__name__\n+            )\n         cls._registry[type_] = serializer\n \n     @classmethod\n@@ -327,7 +353,7 @@ def serializer_factory(value):\n     if isinstance(value, type):\n         return TypeSerializer(value)\n     # Anything that knows how to deconstruct itself.\n-    if hasattr(value, 'deconstruct'):\n+    if hasattr(value, \"deconstruct\"):\n         return DeconstructableSerializer(value)\n     for type_, serializer_cls in Serializer._registry.items():\n         if isinstance(value, type_):\n"}
{"instance_id": "django__django-11848", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..f31c81c5e2 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -7,9 +7,18 @@ import warnings\n from binascii import Error as BinasciiError\n from email.utils import formatdate\n from urllib.parse import (\n-    ParseResult, SplitResult, _coerce_args, _splitnetloc, _splitparams, quote,\n-    quote_plus, scheme_chars, unquote, unquote_plus,\n-    urlencode as original_urlencode, uses_params,\n+    ParseResult,\n+    SplitResult,\n+    _coerce_args,\n+    _splitnetloc,\n+    _splitparams,\n+    quote,\n+    quote_plus,\n+    scheme_chars,\n+    unquote,\n+    unquote_plus,\n+    urlencode as original_urlencode,\n+    uses_params,\n )\n \n from django.core.exceptions import TooManyFieldsSent\n@@ -18,56 +27,60 @@ from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import keep_lazy_text\n \n # based on RFC 7232, Appendix C\n-ETAG_MATCH = re.compile(r'''\n+ETAG_MATCH = re.compile(\n+    r\"\"\"\n     \\A(      # start of string and capture group\n     (?:W/)?  # optional weak indicator\n     \"        # opening quote\n     [^\"]*    # any sequence of non-quote characters\n     \"        # end quote\n     )\\Z      # end of string and capture group\n-''', re.X)\n-\n-MONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n-__D = r'(?P<day>\\d{2})'\n-__D2 = r'(?P<day>[ \\d]\\d)'\n-__M = r'(?P<mon>\\w{3})'\n-__Y = r'(?P<year>\\d{4})'\n-__Y2 = r'(?P<year>\\d{2})'\n-__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\n-RFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\n-RFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\n-ASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n+\"\"\",\n+    re.X,\n+)\n+\n+MONTHS = \"jan feb mar apr may jun jul aug sep oct nov dec\".split()\n+__D = r\"(?P<day>\\d{2})\"\n+__D2 = r\"(?P<day>[ \\d]\\d)\"\n+__M = r\"(?P<mon>\\w{3})\"\n+__Y = r\"(?P<year>\\d{4})\"\n+__Y2 = r\"(?P<year>\\d{2})\"\n+__T = r\"(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})\"\n+RFC1123_DATE = re.compile(r\"^\\w{3}, %s %s %s %s GMT$\" % (__D, __M, __Y, __T))\n+RFC850_DATE = re.compile(r\"^\\w{6,9}, %s-%s-%s %s GMT$\" % (__D, __M, __Y2, __T))\n+ASCTIME_DATE = re.compile(r\"^\\w{3} %s %s %s %s$\" % (__M, __D2, __T, __Y))\n \n RFC3986_GENDELIMS = \":/?#[]@\"\n RFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n \n-FIELDS_MATCH = re.compile('[&;]')\n+FIELDS_MATCH = re.compile(\"[&;]\")\n \n \n @keep_lazy_text\n-def urlquote(url, safe='/'):\n+def urlquote(url, safe=\"/\"):\n     \"\"\"\n     A legacy compatibility wrapper to Python's urllib.parse.quote() function.\n     (was used for unicode handling on Python 2)\n     \"\"\"\n     warnings.warn(\n-        'django.utils.http.urlquote() is deprecated in favor of '\n-        'urllib.parse.quote().',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.http.urlquote() is deprecated in favor of urllib.parse.quote().\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return quote(url, safe)\n \n \n @keep_lazy_text\n-def urlquote_plus(url, safe=''):\n+def urlquote_plus(url, safe=\"\"):\n     \"\"\"\n     A legacy compatibility wrapper to Python's urllib.parse.quote_plus()\n     function. (was used for unicode handling on Python 2)\n     \"\"\"\n     warnings.warn(\n-        'django.utils.http.urlquote_plus() is deprecated in favor of '\n-        'urllib.parse.quote_plus(),',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.http.urlquote_plus() is deprecated in favor of \"\n+        \"urllib.parse.quote_plus(),\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return quote_plus(url, safe)\n \n@@ -79,9 +92,10 @@ def urlunquote(quoted_url):\n     (was used for unicode handling on Python 2)\n     \"\"\"\n     warnings.warn(\n-        'django.utils.http.urlunquote() is deprecated in favor of '\n-        'urllib.parse.unquote().',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.http.urlunquote() is deprecated in favor of \"\n+        \"urllib.parse.unquote().\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return unquote(quoted_url)\n \n@@ -93,9 +107,10 @@ def urlunquote_plus(quoted_url):\n     function. (was used for unicode handling on Python 2)\n     \"\"\"\n     warnings.warn(\n-        'django.utils.http.urlunquote_plus() is deprecated in favor of '\n-        'urllib.parse.unquote_plus().',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.http.urlunquote_plus() is deprecated in favor of \"\n+        \"urllib.parse.unquote_plus().\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return unquote_plus(quoted_url)\n \n@@ -107,7 +122,7 @@ def urlencode(query, doseq=False):\n     \"\"\"\n     if isinstance(query, MultiValueDict):\n         query = query.lists()\n-    elif hasattr(query, 'items'):\n+    elif hasattr(query, \"items\"):\n         query = query.items()\n     query_params = []\n     for key, value in query:\n@@ -174,17 +189,17 @@ def parse_http_date(date):\n     else:\n         raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n     try:\n-        year = int(m.group('year'))\n+        year = int(m.group(\"year\"))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n-        month = MONTHS.index(m.group('mon').lower()) + 1\n-        day = int(m.group('day'))\n-        hour = int(m.group('hour'))\n-        min = int(m.group('min'))\n-        sec = int(m.group('sec'))\n+            current_year = datetime.datetime.utcnow().year\n+            year += (current_year // 100) * 100\n+            if year > current_year + 50:\n+                year -= 100\n+        month = MONTHS.index(m.group(\"mon\").lower()) + 1\n+        day = int(m.group(\"day\"))\n+        hour = int(m.group(\"hour\"))\n+        min = int(m.group(\"min\"))\n+        sec = int(m.group(\"sec\"))\n         result = datetime.datetime(year, month, day, hour, min, sec)\n         return calendar.timegm(result.utctimetuple())\n     except Exception as exc:\n@@ -203,6 +218,7 @@ def parse_http_date_safe(date):\n \n # Base 36 functions: useful for generating compact URLs\n \n+\n def base36_to_int(s):\n     \"\"\"\n     Convert a base 36 string to an int. Raise ValueError if the input won't fit\n@@ -218,12 +234,12 @@ def base36_to_int(s):\n \n def int_to_base36(i):\n     \"\"\"Convert an integer to a base36 string.\"\"\"\n-    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'\n+    char_set = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n     if i < 0:\n         raise ValueError(\"Negative base36 conversion input.\")\n     if i < 36:\n         return char_set[i]\n-    b36 = ''\n+    b36 = \"\"\n     while i != 0:\n         i, n = divmod(i, 36)\n         b36 = char_set[n] + b36\n@@ -235,7 +251,7 @@ def urlsafe_base64_encode(s):\n     Encode a bytestring to a base64 string for use in URLs. Strip any trailing\n     equal signs.\n     \"\"\"\n-    return base64.urlsafe_b64encode(s).rstrip(b'\\n=').decode('ascii')\n+    return base64.urlsafe_b64encode(s).rstrip(b\"\\n=\").decode(\"ascii\")\n \n \n def urlsafe_base64_decode(s):\n@@ -245,7 +261,7 @@ def urlsafe_base64_decode(s):\n     \"\"\"\n     s = s.encode()\n     try:\n-        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))\n+        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b\"=\"))\n     except (LookupError, BinasciiError) as e:\n         raise ValueError(e)\n \n@@ -256,11 +272,11 @@ def parse_etags(etag_str):\n     defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags\n     should be matched.\n     \"\"\"\n-    if etag_str.strip() == '*':\n-        return ['*']\n+    if etag_str.strip() == \"*\":\n+        return [\"*\"]\n     else:\n         # Parse each ETag individually, and return any that are valid.\n-        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))\n+        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(\",\"))\n         return [match.group(1) for match in etag_matches if match]\n \n \n@@ -289,8 +305,9 @@ def is_same_domain(host, pattern):\n \n     pattern = pattern.lower()\n     return (\n-        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or\n-        pattern == host\n+        pattern[0] == \".\"\n+        and (host.endswith(pattern) or host == pattern[1:])\n+        or pattern == host\n     )\n \n \n@@ -317,23 +334,25 @@ def url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n         allowed_hosts = {allowed_hosts}\n     # Chrome treats \\ completely as / in paths but it could be part of some\n     # basic auth credentials so we need to check both URLs.\n-    return (\n-        _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=require_https) and\n-        _url_has_allowed_host_and_scheme(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https)\n+    return _url_has_allowed_host_and_scheme(\n+        url, allowed_hosts, require_https=require_https\n+    ) and _url_has_allowed_host_and_scheme(\n+        url.replace(\"\\\\\", \"/\"), allowed_hosts, require_https=require_https\n     )\n \n \n def is_safe_url(url, allowed_hosts, require_https=False):\n     warnings.warn(\n-        'django.utils.http.is_safe_url() is deprecated in favor of '\n-        'url_has_allowed_host_and_scheme().',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.http.is_safe_url() is deprecated in favor of \"\n+        \"url_has_allowed_host_and_scheme().\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return url_has_allowed_host_and_scheme(url, allowed_hosts, require_https)\n \n \n # Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\n-def _urlparse(url, scheme='', allow_fragments=True):\n+def _urlparse(url, scheme=\"\", allow_fragments=True):\n     \"\"\"Parse a URL into 6 components:\n     <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n     Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n@@ -342,41 +361,42 @@ def _urlparse(url, scheme='', allow_fragments=True):\n     url, scheme, _coerce_result = _coerce_args(url, scheme)\n     splitresult = _urlsplit(url, scheme, allow_fragments)\n     scheme, netloc, url, query, fragment = splitresult\n-    if scheme in uses_params and ';' in url:\n+    if scheme in uses_params and \";\" in url:\n         url, params = _splitparams(url)\n     else:\n-        params = ''\n+        params = \"\"\n     result = ParseResult(scheme, netloc, url, params, query, fragment)\n     return _coerce_result(result)\n \n \n # Copied from urllib.parse.urlsplit() with\n # https://github.com/python/cpython/pull/661 applied.\n-def _urlsplit(url, scheme='', allow_fragments=True):\n+def _urlsplit(url, scheme=\"\", allow_fragments=True):\n     \"\"\"Parse a URL into 5 components:\n     <scheme>://<netloc>/<path>?<query>#<fragment>\n     Return a 5-tuple: (scheme, netloc, path, query, fragment).\n     Note that we don't break the components up in smaller bits\n     (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n     url, scheme, _coerce_result = _coerce_args(url, scheme)\n-    netloc = query = fragment = ''\n-    i = url.find(':')\n+    netloc = query = fragment = \"\"\n+    i = url.find(\":\")\n     if i > 0:\n         for c in url[:i]:\n             if c not in scheme_chars:\n                 break\n         else:\n-            scheme, url = url[:i].lower(), url[i + 1:]\n+            scheme, url = url[:i].lower(), url[i + 1 :]\n \n-    if url[:2] == '//':\n+    if url[:2] == \"//\":\n         netloc, url = _splitnetloc(url, 2)\n-        if (('[' in netloc and ']' not in netloc) or\n-                (']' in netloc and '[' not in netloc)):\n+        if (\"[\" in netloc and \"]\" not in netloc) or (\n+            \"]\" in netloc and \"[\" not in netloc\n+        ):\n             raise ValueError(\"Invalid IPv6 URL\")\n-    if allow_fragments and '#' in url:\n-        url, fragment = url.split('#', 1)\n-    if '?' in url:\n-        url, query = url.split('?', 1)\n+    if allow_fragments and \"#\" in url:\n+        url, fragment = url.split(\"#\", 1)\n+    if \"?\" in url:\n+        url, query = url.split(\"?\", 1)\n     v = SplitResult(scheme, netloc, url, query, fragment)\n     return _coerce_result(v)\n \n@@ -384,7 +404,7 @@ def _urlsplit(url, scheme='', allow_fragments=True):\n def _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n     # Chrome considers any URL with more than two slashes to be absolute, but\n     # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n-    if url.startswith('///'):\n+    if url.startswith(\"///\"):\n         return False\n     try:\n         url_info = _urlparse(url)\n@@ -399,19 +419,21 @@ def _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n     # Forbid URLs that start with control characters. Some browsers (like\n     # Chrome) ignore quite a few control characters at the start of a\n     # URL and might consider the URL as scheme relative.\n-    if unicodedata.category(url[0])[0] == 'C':\n+    if unicodedata.category(url[0])[0] == \"C\":\n         return False\n     scheme = url_info.scheme\n     # Consider URLs without a scheme (e.g. //example.com/p) to be http.\n     if not url_info.scheme and url_info.netloc:\n-        scheme = 'http'\n-    valid_schemes = ['https'] if require_https else ['http', 'https']\n-    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and\n-            (not scheme or scheme in valid_schemes))\n+        scheme = \"http\"\n+    valid_schemes = [\"https\"] if require_https else [\"http\", \"https\"]\n+    return (not url_info.netloc or url_info.netloc in allowed_hosts) and (\n+        not scheme or scheme in valid_schemes\n+    )\n \n \n-def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',\n-                      errors='replace', fields_limit=None):\n+def limited_parse_qsl(\n+    qs, keep_blank_values=False, encoding=\"utf-8\", errors=\"replace\", fields_limit=None\n+):\n     \"\"\"\n     Return a list of key/value tuples parsed from query string.\n \n@@ -438,8 +460,8 @@ def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',\n         pairs = FIELDS_MATCH.split(qs, fields_limit)\n         if len(pairs) > fields_limit:\n             raise TooManyFieldsSent(\n-                'The number of GET/POST parameters exceeded '\n-                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n+                \"The number of GET/POST parameters exceeded \"\n+                \"settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.\"\n             )\n     else:\n         pairs = FIELDS_MATCH.split(qs)\n@@ -447,17 +469,17 @@ def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',\n     for name_value in pairs:\n         if not name_value:\n             continue\n-        nv = name_value.split('=', 1)\n+        nv = name_value.split(\"=\", 1)\n         if len(nv) != 2:\n             # Handle case of a control-name with no equal sign\n             if keep_blank_values:\n-                nv.append('')\n+                nv.append(\"\")\n             else:\n                 continue\n         if nv[1] or keep_blank_values:\n-            name = nv[0].replace('+', ' ')\n+            name = nv[0].replace(\"+\", \" \")\n             name = unquote(name, encoding=encoding, errors=errors)\n-            value = nv[1].replace('+', ' ')\n+            value = nv[1].replace(\"+\", \" \")\n             value = unquote(value, encoding=encoding, errors=errors)\n             r.append((name, value))\n     return r\n@@ -469,6 +491,6 @@ def escape_leading_slashes(url):\n     escaped to prevent browsers from handling the path as schemaless and\n     redirecting to another host.\n     \"\"\"\n-    if url.startswith('//'):\n-        url = '/%2F{}'.format(url[2:])\n+    if url.startswith(\"//\"):\n+        url = \"/%2F{}\".format(url[2:])\n     return url\n"}
{"instance_id": "django__django-11905", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 9344979c56..36e1f19924 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -5,7 +5,12 @@ from copy import copy\n from django.core.exceptions import EmptyResultSet\n from django.db.models.expressions import Case, Exists, Func, Value, When\n from django.db.models.fields import (\n-    BooleanField, CharField, DateTimeField, Field, IntegerField, UUIDField,\n+    BooleanField,\n+    CharField,\n+    DateTimeField,\n+    Field,\n+    IntegerField,\n+    UUIDField,\n )\n from django.db.models.query_utils import RegisterLookupMixin\n from django.utils.datastructures import OrderedSet\n@@ -20,7 +25,7 @@ class Lookup:\n     def __init__(self, lhs, rhs):\n         self.lhs, self.rhs = lhs, rhs\n         self.rhs = self.get_prep_lookup()\n-        if hasattr(self.lhs, 'get_bilateral_transforms'):\n+        if hasattr(self.lhs, \"get_bilateral_transforms\"):\n             bilateral_transforms = self.lhs.get_bilateral_transforms()\n         else:\n             bilateral_transforms = []\n@@ -28,8 +33,11 @@ class Lookup:\n             # Warn the user as soon as possible if they are trying to apply\n             # a bilateral transformation on a nested QuerySet: that won't work.\n             from django.db.models.sql.query import Query  # avoid circular import\n+\n             if isinstance(rhs, Query):\n-                raise NotImplementedError(\"Bilateral transformations on nested querysets are not implemented.\")\n+                raise NotImplementedError(\n+                    \"Bilateral transformations on nested querysets are not implemented.\"\n+                )\n         self.bilateral_transforms = bilateral_transforms\n \n     def apply_bilateral_transforms(self, value):\n@@ -51,7 +59,7 @@ class Lookup:\n                 sqls_params.extend(sql_params)\n         else:\n             _, params = self.get_db_prep_lookup(rhs, connection)\n-            sqls, sqls_params = ['%s'] * len(params), params\n+            sqls, sqls_params = [\"%s\"] * len(params), params\n         return sqls, sqls_params\n \n     def get_source_expressions(self):\n@@ -66,18 +74,18 @@ class Lookup:\n             self.lhs, self.rhs = new_exprs\n \n     def get_prep_lookup(self):\n-        if hasattr(self.rhs, 'resolve_expression'):\n+        if hasattr(self.rhs, \"resolve_expression\"):\n             return self.rhs\n-        if self.prepare_rhs and hasattr(self.lhs.output_field, 'get_prep_value'):\n+        if self.prepare_rhs and hasattr(self.lhs.output_field, \"get_prep_value\"):\n             return self.lhs.output_field.get_prep_value(self.rhs)\n         return self.rhs\n \n     def get_db_prep_lookup(self, value, connection):\n-        return ('%s', [value])\n+        return (\"%s\", [value])\n \n     def process_lhs(self, compiler, connection, lhs=None):\n         lhs = lhs or self.lhs\n-        if hasattr(lhs, 'resolve_expression'):\n+        if hasattr(lhs, \"resolve_expression\"):\n             lhs = lhs.resolve_expression(compiler.query)\n         return compiler.compile(lhs)\n \n@@ -90,24 +98,24 @@ class Lookup:\n                 value = Value(value, output_field=self.lhs.output_field)\n             value = self.apply_bilateral_transforms(value)\n             value = value.resolve_expression(compiler.query)\n-        if hasattr(value, 'as_sql'):\n+        if hasattr(value, \"as_sql\"):\n             return compiler.compile(value)\n         else:\n             return self.get_db_prep_lookup(value, connection)\n \n     def rhs_is_direct_value(self):\n-        return not hasattr(self.rhs, 'as_sql')\n+        return not hasattr(self.rhs, \"as_sql\")\n \n     def relabeled_clone(self, relabels):\n         new = copy(self)\n         new.lhs = new.lhs.relabeled_clone(relabels)\n-        if hasattr(new.rhs, 'relabeled_clone'):\n+        if hasattr(new.rhs, \"relabeled_clone\"):\n             new.rhs = new.rhs.relabeled_clone(relabels)\n         return new\n \n     def get_group_by_cols(self, alias=None):\n         cols = self.lhs.get_group_by_cols()\n-        if hasattr(self.rhs, 'get_group_by_cols'):\n+        if hasattr(self.rhs, \"get_group_by_cols\"):\n             cols.extend(self.rhs.get_group_by_cols())\n         return cols\n \n@@ -121,7 +129,9 @@ class Lookup:\n         exprs = []\n         for expr in (self.lhs, self.rhs):\n             if isinstance(expr, Exists):\n-                expr = Case(When(expr, then=True), default=False, output_field=BooleanField())\n+                expr = Case(\n+                    When(expr, then=True), default=False, output_field=BooleanField()\n+                )\n                 wrapped = True\n             exprs.append(expr)\n         lookup = type(self)(*exprs) if wrapped else self\n@@ -129,15 +139,19 @@ class Lookup:\n \n     @cached_property\n     def contains_aggregate(self):\n-        return self.lhs.contains_aggregate or getattr(self.rhs, 'contains_aggregate', False)\n+        return self.lhs.contains_aggregate or getattr(\n+            self.rhs, \"contains_aggregate\", False\n+        )\n \n     @cached_property\n     def contains_over_clause(self):\n-        return self.lhs.contains_over_clause or getattr(self.rhs, 'contains_over_clause', False)\n+        return self.lhs.contains_over_clause or getattr(\n+            self.rhs, \"contains_over_clause\", False\n+        )\n \n     @property\n     def is_summary(self):\n-        return self.lhs.is_summary or getattr(self.rhs, 'is_summary', False)\n+        return self.lhs.is_summary or getattr(self.rhs, \"is_summary\", False)\n \n \n class Transform(RegisterLookupMixin, Func):\n@@ -145,6 +159,7 @@ class Transform(RegisterLookupMixin, Func):\n     RegisterLookupMixin() is first so that get_lookup() and get_transform()\n     first examine self and then check output_field.\n     \"\"\"\n+\n     bilateral = False\n     arity = 1\n \n@@ -153,7 +168,7 @@ class Transform(RegisterLookupMixin, Func):\n         return self.get_source_expressions()[0]\n \n     def get_bilateral_transforms(self):\n-        if hasattr(self.lhs, 'get_bilateral_transforms'):\n+        if hasattr(self.lhs, \"get_bilateral_transforms\"):\n             bilateral_transforms = self.lhs.get_bilateral_transforms()\n         else:\n             bilateral_transforms = []\n@@ -167,9 +182,10 @@ class BuiltinLookup(Lookup):\n         lhs_sql, params = super().process_lhs(compiler, connection, lhs)\n         field_internal_type = self.lhs.output_field.get_internal_type()\n         db_type = self.lhs.output_field.db_type(connection=connection)\n-        lhs_sql = connection.ops.field_cast_sql(\n-            db_type, field_internal_type) % lhs_sql\n-        lhs_sql = connection.ops.lookup_cast(self.lookup_name, field_internal_type) % lhs_sql\n+        lhs_sql = connection.ops.field_cast_sql(db_type, field_internal_type) % lhs_sql\n+        lhs_sql = (\n+            connection.ops.lookup_cast(self.lookup_name, field_internal_type) % lhs_sql\n+        )\n         return lhs_sql, list(params)\n \n     def as_sql(self, compiler, connection):\n@@ -177,7 +193,7 @@ class BuiltinLookup(Lookup):\n         rhs_sql, rhs_params = self.process_rhs(compiler, connection)\n         params.extend(rhs_params)\n         rhs_sql = self.get_rhs_op(connection, rhs_sql)\n-        return '%s %s' % (lhs_sql, rhs_sql), params\n+        return \"%s %s\" % (lhs_sql, rhs_sql), params\n \n     def get_rhs_op(self, connection, rhs):\n         return connection.operators[self.lookup_name] % rhs\n@@ -188,18 +204,22 @@ class FieldGetDbPrepValueMixin:\n     Some lookups require Field.get_db_prep_value() to be called on their\n     inputs.\n     \"\"\"\n+\n     get_db_prep_lookup_value_is_iterable = False\n \n     def get_db_prep_lookup(self, value, connection):\n         # For relational fields, use the 'target_field' attribute of the\n         # output_field.\n-        field = getattr(self.lhs.output_field, 'target_field', None)\n-        get_db_prep_value = getattr(field, 'get_db_prep_value', None) or self.lhs.output_field.get_db_prep_value\n+        field = getattr(self.lhs.output_field, \"target_field\", None)\n+        get_db_prep_value = (\n+            getattr(field, \"get_db_prep_value\", None)\n+            or self.lhs.output_field.get_db_prep_value\n+        )\n         return (\n-            '%s',\n+            \"%s\",\n             [get_db_prep_value(v, connection, prepared=True) for v in value]\n-            if self.get_db_prep_lookup_value_is_iterable else\n-            [get_db_prep_value(value, connection, prepared=True)]\n+            if self.get_db_prep_lookup_value_is_iterable\n+            else [get_db_prep_value(value, connection, prepared=True)],\n         )\n \n \n@@ -208,18 +228,19 @@ class FieldGetDbPrepValueIterableMixin(FieldGetDbPrepValueMixin):\n     Some lookups require Field.get_db_prep_value() to be called on each value\n     in an iterable.\n     \"\"\"\n+\n     get_db_prep_lookup_value_is_iterable = True\n \n     def get_prep_lookup(self):\n-        if hasattr(self.rhs, 'resolve_expression'):\n+        if hasattr(self.rhs, \"resolve_expression\"):\n             return self.rhs\n         prepared_values = []\n         for rhs_value in self.rhs:\n-            if hasattr(rhs_value, 'resolve_expression'):\n+            if hasattr(rhs_value, \"resolve_expression\"):\n                 # An expression will be handled by the database but can coexist\n                 # alongside real values.\n                 pass\n-            elif self.prepare_rhs and hasattr(self.lhs.output_field, 'get_prep_value'):\n+            elif self.prepare_rhs and hasattr(self.lhs.output_field, \"get_prep_value\"):\n                 rhs_value = self.lhs.output_field.get_prep_value(rhs_value)\n             prepared_values.append(rhs_value)\n         return prepared_values\n@@ -234,9 +255,9 @@ class FieldGetDbPrepValueIterableMixin(FieldGetDbPrepValueMixin):\n \n     def resolve_expression_parameter(self, compiler, connection, sql, param):\n         params = [param]\n-        if hasattr(param, 'resolve_expression'):\n+        if hasattr(param, \"resolve_expression\"):\n             param = param.resolve_expression(compiler.query)\n-        if hasattr(param, 'as_sql'):\n+        if hasattr(param, \"as_sql\"):\n             sql, params = param.as_sql(compiler, connection)\n         return sql, params\n \n@@ -246,36 +267,39 @@ class FieldGetDbPrepValueIterableMixin(FieldGetDbPrepValueMixin):\n         # sql/param pair. Zip them to get sql and param pairs that refer to the\n         # same argument and attempt to replace them with the result of\n         # compiling the param step.\n-        sql, params = zip(*(\n-            self.resolve_expression_parameter(compiler, connection, sql, param)\n-            for sql, param in zip(*pre_processed)\n-        ))\n+        sql, params = zip(\n+            *(\n+                self.resolve_expression_parameter(compiler, connection, sql, param)\n+                for sql, param in zip(*pre_processed)\n+            )\n+        )\n         params = itertools.chain.from_iterable(params)\n         return sql, tuple(params)\n \n \n @Field.register_lookup\n class Exact(FieldGetDbPrepValueMixin, BuiltinLookup):\n-    lookup_name = 'exact'\n+    lookup_name = \"exact\"\n \n     def process_rhs(self, compiler, connection):\n         from django.db.models.sql.query import Query\n+\n         if isinstance(self.rhs, Query):\n             if self.rhs.has_limit_one():\n                 if not self.rhs.has_select_fields:\n                     self.rhs.clear_select_clause()\n-                    self.rhs.add_fields(['pk'])\n+                    self.rhs.add_fields([\"pk\"])\n             else:\n                 raise ValueError(\n-                    'The QuerySet value for an exact lookup must be limited to '\n-                    'one result using slicing.'\n+                    \"The QuerySet value for an exact lookup must be limited to \"\n+                    \"one result using slicing.\"\n                 )\n         return super().process_rhs(compiler, connection)\n \n \n @Field.register_lookup\n class IExact(BuiltinLookup):\n-    lookup_name = 'iexact'\n+    lookup_name = \"iexact\"\n     prepare_rhs = False\n \n     def process_rhs(self, qn, connection):\n@@ -287,22 +311,22 @@ class IExact(BuiltinLookup):\n \n @Field.register_lookup\n class GreaterThan(FieldGetDbPrepValueMixin, BuiltinLookup):\n-    lookup_name = 'gt'\n+    lookup_name = \"gt\"\n \n \n @Field.register_lookup\n class GreaterThanOrEqual(FieldGetDbPrepValueMixin, BuiltinLookup):\n-    lookup_name = 'gte'\n+    lookup_name = \"gte\"\n \n \n @Field.register_lookup\n class LessThan(FieldGetDbPrepValueMixin, BuiltinLookup):\n-    lookup_name = 'lt'\n+    lookup_name = \"lt\"\n \n \n @Field.register_lookup\n class LessThanOrEqual(FieldGetDbPrepValueMixin, BuiltinLookup):\n-    lookup_name = 'lte'\n+    lookup_name = \"lte\"\n \n \n class IntegerFieldFloatRounding:\n@@ -310,6 +334,7 @@ class IntegerFieldFloatRounding:\n     Allow floats to work as query values for IntegerField. Without this, the\n     decimal portion of the float would always be discarded.\n     \"\"\"\n+\n     def get_prep_lookup(self):\n         if isinstance(self.rhs, float):\n             self.rhs = math.ceil(self.rhs)\n@@ -328,10 +353,10 @@ class IntegerLessThan(IntegerFieldFloatRounding, LessThan):\n \n @Field.register_lookup\n class In(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n-    lookup_name = 'in'\n+    lookup_name = \"in\"\n \n     def process_rhs(self, compiler, connection):\n-        db_rhs = getattr(self.rhs, '_db', None)\n+        db_rhs = getattr(self.rhs, \"_db\", None)\n         if db_rhs is not None and db_rhs != connection.alias:\n             raise ValueError(\n                 \"Subqueries aren't allowed across different databases. Force \"\n@@ -350,20 +375,24 @@ class In(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n             # rhs should be an iterable; use batch_process_rhs() to\n             # prepare/transform those values.\n             sqls, sqls_params = self.batch_process_rhs(compiler, connection, rhs)\n-            placeholder = '(' + ', '.join(sqls) + ')'\n+            placeholder = \"(\" + \", \".join(sqls) + \")\"\n             return (placeholder, sqls_params)\n         else:\n-            if not getattr(self.rhs, 'has_select_fields', True):\n+            if not getattr(self.rhs, \"has_select_fields\", True):\n                 self.rhs.clear_select_clause()\n-                self.rhs.add_fields(['pk'])\n+                self.rhs.add_fields([\"pk\"])\n             return super().process_rhs(compiler, connection)\n \n     def get_rhs_op(self, connection, rhs):\n-        return 'IN %s' % rhs\n+        return \"IN %s\" % rhs\n \n     def as_sql(self, compiler, connection):\n         max_in_list_size = connection.ops.max_in_list_size()\n-        if self.rhs_is_direct_value() and max_in_list_size and len(self.rhs) > max_in_list_size:\n+        if (\n+            self.rhs_is_direct_value()\n+            and max_in_list_size\n+            and len(self.rhs) > max_in_list_size\n+        ):\n             return self.split_parameter_list_as_sql(compiler, connection)\n         return super().as_sql(compiler, connection)\n \n@@ -373,25 +402,25 @@ class In(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n         max_in_list_size = connection.ops.max_in_list_size()\n         lhs, lhs_params = self.process_lhs(compiler, connection)\n         rhs, rhs_params = self.batch_process_rhs(compiler, connection)\n-        in_clause_elements = ['(']\n+        in_clause_elements = [\"(\"]\n         params = []\n         for offset in range(0, len(rhs_params), max_in_list_size):\n             if offset > 0:\n-                in_clause_elements.append(' OR ')\n-            in_clause_elements.append('%s IN (' % lhs)\n+                in_clause_elements.append(\" OR \")\n+            in_clause_elements.append(\"%s IN (\" % lhs)\n             params.extend(lhs_params)\n-            sqls = rhs[offset: offset + max_in_list_size]\n-            sqls_params = rhs_params[offset: offset + max_in_list_size]\n-            param_group = ', '.join(sqls)\n+            sqls = rhs[offset : offset + max_in_list_size]\n+            sqls_params = rhs_params[offset : offset + max_in_list_size]\n+            param_group = \", \".join(sqls)\n             in_clause_elements.append(param_group)\n-            in_clause_elements.append(')')\n+            in_clause_elements.append(\")\")\n             params.extend(sqls_params)\n-        in_clause_elements.append(')')\n-        return ''.join(in_clause_elements), params\n+        in_clause_elements.append(\")\")\n+        return \"\".join(in_clause_elements), params\n \n \n class PatternLookup(BuiltinLookup):\n-    param_pattern = '%%%s%%'\n+    param_pattern = \"%%%s%%\"\n     prepare_rhs = False\n \n     def get_rhs_op(self, connection, rhs):\n@@ -404,8 +433,10 @@ class PatternLookup(BuiltinLookup):\n         # So, for Python values we don't need any special pattern, but for\n         # SQL reference values or SQL transformations we need the correct\n         # pattern added.\n-        if hasattr(self.rhs, 'as_sql') or self.bilateral_transforms:\n-            pattern = connection.pattern_ops[self.lookup_name].format(connection.pattern_esc)\n+        if hasattr(self.rhs, \"as_sql\") or self.bilateral_transforms:\n+            pattern = connection.pattern_ops[self.lookup_name].format(\n+                connection.pattern_esc\n+            )\n             return pattern.format(rhs)\n         else:\n             return super().get_rhs_op(connection, rhs)\n@@ -413,45 +444,47 @@ class PatternLookup(BuiltinLookup):\n     def process_rhs(self, qn, connection):\n         rhs, params = super().process_rhs(qn, connection)\n         if self.rhs_is_direct_value() and params and not self.bilateral_transforms:\n-            params[0] = self.param_pattern % connection.ops.prep_for_like_query(params[0])\n+            params[0] = self.param_pattern % connection.ops.prep_for_like_query(\n+                params[0]\n+            )\n         return rhs, params\n \n \n @Field.register_lookup\n class Contains(PatternLookup):\n-    lookup_name = 'contains'\n+    lookup_name = \"contains\"\n \n \n @Field.register_lookup\n class IContains(Contains):\n-    lookup_name = 'icontains'\n+    lookup_name = \"icontains\"\n \n \n @Field.register_lookup\n class StartsWith(PatternLookup):\n-    lookup_name = 'startswith'\n-    param_pattern = '%s%%'\n+    lookup_name = \"startswith\"\n+    param_pattern = \"%s%%\"\n \n \n @Field.register_lookup\n class IStartsWith(StartsWith):\n-    lookup_name = 'istartswith'\n+    lookup_name = \"istartswith\"\n \n \n @Field.register_lookup\n class EndsWith(PatternLookup):\n-    lookup_name = 'endswith'\n-    param_pattern = '%%%s'\n+    lookup_name = \"endswith\"\n+    param_pattern = \"%%%s\"\n \n \n @Field.register_lookup\n class IEndsWith(EndsWith):\n-    lookup_name = 'iendswith'\n+    lookup_name = \"iendswith\"\n \n \n @Field.register_lookup\n class Range(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n-    lookup_name = 'range'\n+    lookup_name = \"range\"\n \n     def get_rhs_op(self, connection, rhs):\n         return \"BETWEEN %s AND %s\" % (rhs[0], rhs[1])\n@@ -459,9 +492,14 @@ class Range(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n \n @Field.register_lookup\n class IsNull(BuiltinLookup):\n-    lookup_name = 'isnull'\n+    lookup_name = \"isnull\"\n     prepare_rhs = False\n \n+    def get_prep_lookup(self):\n+        if not isinstance(self.rhs, bool):\n+            raise ValueError(\"The __isnull lookup must be used with a boolean value.\")\n+        return super().get_prep_lookup()\n+\n     def as_sql(self, compiler, connection):\n         sql, params = compiler.compile(self.lhs)\n         if self.rhs:\n@@ -472,7 +510,7 @@ class IsNull(BuiltinLookup):\n \n @Field.register_lookup\n class Regex(BuiltinLookup):\n-    lookup_name = 'regex'\n+    lookup_name = \"regex\"\n     prepare_rhs = False\n \n     def as_sql(self, compiler, connection):\n@@ -487,7 +525,7 @@ class Regex(BuiltinLookup):\n \n @Field.register_lookup\n class IRegex(Regex):\n-    lookup_name = 'iregex'\n+    lookup_name = \"iregex\"\n \n \n class YearLookup(Lookup):\n@@ -510,7 +548,7 @@ class YearLookup(Lookup):\n             rhs_sql = self.get_direct_rhs_sql(connection, rhs_sql)\n             start, finish = self.year_lookup_bounds(connection, self.rhs)\n             params.extend(self.get_bound_params(start, finish))\n-            return '%s %s' % (lhs_sql, rhs_sql), params\n+            return \"%s %s\" % (lhs_sql, rhs_sql), params\n         return super().as_sql(compiler, connection)\n \n     def get_direct_rhs_sql(self, connection, rhs):\n@@ -518,13 +556,13 @@ class YearLookup(Lookup):\n \n     def get_bound_params(self, start, finish):\n         raise NotImplementedError(\n-            'subclasses of YearLookup must provide a get_bound_params() method'\n+            \"subclasses of YearLookup must provide a get_bound_params() method\"\n         )\n \n \n class YearExact(YearLookup, Exact):\n     def get_direct_rhs_sql(self, connection, rhs):\n-        return 'BETWEEN %s AND %s'\n+        return \"BETWEEN %s AND %s\"\n \n     def get_bound_params(self, start, finish):\n         return (start, finish)\n@@ -555,12 +593,16 @@ class UUIDTextMixin:\n     Strip hyphens from a value when filtering a UUIDField on backends without\n     a native datatype for UUID.\n     \"\"\"\n+\n     def process_rhs(self, qn, connection):\n         if not connection.features.has_native_uuid_field:\n             from django.db.models.functions import Replace\n+\n             if self.rhs_is_direct_value():\n                 self.rhs = Value(self.rhs)\n-            self.rhs = Replace(self.rhs, Value('-'), Value(''), output_field=CharField())\n+            self.rhs = Replace(\n+                self.rhs, Value(\"-\"), Value(\"\"), output_field=CharField()\n+            )\n         rhs, params = super().process_rhs(qn, connection)\n         return rhs, params\n \n"}
{"instance_id": "django__django-11910", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 1c40161c7f..49fa53a404 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -10,7 +10,9 @@ from django.db.migrations.operations.models import AlterModelOptions\n from django.db.migrations.optimizer import MigrationOptimizer\n from django.db.migrations.questioner import MigrationQuestioner\n from django.db.migrations.utils import (\n-    COMPILED_REGEX_TYPE, RegexObject, get_migration_name_timestamp,\n+    COMPILED_REGEX_TYPE,\n+    RegexObject,\n+    get_migration_name_timestamp,\n )\n from django.utils.topological_sort import stable_topological_sort\n \n@@ -57,19 +59,20 @@ class MigrationAutodetector:\n         elif isinstance(obj, tuple):\n             return tuple(self.deep_deconstruct(value) for value in obj)\n         elif isinstance(obj, dict):\n-            return {\n-                key: self.deep_deconstruct(value)\n-                for key, value in obj.items()\n-            }\n+            return {key: self.deep_deconstruct(value) for key, value in obj.items()}\n         elif isinstance(obj, functools.partial):\n-            return (obj.func, self.deep_deconstruct(obj.args), self.deep_deconstruct(obj.keywords))\n+            return (\n+                obj.func,\n+                self.deep_deconstruct(obj.args),\n+                self.deep_deconstruct(obj.keywords),\n+            )\n         elif isinstance(obj, COMPILED_REGEX_TYPE):\n             return RegexObject(obj)\n         elif isinstance(obj, type):\n             # If this is a type that implements 'deconstruct' as an instance method,\n             # avoid treating this as being deconstructible itself - see #22951\n             return obj\n-        elif hasattr(obj, 'deconstruct'):\n+        elif hasattr(obj, \"deconstruct\"):\n             deconstructed = obj.deconstruct()\n             if isinstance(obj, models.Field):\n                 # we have a field which also returns a name\n@@ -78,10 +81,7 @@ class MigrationAutodetector:\n             return (\n                 path,\n                 [self.deep_deconstruct(value) for value in args],\n-                {\n-                    key: self.deep_deconstruct(value)\n-                    for key, value in kwargs.items()\n-                },\n+                {key: self.deep_deconstruct(value) for key, value in kwargs.items()},\n             )\n         else:\n             return obj\n@@ -96,7 +96,7 @@ class MigrationAutodetector:\n         for name, field in sorted(fields):\n             deconstruction = self.deep_deconstruct(field)\n             if field.remote_field and field.remote_field.model:\n-                del deconstruction[2]['to']\n+                del deconstruction[2][\"to\"]\n             fields_def.append(deconstruction)\n         return fields_def\n \n@@ -147,9 +147,8 @@ class MigrationAutodetector:\n             model = self.new_apps.get_model(al, mn)\n             if not model._meta.managed:\n                 self.new_unmanaged_keys.add((al, mn))\n-            elif (\n-                al not in self.from_state.real_apps or\n-                (convert_apps and al in convert_apps)\n+            elif al not in self.from_state.real_apps or (\n+                convert_apps and al in convert_apps\n             ):\n                 if model._meta.proxy:\n                     self.new_proxy_keys.add((al, mn))\n@@ -211,8 +210,7 @@ class MigrationAutodetector:\n             (app_label, model_name, x)\n             for app_label, model_name in self.kept_model_keys\n             for x, y in self.from_state.models[\n-                app_label,\n-                self.renamed_models.get((app_label, model_name), model_name)\n+                app_label, self.renamed_models.get((app_label, model_name), model_name)\n             ].fields\n         }\n         self.new_field_keys = {\n@@ -224,17 +222,28 @@ class MigrationAutodetector:\n     def _generate_through_model_map(self):\n         \"\"\"Through model map generation.\"\"\"\n         for app_label, model_name in sorted(self.old_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             for field_name, field in old_model_state.fields:\n-                old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(field_name)\n-                if (hasattr(old_field, \"remote_field\") and getattr(old_field.remote_field, \"through\", None) and\n-                        not old_field.remote_field.through._meta.auto_created):\n+                old_field = self.old_apps.get_model(\n+                    app_label, old_model_name\n+                )._meta.get_field(field_name)\n+                if (\n+                    hasattr(old_field, \"remote_field\")\n+                    and getattr(old_field.remote_field, \"through\", None)\n+                    and not old_field.remote_field.through._meta.auto_created\n+                ):\n                     through_key = (\n                         old_field.remote_field.through._meta.app_label,\n                         old_field.remote_field.through._meta.model_name,\n                     )\n-                    self.through_users[through_key] = (app_label, old_model_name, field_name)\n+                    self.through_users[through_key] = (\n+                        app_label,\n+                        old_model_name,\n+                        field_name,\n+                    )\n \n     @staticmethod\n     def _resolve_dependency(dependency):\n@@ -242,9 +251,11 @@ class MigrationAutodetector:\n         Return the resolved dependency and a boolean denoting whether or not\n         it was swappable.\n         \"\"\"\n-        if dependency[0] != '__setting__':\n+        if dependency[0] != \"__setting__\":\n             return dependency, False\n-        resolved_app_label, resolved_object_name = getattr(settings, dependency[1]).split('.')\n+        resolved_app_label, resolved_object_name = getattr(\n+            settings, dependency[1]\n+        ).split(\".\")\n         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True\n \n     def _build_migration_list(self, graph=None):\n@@ -284,7 +295,9 @@ class MigrationAutodetector:\n                         if dep[0] != app_label:\n                             # External app dependency. See if it's not yet\n                             # satisfied.\n-                            for other_operation in self.generated_operations.get(dep[0], []):\n+                            for other_operation in self.generated_operations.get(\n+                                dep[0], []\n+                            ):\n                                 if self.check_dependency(other_operation, dep):\n                                     deps_satisfied = False\n                                     break\n@@ -292,9 +305,13 @@ class MigrationAutodetector:\n                                 break\n                             else:\n                                 if is_swappable_dep:\n-                                    operation_dependencies.add((original_dep[0], original_dep[1]))\n+                                    operation_dependencies.add(\n+                                        (original_dep[0], original_dep[1])\n+                                    )\n                                 elif dep[0] in self.migrations:\n-                                    operation_dependencies.add((dep[0], self.migrations[dep[0]][-1].name))\n+                                    operation_dependencies.add(\n+                                        (dep[0], self.migrations[dep[0]][-1].name)\n+                                    )\n                                 else:\n                                     # If we can't find the other app, we add a first/last dependency,\n                                     # but only if we've already been through once and checked everything\n@@ -303,9 +320,13 @@ class MigrationAutodetector:\n                                         # as we don't know which migration contains the target field.\n                                         # If it's not yet migrated or has no migrations, we use __first__\n                                         if graph and graph.leaf_nodes(dep[0]):\n-                                            operation_dependencies.add(graph.leaf_nodes(dep[0])[0])\n+                                            operation_dependencies.add(\n+                                                graph.leaf_nodes(dep[0])[0]\n+                                            )\n                                         else:\n-                                            operation_dependencies.add((dep[0], \"__first__\"))\n+                                            operation_dependencies.add(\n+                                                (dep[0], \"__first__\")\n+                                            )\n                                     else:\n                                         deps_satisfied = False\n                     if deps_satisfied:\n@@ -317,21 +338,33 @@ class MigrationAutodetector:\n                 # Make a migration! Well, only if there's stuff to put in it\n                 if dependencies or chopped:\n                     if not self.generated_operations[app_label] or chop_mode:\n-                        subclass = type(\"Migration\", (Migration,), {\"operations\": [], \"dependencies\": []})\n-                        instance = subclass(\"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1), app_label)\n+                        subclass = type(\n+                            \"Migration\",\n+                            (Migration,),\n+                            {\"operations\": [], \"dependencies\": []},\n+                        )\n+                        instance = subclass(\n+                            \"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1),\n+                            app_label,\n+                        )\n                         instance.dependencies = list(dependencies)\n                         instance.operations = chopped\n                         instance.initial = app_label not in self.existing_apps\n                         self.migrations.setdefault(app_label, []).append(instance)\n                         chop_mode = False\n                     else:\n-                        self.generated_operations[app_label] = chopped + self.generated_operations[app_label]\n+                        self.generated_operations[app_label] = (\n+                            chopped + self.generated_operations[app_label]\n+                        )\n             new_num_ops = sum(len(x) for x in self.generated_operations.values())\n             if new_num_ops == num_ops:\n                 if not chop_mode:\n                     chop_mode = True\n                 else:\n-                    raise ValueError(\"Cannot resolve operation dependencies: %r\" % self.generated_operations)\n+                    raise ValueError(\n+                        \"Cannot resolve operation dependencies: %r\"\n+                        % self.generated_operations\n+                    )\n             num_ops = new_num_ops\n \n     def _sort_migrations(self):\n@@ -353,7 +386,9 @@ class MigrationAutodetector:\n                                 dependency_graph[op].add(op2)\n \n             # we use a stable sort for deterministic tests & general behavior\n-            self.generated_operations[app_label] = stable_topological_sort(ops, dependency_graph)\n+            self.generated_operations[app_label] = stable_topological_sort(\n+                ops, dependency_graph\n+            )\n \n     def _optimize_migrations(self):\n         # Add in internal dependencies among the migrations\n@@ -369,7 +404,9 @@ class MigrationAutodetector:\n         # Optimize migrations\n         for app_label, migrations in self.migrations.items():\n             for migration in migrations:\n-                migration.operations = MigrationOptimizer().optimize(migration.operations, app_label=app_label)\n+                migration.operations = MigrationOptimizer().optimize(\n+                    migration.operations, app_label=app_label\n+                )\n \n     def check_dependency(self, operation, dependency):\n         \"\"\"\n@@ -379,56 +416,56 @@ class MigrationAutodetector:\n         # Created model\n         if dependency[2] is None and dependency[3] is True:\n             return (\n-                isinstance(operation, operations.CreateModel) and\n-                operation.name_lower == dependency[1].lower()\n+                isinstance(operation, operations.CreateModel)\n+                and operation.name_lower == dependency[1].lower()\n             )\n         # Created field\n         elif dependency[2] is not None and dependency[3] is True:\n             return (\n-                (\n-                    isinstance(operation, operations.CreateModel) and\n-                    operation.name_lower == dependency[1].lower() and\n-                    any(dependency[2] == x for x, y in operation.fields)\n-                ) or\n-                (\n-                    isinstance(operation, operations.AddField) and\n-                    operation.model_name_lower == dependency[1].lower() and\n-                    operation.name_lower == dependency[2].lower()\n-                )\n+                isinstance(operation, operations.CreateModel)\n+                and operation.name_lower == dependency[1].lower()\n+                and any(dependency[2] == x for x, y in operation.fields)\n+            ) or (\n+                isinstance(operation, operations.AddField)\n+                and operation.model_name_lower == dependency[1].lower()\n+                and operation.name_lower == dependency[2].lower()\n             )\n         # Removed field\n         elif dependency[2] is not None and dependency[3] is False:\n             return (\n-                isinstance(operation, operations.RemoveField) and\n-                operation.model_name_lower == dependency[1].lower() and\n-                operation.name_lower == dependency[2].lower()\n+                isinstance(operation, operations.RemoveField)\n+                and operation.model_name_lower == dependency[1].lower()\n+                and operation.name_lower == dependency[2].lower()\n             )\n         # Removed model\n         elif dependency[2] is None and dependency[3] is False:\n             return (\n-                isinstance(operation, operations.DeleteModel) and\n-                operation.name_lower == dependency[1].lower()\n+                isinstance(operation, operations.DeleteModel)\n+                and operation.name_lower == dependency[1].lower()\n             )\n         # Field being altered\n         elif dependency[2] is not None and dependency[3] == \"alter\":\n             return (\n-                isinstance(operation, operations.AlterField) and\n-                operation.model_name_lower == dependency[1].lower() and\n-                operation.name_lower == dependency[2].lower()\n+                isinstance(operation, operations.AlterField)\n+                and operation.model_name_lower == dependency[1].lower()\n+                and operation.name_lower == dependency[2].lower()\n             )\n         # order_with_respect_to being unset for a field\n         elif dependency[2] is not None and dependency[3] == \"order_wrt_unset\":\n             return (\n-                isinstance(operation, operations.AlterOrderWithRespectTo) and\n-                operation.name_lower == dependency[1].lower() and\n-                (operation.order_with_respect_to or \"\").lower() != dependency[2].lower()\n+                isinstance(operation, operations.AlterOrderWithRespectTo)\n+                and operation.name_lower == dependency[1].lower()\n+                and (operation.order_with_respect_to or \"\").lower()\n+                != dependency[2].lower()\n             )\n         # Field is removed and part of an index/unique_together\n         elif dependency[2] is not None and dependency[3] == \"foo_together_change\":\n             return (\n-                isinstance(operation, (operations.AlterUniqueTogether,\n-                                       operations.AlterIndexTogether)) and\n-                operation.name_lower == dependency[1].lower()\n+                isinstance(\n+                    operation,\n+                    (operations.AlterUniqueTogether, operations.AlterIndexTogether),\n+                )\n+                and operation.name_lower == dependency[1].lower()\n             )\n         # Unknown dependency. Raise an error.\n         else:\n@@ -452,10 +489,10 @@ class MigrationAutodetector:\n             base_names = [base.__name__ for base in model.__bases__]\n             string_version = \"%s.%s\" % (item[0], item[1])\n             if (\n-                model._meta.swappable or\n-                \"AbstractUser\" in base_names or\n-                \"AbstractBaseUser\" in base_names or\n-                settings.AUTH_USER_MODEL.lower() == string_version.lower()\n+                model._meta.swappable\n+                or \"AbstractUser\" in base_names\n+                or \"AbstractBaseUser\" in base_names\n+                or settings.AUTH_USER_MODEL.lower() == string_version.lower()\n             ):\n                 return (\"___\" + item[0], \"___\" + item[1])\n         except LookupError:\n@@ -478,15 +515,25 @@ class MigrationAutodetector:\n             removed_models = self.old_model_keys - self.new_model_keys\n             for rem_app_label, rem_model_name in removed_models:\n                 if rem_app_label == app_label:\n-                    rem_model_state = self.from_state.models[rem_app_label, rem_model_name]\n-                    rem_model_fields_def = self.only_relation_agnostic_fields(rem_model_state.fields)\n+                    rem_model_state = self.from_state.models[\n+                        rem_app_label, rem_model_name\n+                    ]\n+                    rem_model_fields_def = self.only_relation_agnostic_fields(\n+                        rem_model_state.fields\n+                    )\n                     if model_fields_def == rem_model_fields_def:\n-                        if self.questioner.ask_rename_model(rem_model_state, model_state):\n-                            model_opts = self.new_apps.get_model(app_label, model_name)._meta\n+                        if self.questioner.ask_rename_model(\n+                            rem_model_state, model_state\n+                        ):\n+                            model_opts = self.new_apps.get_model(\n+                                app_label, model_name\n+                            )._meta\n                             dependencies = []\n                             for field in model_opts.get_fields():\n                                 if field.is_relation:\n-                                    dependencies.extend(self._get_dependencies_for_foreign_key(field))\n+                                    dependencies.extend(\n+                                        self._get_dependencies_for_foreign_key(field)\n+                                    )\n                             self.add_operation(\n                                 app_label,\n                                 operations.RenameModel(\n@@ -496,10 +543,16 @@ class MigrationAutodetector:\n                                 dependencies=dependencies,\n                             )\n                             self.renamed_models[app_label, model_name] = rem_model_name\n-                            renamed_models_rel_key = '%s.%s' % (rem_model_state.app_label, rem_model_state.name)\n-                            self.renamed_models_rel[renamed_models_rel_key] = '%s.%s' % (\n-                                model_state.app_label,\n-                                model_state.name,\n+                            renamed_models_rel_key = \"%s.%s\" % (\n+                                rem_model_state.app_label,\n+                                rem_model_state.name,\n+                            )\n+                            self.renamed_models_rel[renamed_models_rel_key] = (\n+                                \"%s.%s\"\n+                                % (\n+                                    model_state.app_label,\n+                                    model_state.name,\n+                                )\n                             )\n                             self.old_model_keys.remove((rem_app_label, rem_model_name))\n                             self.old_model_keys.add((app_label, model_name))\n@@ -520,7 +573,7 @@ class MigrationAutodetector:\n         added_unmanaged_models = self.new_unmanaged_keys - old_keys\n         all_added_models = chain(\n             sorted(added_models, key=self.swappable_first_key, reverse=True),\n-            sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True)\n+            sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),\n         )\n         for app_label, model_name in all_added_models:\n             model_state = self.to_state.models[app_label, model_name]\n@@ -537,20 +590,27 @@ class MigrationAutodetector:\n                             related_fields[field.name] = field\n                     # through will be none on M2Ms on swapped-out models;\n                     # we can treat lack of through as auto_created=True, though.\n-                    if (getattr(field.remote_field, \"through\", None) and\n-                            not field.remote_field.through._meta.auto_created):\n+                    if (\n+                        getattr(field.remote_field, \"through\", None)\n+                        and not field.remote_field.through._meta.auto_created\n+                    ):\n                         related_fields[field.name] = field\n             for field in model_opts.local_many_to_many:\n                 if field.remote_field.model:\n                     related_fields[field.name] = field\n-                if getattr(field.remote_field, \"through\", None) and not field.remote_field.through._meta.auto_created:\n+                if (\n+                    getattr(field.remote_field, \"through\", None)\n+                    and not field.remote_field.through._meta.auto_created\n+                ):\n                     related_fields[field.name] = field\n             # Are there indexes/unique|index_together to defer?\n-            indexes = model_state.options.pop('indexes')\n-            constraints = model_state.options.pop('constraints')\n-            unique_together = model_state.options.pop('unique_together', None)\n-            index_together = model_state.options.pop('index_together', None)\n-            order_with_respect_to = model_state.options.pop('order_with_respect_to', None)\n+            indexes = model_state.options.pop(\"indexes\")\n+            constraints = model_state.options.pop(\"constraints\")\n+            unique_together = model_state.options.pop(\"unique_together\", None)\n+            index_together = model_state.options.pop(\"index_together\", None)\n+            order_with_respect_to = model_state.options.pop(\n+                \"order_with_respect_to\", None\n+            )\n             # Depend on the deletion of any possible proxy version of us\n             dependencies = [\n                 (app_label, model_name, None, False),\n@@ -562,18 +622,22 @@ class MigrationAutodetector:\n                     dependencies.append((base_app_label, base_name, None, True))\n             # Depend on the other end of the primary key if it's a relation\n             if primary_key_rel:\n-                dependencies.append((\n-                    primary_key_rel._meta.app_label,\n-                    primary_key_rel._meta.object_name,\n-                    None,\n-                    True\n-                ))\n+                dependencies.append(\n+                    (\n+                        primary_key_rel._meta.app_label,\n+                        primary_key_rel._meta.object_name,\n+                        None,\n+                        True,\n+                    )\n+                )\n             # Generate creation operation\n             self.add_operation(\n                 app_label,\n                 operations.CreateModel(\n                     name=model_state.name,\n-                    fields=[d for d in model_state.fields if d[0] not in related_fields],\n+                    fields=[\n+                        d for d in model_state.fields if d[0] not in related_fields\n+                    ],\n                     options=model_state.options,\n                     bases=model_state.bases,\n                     managers=model_state.managers,\n@@ -603,8 +667,7 @@ class MigrationAutodetector:\n                 )\n             # Generate other opns\n             related_dependencies = [\n-                (app_label, model_name, name, True)\n-                for name in sorted(related_fields)\n+                (app_label, model_name, name, True) for name in sorted(related_fields)\n             ]\n             related_dependencies.append((app_label, model_name, None, True))\n             for index in indexes:\n@@ -632,7 +695,7 @@ class MigrationAutodetector:\n                         name=model_name,\n                         unique_together=unique_together,\n                     ),\n-                    dependencies=related_dependencies\n+                    dependencies=related_dependencies,\n                 )\n             if index_together:\n                 self.add_operation(\n@@ -641,7 +704,7 @@ class MigrationAutodetector:\n                         name=model_name,\n                         index_together=index_together,\n                     ),\n-                    dependencies=related_dependencies\n+                    dependencies=related_dependencies,\n                 )\n             if order_with_respect_to:\n                 self.add_operation(\n@@ -653,7 +716,7 @@ class MigrationAutodetector:\n                     dependencies=[\n                         (app_label, model_name, order_with_respect_to, True),\n                         (app_label, model_name, None, True),\n-                    ]\n+                    ],\n                 )\n \n             # Fix relationships if the model changed from a proxy model to a\n@@ -717,7 +780,9 @@ class MigrationAutodetector:\n         new_keys = self.new_model_keys | self.new_unmanaged_keys\n         deleted_models = self.old_model_keys - new_keys\n         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys\n-        all_deleted_models = chain(sorted(deleted_models), sorted(deleted_unmanaged_models))\n+        all_deleted_models = chain(\n+            sorted(deleted_models), sorted(deleted_unmanaged_models)\n+        )\n         for app_label, model_name in all_deleted_models:\n             model_state = self.from_state.models[app_label, model_name]\n             model = self.old_apps.get_model(app_label, model_name)\n@@ -729,24 +794,29 @@ class MigrationAutodetector:\n                         related_fields[field.name] = field\n                     # through will be none on M2Ms on swapped-out models;\n                     # we can treat lack of through as auto_created=True, though.\n-                    if (getattr(field.remote_field, \"through\", None) and\n-                            not field.remote_field.through._meta.auto_created):\n+                    if (\n+                        getattr(field.remote_field, \"through\", None)\n+                        and not field.remote_field.through._meta.auto_created\n+                    ):\n                         related_fields[field.name] = field\n             for field in model._meta.local_many_to_many:\n                 if field.remote_field.model:\n                     related_fields[field.name] = field\n-                if getattr(field.remote_field, \"through\", None) and not field.remote_field.through._meta.auto_created:\n+                if (\n+                    getattr(field.remote_field, \"through\", None)\n+                    and not field.remote_field.through._meta.auto_created\n+                ):\n                     related_fields[field.name] = field\n             # Generate option removal first\n-            unique_together = model_state.options.pop('unique_together', None)\n-            index_together = model_state.options.pop('index_together', None)\n+            unique_together = model_state.options.pop(\"unique_together\", None)\n+            index_together = model_state.options.pop(\"index_together\", None)\n             if unique_together:\n                 self.add_operation(\n                     app_label,\n                     operations.AlterUniqueTogether(\n                         name=model_name,\n                         unique_together=None,\n-                    )\n+                    ),\n                 )\n             if index_together:\n                 self.add_operation(\n@@ -754,7 +824,7 @@ class MigrationAutodetector:\n                     operations.AlterIndexTogether(\n                         name=model_name,\n                         index_together=None,\n-                    )\n+                    ),\n                 )\n             # Then remove each related field\n             for name in sorted(related_fields):\n@@ -763,7 +833,7 @@ class MigrationAutodetector:\n                     operations.RemoveField(\n                         model_name=model_name,\n                         name=name,\n-                    )\n+                    ),\n                 )\n             # Finally, remove the model.\n             # This depends on both the removal/alteration of all incoming fields\n@@ -774,16 +844,22 @@ class MigrationAutodetector:\n                 related_object_app_label = related_object.related_model._meta.app_label\n                 object_name = related_object.related_model._meta.object_name\n                 field_name = related_object.field.name\n-                dependencies.append((related_object_app_label, object_name, field_name, False))\n+                dependencies.append(\n+                    (related_object_app_label, object_name, field_name, False)\n+                )\n                 if not related_object.many_to_many:\n-                    dependencies.append((related_object_app_label, object_name, field_name, \"alter\"))\n+                    dependencies.append(\n+                        (related_object_app_label, object_name, field_name, \"alter\")\n+                    )\n \n             for name in sorted(related_fields):\n                 dependencies.append((app_label, model_name, name, False))\n             # We're referenced in another field's through=\n             through_user = self.through_users.get((app_label, model_state.name_lower))\n             if through_user:\n-                dependencies.append((through_user[0], through_user[1], through_user[2], False))\n+                dependencies.append(\n+                    (through_user[0], through_user[1], through_user[2], False)\n+                )\n             # Finally, make the operation, deduping any dependencies\n             self.add_operation(\n                 app_label,\n@@ -809,48 +885,72 @@ class MigrationAutodetector:\n     def generate_renamed_fields(self):\n         \"\"\"Work out renamed fields.\"\"\"\n         self.renamed_fields = {}\n-        for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+        for app_label, model_name, field_name in sorted(\n+            self.new_field_keys - self.old_field_keys\n+        ):\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n-            field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n+            field = self.new_apps.get_model(app_label, model_name)._meta.get_field(\n+                field_name\n+            )\n             # Scan to see if this is actually a rename!\n             field_dec = self.deep_deconstruct(field)\n-            for rem_app_label, rem_model_name, rem_field_name in sorted(self.old_field_keys - self.new_field_keys):\n+            for rem_app_label, rem_model_name, rem_field_name in sorted(\n+                self.old_field_keys - self.new_field_keys\n+            ):\n                 if rem_app_label == app_label and rem_model_name == model_name:\n                     old_field = old_model_state.get_field_by_name(rem_field_name)\n                     old_field_dec = self.deep_deconstruct(old_field)\n-                    if field.remote_field and field.remote_field.model and 'to' in old_field_dec[2]:\n-                        old_rel_to = old_field_dec[2]['to']\n+                    if (\n+                        field.remote_field\n+                        and field.remote_field.model\n+                        and \"to\" in old_field_dec[2]\n+                    ):\n+                        old_rel_to = old_field_dec[2][\"to\"]\n                         if old_rel_to in self.renamed_models_rel:\n-                            old_field_dec[2]['to'] = self.renamed_models_rel[old_rel_to]\n+                            old_field_dec[2][\"to\"] = self.renamed_models_rel[old_rel_to]\n                     old_field.set_attributes_from_name(rem_field_name)\n                     old_db_column = old_field.get_attname_column()[1]\n-                    if (old_field_dec == field_dec or (\n-                            # Was the field renamed and db_column equal to the\n-                            # old field's column added?\n-                            old_field_dec[0:2] == field_dec[0:2] and\n-                            dict(old_field_dec[2], db_column=old_db_column) == field_dec[2])):\n-                        if self.questioner.ask_rename(model_name, rem_field_name, field_name, field):\n+                    if old_field_dec == field_dec or (\n+                        # Was the field renamed and db_column equal to the\n+                        # old field's column added?\n+                        old_field_dec[0:2] == field_dec[0:2]\n+                        and dict(old_field_dec[2], db_column=old_db_column)\n+                        == field_dec[2]\n+                    ):\n+                        if self.questioner.ask_rename(\n+                            model_name, rem_field_name, field_name, field\n+                        ):\n                             self.add_operation(\n                                 app_label,\n                                 operations.RenameField(\n                                     model_name=model_name,\n                                     old_name=rem_field_name,\n                                     new_name=field_name,\n-                                )\n+                                ),\n+                            )\n+                            self.old_field_keys.remove(\n+                                (rem_app_label, rem_model_name, rem_field_name)\n                             )\n-                            self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))\n                             self.old_field_keys.add((app_label, model_name, field_name))\n-                            self.renamed_fields[app_label, model_name, field_name] = rem_field_name\n+                            self.renamed_fields[app_label, model_name, field_name] = (\n+                                rem_field_name\n+                            )\n                             break\n \n     def generate_added_fields(self):\n         \"\"\"Make AddField operations.\"\"\"\n-        for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n+        for app_label, model_name, field_name in sorted(\n+            self.new_field_keys - self.old_field_keys\n+        ):\n             self._generate_added_field(app_label, model_name, field_name)\n \n     def _generate_added_field(self, app_label, model_name, field_name):\n-        field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n+        field = self.new_apps.get_model(app_label, model_name)._meta.get_field(\n+            field_name\n+        )\n         # Fields that are foreignkeys/m2ms depend on stuff\n         dependencies = []\n         if field.remote_field and field.remote_field.model:\n@@ -859,16 +959,22 @@ class MigrationAutodetector:\n         # which don't allow empty strings as default.\n         time_fields = (models.DateField, models.DateTimeField, models.TimeField)\n         preserve_default = (\n-            field.null or field.has_default() or field.many_to_many or\n-            (field.blank and field.empty_strings_allowed) or\n-            (isinstance(field, time_fields) and field.auto_now)\n+            field.null\n+            or field.has_default()\n+            or field.many_to_many\n+            or (field.blank and field.empty_strings_allowed)\n+            or (isinstance(field, time_fields) and field.auto_now)\n         )\n         if not preserve_default:\n             field = field.clone()\n             if isinstance(field, time_fields) and field.auto_now_add:\n-                field.default = self.questioner.ask_auto_now_add_addition(field_name, model_name)\n+                field.default = self.questioner.ask_auto_now_add_addition(\n+                    field_name, model_name\n+                )\n             else:\n-                field.default = self.questioner.ask_not_null_addition(field_name, model_name)\n+                field.default = self.questioner.ask_not_null_addition(\n+                    field_name, model_name\n+                )\n         self.add_operation(\n             app_label,\n             operations.AddField(\n@@ -882,7 +988,9 @@ class MigrationAutodetector:\n \n     def generate_removed_fields(self):\n         \"\"\"Make RemoveField operations.\"\"\"\n-        for app_label, model_name, field_name in sorted(self.old_field_keys - self.new_field_keys):\n+        for app_label, model_name, field_name in sorted(\n+            self.old_field_keys - self.new_field_keys\n+        ):\n             self._generate_removed_field(app_label, model_name, field_name)\n \n     def _generate_removed_field(self, app_label, model_name, field_name):\n@@ -906,16 +1014,28 @@ class MigrationAutodetector:\n         Make AlterField operations, or possibly RemovedField/AddField if alter\n         isn's possible.\n         \"\"\"\n-        for app_label, model_name, field_name in sorted(self.old_field_keys & self.new_field_keys):\n+        for app_label, model_name, field_name in sorted(\n+            self.old_field_keys & self.new_field_keys\n+        ):\n             # Did the field change?\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n-            old_field_name = self.renamed_fields.get((app_label, model_name, field_name), field_name)\n-            old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(old_field_name)\n-            new_field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n+            old_field_name = self.renamed_fields.get(\n+                (app_label, model_name, field_name), field_name\n+            )\n+            old_field = self.old_apps.get_model(\n+                app_label, old_model_name\n+            )._meta.get_field(old_field_name)\n+            new_field = self.new_apps.get_model(app_label, model_name)._meta.get_field(\n+                field_name\n+            )\n             dependencies = []\n             # Implement any model renames on relations; these are handled by RenameModel\n             # so we need to exclude them from the comparison\n-            if hasattr(new_field, \"remote_field\") and getattr(new_field.remote_field, \"model\", None):\n+            if hasattr(new_field, \"remote_field\") and getattr(\n+                new_field.remote_field, \"model\", None\n+            ):\n                 rename_key = (\n                     new_field.remote_field.model._meta.app_label,\n                     new_field.remote_field.model._meta.model_name,\n@@ -923,25 +1043,32 @@ class MigrationAutodetector:\n                 if rename_key in self.renamed_models:\n                     new_field.remote_field.model = old_field.remote_field.model\n                 # Handle ForeignKey which can only have a single to_field.\n-                remote_field_name = getattr(new_field.remote_field, 'field_name', None)\n+                remote_field_name = getattr(new_field.remote_field, \"field_name\", None)\n                 if remote_field_name:\n-                    to_field_rename_key = rename_key + (remote_field_name,)\n-                    if to_field_rename_key in self.renamed_fields:\n-                        new_field.remote_field.field_name = old_field.remote_field.field_name\n+                    to_model = new_field.remote_field.model\n+                    new_field.remote_field.field_name = to_model._meta.pk.name\n                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n-                from_fields = getattr(new_field, 'from_fields', None)\n+                from_fields = getattr(new_field, \"from_fields\", None)\n                 if from_fields:\n                     from_rename_key = (app_label, model_name)\n-                    new_field.from_fields = tuple([\n-                        self.renamed_fields.get(from_rename_key + (from_field,), from_field)\n-                        for from_field in from_fields\n-                    ])\n-                    new_field.to_fields = tuple([\n-                        self.renamed_fields.get(rename_key + (to_field,), to_field)\n-                        for to_field in new_field.to_fields\n-                    ])\n+                    new_field.from_fields = tuple(\n+                        [\n+                            self.renamed_fields.get(\n+                                from_rename_key + (from_field,), from_field\n+                            )\n+                            for from_field in from_fields\n+                        ]\n+                    )\n+                    new_field.to_fields = tuple(\n+                        [\n+                            self.renamed_fields.get(rename_key + (to_field,), to_field)\n+                            for to_field in new_field.to_fields\n+                        ]\n+                    )\n                 dependencies.extend(self._get_dependencies_for_foreign_key(new_field))\n-            if hasattr(new_field, \"remote_field\") and getattr(new_field.remote_field, \"through\", None):\n+            if hasattr(new_field, \"remote_field\") and getattr(\n+                new_field.remote_field, \"through\", None\n+            ):\n                 rename_key = (\n                     new_field.remote_field.through._meta.app_label,\n                     new_field.remote_field.through._meta.model_name,\n@@ -956,10 +1083,16 @@ class MigrationAutodetector:\n                 if both_m2m or neither_m2m:\n                     # Either both fields are m2m or neither is\n                     preserve_default = True\n-                    if (old_field.null and not new_field.null and not new_field.has_default() and\n-                            not new_field.many_to_many):\n+                    if (\n+                        old_field.null\n+                        and not new_field.null\n+                        and not new_field.has_default()\n+                        and not new_field.many_to_many\n+                    ):\n                         field = new_field.clone()\n-                        new_default = self.questioner.ask_not_null_alteration(field_name, model_name)\n+                        new_default = self.questioner.ask_not_null_alteration(\n+                            field_name, model_name\n+                        )\n                         if new_default is not models.NOT_PROVIDED:\n                             field.default = new_default\n                             preserve_default = False\n@@ -983,7 +1116,9 @@ class MigrationAutodetector:\n     def create_altered_indexes(self):\n         option_name = operations.AddIndex.option_name\n         for app_label, model_name in sorted(self.kept_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n \n@@ -992,38 +1127,43 @@ class MigrationAutodetector:\n             add_idx = [idx for idx in new_indexes if idx not in old_indexes]\n             rem_idx = [idx for idx in old_indexes if idx not in new_indexes]\n \n-            self.altered_indexes.update({\n-                (app_label, model_name): {\n-                    'added_indexes': add_idx, 'removed_indexes': rem_idx,\n+            self.altered_indexes.update(\n+                {\n+                    (app_label, model_name): {\n+                        \"added_indexes\": add_idx,\n+                        \"removed_indexes\": rem_idx,\n+                    }\n                 }\n-            })\n+            )\n \n     def generate_added_indexes(self):\n         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n-            for index in alt_indexes['added_indexes']:\n+            for index in alt_indexes[\"added_indexes\"]:\n                 self.add_operation(\n                     app_label,\n                     operations.AddIndex(\n                         model_name=model_name,\n                         index=index,\n-                    )\n+                    ),\n                 )\n \n     def generate_removed_indexes(self):\n         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n-            for index in alt_indexes['removed_indexes']:\n+            for index in alt_indexes[\"removed_indexes\"]:\n                 self.add_operation(\n                     app_label,\n                     operations.RemoveIndex(\n                         model_name=model_name,\n                         name=index.name,\n-                    )\n+                    ),\n                 )\n \n     def create_altered_constraints(self):\n         option_name = operations.AddConstraint.option_name\n         for app_label, model_name in sorted(self.kept_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n \n@@ -1032,37 +1172,46 @@ class MigrationAutodetector:\n             add_constraints = [c for c in new_constraints if c not in old_constraints]\n             rem_constraints = [c for c in old_constraints if c not in new_constraints]\n \n-            self.altered_constraints.update({\n-                (app_label, model_name): {\n-                    'added_constraints': add_constraints, 'removed_constraints': rem_constraints,\n+            self.altered_constraints.update(\n+                {\n+                    (app_label, model_name): {\n+                        \"added_constraints\": add_constraints,\n+                        \"removed_constraints\": rem_constraints,\n+                    }\n                 }\n-            })\n+            )\n \n     def generate_added_constraints(self):\n-        for (app_label, model_name), alt_constraints in self.altered_constraints.items():\n-            for constraint in alt_constraints['added_constraints']:\n+        for (\n+            app_label,\n+            model_name,\n+        ), alt_constraints in self.altered_constraints.items():\n+            for constraint in alt_constraints[\"added_constraints\"]:\n                 self.add_operation(\n                     app_label,\n                     operations.AddConstraint(\n                         model_name=model_name,\n                         constraint=constraint,\n-                    )\n+                    ),\n                 )\n \n     def generate_removed_constraints(self):\n-        for (app_label, model_name), alt_constraints in self.altered_constraints.items():\n-            for constraint in alt_constraints['removed_constraints']:\n+        for (\n+            app_label,\n+            model_name,\n+        ), alt_constraints in self.altered_constraints.items():\n+            for constraint in alt_constraints[\"removed_constraints\"]:\n                 self.add_operation(\n                     app_label,\n                     operations.RemoveConstraint(\n                         model_name=model_name,\n                         name=constraint.name,\n-                    )\n+                    ),\n                 )\n \n     def _get_dependencies_for_foreign_key(self, field):\n         # Account for FKs to swappable models\n-        swappable_setting = getattr(field, 'swappable_setting', None)\n+        swappable_setting = getattr(field, \"swappable_setting\", None)\n         if swappable_setting is not None:\n             dep_app_label = \"__setting__\"\n             dep_object_name = swappable_setting\n@@ -1070,31 +1219,42 @@ class MigrationAutodetector:\n             dep_app_label = field.remote_field.model._meta.app_label\n             dep_object_name = field.remote_field.model._meta.object_name\n         dependencies = [(dep_app_label, dep_object_name, None, True)]\n-        if getattr(field.remote_field, \"through\", None) and not field.remote_field.through._meta.auto_created:\n-            dependencies.append((\n-                field.remote_field.through._meta.app_label,\n-                field.remote_field.through._meta.object_name,\n-                None,\n-                True,\n-            ))\n+        if (\n+            getattr(field.remote_field, \"through\", None)\n+            and not field.remote_field.through._meta.auto_created\n+        ):\n+            dependencies.append(\n+                (\n+                    field.remote_field.through._meta.app_label,\n+                    field.remote_field.through._meta.object_name,\n+                    None,\n+                    True,\n+                )\n+            )\n         return dependencies\n \n     def _generate_altered_foo_together(self, operation):\n         option_name = operation.option_name\n         for app_label, model_name in sorted(self.kept_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n \n             # We run the old version through the field renames to account for those\n             old_value = old_model_state.options.get(option_name)\n-            old_value = {\n-                tuple(\n-                    self.renamed_fields.get((app_label, model_name, n), n)\n-                    for n in unique\n-                )\n-                for unique in old_value\n-            } if old_value else set()\n+            old_value = (\n+                {\n+                    tuple(\n+                        self.renamed_fields.get((app_label, model_name, n), n)\n+                        for n in unique\n+                    )\n+                    for unique in old_value\n+                }\n+                if old_value\n+                else set()\n+            )\n \n             new_value = new_model_state.options.get(option_name)\n             new_value = set(new_value) if new_value else set()\n@@ -1103,16 +1263,17 @@ class MigrationAutodetector:\n                 dependencies = []\n                 for foo_togethers in new_value:\n                     for field_name in foo_togethers:\n-                        field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n+                        field = self.new_apps.get_model(\n+                            app_label, model_name\n+                        )._meta.get_field(field_name)\n                         if field.remote_field and field.remote_field.model:\n-                            dependencies.extend(self._get_dependencies_for_foreign_key(field))\n+                            dependencies.extend(\n+                                self._get_dependencies_for_foreign_key(field)\n+                            )\n \n                 self.add_operation(\n                     app_label,\n-                    operation(\n-                        name=model_name,\n-                        **{option_name: new_value}\n-                    ),\n+                    operation(name=model_name, **{option_name: new_value}),\n                     dependencies=dependencies,\n                 )\n \n@@ -1123,20 +1284,24 @@ class MigrationAutodetector:\n         self._generate_altered_foo_together(operations.AlterIndexTogether)\n \n     def generate_altered_db_table(self):\n-        models_to_check = self.kept_model_keys.union(self.kept_proxy_keys, self.kept_unmanaged_keys)\n+        models_to_check = self.kept_model_keys.union(\n+            self.kept_proxy_keys, self.kept_unmanaged_keys\n+        )\n         for app_label, model_name in sorted(models_to_check):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n-            old_db_table_name = old_model_state.options.get('db_table')\n-            new_db_table_name = new_model_state.options.get('db_table')\n+            old_db_table_name = old_model_state.options.get(\"db_table\")\n+            new_db_table_name = new_model_state.options.get(\"db_table\")\n             if old_db_table_name != new_db_table_name:\n                 self.add_operation(\n                     app_label,\n                     operations.AlterModelTable(\n                         name=model_name,\n                         table=new_db_table_name,\n-                    )\n+                    ),\n                 )\n \n     def generate_altered_options(self):\n@@ -1155,15 +1320,19 @@ class MigrationAutodetector:\n         )\n \n         for app_label, model_name in sorted(models_to_check):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n             old_options = {\n-                key: value for key, value in old_model_state.options.items()\n+                key: value\n+                for key, value in old_model_state.options.items()\n                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n             }\n             new_options = {\n-                key: value for key, value in new_model_state.options.items()\n+                key: value\n+                for key, value in new_model_state.options.items()\n                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n             }\n             if old_options != new_options:\n@@ -1172,39 +1341,48 @@ class MigrationAutodetector:\n                     operations.AlterModelOptions(\n                         name=model_name,\n                         options=new_options,\n-                    )\n+                    ),\n                 )\n \n     def generate_altered_order_with_respect_to(self):\n         for app_label, model_name in sorted(self.kept_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n-            if (old_model_state.options.get(\"order_with_respect_to\") !=\n-                    new_model_state.options.get(\"order_with_respect_to\")):\n+            if old_model_state.options.get(\n+                \"order_with_respect_to\"\n+            ) != new_model_state.options.get(\"order_with_respect_to\"):\n                 # Make sure it comes second if we're adding\n                 # (removal dependency is part of RemoveField)\n                 dependencies = []\n                 if new_model_state.options.get(\"order_with_respect_to\"):\n-                    dependencies.append((\n-                        app_label,\n-                        model_name,\n-                        new_model_state.options[\"order_with_respect_to\"],\n-                        True,\n-                    ))\n+                    dependencies.append(\n+                        (\n+                            app_label,\n+                            model_name,\n+                            new_model_state.options[\"order_with_respect_to\"],\n+                            True,\n+                        )\n+                    )\n                 # Actually generate the operation\n                 self.add_operation(\n                     app_label,\n                     operations.AlterOrderWithRespectTo(\n                         name=model_name,\n-                        order_with_respect_to=new_model_state.options.get('order_with_respect_to'),\n+                        order_with_respect_to=new_model_state.options.get(\n+                            \"order_with_respect_to\"\n+                        ),\n                     ),\n                     dependencies=dependencies,\n                 )\n \n     def generate_altered_managers(self):\n         for app_label, model_name in sorted(self.kept_model_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+            old_model_name = self.renamed_models.get(\n+                (app_label, model_name), model_name\n+            )\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             new_model_state = self.to_state.models[app_label, model_name]\n             if old_model_state.managers != new_model_state.managers:\n@@ -1213,7 +1391,7 @@ class MigrationAutodetector:\n                     operations.AlterModelManagers(\n                         name=model_name,\n                         managers=new_model_state.managers,\n-                    )\n+                    ),\n                 )\n \n     def arrange_for_graph(self, changes, graph, migration_name=None):\n@@ -1250,7 +1428,9 @@ class MigrationAutodetector:\n                 if i == 0 and app_leaf:\n                     migration.dependencies.append(app_leaf)\n                 if i == 0 and not app_leaf:\n-                    new_name = \"0001_%s\" % migration_name if migration_name else \"0001_initial\"\n+                    new_name = (\n+                        \"0001_%s\" % migration_name if migration_name else \"0001_initial\"\n+                    )\n                 else:\n                     new_name = \"%04i_%s\" % (\n                         next_number,\n@@ -1262,7 +1442,9 @@ class MigrationAutodetector:\n         # Now fix dependencies\n         for migrations in changes.values():\n             for migration in migrations:\n-                migration.dependencies = [name_map.get(d, d) for d in migration.dependencies]\n+                migration.dependencies = [\n+                    name_map.get(d, d) for d in migration.dependencies\n+                ]\n         return changes\n \n     def _trim_to_apps(self, changes, app_labels):\n@@ -1283,7 +1465,9 @@ class MigrationAutodetector:\n         old_required_apps = None\n         while old_required_apps != required_apps:\n             old_required_apps = set(required_apps)\n-            required_apps.update(*[app_dependencies.get(app_label, ()) for app_label in required_apps])\n+            required_apps.update(\n+                *[app_dependencies.get(app_label, ()) for app_label in required_apps]\n+            )\n         # Remove all migrations that aren't needed\n         for app_label in list(changes):\n             if app_label not in required_apps:\n@@ -1317,7 +1501,7 @@ class MigrationAutodetector:\n         Given a migration name, try to extract a number from the beginning of\n         it. If no number is found, return None.\n         \"\"\"\n-        match = re.match(r'^\\d+', name)\n+        match = re.match(r\"^\\d+\", name)\n         if match:\n             return int(match.group())\n         return None\n"}
{"instance_id": "django__django-11964", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex d610dc86f0..08064c0ed1 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2,6 +2,7 @@ import collections.abc\n import copy\n import datetime\n import decimal\n+import enum\n import operator\n import uuid\n import warnings\n@@ -18,7 +19,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -28,14 +32,37 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FilePathField', 'FloatField',\n-    'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED',\n-    'NullBooleanField', 'PositiveIntegerField', 'PositiveSmallIntegerField',\n-    'SlugField', 'SmallAutoField', 'SmallIntegerField', 'TextField',\n-    'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -71,6 +98,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -97,15 +125,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -123,18 +151,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -170,7 +217,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -180,19 +227,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -210,12 +257,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -223,15 +270,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % (LOOKUP_SEP,),\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -242,14 +289,16 @@ class Field(RegisterLookupMixin):\n             return []\n \n         def is_value(value, accept_promise=True):\n-            return isinstance(value, (str, Promise) if accept_promise else str) or not is_iterable(value)\n+            return isinstance(\n+                value, (str, Promise) if accept_promise else str\n+            ) or not is_iterable(value)\n \n         if is_value(self.choices, accept_promise=False):\n             return [\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -270,7 +319,11 @@ class Field(RegisterLookupMixin):\n                 if self.max_length is not None and group_choices:\n                     choice_max_length = max(\n                         choice_max_length,\n-                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n+                        *(\n+                            len(value)\n+                            for value, _ in group_choices\n+                            if isinstance(value, str)\n+                        ),\n                     )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n@@ -290,7 +343,7 @@ class Field(RegisterLookupMixin):\n                         \"'max_length' is too small to fit the longest value \"\n                         \"in 'choices' (%d characters).\" % choice_max_length,\n                         obj=self,\n-                        id='fields.E009',\n+                        id=\"fields.E009\",\n                     ),\n                 ]\n             return []\n@@ -300,7 +353,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -310,25 +363,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -337,7 +395,9 @@ class Field(RegisterLookupMixin):\n     def _check_backend_specific_checks(self, **kwargs):\n         app_label = self.model._meta.app_label\n         for db in connections:\n-            if router.allow_migrate(db, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                db, app_label, model_name=self.model._meta.model_name\n+            ):\n                 return connections[db].validation.check_field(self, **kwargs)\n         return []\n \n@@ -351,11 +411,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -365,25 +426,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -393,6 +453,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -400,6 +461,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -459,7 +521,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -528,7 +590,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -547,7 +609,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -556,10 +618,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -597,7 +662,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -624,16 +689,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -647,7 +712,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -657,7 +722,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -719,7 +786,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -744,7 +811,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -763,8 +830,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            setattr(\n+                cls,\n+                \"get_%s_display\" % self.name,\n+                partialmethod(cls._get_FIELD_display, field=self),\n+            )\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n@@ -823,11 +893,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -835,7 +915,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -843,8 +925,8 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n@@ -871,6 +953,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -879,24 +962,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -905,9 +989,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -922,8 +1016,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -936,14 +1030,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -954,14 +1048,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -984,16 +1078,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1020,10 +1117,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1032,20 +1129,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1057,8 +1152,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1066,7 +1167,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1079,19 +1180,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1122,13 +1228,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1137,12 +1243,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1167,15 +1273,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1190,12 +1296,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1210,25 +1322,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1265,13 +1385,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1292,10 +1412,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1306,9 +1428,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1317,15 +1439,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1347,13 +1469,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1366,24 +1489,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1410,7 +1541,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1418,7 +1549,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1434,7 +1565,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1442,7 +1573,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1454,7 +1585,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1472,9 +1603,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1489,25 +1620,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except decimal.InvalidOperation:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1517,10 +1652,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1541,9 +1679,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1561,13 +1699,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1576,7 +1716,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1588,20 +1728,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1616,23 +1767,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1644,15 +1795,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1661,7 +1814,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1686,22 +1839,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1715,10 +1870,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1732,22 +1888,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1773,16 +1935,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1793,32 +1957,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1836,14 +2002,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1853,13 +2027,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1867,11 +2041,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1883,8 +2057,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1896,7 +2072,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1904,29 +2080,31 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1934,7 +2112,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -1957,10 +2134,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -1970,17 +2149,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -1989,24 +2172,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2035,29 +2220,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2091,13 +2283,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2110,8 +2302,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2134,15 +2326,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2165,13 +2357,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2179,30 +2373,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2217,7 +2413,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2225,9 +2421,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2240,8 +2436,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2252,29 +2448,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2296,29 +2492,31 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n     db_returning = True\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2331,9 +2529,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2341,8 +2539,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2356,8 +2554,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2388,34 +2585,33 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n         return subclass in self._subclasses or super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\n"}
{"instance_id": "django__django-11999", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..ac3f58ae7c 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -18,7 +18,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -28,14 +31,37 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FilePathField', 'FloatField',\n-    'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED',\n-    'NullBooleanField', 'PositiveIntegerField', 'PositiveSmallIntegerField',\n-    'SlugField', 'SmallAutoField', 'SmallIntegerField', 'TextField',\n-    'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -71,6 +97,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -97,15 +124,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -123,18 +150,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -170,7 +216,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -180,19 +226,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -210,12 +256,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -223,15 +269,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % (LOOKUP_SEP,),\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -249,7 +295,7 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -270,7 +316,11 @@ class Field(RegisterLookupMixin):\n                 if self.max_length is not None and group_choices:\n                     choice_max_length = max(\n                         choice_max_length,\n-                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n+                        *(\n+                            len(value)\n+                            for value, _ in group_choices\n+                            if isinstance(value, str)\n+                        ),\n                     )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n@@ -290,7 +340,7 @@ class Field(RegisterLookupMixin):\n                         \"'max_length' is too small to fit the longest value \"\n                         \"in 'choices' (%d characters).\" % choice_max_length,\n                         obj=self,\n-                        id='fields.E009',\n+                        id=\"fields.E009\",\n                     ),\n                 ]\n             return []\n@@ -300,7 +350,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -310,25 +360,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -337,7 +392,9 @@ class Field(RegisterLookupMixin):\n     def _check_backend_specific_checks(self, **kwargs):\n         app_label = self.model._meta.app_label\n         for db in connections:\n-            if router.allow_migrate(db, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                db, app_label, model_name=self.model._meta.model_name\n+            ):\n                 return connections[db].validation.check_field(self, **kwargs)\n         return []\n \n@@ -351,11 +408,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -365,25 +423,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -393,6 +450,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -400,6 +458,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -459,7 +518,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -528,7 +587,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -547,7 +606,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -556,10 +615,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -597,7 +659,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -624,16 +686,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -647,7 +709,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -657,7 +719,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -719,7 +783,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -744,7 +808,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -763,8 +827,12 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            if \"get_%s_display\" % self.name not in cls.__dict__:\n+                setattr(\n+                    cls,\n+                    \"get_%s_display\" % self.name,\n+                    partialmethod(cls._get_FIELD_display, field=self),\n+                )\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n@@ -823,11 +891,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -835,7 +913,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -843,8 +923,8 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n@@ -871,6 +951,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -879,24 +960,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -905,9 +987,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -922,8 +1014,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -936,14 +1028,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -954,14 +1046,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -984,16 +1076,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1020,10 +1115,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1032,20 +1127,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1057,8 +1150,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1066,7 +1165,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1079,19 +1178,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1122,13 +1226,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1137,12 +1241,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1167,15 +1271,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1190,12 +1294,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1210,25 +1320,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1265,13 +1383,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1292,10 +1410,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1306,9 +1426,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1317,15 +1437,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1347,13 +1467,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1366,24 +1487,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1410,7 +1539,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1418,7 +1547,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1434,7 +1563,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1442,7 +1571,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1454,7 +1583,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1472,9 +1601,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1489,25 +1618,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except decimal.InvalidOperation:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1517,10 +1650,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1541,9 +1677,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1561,13 +1697,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1576,7 +1714,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1588,20 +1726,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1616,23 +1765,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1644,15 +1793,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1661,7 +1812,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1686,22 +1837,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1715,10 +1868,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1732,22 +1886,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1773,16 +1933,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1793,32 +1955,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1836,14 +2000,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1853,13 +2025,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1867,11 +2039,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1883,8 +2055,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1896,7 +2070,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1904,29 +2078,31 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1934,7 +2110,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -1957,10 +2132,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -1970,17 +2147,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -1989,24 +2170,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2035,29 +2218,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2091,13 +2281,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2110,8 +2300,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2134,15 +2324,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2165,13 +2355,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2179,30 +2371,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2217,7 +2411,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2225,9 +2419,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2240,8 +2434,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2252,29 +2446,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2296,29 +2490,31 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n     db_returning = True\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2331,9 +2527,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2341,8 +2537,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2356,8 +2552,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2388,34 +2583,33 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n         return subclass in self._subclasses or super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\n"}
{"instance_id": "django__django-12113", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": ""}
{"instance_id": "django__django-12125", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..4da489d1fd 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -23,12 +23,16 @@ class BaseSerializer:\n         self.value = value\n \n     def serialize(self):\n-        raise NotImplementedError('Subclasses of BaseSerializer must implement the serialize() method.')\n+        raise NotImplementedError(\n+            \"Subclasses of BaseSerializer must implement the serialize() method.\"\n+        )\n \n \n class BaseSequenceSerializer(BaseSerializer):\n     def _format(self):\n-        raise NotImplementedError('Subclasses of BaseSequenceSerializer must implement the _format() method.')\n+        raise NotImplementedError(\n+            \"Subclasses of BaseSequenceSerializer must implement the _format() method.\"\n+        )\n \n     def serialize(self):\n         imports = set()\n@@ -53,19 +57,21 @@ class ChoicesSerializer(BaseSerializer):\n \n class DateTimeSerializer(BaseSerializer):\n     \"\"\"For datetime.*, except datetime.datetime.\"\"\"\n+\n     def serialize(self):\n-        return repr(self.value), {'import datetime'}\n+        return repr(self.value), {\"import datetime\"}\n \n \n class DatetimeDatetimeSerializer(BaseSerializer):\n     \"\"\"For datetime.datetime.\"\"\"\n+\n     def serialize(self):\n         if self.value.tzinfo is not None and self.value.tzinfo != utc:\n             self.value = self.value.astimezone(utc)\n         imports = [\"import datetime\"]\n         if self.value.tzinfo is not None:\n             imports.append(\"from django.utils.timezone import utc\")\n-        return repr(self.value).replace('<UTC>', 'utc'), set(imports)\n+        return repr(self.value).replace(\"<UTC>\", \"utc\"), set(imports)\n \n \n class DecimalSerializer(BaseSerializer):\n@@ -121,8 +127,8 @@ class EnumSerializer(BaseSerializer):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n         return (\n-            '%s.%s[%r]' % (module, enum_class.__qualname__, self.value.name),\n-            {'import %s' % module},\n+            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n+            {\"import %s\" % module},\n         )\n \n \n@@ -140,23 +146,29 @@ class FrozensetSerializer(BaseSequenceSerializer):\n \n class FunctionTypeSerializer(BaseSerializer):\n     def serialize(self):\n-        if getattr(self.value, \"__self__\", None) and isinstance(self.value.__self__, type):\n+        if getattr(self.value, \"__self__\", None) and isinstance(\n+            self.value.__self__, type\n+        ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\"import %s\" % module}\n+            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+                \"import %s\" % module\n+            }\n         # Further error checking\n-        if self.value.__name__ == '<lambda>':\n+        if self.value.__name__ == \"<lambda>\":\n             raise ValueError(\"Cannot serialize function: lambda\")\n         if self.value.__module__ is None:\n             raise ValueError(\"Cannot serialize function %r: No module\" % self.value)\n \n         module_name = self.value.__module__\n \n-        if '<' not in self.value.__qualname__:  # Qualname can include <locals>\n-            return '%s.%s' % (module_name, self.value.__qualname__), {'import %s' % self.value.__module__}\n+        if \"<\" not in self.value.__qualname__:  # Qualname can include <locals>\n+            return \"%s.%s\" % (module_name, self.value.__qualname__), {\n+                \"import %s\" % self.value.__module__\n+            }\n \n         raise ValueError(\n-            'Could not find function %s in %s.\\n' % (self.value.__name__, module_name)\n+            \"Could not find function %s in %s.\\n\" % (self.value.__name__, module_name)\n         )\n \n \n@@ -165,11 +177,14 @@ class FunctoolsPartialSerializer(BaseSerializer):\n         # Serialize functools.partial() arguments\n         func_string, func_imports = serializer_factory(self.value.func).serialize()\n         args_string, args_imports = serializer_factory(self.value.args).serialize()\n-        keywords_string, keywords_imports = serializer_factory(self.value.keywords).serialize()\n+        keywords_string, keywords_imports = serializer_factory(\n+            self.value.keywords\n+        ).serialize()\n         # Add any imports needed by arguments\n-        imports = {'import functools', *func_imports, *args_imports, *keywords_imports}\n+        imports = {\"import functools\", *func_imports, *args_imports, *keywords_imports}\n         return (\n-            'functools.%s(%s, *%s, **%s)' % (\n+            \"functools.%s(%s, *%s, **%s)\"\n+            % (\n                 self.value.__class__.__name__,\n                 func_string,\n                 args_string,\n@@ -212,23 +227,26 @@ class ModelManagerSerializer(DeconstructableSerializer):\n class OperationSerializer(BaseSerializer):\n     def serialize(self):\n         from django.db.migrations.writer import OperationWriter\n+\n         string, imports = OperationWriter(self.value, indentation=0).serialize()\n         # Nested operation, trailing comma is handled in upper OperationWriter._write()\n-        return string.rstrip(','), imports\n+        return string.rstrip(\",\"), imports\n \n \n class RegexSerializer(BaseSerializer):\n     def serialize(self):\n-        regex_pattern, pattern_imports = serializer_factory(self.value.pattern).serialize()\n+        regex_pattern, pattern_imports = serializer_factory(\n+            self.value.pattern\n+        ).serialize()\n         # Turn off default implicit flags (e.g. re.U) because regexes with the\n         # same implicit and explicit flags aren't equal.\n-        flags = self.value.flags ^ re.compile('').flags\n+        flags = self.value.flags ^ re.compile(\"\").flags\n         regex_flags, flag_imports = serializer_factory(flags).serialize()\n-        imports = {'import re', *pattern_imports, *flag_imports}\n+        imports = {\"import re\", *pattern_imports, *flag_imports}\n         args = [regex_pattern]\n         if flags:\n             args.append(regex_flags)\n-        return \"re.compile(%s)\" % ', '.join(args), imports\n+        return \"re.compile(%s)\" % \", \".join(args), imports\n \n \n class SequenceSerializer(BaseSequenceSerializer):\n@@ -240,12 +258,14 @@ class SetSerializer(BaseSequenceSerializer):\n     def _format(self):\n         # Serialize as a set literal except when value is empty because {}\n         # is an empty dict.\n-        return '{%s}' if self.value else 'set(%s)'\n+        return \"{%s}\" if self.value else \"set(%s)\"\n \n \n class SettingsReferenceSerializer(BaseSerializer):\n     def serialize(self):\n-        return \"settings.%s\" % self.value.setting_name, {\"from django.conf import settings\"}\n+        return \"settings.%s\" % self.value.setting_name, {\n+            \"from django.conf import settings\"\n+        }\n \n \n class TupleSerializer(BaseSequenceSerializer):\n@@ -259,7 +279,7 @@ class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n             (models.Model, \"models.Model\", []),\n-            (type(None), 'type(None)', []),\n+            (type(None), \"type(None)\", []),\n         ]\n         for case, string, imports in special_cases:\n             if case is self.value:\n@@ -269,7 +289,9 @@ class TypeSerializer(BaseSerializer):\n             if module == builtins.__name__:\n                 return self.value.__name__, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, self.value.__qualname__), {\n+                    \"import %s\" % module\n+                }\n \n \n class UUIDSerializer(BaseSerializer):\n@@ -294,7 +316,11 @@ class Serializer:\n         (bool, int, type(None), bytes, str, range): BaseSimpleSerializer,\n         decimal.Decimal: DecimalSerializer,\n         (functools.partial, functools.partialmethod): FunctoolsPartialSerializer,\n-        (types.FunctionType, types.BuiltinFunctionType, types.MethodType): FunctionTypeSerializer,\n+        (\n+            types.FunctionType,\n+            types.BuiltinFunctionType,\n+            types.MethodType,\n+        ): FunctionTypeSerializer,\n         collections.abc.Iterable: IterableSerializer,\n         (COMPILED_REGEX_TYPE, RegexObject): RegexSerializer,\n         uuid.UUID: UUIDSerializer,\n@@ -303,7 +329,9 @@ class Serializer:\n     @classmethod\n     def register(cls, type_, serializer):\n         if not issubclass(serializer, BaseSerializer):\n-            raise ValueError(\"'%s' must inherit from 'BaseSerializer'.\" % serializer.__name__)\n+            raise ValueError(\n+                \"'%s' must inherit from 'BaseSerializer'.\" % serializer.__name__\n+            )\n         cls._registry[type_] = serializer\n \n     @classmethod\n@@ -328,7 +356,7 @@ def serializer_factory(value):\n     if isinstance(value, type):\n         return TypeSerializer(value)\n     # Anything that knows how to deconstruct itself.\n-    if hasattr(value, 'deconstruct'):\n+    if hasattr(value, \"deconstruct\"):\n         return DeconstructableSerializer(value)\n     for type_, serializer_cls in Serializer._registry.items():\n         if isinstance(value, type_):\n"}
{"instance_id": "django__django-12184", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 2d4610aac4..846e18d47a 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -5,6 +5,7 @@ URLResolver is the main class here. Its resolve() method takes a URL (as\n a string) and returns a ResolverMatch object which provides access to all\n attributes of the resolved URL match.\n \"\"\"\n+\n import functools\n import inspect\n import re\n@@ -30,7 +31,16 @@ from .utils import get_callable\n \n \n class ResolverMatch:\n-    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None):\n+    def __init__(\n+        self,\n+        func,\n+        args,\n+        kwargs,\n+        url_name=None,\n+        app_names=None,\n+        namespaces=None,\n+        route=None,\n+    ):\n         self.func = func\n         self.args = args\n         self.kwargs = kwargs\n@@ -40,27 +50,35 @@ class ResolverMatch:\n         # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n         # in an empty value.\n         self.app_names = [x for x in app_names if x] if app_names else []\n-        self.app_name = ':'.join(self.app_names)\n+        self.app_name = \":\".join(self.app_names)\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n-        self.namespace = ':'.join(self.namespaces)\n+        self.namespace = \":\".join(self.namespaces)\n \n-        if not hasattr(func, '__name__'):\n+        if not hasattr(func, \"__name__\"):\n             # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+            self._func_path = func.__class__.__module__ + \".\" + func.__class__.__name__\n         else:\n             # A function-based view\n-            self._func_path = func.__module__ + '.' + func.__name__\n+            self._func_path = func.__module__ + \".\" + func.__name__\n \n         view_path = url_name or self._func_path\n-        self.view_name = ':'.join(self.namespaces + [view_path])\n+        self.view_name = \":\".join(self.namespaces + [view_path])\n \n     def __getitem__(self, index):\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n-        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n-            self._func_path, self.args, self.kwargs, self.url_name,\n-            self.app_names, self.namespaces, self.route,\n+        return (\n+            \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\"\n+            % (\n+                self._func_path,\n+                self.args,\n+                self.kwargs,\n+                self.url_name,\n+                self.app_names,\n+                self.namespaces,\n+                self.route,\n+            )\n         )\n \n \n@@ -72,7 +90,7 @@ def get_resolver(urlconf=None):\n \n @functools.lru_cache(maxsize=None)\n def _get_cached_resolver(urlconf=None):\n-    return URLResolver(RegexPattern(r'^/'), urlconf)\n+    return URLResolver(RegexPattern(r\"^/\"), urlconf)\n \n \n @functools.lru_cache(maxsize=None)\n@@ -83,7 +101,7 @@ def get_ns_resolver(ns_pattern, resolver, converters):\n     pattern = RegexPattern(ns_pattern)\n     pattern.converters = dict(converters)\n     ns_resolver = URLResolver(pattern, resolver.url_patterns)\n-    return URLResolver(RegexPattern(r'^/'), [ns_resolver])\n+    return URLResolver(RegexPattern(r\"^/\"), [ns_resolver])\n \n \n class LocaleRegexDescriptor:\n@@ -101,8 +119,8 @@ class LocaleRegexDescriptor:\n         # avoid per-language compilation.\n         pattern = getattr(instance, self.attr)\n         if isinstance(pattern, str):\n-            instance.__dict__['regex'] = instance._compile(pattern)\n-            return instance.__dict__['regex']\n+            instance.__dict__[\"regex\"] = instance._compile(pattern)\n+            return instance.__dict__[\"regex\"]\n         language_code = get_language()\n         if language_code not in instance._regex_dict:\n             instance._regex_dict[language_code] = instance._compile(str(pattern))\n@@ -128,7 +146,9 @@ class CheckURLMixin:\n             # Skip check as it can be useful to start a URL pattern with a slash\n             # when APPEND_SLASH=False.\n             return []\n-        if regex_pattern.startswith(('/', '^/', '^\\\\/')) and not regex_pattern.endswith('/'):\n+        if regex_pattern.startswith((\"/\", \"^/\", \"^\\\\/\")) and not regex_pattern.endswith(\n+            \"/\"\n+        ):\n             warning = Warning(\n                 \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                 \"slash as it is unnecessary. If this pattern is targeted in an \"\n@@ -143,7 +163,7 @@ class CheckURLMixin:\n \n \n class RegexPattern(CheckURLMixin):\n-    regex = LocaleRegexDescriptor('_regex')\n+    regex = LocaleRegexDescriptor(\"_regex\")\n \n     def __init__(self, regex, name=None, is_endpoint=False):\n         self._regex = regex\n@@ -159,8 +179,8 @@ class RegexPattern(CheckURLMixin):\n             # non-named groups. Otherwise, pass all non-named arguments as\n             # positional arguments.\n             kwargs = {k: v for k, v in match.groupdict().items() if v is not None}\n-            args = () if kwargs else match.groups()\n-            return path[match.end():], args, kwargs\n+            args = () if kwargs else tuple(v for v in match.groups() if v is not None)\n+            return path[match.end() :], args, kwargs\n         return None\n \n     def check(self):\n@@ -172,13 +192,15 @@ class RegexPattern(CheckURLMixin):\n \n     def _check_include_trailing_dollar(self):\n         regex_pattern = self.regex.pattern\n-        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):\n-            return [Warning(\n-                \"Your URL pattern {} uses include with a route ending with a '$'. \"\n-                \"Remove the dollar from the route to avoid problems including \"\n-                \"URLs.\".format(self.describe()),\n-                id='urls.W001',\n-            )]\n+        if regex_pattern.endswith(\"$\") and not regex_pattern.endswith(r\"\\$\"):\n+            return [\n+                Warning(\n+                    \"Your URL pattern {} uses include with a route ending with a '$'. \"\n+                    \"Remove the dollar from the route to avoid problems including \"\n+                    \"URLs.\".format(self.describe()),\n+                    id=\"urls.W001\",\n+                )\n+            ]\n         else:\n             return []\n \n@@ -196,7 +218,7 @@ class RegexPattern(CheckURLMixin):\n \n \n _PATH_PARAMETER_COMPONENT_RE = _lazy_re_compile(\n-    r'<(?:(?P<converter>[^>:]+):)?(?P<parameter>\\w+)>'\n+    r\"<(?:(?P<converter>[^>:]+):)?(?P<parameter>\\w+)>\"\n )\n \n \n@@ -210,25 +232,25 @@ def _route_to_regex(route, is_endpoint=False):\n     if not set(route).isdisjoint(string.whitespace):\n         raise ImproperlyConfigured(\"URL route '%s' cannot contain whitespace.\" % route)\n     original_route = route\n-    parts = ['^']\n+    parts = [\"^\"]\n     converters = {}\n     while True:\n         match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n         if not match:\n             parts.append(re.escape(route))\n             break\n-        parts.append(re.escape(route[:match.start()]))\n-        route = route[match.end():]\n-        parameter = match.group('parameter')\n+        parts.append(re.escape(route[: match.start()]))\n+        route = route[match.end() :]\n+        parameter = match.group(\"parameter\")\n         if not parameter.isidentifier():\n             raise ImproperlyConfigured(\n                 \"URL route '%s' uses parameter name %r which isn't a valid \"\n                 \"Python identifier.\" % (original_route, parameter)\n             )\n-        raw_converter = match.group('converter')\n+        raw_converter = match.group(\"converter\")\n         if raw_converter is None:\n             # If a converter isn't specified, the default is `str`.\n-            raw_converter = 'str'\n+            raw_converter = \"str\"\n         try:\n             converter = get_converter(raw_converter)\n         except KeyError as e:\n@@ -236,14 +258,14 @@ def _route_to_regex(route, is_endpoint=False):\n                 \"URL route '%s' uses invalid converter %s.\" % (original_route, e)\n             )\n         converters[parameter] = converter\n-        parts.append('(?P<' + parameter + '>' + converter.regex + ')')\n+        parts.append(\"(?P<\" + parameter + \">\" + converter.regex + \")\")\n     if is_endpoint:\n-        parts.append('$')\n-    return ''.join(parts), converters\n+        parts.append(\"$\")\n+    return \"\".join(parts), converters\n \n \n class RoutePattern(CheckURLMixin):\n-    regex = LocaleRegexDescriptor('_route')\n+    regex = LocaleRegexDescriptor(\"_route\")\n \n     def __init__(self, route, name=None, is_endpoint=False):\n         self._route = route\n@@ -263,19 +285,21 @@ class RoutePattern(CheckURLMixin):\n                     kwargs[key] = converter.to_python(value)\n                 except ValueError:\n                     return None\n-            return path[match.end():], (), kwargs\n+            return path[match.end() :], (), kwargs\n         return None\n \n     def check(self):\n         warnings = self._check_pattern_startswith_slash()\n         route = self._route\n-        if '(?P<' in route or route.startswith('^') or route.endswith('$'):\n-            warnings.append(Warning(\n-                \"Your URL pattern {} has a route that contains '(?P<', begins \"\n-                \"with a '^', or ends with a '$'. This was likely an oversight \"\n-                \"when migrating to django.urls.path().\".format(self.describe()),\n-                id='2_0.W001',\n-            ))\n+        if \"(?P<\" in route or route.startswith(\"^\") or route.endswith(\"$\"):\n+            warnings.append(\n+                Warning(\n+                    \"Your URL pattern {} has a route that contains '(?P<', begins \"\n+                    \"with a '^', or ends with a '$'. This was likely an oversight \"\n+                    \"when migrating to django.urls.path().\".format(self.describe()),\n+                    id=\"2_0.W001\",\n+                )\n+            )\n         return warnings\n \n     def _compile(self, route):\n@@ -299,14 +323,14 @@ class LocalePrefixPattern:\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n         if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n-            return ''\n+            return \"\"\n         else:\n-            return '%s/' % language_code\n+            return \"%s/\" % language_code\n \n     def match(self, path):\n         language_prefix = self.language_prefix\n         if path.startswith(language_prefix):\n-            return path[len(language_prefix):], (), {}\n+            return path[len(language_prefix) :], (), {}\n         return None\n \n     def check(self):\n@@ -327,7 +351,7 @@ class URLPattern:\n         self.name = name\n \n     def __repr__(self):\n-        return '<%s %s>' % (self.__class__.__name__, self.pattern.describe())\n+        return \"<%s %s>\" % (self.__class__.__name__, self.pattern.describe())\n \n     def check(self):\n         warnings = self._check_pattern_name()\n@@ -354,7 +378,9 @@ class URLPattern:\n             new_path, args, kwargs = match\n             # Pass any extra_kwargs as **kwargs.\n             kwargs.update(self.default_args)\n-            return ResolverMatch(self.callback, args, kwargs, self.pattern.name, route=str(self.pattern))\n+            return ResolverMatch(\n+                self.callback, args, kwargs, self.pattern.name, route=str(self.pattern)\n+            )\n \n     @cached_property\n     def lookup_str(self):\n@@ -365,13 +391,15 @@ class URLPattern:\n         callback = self.callback\n         if isinstance(callback, functools.partial):\n             callback = callback.func\n-        if not hasattr(callback, '__name__'):\n+        if not hasattr(callback, \"__name__\"):\n             return callback.__module__ + \".\" + callback.__class__.__name__\n         return callback.__module__ + \".\" + callback.__qualname__\n \n \n class URLResolver:\n-    def __init__(self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None):\n+    def __init__(\n+        self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None\n+    ):\n         self.pattern = pattern\n         # urlconf_name is the dotted Python path to the module defining\n         # urlpatterns. It may also be an object with an urlpatterns attribute\n@@ -393,12 +421,15 @@ class URLResolver:\n     def __repr__(self):\n         if isinstance(self.urlconf_name, list) and self.urlconf_name:\n             # Don't bother to output the whole list, it can be huge\n-            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__\n+            urlconf_repr = \"<%s list>\" % self.urlconf_name[0].__class__.__name__\n         else:\n             urlconf_repr = repr(self.urlconf_name)\n-        return '<%s %s (%s:%s) %s>' % (\n-            self.__class__.__name__, urlconf_repr, self.app_name,\n-            self.namespace, self.pattern.describe(),\n+        return \"<%s %s (%s:%s) %s>\" % (\n+            self.__class__.__name__,\n+            urlconf_repr,\n+            self.app_name,\n+            self.namespace,\n+            self.pattern.describe(),\n         )\n \n     def check(self):\n@@ -416,11 +447,11 @@ class URLResolver:\n             try:\n                 handler, param_dict = self.resolve_error_handler(status_code)\n             except (ImportError, ViewDoesNotExist) as e:\n-                path = getattr(self.urlconf_module, 'handler%s' % status_code)\n+                path = getattr(self.urlconf_module, \"handler%s\" % status_code)\n                 msg = (\n                     \"The custom handler{status_code} view '{path}' could not be imported.\"\n                 ).format(status_code=status_code, path=path)\n-                messages.append(Error(msg, hint=str(e), id='urls.E008'))\n+                messages.append(Error(msg, hint=str(e), id=\"urls.E008\"))\n                 continue\n             signature = inspect.signature(handler)\n             args = [None] * num_parameters\n@@ -432,10 +463,10 @@ class URLResolver:\n                     \"take the correct number of arguments ({args}).\"\n                 ).format(\n                     status_code=status_code,\n-                    path=handler.__module__ + '.' + handler.__qualname__,\n-                    args='request, exception' if num_parameters == 2 else 'request',\n+                    path=handler.__module__ + \".\" + handler.__qualname__,\n+                    args=\"request, exception\" if num_parameters == 2 else \"request\",\n                 )\n-                messages.append(Error(msg, id='urls.E007'))\n+                messages.append(Error(msg, id=\"urls.E007\"))\n         return messages\n \n     def _populate(self):\n@@ -443,7 +474,7 @@ class URLResolver:\n         # infinite recursion. Concurrent threads may call this at the same\n         # time and will need to continue, so set 'populating' on a\n         # thread-local variable.\n-        if getattr(self._local, 'populating', False):\n+        if getattr(self._local, \"populating\", False):\n             return\n         try:\n             self._local.populating = True\n@@ -453,28 +484,45 @@ class URLResolver:\n             language_code = get_language()\n             for url_pattern in reversed(self.url_patterns):\n                 p_pattern = url_pattern.pattern.regex.pattern\n-                if p_pattern.startswith('^'):\n+                if p_pattern.startswith(\"^\"):\n                     p_pattern = p_pattern[1:]\n                 if isinstance(url_pattern, URLPattern):\n                     self._callback_strs.add(url_pattern.lookup_str)\n                     bits = normalize(url_pattern.pattern.regex.pattern)\n                     lookups.appendlist(\n                         url_pattern.callback,\n-                        (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n+                        (\n+                            bits,\n+                            p_pattern,\n+                            url_pattern.default_args,\n+                            url_pattern.pattern.converters,\n+                        ),\n                     )\n                     if url_pattern.name is not None:\n                         lookups.appendlist(\n                             url_pattern.name,\n-                            (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n+                            (\n+                                bits,\n+                                p_pattern,\n+                                url_pattern.default_args,\n+                                url_pattern.pattern.converters,\n+                            ),\n                         )\n                 else:  # url_pattern is a URLResolver.\n                     url_pattern._populate()\n                     if url_pattern.app_name:\n-                        apps.setdefault(url_pattern.app_name, []).append(url_pattern.namespace)\n+                        apps.setdefault(url_pattern.app_name, []).append(\n+                            url_pattern.namespace\n+                        )\n                         namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                     else:\n                         for name in url_pattern.reverse_dict:\n-                            for matches, pat, defaults, converters in url_pattern.reverse_dict.getlist(name):\n+                            for (\n+                                matches,\n+                                pat,\n+                                defaults,\n+                                converters,\n+                            ) in url_pattern.reverse_dict.getlist(name):\n                                 new_matches = normalize(p_pattern + pat)\n                                 lookups.appendlist(\n                                     name,\n@@ -482,10 +530,17 @@ class URLResolver:\n                                         new_matches,\n                                         p_pattern + pat,\n                                         {**defaults, **url_pattern.default_kwargs},\n-                                        {**self.pattern.converters, **url_pattern.pattern.converters, **converters}\n-                                    )\n+                                        {\n+                                            **self.pattern.converters,\n+                                            **url_pattern.pattern.converters,\n+                                            **converters,\n+                                        },\n+                                    ),\n                                 )\n-                        for namespace, (prefix, sub_pattern) in url_pattern.namespace_dict.items():\n+                        for namespace, (\n+                            prefix,\n+                            sub_pattern,\n+                        ) in url_pattern.namespace_dict.items():\n                             current_converters = url_pattern.pattern.converters\n                             sub_pattern.pattern.converters.update(current_converters)\n                             namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n@@ -525,7 +580,7 @@ class URLResolver:\n         \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n         if not route1:\n             return route2\n-        if route2.startswith('^'):\n+        if route2.startswith(\"^\"):\n             route2 = route2[1:]\n         return route1 + route2\n \n@@ -544,7 +599,7 @@ class URLResolver:\n                 try:\n                     sub_match = pattern.resolve(new_path)\n                 except Resolver404 as e:\n-                    sub_tried = e.args[0].get('tried')\n+                    sub_tried = e.args[0].get(\"tried\")\n                     if sub_tried is not None:\n                         tried.extend([pattern] + t for t in sub_tried)\n                     else:\n@@ -560,7 +615,11 @@ class URLResolver:\n                         sub_match_args = sub_match.args\n                         if not sub_match_dict:\n                             sub_match_args = args + sub_match.args\n-                        current_route = '' if isinstance(pattern, URLPattern) else str(pattern.pattern)\n+                        current_route = (\n+                            \"\"\n+                            if isinstance(pattern, URLPattern)\n+                            else str(pattern.pattern)\n+                        )\n                         return ResolverMatch(\n                             sub_match.func,\n                             sub_match_args,\n@@ -571,8 +630,8 @@ class URLResolver:\n                             self._join_route(current_route, sub_match.route),\n                         )\n                     tried.append([pattern])\n-            raise Resolver404({'tried': tried, 'path': new_path})\n-        raise Resolver404({'path': path})\n+            raise Resolver404({\"tried\": tried, \"path\": new_path})\n+        raise Resolver404({\"path\": path})\n \n     @cached_property\n     def urlconf_module(self):\n@@ -597,16 +656,17 @@ class URLResolver:\n         return patterns\n \n     def resolve_error_handler(self, view_type):\n-        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)\n+        callback = getattr(self.urlconf_module, \"handler%s\" % view_type, None)\n         if not callback:\n             # No handler specified in file; use lazy import, since\n             # django.conf.urls imports this file.\n             from django.conf import urls\n-            callback = getattr(urls, 'handler%s' % view_type)\n+\n+            callback = getattr(urls, \"handler%s\" % view_type)\n         return get_callable(callback), {}\n \n     def reverse(self, lookup_view, *args, **kwargs):\n-        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)\n+        return self._reverse_with_prefix(lookup_view, \"\", *args, **kwargs)\n \n     def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n         if args and kwargs:\n@@ -641,16 +701,22 @@ class URLResolver:\n                 # without quoting to build a decoded URL and look for a match.\n                 # Then, if we have a match, redo the substitution with quoted\n                 # arguments in order to return a properly encoded URL.\n-                candidate_pat = _prefix.replace('%', '%%') + result\n-                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % text_candidate_subs):\n+                candidate_pat = _prefix.replace(\"%\", \"%%\") + result\n+                if re.search(\n+                    \"^%s%s\" % (re.escape(_prefix), pattern),\n+                    candidate_pat % text_candidate_subs,\n+                ):\n                     # safe characters from `pchar` definition of RFC 3986\n-                    url = quote(candidate_pat % text_candidate_subs, safe=RFC3986_SUBDELIMS + '/~:@')\n+                    url = quote(\n+                        candidate_pat % text_candidate_subs,\n+                        safe=RFC3986_SUBDELIMS + \"/~:@\",\n+                    )\n                     # Don't allow construction of scheme relative urls.\n                     return escape_leading_slashes(url)\n         # lookup_view can be URL name or callable, but callables are not\n         # friendly in error messages.\n-        m = getattr(lookup_view, '__module__', None)\n-        n = getattr(lookup_view, '__name__', None)\n+        m = getattr(lookup_view, \"__module__\", None)\n+        n = getattr(lookup_view, \"__name__\", None)\n         if m is not None and n is not None:\n             lookup_view_s = \"%s.%s\" % (m, n)\n         else:\n@@ -664,13 +730,15 @@ class URLResolver:\n                 arg_msg = \"keyword arguments '%s'\" % (kwargs,)\n             else:\n                 arg_msg = \"no arguments\"\n-            msg = (\n-                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %\n-                (lookup_view_s, arg_msg, len(patterns), patterns)\n+            msg = \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" % (\n+                lookup_view_s,\n+                arg_msg,\n+                len(patterns),\n+                patterns,\n             )\n         else:\n             msg = (\n                 \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n-                \"a valid view function or pattern name.\" % {'view': lookup_view_s}\n+                \"a valid view function or pattern name.\" % {\"view\": lookup_view_s}\n             )\n         raise NoReverseMatch(msg)\n"}
{"instance_id": "django__django-12284", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1a55d3d417..5b75eb756a 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -764,7 +764,7 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n+            if 'get_%s_display' % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n                     'get_%s_display' % self.name,\n"}
{"instance_id": "django__django-12286", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\nindex 138ed07ff8..479a619757 100644\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -4,24 +4,24 @@ from django.utils.translation.trans_real import language_code_re\n from . import Error, Tags, register\n \n E001 = Error(\n-    'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.',\n-    id='translation.E001',\n+    \"You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.\",\n+    id=\"translation.E001\",\n )\n \n E002 = Error(\n-    'You have provided an invalid language code in the LANGUAGES setting: {!r}.',\n-    id='translation.E002',\n+    \"You have provided an invalid language code in the LANGUAGES setting: {!r}.\",\n+    id=\"translation.E002\",\n )\n \n E003 = Error(\n-    'You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}.',\n-    id='translation.E003',\n+    \"You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}.\",\n+    id=\"translation.E003\",\n )\n \n E004 = Error(\n-    'You have provided a value for the LANGUAGE_CODE setting that is not in '\n-    'the LANGUAGES setting.',\n-    id='translation.E004',\n+    \"You have provided a value for the LANGUAGE_CODE setting that is not in \"\n+    \"the LANGUAGES setting.\",\n+    id=\"translation.E004\",\n )\n \n \n@@ -39,7 +39,8 @@ def check_setting_languages(app_configs, **kwargs):\n     \"\"\"Error if LANGUAGES setting is invalid.\"\"\"\n     return [\n         Error(E002.msg.format(tag), id=E002.id)\n-        for tag, _ in settings.LANGUAGES if not isinstance(tag, str) or not language_code_re.match(tag)\n+        for tag, _ in settings.LANGUAGES\n+        if not isinstance(tag, str) or not language_code_re.match(tag)\n     ]\n \n \n@@ -48,14 +49,17 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n     \"\"\"Error if LANGUAGES_BIDI setting is invalid.\"\"\"\n     return [\n         Error(E003.msg.format(tag), id=E003.id)\n-        for tag in settings.LANGUAGES_BIDI if not isinstance(tag, str) or not language_code_re.match(tag)\n+        for tag in settings.LANGUAGES_BIDI\n+        if not isinstance(tag, str) or not language_code_re.match(tag)\n     ]\n \n \n @register(Tags.translation)\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n-    available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n+    available_tags = {i for i, _ in settings.LANGUAGES} | {\"en-us\"}\n     if settings.LANGUAGE_CODE not in available_tags:\n-        return [E004]\n+        lang_code = settings.LANGUAGE_CODE.split(\"-\")[0]\n+        if lang_code not in available_tags:\n+            return [E004]\n     return []\n"}
{"instance_id": "django__django-12308", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..f85ff64d1d 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -1,5 +1,6 @@\n import datetime\n import decimal\n+import json\n from collections import defaultdict\n \n from django.core.exceptions import FieldDoesNotExist\n@@ -14,13 +15,14 @@ from django.utils.regex_helper import _lazy_re_compile\n from django.utils.text import capfirst\n from django.utils.translation import ngettext, override as translation_override\n \n-QUOTE_MAP = {i: '_%02X' % i for i in b'\":/_#?;@&=+$,\"[]<>%\\n\\\\'}\n+QUOTE_MAP = {i: \"_%02X\" % i for i in b'\":/_#?;@&=+$,\"[]<>%\\n\\\\'}\n UNQUOTE_MAP = {v: chr(k) for k, v in QUOTE_MAP.items()}\n-UNQUOTE_RE = _lazy_re_compile('_(?:%s)' % '|'.join([x[1:] for x in UNQUOTE_MAP]))\n+UNQUOTE_RE = _lazy_re_compile(\"_(?:%s)\" % \"|\".join([x[1:] for x in UNQUOTE_MAP]))\n \n \n class FieldIsAForeignKeyColumnName(Exception):\n     \"\"\"A field is a foreign key attname, i.e. <FK>_id.\"\"\"\n+\n     pass\n \n \n@@ -31,7 +33,7 @@ def lookup_needs_distinct(opts, lookup_path):\n     lookup_fields = lookup_path.split(LOOKUP_SEP)\n     # Go through the fields (following all relations) and look for an m2m.\n     for field_name in lookup_fields:\n-        if field_name == 'pk':\n+        if field_name == \"pk\":\n             field_name = opts.pk.name\n         try:\n             field = opts.get_field(field_name)\n@@ -39,7 +41,7 @@ def lookup_needs_distinct(opts, lookup_path):\n             # Ignore query lookups.\n             continue\n         else:\n-            if hasattr(field, 'get_path_info'):\n+            if hasattr(field, \"get_path_info\"):\n                 # This field is a relation; update opts to follow the relation.\n                 path_info = field.get_path_info()\n                 opts = path_info[-1].to_opts\n@@ -54,11 +56,11 @@ def prepare_lookup_value(key, value):\n     Return a lookup value prepared to be used in queryset filtering.\n     \"\"\"\n     # if key ends with __in, split parameter into separate values\n-    if key.endswith('__in'):\n-        value = value.split(',')\n+    if key.endswith(\"__in\"):\n+        value = value.split(\",\")\n     # if key ends with __isnull, special case '' and the string literals 'false' and '0'\n-    elif key.endswith('__isnull'):\n-        value = value.lower() not in ('', 'false', '0')\n+    elif key.endswith(\"__isnull\"):\n+        value = value.lower() not in (\"\", \"false\", \"0\")\n     return value\n \n \n@@ -94,9 +96,7 @@ def flatten_fieldsets(fieldsets):\n     \"\"\"Return a list of field names from an admin fieldsets structure.\"\"\"\n     field_names = []\n     for name, opts in fieldsets:\n-        field_names.extend(\n-            flatten(opts['fields'])\n-        )\n+        field_names.extend(flatten(opts[\"fields\"]))\n     return field_names\n \n \n@@ -123,26 +123,26 @@ def get_deleted_objects(objs, request, admin_site):\n         has_admin = model in admin_site._registry\n         opts = obj._meta\n \n-        no_edit_link = '%s: %s' % (capfirst(opts.verbose_name), obj)\n+        no_edit_link = \"%s: %s\" % (capfirst(opts.verbose_name), obj)\n \n         if has_admin:\n             if not admin_site._registry[model].has_delete_permission(request, obj):\n                 perms_needed.add(opts.verbose_name)\n             try:\n-                admin_url = reverse('%s:%s_%s_change'\n-                                    % (admin_site.name,\n-                                       opts.app_label,\n-                                       opts.model_name),\n-                                    None, (quote(obj.pk),))\n+                admin_url = reverse(\n+                    \"%s:%s_%s_change\"\n+                    % (admin_site.name, opts.app_label, opts.model_name),\n+                    None,\n+                    (quote(obj.pk),),\n+                )\n             except NoReverseMatch:\n                 # Change url doesn't exist -- don't display link to edit\n                 return no_edit_link\n \n             # Display a link to the admin page.\n-            return format_html('{}: <a href=\"{}\">{}</a>',\n-                               capfirst(opts.verbose_name),\n-                               admin_url,\n-                               obj)\n+            return format_html(\n+                '{}: <a href=\"{}\">{}</a>', capfirst(opts.verbose_name), admin_url, obj\n+            )\n         else:\n             # Don't display link to edit, because it either has no\n             # admin or is edited inline.\n@@ -151,7 +151,10 @@ def get_deleted_objects(objs, request, admin_site):\n     to_delete = collector.nested(format_callback)\n \n     protected = [format_callback(obj) for obj in collector.protected]\n-    model_count = {model._meta.verbose_name_plural: len(objs) for model, objs in collector.model_objs.items()}\n+    model_count = {\n+        model._meta.verbose_name_plural: len(objs)\n+        for model, objs in collector.model_objs.items()\n+    }\n \n     return to_delete, model_count, perms_needed, protected\n \n@@ -168,10 +171,10 @@ class NestedObjects(Collector):\n \n     def collect(self, objs, source=None, source_attr=None, **kwargs):\n         for obj in objs:\n-            if source_attr and not source_attr.endswith('+'):\n+            if source_attr and not source_attr.endswith(\"+\"):\n                 related_name = source_attr % {\n-                    'class': source._meta.model_name,\n-                    'app_label': source._meta.app_label,\n+                    \"class\": source._meta.model_name,\n+                    \"app_label\": source._meta.app_label,\n                 }\n                 self.add_edge(getattr(obj, related_name), obj)\n             else:\n@@ -186,7 +189,9 @@ class NestedObjects(Collector):\n \n     def related_objects(self, related_model, related_fields, objs):\n         qs = super().related_objects(related_model, related_fields, objs)\n-        return qs.select_related(*[related_field.name for related_field in related_fields])\n+        return qs.select_related(\n+            *[related_field.name for related_field in related_fields]\n+        )\n \n     def _nested(self, obj, seen, format_callback):\n         if obj in seen:\n@@ -235,8 +240,8 @@ def model_format_dict(obj):\n     else:\n         opts = obj\n     return {\n-        'verbose_name': opts.verbose_name,\n-        'verbose_name_plural': opts.verbose_name_plural,\n+        \"verbose_name\": opts.verbose_name,\n+        \"verbose_name_plural\": opts.verbose_name_plural,\n     }\n \n \n@@ -268,7 +273,7 @@ def lookup_field(name, obj, model_admin=None):\n         if callable(name):\n             attr = name\n             value = attr(obj)\n-        elif hasattr(model_admin, name) and name != '__str__':\n+        elif hasattr(model_admin, name) and name != \"__str__\":\n             attr = getattr(model_admin, name)\n             value = attr(obj)\n         else:\n@@ -293,13 +298,21 @@ def _get_non_gfk_field(opts, name):\n     model (rather something like `foo_set`).\n     \"\"\"\n     field = opts.get_field(name)\n-    if (field.is_relation and\n-            # Generic foreign keys OR reverse relations\n-            ((field.many_to_one and not field.related_model) or field.one_to_many)):\n+    if (\n+        field.is_relation\n+        and\n+        # Generic foreign keys OR reverse relations\n+        ((field.many_to_one and not field.related_model) or field.one_to_many)\n+    ):\n         raise FieldDoesNotExist()\n \n     # Avoid coercing <FK>_id fields to FK\n-    if field.is_relation and not field.many_to_many and hasattr(field, 'attname') and field.attname == name:\n+    if (\n+        field.is_relation\n+        and not field.many_to_many\n+        and hasattr(field, \"attname\")\n+        and field.attname == name\n+    ):\n         raise FieldIsAForeignKeyColumnName()\n \n     return field\n@@ -335,7 +348,10 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n             elif form and name in form.fields:\n                 attr = form.fields[name]\n             else:\n-                message = \"Unable to lookup '%s' on %s\" % (name, model._meta.object_name)\n+                message = \"Unable to lookup '%s' on %s\" % (\n+                    name,\n+                    model._meta.object_name,\n+                )\n                 if model_admin:\n                     message += \" or %s\" % model_admin.__class__.__name__\n                 if form:\n@@ -344,9 +360,11 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n \n             if hasattr(attr, \"short_description\"):\n                 label = attr.short_description\n-            elif (isinstance(attr, property) and\n-                  hasattr(attr, \"fget\") and\n-                  hasattr(attr.fget, \"short_description\")):\n+            elif (\n+                isinstance(attr, property)\n+                and hasattr(attr, \"fget\")\n+                and hasattr(attr.fget, \"short_description\")\n+            ):\n                 label = attr.fget.short_description\n             elif callable(attr):\n                 if attr.__name__ == \"<lambda>\":\n@@ -372,7 +390,7 @@ def help_text_for_field(name, model):\n     except (FieldDoesNotExist, FieldIsAForeignKeyColumnName):\n         pass\n     else:\n-        if hasattr(field, 'help_text'):\n+        if hasattr(field, \"help_text\"):\n             help_text = field.help_text\n     return help_text\n \n@@ -380,7 +398,7 @@ def help_text_for_field(name, model):\n def display_for_field(value, field, empty_value_display):\n     from django.contrib.admin.templatetags.admin_list import _boolean_icon\n \n-    if getattr(field, 'flatchoices', None):\n+    if getattr(field, \"flatchoices\", None):\n         return dict(field.flatchoices).get(value, empty_value_display)\n     # BooleanField needs special-case null-handling, so it comes before the\n     # general null test.\n@@ -398,6 +416,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        return json.dumps(value, cls=getattr(field, \"encoder\", None))\n     else:\n         return display_for_value(value, empty_value_display)\n \n@@ -418,7 +438,7 @@ def display_for_value(value, empty_value_display, boolean=False):\n     elif isinstance(value, (int, decimal.Decimal, float)):\n         return formats.number_format(value)\n     elif isinstance(value, (list, tuple)):\n-        return ', '.join(str(v) for v in value)\n+        return \", \".join(str(v) for v in value)\n     else:\n         return str(value)\n \n@@ -428,14 +448,14 @@ class NotRelationField(Exception):\n \n \n def get_model_from_relation(field):\n-    if hasattr(field, 'get_path_info'):\n+    if hasattr(field, \"get_path_info\"):\n         return field.get_path_info()[-1].to_opts.model\n     else:\n         raise NotRelationField\n \n \n def reverse_field_path(model, path):\n-    \"\"\" Create a reversed field path.\n+    \"\"\"Create a reversed field path.\n \n     E.g. Given (Order, \"user__groups\"),\n     return (Group, \"user__order\").\n@@ -466,7 +486,7 @@ def reverse_field_path(model, path):\n \n \n def get_fields_from_path(model, path):\n-    \"\"\" Return list of Fields given path relative to model.\n+    \"\"\"Return list of Fields given path relative to model.\n \n     e.g. (ModelX, \"user__groups__name\") -> [\n         <django.db.models.fields.related.ForeignKey object at 0x...>,\n@@ -503,34 +523,42 @@ def construct_change_message(form, formsets, add):\n \n     change_message = []\n     if add:\n-        change_message.append({'added': {}})\n+        change_message.append({\"added\": {}})\n     elif form.changed_data:\n-        change_message.append({'changed': {'fields': changed_field_labels}})\n+        change_message.append({\"changed\": {\"fields\": changed_field_labels}})\n     if formsets:\n         with translation_override(None):\n             for formset in formsets:\n                 for added_object in formset.new_objects:\n-                    change_message.append({\n-                        'added': {\n-                            'name': str(added_object._meta.verbose_name),\n-                            'object': str(added_object),\n+                    change_message.append(\n+                        {\n+                            \"added\": {\n+                                \"name\": str(added_object._meta.verbose_name),\n+                                \"object\": str(added_object),\n+                            }\n                         }\n-                    })\n+                    )\n                 for changed_object, changed_fields in formset.changed_objects:\n-                    change_message.append({\n-                        'changed': {\n-                            'name': str(changed_object._meta.verbose_name),\n-                            'object': str(changed_object),\n-                            'fields': _get_changed_field_labels_from_form(formset.forms[0], changed_fields),\n+                    change_message.append(\n+                        {\n+                            \"changed\": {\n+                                \"name\": str(changed_object._meta.verbose_name),\n+                                \"object\": str(changed_object),\n+                                \"fields\": _get_changed_field_labels_from_form(\n+                                    formset.forms[0], changed_fields\n+                                ),\n+                            }\n                         }\n-                    })\n+                    )\n                 for deleted_object in formset.deleted_objects:\n-                    change_message.append({\n-                        'deleted': {\n-                            'name': str(deleted_object._meta.verbose_name),\n-                            'object': str(deleted_object),\n+                    change_message.append(\n+                        {\n+                            \"deleted\": {\n+                                \"name\": str(deleted_object._meta.verbose_name),\n+                                \"object\": str(deleted_object),\n+                            }\n                         }\n-                    })\n+                    )\n     return change_message\n \n \n"}
{"instance_id": "django__django-12453", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex c50fc90171..f1e2ce3ac3 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -5,11 +5,11 @@ from io import StringIO\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n \n # The prefix to put on the default database name when creating\n # the test database.\n-TEST_DATABASE_PREFIX = 'test_'\n+TEST_DATABASE_PREFIX = \"test_\"\n \n \n class BaseDatabaseCreation:\n@@ -17,6 +17,7 @@ class BaseDatabaseCreation:\n     Encapsulate backend-specific differences pertaining to creation and\n     destruction of the test database.\n     \"\"\"\n+\n     def __init__(self, connection):\n         self.connection = connection\n \n@@ -26,7 +27,9 @@ class BaseDatabaseCreation:\n     def log(self, msg):\n         sys.stderr.write(msg + os.linesep)\n \n-    def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=False):\n+    def create_test_db(\n+        self, verbosity=1, autoclobber=False, serialize=True, keepdb=False\n+    ):\n         \"\"\"\n         Create a test database, prompting the user for confirmation if the\n         database already exists. Return the name of the test database created.\n@@ -37,14 +40,17 @@ class BaseDatabaseCreation:\n         test_database_name = self._get_test_db_name()\n \n         if verbosity >= 1:\n-            action = 'Creating'\n+            action = \"Creating\"\n             if keepdb:\n                 action = \"Using existing\"\n \n-            self.log('%s test database for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, test_database_name),\n-            ))\n+            self.log(\n+                \"%s test database for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, test_database_name),\n+                )\n+            )\n \n         # We could skip this call if keepdb is True, but we instead\n         # give it the keepdb param. This is to handle the case\n@@ -57,12 +63,12 @@ class BaseDatabaseCreation:\n         settings.DATABASES[self.connection.alias][\"NAME\"] = test_database_name\n         self.connection.settings_dict[\"NAME\"] = test_database_name\n \n-        if self.connection.settings_dict['TEST']['MIGRATE']:\n+        if self.connection.settings_dict[\"TEST\"][\"MIGRATE\"]:\n             # We report migrate messages at one level lower than that\n             # requested. This ensures we don't get flooded with messages during\n             # testing (unless you really ask to be flooded).\n             call_command(\n-                'migrate',\n+                \"migrate\",\n                 verbosity=max(verbosity - 1, 0),\n                 interactive=False,\n                 database=self.connection.alias,\n@@ -76,7 +82,7 @@ class BaseDatabaseCreation:\n         if serialize:\n             self.connection._test_serialized_contents = self.serialize_db_to_string()\n \n-        call_command('createcachetable', database=self.connection.alias)\n+        call_command(\"createcachetable\", database=self.connection.alias)\n \n         # Ensure a connection for the side effect of initializing the test database.\n         self.connection.ensure_connection()\n@@ -88,7 +94,7 @@ class BaseDatabaseCreation:\n         Set this database up to be used in testing as a mirror of a primary\n         database whose settings are given.\n         \"\"\"\n-        self.connection.settings_dict['NAME'] = primary_settings_dict['NAME']\n+        self.connection.settings_dict[\"NAME\"] = primary_settings_dict[\"NAME\"]\n \n     def serialize_db_to_string(self):\n         \"\"\"\n@@ -98,23 +104,28 @@ class BaseDatabaseCreation:\n         \"\"\"\n         # Build list of all apps to serialize\n         from django.db.migrations.loader import MigrationLoader\n+\n         loader = MigrationLoader(self.connection)\n         app_list = []\n         for app_config in apps.get_app_configs():\n             if (\n-                app_config.models_module is not None and\n-                app_config.label in loader.migrated_apps and\n-                app_config.name not in settings.TEST_NON_SERIALIZED_APPS\n+                app_config.models_module is not None\n+                and app_config.label in loader.migrated_apps\n+                and app_config.name not in settings.TEST_NON_SERIALIZED_APPS\n             ):\n                 app_list.append((app_config, None))\n \n         # Make a function to iteratively return every object\n         def get_objects():\n             for model in serializers.sort_dependencies(app_list):\n-                if (model._meta.can_migrate(self.connection) and\n-                        router.allow_migrate_model(self.connection.alias, model)):\n-                    queryset = model._default_manager.using(self.connection.alias).order_by(model._meta.pk.name)\n+                if model._meta.can_migrate(\n+                    self.connection\n+                ) and router.allow_migrate_model(self.connection.alias, model):\n+                    queryset = model._default_manager.using(\n+                        self.connection.alias\n+                    ).order_by(model._meta.pk.name)\n                     yield from queryset.iterator()\n+\n         # Serialize to a string\n         out = StringIO()\n         serializers.serialize(\"json\", get_objects(), indent=None, stream=out)\n@@ -126,8 +137,11 @@ class BaseDatabaseCreation:\n         the serialize_db_to_string() method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\n+                \"json\", data, using=self.connection.alias\n+            ):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n@@ -135,7 +149,7 @@ class BaseDatabaseCreation:\n         \"\"\"\n         return \"'%s'%s\" % (\n             self.connection.alias,\n-            (\" ('%s')\" % database_name) if verbosity >= 2 else '',\n+            (\" ('%s')\" % database_name) if verbosity >= 2 else \"\",\n         )\n \n     def _get_test_db_name(self):\n@@ -145,12 +159,12 @@ class BaseDatabaseCreation:\n         _create_test_db() and when no external munging is done with the 'NAME'\n         settings.\n         \"\"\"\n-        if self.connection.settings_dict['TEST']['NAME']:\n-            return self.connection.settings_dict['TEST']['NAME']\n-        return TEST_DATABASE_PREFIX + self.connection.settings_dict['NAME']\n+        if self.connection.settings_dict[\"TEST\"][\"NAME\"]:\n+            return self.connection.settings_dict[\"TEST\"][\"NAME\"]\n+        return TEST_DATABASE_PREFIX + self.connection.settings_dict[\"NAME\"]\n \n     def _execute_create_test_db(self, cursor, parameters, keepdb=False):\n-        cursor.execute('CREATE DATABASE %(dbname)s %(suffix)s' % parameters)\n+        cursor.execute(\"CREATE DATABASE %(dbname)s %(suffix)s\" % parameters)\n \n     def _create_test_db(self, verbosity, autoclobber, keepdb=False):\n         \"\"\"\n@@ -158,8 +172,8 @@ class BaseDatabaseCreation:\n         \"\"\"\n         test_database_name = self._get_test_db_name()\n         test_db_params = {\n-            'dbname': self.connection.ops.quote_name(test_database_name),\n-            'suffix': self.sql_table_creation_suffix(),\n+            \"dbname\": self.connection.ops.quote_name(test_database_name),\n+            \"suffix\": self.sql_table_creation_suffix(),\n         }\n         # Create the test database and connect to it.\n         with self._nodb_cursor() as cursor:\n@@ -171,24 +185,30 @@ class BaseDatabaseCreation:\n                 if keepdb:\n                     return test_database_name\n \n-                self.log('Got an error creating the test database: %s' % e)\n+                self.log(\"Got an error creating the test database: %s\" % e)\n                 if not autoclobber:\n                     confirm = input(\n                         \"Type 'yes' if you would like to try deleting the test \"\n-                        \"database '%s', or 'no' to cancel: \" % test_database_name)\n-                if autoclobber or confirm == 'yes':\n+                        \"database '%s', or 'no' to cancel: \" % test_database_name\n+                    )\n+                if autoclobber or confirm == \"yes\":\n                     try:\n                         if verbosity >= 1:\n-                            self.log('Destroying old test database for alias %s...' % (\n-                                self._get_database_display_str(verbosity, test_database_name),\n-                            ))\n-                        cursor.execute('DROP DATABASE %(dbname)s' % test_db_params)\n+                            self.log(\n+                                \"Destroying old test database for alias %s...\"\n+                                % (\n+                                    self._get_database_display_str(\n+                                        verbosity, test_database_name\n+                                    ),\n+                                )\n+                            )\n+                        cursor.execute(\"DROP DATABASE %(dbname)s\" % test_db_params)\n                         self._execute_create_test_db(cursor, test_db_params, keepdb)\n                     except Exception as e:\n-                        self.log('Got an error recreating the test database: %s' % e)\n+                        self.log(\"Got an error recreating the test database: %s\" % e)\n                         sys.exit(2)\n                 else:\n-                    self.log('Tests cancelled.')\n+                    self.log(\"Tests cancelled.\")\n                     sys.exit(1)\n \n         return test_database_name\n@@ -197,16 +217,19 @@ class BaseDatabaseCreation:\n         \"\"\"\n         Clone a test database.\n         \"\"\"\n-        source_database_name = self.connection.settings_dict['NAME']\n+        source_database_name = self.connection.settings_dict[\"NAME\"]\n \n         if verbosity >= 1:\n-            action = 'Cloning test database'\n+            action = \"Cloning test database\"\n             if keepdb:\n-                action = 'Using existing clone'\n-            self.log('%s for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, source_database_name),\n-            ))\n+                action = \"Using existing clone\"\n+            self.log(\n+                \"%s for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, source_database_name),\n+                )\n+            )\n \n         # We could skip this call if keepdb is True, but we instead\n         # give it the keepdb param. See create_test_db for details.\n@@ -220,7 +243,10 @@ class BaseDatabaseCreation:\n         # already and its name has been copied to settings_dict['NAME'] so\n         # we don't need to call _get_test_db_name.\n         orig_settings_dict = self.connection.settings_dict\n-        return {**orig_settings_dict, 'NAME': '{}_{}'.format(orig_settings_dict['NAME'], suffix)}\n+        return {\n+            **orig_settings_dict,\n+            \"NAME\": \"{}_{}\".format(orig_settings_dict[\"NAME\"], suffix),\n+        }\n \n     def _clone_test_db(self, suffix, verbosity, keepdb=False):\n         \"\"\"\n@@ -228,27 +254,33 @@ class BaseDatabaseCreation:\n         \"\"\"\n         raise NotImplementedError(\n             \"The database backend doesn't support cloning databases. \"\n-            \"Disable the option to run tests in parallel processes.\")\n+            \"Disable the option to run tests in parallel processes.\"\n+        )\n \n-    def destroy_test_db(self, old_database_name=None, verbosity=1, keepdb=False, suffix=None):\n+    def destroy_test_db(\n+        self, old_database_name=None, verbosity=1, keepdb=False, suffix=None\n+    ):\n         \"\"\"\n         Destroy a test database, prompting the user for confirmation if the\n         database already exists.\n         \"\"\"\n         self.connection.close()\n         if suffix is None:\n-            test_database_name = self.connection.settings_dict['NAME']\n+            test_database_name = self.connection.settings_dict[\"NAME\"]\n         else:\n-            test_database_name = self.get_test_db_clone_settings(suffix)['NAME']\n+            test_database_name = self.get_test_db_clone_settings(suffix)[\"NAME\"]\n \n         if verbosity >= 1:\n-            action = 'Destroying'\n+            action = \"Destroying\"\n             if keepdb:\n-                action = 'Preserving'\n-            self.log('%s test database for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, test_database_name),\n-            ))\n+                action = \"Preserving\"\n+            self.log(\n+                \"%s test database for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, test_database_name),\n+                )\n+            )\n \n         # if we want to preserve the database\n         # skip the actual destroying piece.\n@@ -269,14 +301,15 @@ class BaseDatabaseCreation:\n         # to do so, because it's not allowed to delete a database while being\n         # connected to it.\n         with self._nodb_cursor() as cursor:\n-            cursor.execute(\"DROP DATABASE %s\"\n-                           % self.connection.ops.quote_name(test_database_name))\n+            cursor.execute(\n+                \"DROP DATABASE %s\" % self.connection.ops.quote_name(test_database_name)\n+            )\n \n     def sql_table_creation_suffix(self):\n         \"\"\"\n         SQL to append to the end of the test table creation statements.\n         \"\"\"\n-        return ''\n+        return \"\"\n \n     def test_db_signature(self):\n         \"\"\"\n@@ -286,8 +319,8 @@ class BaseDatabaseCreation:\n         \"\"\"\n         settings_dict = self.connection.settings_dict\n         return (\n-            settings_dict['HOST'],\n-            settings_dict['PORT'],\n-            settings_dict['ENGINE'],\n+            settings_dict[\"HOST\"],\n+            settings_dict[\"PORT\"],\n+            settings_dict[\"ENGINE\"],\n             self._get_test_db_name(),\n         )\n"}
{"instance_id": "django__django-12470", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 92213a4e67..e4ccfe8800 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -10,7 +10,12 @@ from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value\n from django.db.models.functions import Cast\n from django.db.models.query_utils import Q, select_related_descend\n from django.db.models.sql.constants import (\n-    CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n+    CURSOR,\n+    GET_ITERATOR_CHUNK_SIZE,\n+    MULTI,\n+    NO_RESULTS,\n+    ORDER_DIR,\n+    SINGLE,\n )\n from django.db.models.sql.query import Query, get_order_dir\n from django.db.transaction import TransactionManagementError\n@@ -23,7 +28,7 @@ class SQLCompiler:\n         self.query = query\n         self.connection = connection\n         self.using = using\n-        self.quote_cache = {'*': '*'}\n+        self.quote_cache = {\"*\": \"*\"}\n         # The select, klass_info, and annotations are needed by QuerySet.iterator()\n         # these are set as a side-effect of executing the query. Note that we calculate\n         # separately a list of extra select columns needed for grammatical correctness\n@@ -32,7 +37,9 @@ class SQLCompiler:\n         self.annotation_col_map = None\n         self.klass_info = None\n         # Multiline ordering SQL clause may appear from RawSQL.\n-        self.ordering_parts = re.compile(r'^(.*)\\s(ASC|DESC)(.*)', re.MULTILINE | re.DOTALL)\n+        self.ordering_parts = re.compile(\n+            r\"^(.*)\\s(ASC|DESC)(.*)\", re.MULTILINE | re.DOTALL\n+        )\n         self._meta_ordering = None\n \n     def setup_query(self):\n@@ -102,16 +109,14 @@ class SQLCompiler:\n             # when  we have public API way of forcing the GROUP BY clause.\n             # Converts string references to expressions.\n             for expr in self.query.group_by:\n-                if not hasattr(expr, 'as_sql'):\n+                if not hasattr(expr, \"as_sql\"):\n                     expressions.append(self.query.resolve_ref(expr))\n                 else:\n                     expressions.append(expr)\n         # Note that even if the group_by is set, it is only the minimal\n         # set to group by. So, we need to add cols in select, order_by, and\n         # having into the select in any case.\n-        ref_sources = {\n-            expr.source for expr in expressions if isinstance(expr, Ref)\n-        }\n+        ref_sources = {expr.source for expr in expressions if isinstance(expr, Ref)}\n         for expr, _, _ in select:\n             # Skip members of the select clause that are already included\n             # by reference.\n@@ -151,8 +156,10 @@ class SQLCompiler:\n             for expr in expressions:\n                 # Is this a reference to query's base table primary key? If the\n                 # expression isn't a Col-like, then skip the expression.\n-                if (getattr(expr, 'target', None) == self.query.model._meta.pk and\n-                        getattr(expr, 'alias', None) == self.query.base_table):\n+                if (\n+                    getattr(expr, \"target\", None) == self.query.model._meta.pk\n+                    and getattr(expr, \"alias\", None) == self.query.base_table\n+                ):\n                     pk = expr\n                     break\n             # If the main model's primary key is in the query, group by that\n@@ -160,13 +167,17 @@ class SQLCompiler:\n             # that don't have a primary key included in the grouped columns.\n             if pk:\n                 pk_aliases = {\n-                    expr.alias for expr in expressions\n-                    if hasattr(expr, 'target') and expr.target.primary_key\n+                    expr.alias\n+                    for expr in expressions\n+                    if hasattr(expr, \"target\") and expr.target.primary_key\n                 }\n                 expressions = [pk] + [\n-                    expr for expr in expressions\n-                    if expr in having or (\n-                        getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases\n+                    expr\n+                    for expr in expressions\n+                    if expr in having\n+                    or (\n+                        getattr(expr, \"alias\", None) is not None\n+                        and expr.alias not in pk_aliases\n                     )\n                 ]\n         elif self.connection.features.allows_group_by_selected_pks:\n@@ -177,16 +188,21 @@ class SQLCompiler:\n             # Unmanaged models are excluded because they could be representing\n             # database views on which the optimization might not be allowed.\n             pks = {\n-                expr for expr in expressions\n+                expr\n+                for expr in expressions\n                 if (\n-                    hasattr(expr, 'target') and\n-                    expr.target.primary_key and\n-                    self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)\n+                    hasattr(expr, \"target\")\n+                    and expr.target.primary_key\n+                    and self.connection.features.allows_group_by_selected_pks_on_model(\n+                        expr.target.model\n+                    )\n                 )\n             }\n             aliases = {expr.alias for expr in pks}\n             expressions = [\n-                expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases\n+                expr\n+                for expr in expressions\n+                if expr in pks or getattr(expr, \"alias\", None) not in aliases\n             ]\n         return expressions\n \n@@ -230,8 +246,8 @@ class SQLCompiler:\n                 select.append((col, None))\n                 select_idx += 1\n             klass_info = {\n-                'model': self.query.model,\n-                'select_fields': select_list,\n+                \"model\": self.query.model,\n+                \"select_fields\": select_list,\n             }\n         for alias, annotation in self.query.annotation_select.items():\n             annotations[alias] = select_idx\n@@ -240,14 +256,16 @@ class SQLCompiler:\n \n         if self.query.select_related:\n             related_klass_infos = self.get_related_selections(select)\n-            klass_info['related_klass_infos'] = related_klass_infos\n+            klass_info[\"related_klass_infos\"] = related_klass_infos\n \n             def get_select_from_parent(klass_info):\n-                for ki in klass_info['related_klass_infos']:\n-                    if ki['from_parent']:\n-                        ki['select_fields'] = (klass_info['select_fields'] +\n-                                               ki['select_fields'])\n+                for ki in klass_info[\"related_klass_infos\"]:\n+                    if ki[\"from_parent\"]:\n+                        ki[\"select_fields\"] = (\n+                            klass_info[\"select_fields\"] + ki[\"select_fields\"]\n+                        )\n                     get_select_from_parent(ki)\n+\n             get_select_from_parent(klass_info)\n \n         ret = []\n@@ -256,7 +274,7 @@ class SQLCompiler:\n                 sql, params = self.compile(col)\n             except EmptyResultSet:\n                 # Select a predicate that's always False.\n-                sql, params = '0', ()\n+                sql, params = \"0\", ()\n             else:\n                 sql, params = col.select_format(self, sql, params)\n             ret.append((col, (sql, params), alias))\n@@ -283,13 +301,13 @@ class SQLCompiler:\n         else:\n             ordering = []\n         if self.query.standard_ordering:\n-            asc, desc = ORDER_DIR['ASC']\n+            asc, desc = ORDER_DIR[\"ASC\"]\n         else:\n-            asc, desc = ORDER_DIR['DESC']\n+            asc, desc = ORDER_DIR[\"DESC\"]\n \n         order_by = []\n         for field in ordering:\n-            if hasattr(field, 'resolve_expression'):\n+            if hasattr(field, \"resolve_expression\"):\n                 if isinstance(field, Value):\n                     # output_field must be resolved for constants.\n                     field = Cast(field, field.output_field)\n@@ -300,18 +318,24 @@ class SQLCompiler:\n                     field.reverse_ordering()\n                 order_by.append((field, False))\n                 continue\n-            if field == '?':  # random\n+            if field == \"?\":  # random\n                 order_by.append((OrderBy(Random()), False))\n                 continue\n \n             col, order = get_order_dir(field, asc)\n-            descending = order == 'DESC'\n+            descending = order == \"DESC\"\n \n             if col in self.query.annotation_select:\n                 # Reference to expression in SELECT clause\n-                order_by.append((\n-                    OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),\n-                    True))\n+                order_by.append(\n+                    (\n+                        OrderBy(\n+                            Ref(col, self.query.annotation_select[col]),\n+                            descending=descending,\n+                        ),\n+                        True,\n+                    )\n+                )\n                 continue\n             if col in self.query.annotations:\n                 # References to an expression which is masked out of the SELECT\n@@ -323,31 +347,51 @@ class SQLCompiler:\n                 order_by.append((OrderBy(expr, descending=descending), False))\n                 continue\n \n-            if '.' in field:\n+            if \".\" in field:\n                 # This came in through an extra(order_by=...) addition. Pass it\n                 # on verbatim.\n-                table, col = col.split('.', 1)\n-                order_by.append((\n-                    OrderBy(\n-                        RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),\n-                        descending=descending\n-                    ), False))\n+                table, col = col.split(\".\", 1)\n+                order_by.append(\n+                    (\n+                        OrderBy(\n+                            RawSQL(\n+                                \"%s.%s\" % (self.quote_name_unless_alias(table), col), []\n+                            ),\n+                            descending=descending,\n+                        ),\n+                        False,\n+                    )\n+                )\n                 continue\n \n             if not self.query.extra or col not in self.query.extra:\n                 # 'col' is of the form 'field' or 'field1__field2' or\n                 # '-field1__field2__field', etc.\n-                order_by.extend(self.find_ordering_name(\n-                    field, self.query.get_meta(), default_order=asc))\n+                order_by.extend(\n+                    self.find_ordering_name(\n+                        field, self.query.get_meta(), default_order=asc\n+                    )\n+                )\n             else:\n                 if col not in self.query.extra_select:\n-                    order_by.append((\n-                        OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n-                        False))\n+                    order_by.append(\n+                        (\n+                            OrderBy(\n+                                RawSQL(*self.query.extra[col]), descending=descending\n+                            ),\n+                            False,\n+                        )\n+                    )\n                 else:\n-                    order_by.append((\n-                        OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),\n-                        True))\n+                    order_by.append(\n+                        (\n+                            OrderBy(\n+                                Ref(col, RawSQL(*self.query.extra[col])),\n+                                descending=descending,\n+                            ),\n+                            True,\n+                        )\n+                    )\n         result = []\n         seen = set()\n \n@@ -364,15 +408,19 @@ class SQLCompiler:\n                     elif col_alias:\n                         continue\n                     if src == sel_expr:\n-                        resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])\n+                        resolved.set_source_expressions([RawSQL(\"%d\" % (idx + 1), ())])\n                         break\n                 else:\n                     if col_alias:\n-                        raise DatabaseError('ORDER BY term does not match any column in the result set.')\n+                        raise DatabaseError(\n+                            \"ORDER BY term does not match any column in the result set.\"\n+                        )\n                     # Add column used in ORDER BY clause without an alias to\n                     # the selected columns.\n                     self.query.add_select_col(src)\n-                    resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])\n+                    resolved.set_source_expressions(\n+                        [RawSQL(\"%d\" % len(self.query.select), ())]\n+                    )\n             sql, params = self.compile(resolved)\n             # Don't add the same column twice, but the order direction is\n             # not taken into account so we strip it. When this entire method\n@@ -404,9 +452,14 @@ class SQLCompiler:\n         \"\"\"\n         if name in self.quote_cache:\n             return self.quote_cache[name]\n-        if ((name in self.query.alias_map and name not in self.query.table_map) or\n-                name in self.query.extra_select or (\n-                    self.query.external_aliases.get(name) and name not in self.query.table_map)):\n+        if (\n+            (name in self.query.alias_map and name not in self.query.table_map)\n+            or name in self.query.extra_select\n+            or (\n+                self.query.external_aliases.get(name)\n+                and name not in self.query.table_map\n+            )\n+        ):\n             self.quote_cache[name] = name\n             return name\n         r = self.connection.ops.quote_name(name)\n@@ -414,7 +467,7 @@ class SQLCompiler:\n         return r\n \n     def compile(self, node):\n-        vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)\n+        vendor_impl = getattr(node, \"as_\" + self.connection.vendor, None)\n         if vendor_impl:\n             sql, params = vendor_impl(self, self.connection)\n         else:\n@@ -425,14 +478,19 @@ class SQLCompiler:\n         features = self.connection.features\n         compilers = [\n             query.get_compiler(self.using, self.connection)\n-            for query in self.query.combined_queries if not query.is_empty()\n+            for query in self.query.combined_queries\n+            if not query.is_empty()\n         ]\n         if not features.supports_slicing_ordering_in_compound:\n             for query, compiler in zip(self.query.combined_queries, compilers):\n                 if query.low_mark or query.high_mark:\n-                    raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n+                    raise DatabaseError(\n+                        \"LIMIT/OFFSET not allowed in subqueries of compound statements.\"\n+                    )\n                 if compiler.get_order_by():\n-                    raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n+                    raise DatabaseError(\n+                        \"ORDER BY not allowed in subqueries of compound statements.\"\n+                    )\n         parts = ()\n         for compiler in compilers:\n             try:\n@@ -441,36 +499,40 @@ class SQLCompiler:\n                 # the query on all combined queries, if not already set.\n                 if not compiler.query.values_select and self.query.values_select:\n                     compiler.query = compiler.query.clone()\n-                    compiler.query.set_values((\n-                        *self.query.extra_select,\n-                        *self.query.values_select,\n-                        *self.query.annotation_select,\n-                    ))\n+                    compiler.query.set_values(\n+                        (\n+                            *self.query.extra_select,\n+                            *self.query.values_select,\n+                            *self.query.annotation_select,\n+                        )\n+                    )\n                 part_sql, part_args = compiler.as_sql()\n                 if compiler.query.combinator:\n                     # Wrap in a subquery if wrapping in parentheses isn't\n                     # supported.\n                     if not features.supports_parentheses_in_compound:\n-                        part_sql = 'SELECT * FROM ({})'.format(part_sql)\n+                        part_sql = \"SELECT * FROM ({})\".format(part_sql)\n                     # Add parentheses when combining with compound query if not\n                     # already added for all compound queries.\n                     elif not features.supports_slicing_ordering_in_compound:\n-                        part_sql = '({})'.format(part_sql)\n+                        part_sql = \"({})\".format(part_sql)\n                 parts += ((part_sql, part_args),)\n             except EmptyResultSet:\n                 # Omit the empty queryset with UNION and with DIFFERENCE if the\n                 # first queryset is nonempty.\n-                if combinator == 'union' or (combinator == 'difference' and parts):\n+                if combinator == \"union\" or (combinator == \"difference\" and parts):\n                     continue\n                 raise\n         if not parts:\n             raise EmptyResultSet\n         combinator_sql = self.connection.ops.set_operators[combinator]\n-        if all and combinator == 'union':\n-            combinator_sql += ' ALL'\n-        braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n-        sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n-        result = [' {} '.format(combinator_sql).join(sql_parts)]\n+        if all and combinator == \"union\":\n+            combinator_sql += \" ALL\"\n+        braces = \"({})\" if features.supports_slicing_ordering_in_compound else \"{}\"\n+        sql_parts, args_parts = zip(\n+            *((braces.format(sql), args) for sql, args in parts)\n+        )\n+        result = [\" {} \".format(combinator_sql).join(sql_parts)]\n         params = []\n         for part in args_parts:\n             params.extend(part)\n@@ -489,21 +551,33 @@ class SQLCompiler:\n             extra_select, order_by, group_by = self.pre_sql_setup()\n             for_update_part = None\n             # Is a LIMIT/OFFSET clause needed?\n-            with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n+            with_limit_offset = with_limits and (\n+                self.query.high_mark is not None or self.query.low_mark\n+            )\n             combinator = self.query.combinator\n             features = self.connection.features\n             if combinator:\n-                if not getattr(features, 'supports_select_{}'.format(combinator)):\n-                    raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n-                result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n+                if not getattr(features, \"supports_select_{}\".format(combinator)):\n+                    raise NotSupportedError(\n+                        \"{} is not supported on this database backend.\".format(\n+                            combinator\n+                        )\n+                    )\n+                result, params = self.get_combinator_sql(\n+                    combinator, self.query.combinator_all\n+                )\n             else:\n                 distinct_fields, distinct_params = self.get_distinct()\n                 # This must come after 'select', 'ordering', and 'distinct'\n                 # (see docstring of get_from_clause() for details).\n                 from_, f_params = self.get_from_clause()\n-                where, w_params = self.compile(self.where) if self.where is not None else (\"\", [])\n-                having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n-                result = ['SELECT']\n+                where, w_params = (\n+                    self.compile(self.where) if self.where is not None else (\"\", [])\n+                )\n+                having, h_params = (\n+                    self.compile(self.having) if self.having is not None else (\"\", [])\n+                )\n+                result = [\"SELECT\"]\n                 params = []\n \n                 if self.query.distinct:\n@@ -518,24 +592,35 @@ class SQLCompiler:\n                 col_idx = 1\n                 for _, (s_sql, s_params), alias in self.select + extra_select:\n                     if alias:\n-                        s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n+                        s_sql = \"%s AS %s\" % (\n+                            s_sql,\n+                            self.connection.ops.quote_name(alias),\n+                        )\n                     elif with_col_aliases:\n-                        s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)\n+                        s_sql = \"%s AS %s\" % (s_sql, \"Col%d\" % col_idx)\n                         col_idx += 1\n                     params.extend(s_params)\n                     out_cols.append(s_sql)\n \n-                result += [', '.join(out_cols), 'FROM', *from_]\n+                result += [\", \".join(out_cols), \"FROM\", *from_]\n                 params.extend(f_params)\n \n-                if self.query.select_for_update and self.connection.features.has_select_for_update:\n+                if (\n+                    self.query.select_for_update\n+                    and self.connection.features.has_select_for_update\n+                ):\n                     if self.connection.get_autocommit():\n-                        raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n+                        raise TransactionManagementError(\n+                            \"select_for_update cannot be used outside of a transaction.\"\n+                        )\n \n-                    if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n+                    if (\n+                        with_limit_offset\n+                        and not self.connection.features.supports_select_for_update_with_limit\n+                    ):\n                         raise NotSupportedError(\n-                            'LIMIT/OFFSET is not supported with '\n-                            'select_for_update on this database backend.'\n+                            \"LIMIT/OFFSET is not supported with \"\n+                            \"select_for_update on this database backend.\"\n                         )\n                     nowait = self.query.select_for_update_nowait\n                     skip_locked = self.query.select_for_update_skip_locked\n@@ -543,12 +628,24 @@ class SQLCompiler:\n                     # If it's a NOWAIT/SKIP LOCKED/OF query but the backend\n                     # doesn't support it, raise NotSupportedError to prevent a\n                     # possible deadlock.\n-                    if nowait and not self.connection.features.has_select_for_update_nowait:\n-                        raise NotSupportedError('NOWAIT is not supported on this database backend.')\n-                    elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n-                        raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n+                    if (\n+                        nowait\n+                        and not self.connection.features.has_select_for_update_nowait\n+                    ):\n+                        raise NotSupportedError(\n+                            \"NOWAIT is not supported on this database backend.\"\n+                        )\n+                    elif (\n+                        skip_locked\n+                        and not self.connection.features.has_select_for_update_skip_locked\n+                    ):\n+                        raise NotSupportedError(\n+                            \"SKIP LOCKED is not supported on this database backend.\"\n+                        )\n                     elif of and not self.connection.features.has_select_for_update_of:\n-                        raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n+                        raise NotSupportedError(\n+                            \"FOR UPDATE OF is not supported on this database backend.\"\n+                        )\n                     for_update_part = self.connection.ops.for_update_sql(\n                         nowait=nowait,\n                         skip_locked=skip_locked,\n@@ -559,7 +656,7 @@ class SQLCompiler:\n                     result.append(for_update_part)\n \n                 if where:\n-                    result.append('WHERE %s' % where)\n+                    result.append(\"WHERE %s\" % where)\n                     params.extend(w_params)\n \n                 grouping = []\n@@ -568,30 +665,38 @@ class SQLCompiler:\n                     params.extend(g_params)\n                 if grouping:\n                     if distinct_fields:\n-                        raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n+                        raise NotImplementedError(\n+                            \"annotate() + distinct(fields) is not implemented.\"\n+                        )\n                     order_by = order_by or self.connection.ops.force_no_ordering()\n-                    result.append('GROUP BY %s' % ', '.join(grouping))\n+                    result.append(\"GROUP BY %s\" % \", \".join(grouping))\n                     if self._meta_ordering:\n                         order_by = None\n                 if having:\n-                    result.append('HAVING %s' % having)\n+                    result.append(\"HAVING %s\" % having)\n                     params.extend(h_params)\n \n             if self.query.explain_query:\n-                result.insert(0, self.connection.ops.explain_query_prefix(\n-                    self.query.explain_format,\n-                    **self.query.explain_options\n-                ))\n+                result.insert(\n+                    0,\n+                    self.connection.ops.explain_query_prefix(\n+                        self.query.explain_format, **self.query.explain_options\n+                    ),\n+                )\n \n             if order_by:\n                 ordering = []\n                 for _, (o_sql, o_params, _) in order_by:\n                     ordering.append(o_sql)\n                     params.extend(o_params)\n-                result.append('ORDER BY %s' % ', '.join(ordering))\n+                result.append(\"ORDER BY %s\" % \", \".join(ordering))\n \n             if with_limit_offset:\n-                result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n+                result.append(\n+                    self.connection.ops.limit_offset_sql(\n+                        self.query.low_mark, self.query.high_mark\n+                    )\n+                )\n \n             if for_update_part and not self.connection.features.for_update_after_from:\n                 result.append(for_update_part)\n@@ -607,23 +712,30 @@ class SQLCompiler:\n                 sub_params = []\n                 for index, (select, _, alias) in enumerate(self.select, start=1):\n                     if not alias and with_col_aliases:\n-                        alias = 'col%d' % index\n+                        alias = \"col%d\" % index\n                     if alias:\n-                        sub_selects.append(\"%s.%s\" % (\n-                            self.connection.ops.quote_name('subquery'),\n-                            self.connection.ops.quote_name(alias),\n-                        ))\n+                        sub_selects.append(\n+                            \"%s.%s\"\n+                            % (\n+                                self.connection.ops.quote_name(\"subquery\"),\n+                                self.connection.ops.quote_name(alias),\n+                            )\n+                        )\n                     else:\n-                        select_clone = select.relabeled_clone({select.alias: 'subquery'})\n-                        subselect, subparams = select_clone.as_sql(self, self.connection)\n+                        select_clone = select.relabeled_clone(\n+                            {select.alias: \"subquery\"}\n+                        )\n+                        subselect, subparams = select_clone.as_sql(\n+                            self, self.connection\n+                        )\n                         sub_selects.append(subselect)\n                         sub_params.extend(subparams)\n-                return 'SELECT %s FROM (%s) subquery' % (\n-                    ', '.join(sub_selects),\n-                    ' '.join(result),\n+                return \"SELECT %s FROM (%s) subquery\" % (\n+                    \", \".join(sub_selects),\n+                    \" \".join(result),\n                 ), tuple(sub_params + params)\n \n-            return ' '.join(result), tuple(params)\n+            return \" \".join(result), tuple(params)\n         finally:\n             # Finally do cleanup - get rid of the joins we created above.\n             self.query.reset_refcounts(refcounts_before)\n@@ -656,8 +768,13 @@ class SQLCompiler:\n             # will assign None if the field belongs to this model.\n             if model == opts.model:\n                 model = None\n-            if from_parent and model is not None and issubclass(\n-                    from_parent._meta.concrete_model, model._meta.concrete_model):\n+            if (\n+                from_parent\n+                and model is not None\n+                and issubclass(\n+                    from_parent._meta.concrete_model, model._meta.concrete_model\n+                )\n+            ):\n                 # Avoid loading data for already loaded parents.\n                 # We end up here in the case select_related() resolution\n                 # proceeds from parent model to child model. In that case the\n@@ -666,8 +783,7 @@ class SQLCompiler:\n                 continue\n             if field.model in only_load and field.attname not in only_load[field.model]:\n                 continue\n-            alias = self.query.join_parent_model(opts, model, start_alias,\n-                                                 seen_models)\n+            alias = self.query.join_parent_model(opts, model, start_alias, seen_models)\n             column = field.get_col(alias)\n             result.append(column)\n         return result\n@@ -685,7 +801,9 @@ class SQLCompiler:\n \n         for name in self.query.distinct_fields:\n             parts = name.split(LOOKUP_SEP)\n-            _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n+            _, targets, alias, joins, path, _, transform_function = self._setup_joins(\n+                parts, opts, None\n+            )\n             targets, alias, _ = self.query.trim_joins(targets, joins, path)\n             for target in targets:\n                 if name in self.query.annotation_select:\n@@ -696,41 +814,56 @@ class SQLCompiler:\n                     params.append(p)\n         return result, params\n \n-    def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n-                           already_seen=None):\n+    def find_ordering_name(\n+        self, name, opts, alias=None, default_order=\"ASC\", already_seen=None\n+    ):\n         \"\"\"\n         Return the table alias (the name might be ambiguous, the alias will\n         not be) and column name for ordering by the given 'name' parameter.\n         The 'name' is of the form 'field1__field2__...__fieldN'.\n         \"\"\"\n         name, order = get_order_dir(name, default_order)\n-        descending = order == 'DESC'\n+        descending = order == \"DESC\"\n         pieces = name.split(LOOKUP_SEP)\n-        field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n+        field, targets, alias, joins, path, opts, transform_function = (\n+            self._setup_joins(pieces, opts, alias)\n+        )\n \n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless the attribute name\n         # of the field is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name:\n+        if (\n+            field.is_relation\n+            and opts.ordering\n+            and getattr(field, \"attname\", None) != name\n+        ):\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n-            join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n+            join_tuple = tuple(\n+                getattr(self.query.alias_map[j], \"join_cols\", None) for j in joins\n+            )\n             if join_tuple in already_seen:\n-                raise FieldError('Infinite loop caused by ordering.')\n+                raise FieldError(\"Infinite loop caused by ordering.\")\n             already_seen.add(join_tuple)\n \n             results = []\n             for item in opts.ordering:\n-                if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n+                if hasattr(item, \"resolve_expression\") and not isinstance(\n+                    item, OrderBy\n+                ):\n                     item = item.desc() if descending else item.asc()\n                 if isinstance(item, OrderBy):\n                     results.append((item, False))\n                     continue\n-                results.extend(self.find_ordering_name(item, opts, alias,\n-                                                       order, already_seen))\n+                results.extend(\n+                    self.find_ordering_name(item, opts, alias, \"ASC\", already_seen)\n+                )\n             return results\n         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n-        return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]\n+        return [\n+            (OrderBy(transform_function(t, alias), descending=descending), False)\n+            for t in targets\n+        ]\n \n     def _setup_joins(self, pieces, opts, alias):\n         \"\"\"\n@@ -741,7 +874,9 @@ class SQLCompiler:\n         match. Executing SQL where this is not true is an error.\n         \"\"\"\n         alias = alias or self.query.get_initial_alias()\n-        field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)\n+        field, targets, opts, joins, path, transform_function = self.query.setup_joins(\n+            pieces, opts, alias\n+        )\n         alias = joins[-1]\n         return field, targets, alias, joins, path, opts, transform_function\n \n@@ -775,25 +910,39 @@ class SQLCompiler:\n             # Only add the alias if it's not already present (the table_alias()\n             # call increments the refcount, so an alias refcount of one means\n             # this is the only reference).\n-            if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:\n-                result.append(', %s' % self.quote_name_unless_alias(alias))\n+            if (\n+                alias not in self.query.alias_map\n+                or self.query.alias_refcount[alias] == 1\n+            ):\n+                result.append(\", %s\" % self.quote_name_unless_alias(alias))\n         return result, params\n \n-    def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,\n-                               requested=None, restricted=None):\n+    def get_related_selections(\n+        self,\n+        select,\n+        opts=None,\n+        root_alias=None,\n+        cur_depth=1,\n+        requested=None,\n+        restricted=None,\n+    ):\n         \"\"\"\n         Fill in the information needed for a select_related query. The current\n         depth is measured as the number of connections away from the root model\n         (for example, cur_depth=1 means we are looking at models with direct\n         connections to the root model).\n         \"\"\"\n+\n         def _get_field_choices():\n             direct_choices = (f.name for f in opts.fields if f.is_relation)\n             reverse_choices = (\n                 f.field.related_query_name()\n-                for f in opts.related_objects if f.field.unique\n+                for f in opts.related_objects\n+                if f.field.unique\n+            )\n+            return chain(\n+                direct_choices, reverse_choices, self.query._filtered_relations\n             )\n-            return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n \n         related_klass_infos = []\n         if not restricted and cur_depth > self.query.max_depth:\n@@ -814,7 +963,7 @@ class SQLCompiler:\n                 requested = self.query.select_related\n \n         def get_related_klass_infos(klass_info, related_klass_infos):\n-            klass_info['related_klass_infos'] = related_klass_infos\n+            klass_info[\"related_klass_infos\"] = related_klass_infos\n \n         for f in opts.fields:\n             field_model = f.model._meta.concrete_model\n@@ -828,37 +977,48 @@ class SQLCompiler:\n                     if next or f.name in requested:\n                         raise FieldError(\n                             \"Non-relational field given in select_related: '%s'. \"\n-                            \"Choices are: %s\" % (\n+                            \"Choices are: %s\"\n+                            % (\n                                 f.name,\n-                                \", \".join(_get_field_choices()) or '(none)',\n+                                \", \".join(_get_field_choices()) or \"(none)\",\n                             )\n                         )\n             else:\n                 next = False\n \n-            if not select_related_descend(f, restricted, requested,\n-                                          only_load.get(field_model)):\n+            if not select_related_descend(\n+                f, restricted, requested, only_load.get(field_model)\n+            ):\n                 continue\n             klass_info = {\n-                'model': f.remote_field.model,\n-                'field': f,\n-                'reverse': False,\n-                'local_setter': f.set_cached_value,\n-                'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,\n-                'from_parent': False,\n+                \"model\": f.remote_field.model,\n+                \"field\": f,\n+                \"reverse\": False,\n+                \"local_setter\": f.set_cached_value,\n+                \"remote_setter\": f.remote_field.set_cached_value\n+                if f.unique\n+                else lambda x, y: None,\n+                \"from_parent\": False,\n             }\n             related_klass_infos.append(klass_info)\n             select_fields = []\n-            _, _, _, joins, _, _ = self.query.setup_joins(\n-                [f.name], opts, root_alias)\n+            _, _, _, joins, _, _ = self.query.setup_joins([f.name], opts, root_alias)\n             alias = joins[-1]\n-            columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)\n+            columns = self.get_default_columns(\n+                start_alias=alias, opts=f.remote_field.model._meta\n+            )\n             for col in columns:\n                 select_fields.append(len(select))\n                 select.append((col, None))\n-            klass_info['select_fields'] = select_fields\n+            klass_info[\"select_fields\"] = select_fields\n             next_klass_infos = self.get_related_selections(\n-                select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)\n+                select,\n+                f.remote_field.model._meta,\n+                alias,\n+                cur_depth + 1,\n+                next,\n+                restricted,\n+            )\n             get_related_klass_infos(klass_info, next_klass_infos)\n \n         if restricted:\n@@ -868,36 +1028,40 @@ class SQLCompiler:\n                 if o.field.unique and not o.many_to_many\n             ]\n             for f, model in related_fields:\n-                if not select_related_descend(f, restricted, requested,\n-                                              only_load.get(model), reverse=True):\n+                if not select_related_descend(\n+                    f, restricted, requested, only_load.get(model), reverse=True\n+                ):\n                     continue\n \n                 related_field_name = f.related_query_name()\n                 fields_found.add(related_field_name)\n \n-                join_info = self.query.setup_joins([related_field_name], opts, root_alias)\n+                join_info = self.query.setup_joins(\n+                    [related_field_name], opts, root_alias\n+                )\n                 alias = join_info.joins[-1]\n                 from_parent = issubclass(model, opts.model) and model is not opts.model\n                 klass_info = {\n-                    'model': model,\n-                    'field': f,\n-                    'reverse': True,\n-                    'local_setter': f.remote_field.set_cached_value,\n-                    'remote_setter': f.set_cached_value,\n-                    'from_parent': from_parent,\n+                    \"model\": model,\n+                    \"field\": f,\n+                    \"reverse\": True,\n+                    \"local_setter\": f.remote_field.set_cached_value,\n+                    \"remote_setter\": f.set_cached_value,\n+                    \"from_parent\": from_parent,\n                 }\n                 related_klass_infos.append(klass_info)\n                 select_fields = []\n                 columns = self.get_default_columns(\n-                    start_alias=alias, opts=model._meta, from_parent=opts.model)\n+                    start_alias=alias, opts=model._meta, from_parent=opts.model\n+                )\n                 for col in columns:\n                     select_fields.append(len(select))\n                     select.append((col, None))\n-                klass_info['select_fields'] = select_fields\n+                klass_info[\"select_fields\"] = select_fields\n                 next = requested.get(f.related_query_name(), {})\n                 next_klass_infos = self.get_related_selections(\n-                    select, model._meta, alias, cur_depth + 1,\n-                    next, restricted)\n+                    select, model._meta, alias, cur_depth + 1, next, restricted\n+                )\n                 get_related_klass_infos(klass_info, next_klass_infos)\n \n             def local_setter(obj, from_obj):\n@@ -914,32 +1078,40 @@ class SQLCompiler:\n                     break\n                 if name in self.query._filtered_relations:\n                     fields_found.add(name)\n-                    f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)\n+                    f, _, join_opts, joins, _, _ = self.query.setup_joins(\n+                        [name], opts, root_alias\n+                    )\n                     model = join_opts.model\n                     alias = joins[-1]\n-                    from_parent = issubclass(model, opts.model) and model is not opts.model\n+                    from_parent = (\n+                        issubclass(model, opts.model) and model is not opts.model\n+                    )\n                     klass_info = {\n-                        'model': model,\n-                        'field': f,\n-                        'reverse': True,\n-                        'local_setter': local_setter,\n-                        'remote_setter': partial(remote_setter, name),\n-                        'from_parent': from_parent,\n+                        \"model\": model,\n+                        \"field\": f,\n+                        \"reverse\": True,\n+                        \"local_setter\": local_setter,\n+                        \"remote_setter\": partial(remote_setter, name),\n+                        \"from_parent\": from_parent,\n                     }\n                     related_klass_infos.append(klass_info)\n                     select_fields = []\n                     columns = self.get_default_columns(\n-                        start_alias=alias, opts=model._meta,\n+                        start_alias=alias,\n+                        opts=model._meta,\n                         from_parent=opts.model,\n                     )\n                     for col in columns:\n                         select_fields.append(len(select))\n                         select.append((col, None))\n-                    klass_info['select_fields'] = select_fields\n+                    klass_info[\"select_fields\"] = select_fields\n                     next_requested = requested.get(name, {})\n                     next_klass_infos = self.get_related_selections(\n-                        select, opts=model._meta, root_alias=alias,\n-                        cur_depth=cur_depth + 1, requested=next_requested,\n+                        select,\n+                        opts=model._meta,\n+                        root_alias=alias,\n+                        cur_depth=cur_depth + 1,\n+                        requested=next_requested,\n                         restricted=restricted,\n                     )\n                     get_related_klass_infos(klass_info, next_klass_infos)\n@@ -947,10 +1119,11 @@ class SQLCompiler:\n             if fields_not_found:\n                 invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n                 raise FieldError(\n-                    'Invalid field name(s) given in select_related: %s. '\n-                    'Choices are: %s' % (\n-                        ', '.join(invalid_fields),\n-                        ', '.join(_get_field_choices()) or '(none)',\n+                    \"Invalid field name(s) given in select_related: %s. \"\n+                    \"Choices are: %s\"\n+                    % (\n+                        \", \".join(invalid_fields),\n+                        \", \".join(_get_field_choices()) or \"(none)\",\n                     )\n                 )\n         return related_klass_infos\n@@ -960,20 +1133,21 @@ class SQLCompiler:\n         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n         the query.\n         \"\"\"\n+\n         def _get_parent_klass_info(klass_info):\n-            for parent_model, parent_link in klass_info['model']._meta.parents.items():\n+            for parent_model, parent_link in klass_info[\"model\"]._meta.parents.items():\n                 parent_list = parent_model._meta.get_parent_list()\n                 yield {\n-                    'model': parent_model,\n-                    'field': parent_link,\n-                    'reverse': False,\n-                    'select_fields': [\n+                    \"model\": parent_model,\n+                    \"field\": parent_link,\n+                    \"reverse\": False,\n+                    \"select_fields\": [\n                         select_index\n-                        for select_index in klass_info['select_fields']\n+                        for select_index in klass_info[\"select_fields\"]\n                         # Selected columns from a model or its parents.\n                         if (\n-                            self.select[select_index][0].target.model == parent_model or\n-                            self.select[select_index][0].target.model in parent_list\n+                            self.select[select_index][0].target.model == parent_model\n+                            or self.select[select_index][0].target.model in parent_list\n                         )\n                     ],\n                 }\n@@ -986,8 +1160,8 @@ class SQLCompiler:\n             select_fields is filled recursively, so it also contains fields\n             from the parent models.\n             \"\"\"\n-            for select_index in klass_info['select_fields']:\n-                if self.select[select_index][0].target.model == klass_info['model']:\n+            for select_index in klass_info[\"select_fields\"]:\n+                if self.select[select_index][0].target.model == klass_info[\"model\"]:\n                     return self.select[select_index][0]\n \n         def _get_field_choices():\n@@ -997,10 +1171,10 @@ class SQLCompiler:\n                 parent_path, klass_info = queue.popleft()\n                 if parent_path is None:\n                     path = []\n-                    yield 'self'\n+                    yield \"self\"\n                 else:\n-                    field = klass_info['field']\n-                    if klass_info['reverse']:\n+                    field = klass_info[\"field\"]\n+                    if klass_info[\"reverse\"]:\n                         field = field.remote_field\n                     path = parent_path + [field.name]\n                     yield LOOKUP_SEP.join(path)\n@@ -1010,23 +1184,24 @@ class SQLCompiler:\n                 )\n                 queue.extend(\n                     (path, klass_info)\n-                    for klass_info in klass_info.get('related_klass_infos', [])\n+                    for klass_info in klass_info.get(\"related_klass_infos\", [])\n                 )\n+\n         result = []\n         invalid_names = []\n         for name in self.query.select_for_update_of:\n             klass_info = self.klass_info\n-            if name == 'self':\n+            if name == \"self\":\n                 col = _get_first_selected_col_from_model(klass_info)\n             else:\n                 for part in name.split(LOOKUP_SEP):\n                     klass_infos = (\n-                        *klass_info.get('related_klass_infos', []),\n+                        *klass_info.get(\"related_klass_infos\", []),\n                         *_get_parent_klass_info(klass_info),\n                     )\n                     for related_klass_info in klass_infos:\n-                        field = related_klass_info['field']\n-                        if related_klass_info['reverse']:\n+                        field = related_klass_info[\"field\"]\n+                        if related_klass_info[\"reverse\"]:\n                             field = field.remote_field\n                         if field.name == part:\n                             klass_info = related_klass_info\n@@ -1045,11 +1220,12 @@ class SQLCompiler:\n                     result.append(self.quote_name_unless_alias(col.alias))\n         if invalid_names:\n             raise FieldError(\n-                'Invalid field name(s) given in select_for_update(of=(...)): %s. '\n-                'Only relational fields followed in the query are allowed. '\n-                'Choices are: %s.' % (\n-                    ', '.join(invalid_names),\n-                    ', '.join(_get_field_choices()),\n+                \"Invalid field name(s) given in select_for_update(of=(...)): %s. \"\n+                \"Only relational fields followed in the query are allowed. \"\n+                \"Choices are: %s.\"\n+                % (\n+                    \", \".join(invalid_names),\n+                    \", \".join(_get_field_choices()),\n                 )\n             )\n         return result\n@@ -1085,12 +1261,19 @@ class SQLCompiler:\n                 row[pos] = value\n             yield row\n \n-    def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,\n-                     chunk_size=GET_ITERATOR_CHUNK_SIZE):\n+    def results_iter(\n+        self,\n+        results=None,\n+        tuple_expected=False,\n+        chunked_fetch=False,\n+        chunk_size=GET_ITERATOR_CHUNK_SIZE,\n+    ):\n         \"\"\"Return an iterator over the results from executing this query.\"\"\"\n         if results is None:\n-            results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n-        fields = [s[0] for s in self.select[0:self.col_count]]\n+            results = self.execute_sql(\n+                MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size\n+            )\n+        fields = [s[0] for s in self.select[0 : self.col_count]]\n         converters = self.get_converters(fields)\n         rows = chain.from_iterable(results)\n         if converters:\n@@ -1105,11 +1288,13 @@ class SQLCompiler:\n         versions of \"query has any results.\"\n         \"\"\"\n         # This is always executed on a query clone, so we can modify self.query\n-        self.query.add_extra({'a': 1}, None, None, None, None, None)\n-        self.query.set_extra_mask(['a'])\n+        self.query.add_extra({\"a\": 1}, None, None, None, None, None)\n+        self.query.set_extra_mask([\"a\"])\n         return bool(self.execute_sql(SINGLE))\n \n-    def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n+    def execute_sql(\n+        self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE\n+    ):\n         \"\"\"\n         Run the query against the database and return the result(s). The\n         return value is a single data item if result_type is SINGLE, or an\n@@ -1150,7 +1335,7 @@ class SQLCompiler:\n             try:\n                 val = cursor.fetchone()\n                 if val:\n-                    return val[0:self.col_count]\n+                    return val[0 : self.col_count]\n                 return val\n             finally:\n                 # done with the cursor\n@@ -1160,7 +1345,8 @@ class SQLCompiler:\n             return\n \n         result = cursor_iter(\n-            cursor, self.connection.features.empty_fetchmany_value,\n+            cursor,\n+            self.connection.features.empty_fetchmany_value,\n             self.col_count if self.has_extra_select else None,\n             chunk_size,\n         )\n@@ -1182,12 +1368,11 @@ class SQLCompiler:\n \n         for index, select_col in enumerate(self.query.select):\n             lhs_sql, lhs_params = self.compile(select_col)\n-            rhs = '%s.%s' % (qn(alias), qn2(columns[index]))\n-            self.query.where.add(\n-                RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')\n+            rhs = \"%s.%s\" % (qn(alias), qn2(columns[index]))\n+            self.query.where.add(RawSQL(\"%s = %s\" % (lhs_sql, rhs), lhs_params), \"AND\")\n \n         sql, params = self.as_sql()\n-        return 'EXISTS (%s)' % sql, params\n+        return \"EXISTS (%s)\" % sql, params\n \n     def explain_query(self):\n         result = list(self.execute_sql())\n@@ -1195,7 +1380,7 @@ class SQLCompiler:\n         # tuples with integers and strings. Flatten them out into strings.\n         for row in result[0]:\n             if not isinstance(row, str):\n-                yield ' '.join(str(c) for c in row)\n+                yield \" \".join(str(c) for c in row)\n             else:\n                 yield row\n \n@@ -1216,16 +1401,16 @@ class SQLInsertCompiler(SQLCompiler):\n         if field is None:\n             # A field value of None means the value is raw.\n             sql, params = val, []\n-        elif hasattr(val, 'as_sql'):\n+        elif hasattr(val, \"as_sql\"):\n             # This is an expression, let's compile it.\n             sql, params = self.compile(val)\n-        elif hasattr(field, 'get_placeholder'):\n+        elif hasattr(field, \"get_placeholder\"):\n             # Some fields (e.g. geo fields) need special munging before\n             # they can be inserted.\n             sql, params = field.get_placeholder(val, self, self.connection), [val]\n         else:\n             # Return the common case for the placeholder\n-            sql, params = '%s', [val]\n+            sql, params = \"%s\", [val]\n \n         # The following hook is only used by Oracle Spatial, which sometimes\n         # needs to yield 'NULL' and [] as its placeholder and params instead\n@@ -1241,24 +1426,26 @@ class SQLInsertCompiler(SQLCompiler):\n         Prepare a value to be used in a query by resolving it if it is an\n         expression and otherwise calling the field's get_db_prep_save().\n         \"\"\"\n-        if hasattr(value, 'resolve_expression'):\n-            value = value.resolve_expression(self.query, allow_joins=False, for_save=True)\n+        if hasattr(value, \"resolve_expression\"):\n+            value = value.resolve_expression(\n+                self.query, allow_joins=False, for_save=True\n+            )\n             # Don't allow values containing Col expressions. They refer to\n             # existing columns on a row, but in the case of insert the row\n             # doesn't exist yet.\n             if value.contains_column_references:\n                 raise ValueError(\n                     'Failed to insert expression \"%s\" on %s. F() expressions '\n-                    'can only be used to update, not to insert.' % (value, field)\n+                    \"can only be used to update, not to insert.\" % (value, field)\n                 )\n             if value.contains_aggregate:\n                 raise FieldError(\n-                    'Aggregate functions are not allowed in this query '\n-                    '(%s=%r).' % (field.name, value)\n+                    \"Aggregate functions are not allowed in this query \"\n+                    \"(%s=%r).\" % (field.name, value)\n                 )\n             if value.contains_over_clause:\n                 raise FieldError(\n-                    'Window expressions are not allowed in this query (%s=%r).'\n+                    \"Window expressions are not allowed in this query (%s=%r).\"\n                     % (field.name, value)\n                 )\n         else:\n@@ -1314,35 +1501,49 @@ class SQLInsertCompiler(SQLCompiler):\n         # going to be column names (so we can avoid the extra overhead).\n         qn = self.connection.ops.quote_name\n         opts = self.query.get_meta()\n-        insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)\n-        result = ['%s %s' % (insert_statement, qn(opts.db_table))]\n+        insert_statement = self.connection.ops.insert_statement(\n+            ignore_conflicts=self.query.ignore_conflicts\n+        )\n+        result = [\"%s %s\" % (insert_statement, qn(opts.db_table))]\n         fields = self.query.fields or [opts.pk]\n-        result.append('(%s)' % ', '.join(qn(f.column) for f in fields))\n+        result.append(\"(%s)\" % \", \".join(qn(f.column) for f in fields))\n \n         if self.query.fields:\n             value_rows = [\n-                [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]\n+                [\n+                    self.prepare_value(field, self.pre_save_val(field, obj))\n+                    for field in fields\n+                ]\n                 for obj in self.query.objs\n             ]\n         else:\n             # An empty object.\n-            value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]\n+            value_rows = [\n+                [self.connection.ops.pk_default_value()] for _ in self.query.objs\n+            ]\n             fields = [None]\n \n         # Currently the backends just accept values when generating bulk\n         # queries and generate their own placeholders. Doing that isn't\n         # necessary and it should be possible to use placeholders and\n         # expressions in bulk inserts too.\n-        can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)\n+        can_bulk = (\n+            not self.returning_fields and self.connection.features.has_bulk_insert\n+        )\n \n         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n \n         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(\n             ignore_conflicts=self.query.ignore_conflicts\n         )\n-        if self.returning_fields and self.connection.features.can_return_columns_from_insert:\n+        if (\n+            self.returning_fields\n+            and self.connection.features.can_return_columns_from_insert\n+        ):\n             if self.connection.features.can_return_rows_from_bulk_insert:\n-                result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n+                result.append(\n+                    self.connection.ops.bulk_insert_sql(fields, placeholder_rows)\n+                )\n                 params = param_rows\n             else:\n                 result.append(\"VALUES (%s)\" % \", \".join(placeholder_rows[0]))\n@@ -1351,7 +1552,9 @@ class SQLInsertCompiler(SQLCompiler):\n                 result.append(ignore_conflicts_suffix_sql)\n             # Skip empty r_sql to allow subclasses to customize behavior for\n             # 3rd party backends. Refs #19096.\n-            r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)\n+            r_sql, self.returning_params = self.connection.ops.return_insert_columns(\n+                self.returning_fields\n+            )\n             if r_sql:\n                 result.append(r_sql)\n                 params += [self.returning_params]\n@@ -1372,8 +1575,9 @@ class SQLInsertCompiler(SQLCompiler):\n \n     def execute_sql(self, returning_fields=None):\n         assert not (\n-            returning_fields and len(self.query.objs) != 1 and\n-            not self.connection.features.can_return_rows_from_bulk_insert\n+            returning_fields\n+            and len(self.query.objs) != 1\n+            and not self.connection.features.can_return_rows_from_bulk_insert\n         )\n         self.returning_fields = returning_fields\n         with self.connection.cursor() as cursor:\n@@ -1381,14 +1585,23 @@ class SQLInsertCompiler(SQLCompiler):\n                 cursor.execute(sql, params)\n             if not self.returning_fields:\n                 return []\n-            if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n+            if (\n+                self.connection.features.can_return_rows_from_bulk_insert\n+                and len(self.query.objs) > 1\n+            ):\n                 return self.connection.ops.fetch_returned_insert_rows(cursor)\n             if self.connection.features.can_return_columns_from_insert:\n                 assert len(self.query.objs) == 1\n-                return self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)\n-            return [self.connection.ops.last_insert_id(\n-                cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column\n-            )]\n+                return self.connection.ops.fetch_returned_insert_columns(\n+                    cursor, self.returning_params\n+                )\n+            return [\n+                self.connection.ops.last_insert_id(\n+                    cursor,\n+                    self.query.get_meta().db_table,\n+                    self.query.get_meta().pk.column,\n+                )\n+            ]\n \n \n class SQLDeleteCompiler(SQLCompiler):\n@@ -1397,13 +1610,11 @@ class SQLDeleteCompiler(SQLCompiler):\n         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n \n     def _as_sql(self, query):\n-        result = [\n-            'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)\n-        ]\n+        result = [\"DELETE FROM %s\" % self.quote_name_unless_alias(query.base_table)]\n         where, params = self.compile(query.where)\n         if where:\n-            result.append('WHERE %s' % where)\n-        return ' '.join(result), tuple(params)\n+            result.append(\"WHERE %s\" % where)\n+        return \" \".join(result), tuple(params)\n \n     def as_sql(self):\n         \"\"\"\n@@ -1416,9 +1627,7 @@ class SQLDeleteCompiler(SQLCompiler):\n         innerq.__class__ = Query\n         innerq.clear_select_clause()\n         pk = self.query.model._meta.pk\n-        innerq.select = [\n-            pk.get_col(self.query.get_initial_alias())\n-        ]\n+        innerq.select = [pk.get_col(self.query.get_initial_alias())]\n         outerq = Query(self.query.model)\n         outerq.where = self.query.where_class()\n         outerq.add_q(Q(pk__in=innerq))\n@@ -1433,23 +1642,25 @@ class SQLUpdateCompiler(SQLCompiler):\n         \"\"\"\n         self.pre_sql_setup()\n         if not self.query.values:\n-            return '', ()\n+            return \"\", ()\n         qn = self.quote_name_unless_alias\n         values, update_params = [], []\n         for field, model, val in self.query.values:\n-            if hasattr(val, 'resolve_expression'):\n-                val = val.resolve_expression(self.query, allow_joins=False, for_save=True)\n+            if hasattr(val, \"resolve_expression\"):\n+                val = val.resolve_expression(\n+                    self.query, allow_joins=False, for_save=True\n+                )\n                 if val.contains_aggregate:\n                     raise FieldError(\n-                        'Aggregate functions are not allowed in this query '\n-                        '(%s=%r).' % (field.name, val)\n+                        \"Aggregate functions are not allowed in this query \"\n+                        \"(%s=%r).\" % (field.name, val)\n                     )\n                 if val.contains_over_clause:\n                     raise FieldError(\n-                        'Window expressions are not allowed in this query '\n-                        '(%s=%r).' % (field.name, val)\n+                        \"Window expressions are not allowed in this query \"\n+                        \"(%s=%r).\" % (field.name, val)\n                     )\n-            elif hasattr(val, 'prepare_database_save'):\n+            elif hasattr(val, \"prepare_database_save\"):\n                 if field.remote_field:\n                     val = field.get_db_prep_save(\n                         val.prepare_database_save(field),\n@@ -1465,29 +1676,29 @@ class SQLUpdateCompiler(SQLCompiler):\n                 val = field.get_db_prep_save(val, connection=self.connection)\n \n             # Getting the placeholder for the field.\n-            if hasattr(field, 'get_placeholder'):\n+            if hasattr(field, \"get_placeholder\"):\n                 placeholder = field.get_placeholder(val, self, self.connection)\n             else:\n-                placeholder = '%s'\n+                placeholder = \"%s\"\n             name = field.column\n-            if hasattr(val, 'as_sql'):\n+            if hasattr(val, \"as_sql\"):\n                 sql, params = self.compile(val)\n-                values.append('%s = %s' % (qn(name), placeholder % sql))\n+                values.append(\"%s = %s\" % (qn(name), placeholder % sql))\n                 update_params.extend(params)\n             elif val is not None:\n-                values.append('%s = %s' % (qn(name), placeholder))\n+                values.append(\"%s = %s\" % (qn(name), placeholder))\n                 update_params.append(val)\n             else:\n-                values.append('%s = NULL' % qn(name))\n+                values.append(\"%s = NULL\" % qn(name))\n         table = self.query.base_table\n         result = [\n-            'UPDATE %s SET' % qn(table),\n-            ', '.join(values),\n+            \"UPDATE %s SET\" % qn(table),\n+            \", \".join(values),\n         ]\n         where, params = self.compile(self.query.where)\n         if where:\n-            result.append('WHERE %s' % where)\n-        return ' '.join(result), tuple(update_params + params)\n+            result.append(\"WHERE %s\" % where)\n+        return \" \".join(result), tuple(update_params + params)\n \n     def execute_sql(self, result_type):\n         \"\"\"\n@@ -1533,7 +1744,9 @@ class SQLUpdateCompiler(SQLCompiler):\n         query.add_fields([query.get_meta().pk.name])\n         super().pre_sql_setup()\n \n-        must_pre_select = count > 1 and not self.connection.features.update_can_self_select\n+        must_pre_select = (\n+            count > 1 and not self.connection.features.update_can_self_select\n+        )\n \n         # Now we adjust the current query: reset the where clause and get rid\n         # of all the tables we don't need (since they're in the sub-select).\n@@ -1545,11 +1758,11 @@ class SQLUpdateCompiler(SQLCompiler):\n             idents = []\n             for rows in query.get_compiler(self.using).execute_sql(MULTI):\n                 idents.extend(r[0] for r in rows)\n-            self.query.add_filter(('pk__in', idents))\n+            self.query.add_filter((\"pk__in\", idents))\n             self.query.related_ids = idents\n         else:\n             # The fast path. Filters and updates in one query.\n-            self.query.add_filter(('pk__in', query))\n+            self.query.add_filter((\"pk__in\", query))\n         self.query.reset_refcounts(refcounts_before)\n \n \n@@ -1566,10 +1779,10 @@ class SQLAggregateCompiler(SQLCompiler):\n             sql.append(ann_sql)\n             params.extend(ann_params)\n         self.col_count = len(self.query.annotation_select)\n-        sql = ', '.join(sql)\n+        sql = \", \".join(sql)\n         params = tuple(params)\n \n-        sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)\n+        sql = \"SELECT %s FROM (%s) subquery\" % (sql, self.query.subquery)\n         params = params + self.query.sub_params\n         return sql, params\n \n"}
{"instance_id": "django__django-12497", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8ddbb5ba68..c755a1e750 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -19,19 +19,30 @@ from django.utils.translation import gettext_lazy as _\n from . import Field\n from .mixins import FieldCacheMixin\n from .related_descriptors import (\n-    ForeignKeyDeferredAttribute, ForwardManyToOneDescriptor,\n-    ForwardOneToOneDescriptor, ManyToManyDescriptor,\n-    ReverseManyToOneDescriptor, ReverseOneToOneDescriptor,\n+    ForeignKeyDeferredAttribute,\n+    ForwardManyToOneDescriptor,\n+    ForwardOneToOneDescriptor,\n+    ManyToManyDescriptor,\n+    ReverseManyToOneDescriptor,\n+    ReverseOneToOneDescriptor,\n )\n from .related_lookups import (\n-    RelatedExact, RelatedGreaterThan, RelatedGreaterThanOrEqual, RelatedIn,\n-    RelatedIsNull, RelatedLessThan, RelatedLessThanOrEqual,\n+    RelatedExact,\n+    RelatedGreaterThan,\n+    RelatedGreaterThanOrEqual,\n+    RelatedIn,\n+    RelatedIsNull,\n+    RelatedLessThan,\n+    RelatedLessThanOrEqual,\n )\n from .reverse_related import (\n-    ForeignObjectRel, ManyToManyRel, ManyToOneRel, OneToOneRel,\n+    ForeignObjectRel,\n+    ManyToManyRel,\n+    ManyToOneRel,\n+    OneToOneRel,\n )\n \n-RECURSIVE_RELATIONSHIP_CONSTANT = 'self'\n+RECURSIVE_RELATIONSHIP_CONSTANT = \"self\"\n \n \n def resolve_relation(scope_model, relation):\n@@ -107,19 +118,25 @@ class RelatedField(FieldCacheMixin, Field):\n \n     def _check_related_name_is_valid(self):\n         import keyword\n+\n         related_name = self.remote_field.related_name\n         if related_name is None:\n             return []\n-        is_valid_id = not keyword.iskeyword(related_name) and related_name.isidentifier()\n-        if not (is_valid_id or related_name.endswith('+')):\n+        is_valid_id = (\n+            not keyword.iskeyword(related_name) and related_name.isidentifier()\n+        )\n+        if not (is_valid_id or related_name.endswith(\"+\")):\n             return [\n                 checks.Error(\n-                    \"The name '%s' is invalid related_name for field %s.%s\" %\n-                    (self.remote_field.related_name, self.model._meta.object_name,\n-                     self.name),\n+                    \"The name '%s' is invalid related_name for field %s.%s\"\n+                    % (\n+                        self.remote_field.related_name,\n+                        self.model._meta.object_name,\n+                        self.name,\n+                    ),\n                     hint=\"Related name must be a valid Python identifier or end with a '+'\",\n                     obj=self,\n-                    id='fields.E306',\n+                    id=\"fields.E306\",\n                 )\n             ]\n         return []\n@@ -129,15 +146,17 @@ class RelatedField(FieldCacheMixin, Field):\n             return []\n         rel_query_name = self.related_query_name()\n         errors = []\n-        if rel_query_name.endswith('_'):\n+        if rel_query_name.endswith(\"_\"):\n             errors.append(\n                 checks.Error(\n                     \"Reverse query name '%s' must not end with an underscore.\"\n                     % (rel_query_name,),\n-                    hint=(\"Add or change a related_name or related_query_name \"\n-                          \"argument for this field.\"),\n+                    hint=(\n+                        \"Add or change a related_name or related_query_name \"\n+                        \"argument for this field.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E308',\n+                    id=\"fields.E308\",\n                 )\n             )\n         if LOOKUP_SEP in rel_query_name:\n@@ -145,10 +164,12 @@ class RelatedField(FieldCacheMixin, Field):\n                 checks.Error(\n                     \"Reverse query name '%s' must not contain '%s'.\"\n                     % (rel_query_name, LOOKUP_SEP),\n-                    hint=(\"Add or change a related_name or related_query_name \"\n-                          \"argument for this field.\"),\n+                    hint=(\n+                        \"Add or change a related_name or related_query_name \"\n+                        \"argument for this field.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E309',\n+                    id=\"fields.E309\",\n                 )\n             )\n         return errors\n@@ -156,33 +177,42 @@ class RelatedField(FieldCacheMixin, Field):\n     def _check_relation_model_exists(self):\n         rel_is_missing = self.remote_field.model not in self.opts.apps.get_models()\n         rel_is_string = isinstance(self.remote_field.model, str)\n-        model_name = self.remote_field.model if rel_is_string else self.remote_field.model._meta.object_name\n-        if rel_is_missing and (rel_is_string or not self.remote_field.model._meta.swapped):\n+        model_name = (\n+            self.remote_field.model\n+            if rel_is_string\n+            else self.remote_field.model._meta.object_name\n+        )\n+        if rel_is_missing and (\n+            rel_is_string or not self.remote_field.model._meta.swapped\n+        ):\n             return [\n                 checks.Error(\n                     \"Field defines a relation with model '%s', which is either \"\n                     \"not installed, or is abstract.\" % model_name,\n                     obj=self,\n-                    id='fields.E300',\n+                    id=\"fields.E300\",\n                 )\n             ]\n         return []\n \n     def _check_referencing_to_swapped_model(self):\n-        if (self.remote_field.model not in self.opts.apps.get_models() and\n-                not isinstance(self.remote_field.model, str) and\n-                self.remote_field.model._meta.swapped):\n+        if (\n+            self.remote_field.model not in self.opts.apps.get_models()\n+            and not isinstance(self.remote_field.model, str)\n+            and self.remote_field.model._meta.swapped\n+        ):\n             model = \"%s.%s\" % (\n                 self.remote_field.model._meta.app_label,\n-                self.remote_field.model._meta.object_name\n+                self.remote_field.model._meta.object_name,\n             )\n             return [\n                 checks.Error(\n                     \"Field defines a relation with the model '%s', which has \"\n                     \"been swapped out.\" % model,\n-                    hint=\"Update the relation to point at 'settings.%s'.\" % self.remote_field.model._meta.swappable,\n+                    hint=\"Update the relation to point at 'settings.%s'.\"\n+                    % self.remote_field.model._meta.swappable,\n                     obj=self,\n-                    id='fields.E301',\n+                    id=\"fields.E301\",\n                 )\n             ]\n         return []\n@@ -225,26 +255,37 @@ class RelatedField(FieldCacheMixin, Field):\n         # model_set and it clashes with Target.model_set.\n         potential_clashes = rel_opts.fields + rel_opts.many_to_many\n         for clash_field in potential_clashes:\n-            clash_name = \"%s.%s\" % (rel_opts.object_name, clash_field.name)  # i.e. \"Target.model_set\"\n+            clash_name = \"%s.%s\" % (\n+                rel_opts.object_name,\n+                clash_field.name,\n+            )  # i.e. \"Target.model_set\"\n             if not rel_is_hidden and clash_field.name == rel_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse accessor for '%s' clashes with field name '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Rename field '%s', or add/change a related_name \"\n-                              \"argument to the definition for field '%s'.\") % (clash_name, field_name),\n+                        \"Reverse accessor for '%s' clashes with field name '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Rename field '%s', or add/change a related_name \"\n+                            \"argument to the definition for field '%s'.\"\n+                        )\n+                        % (clash_name, field_name),\n                         obj=self,\n-                        id='fields.E302',\n+                        id=\"fields.E302\",\n                     )\n                 )\n \n             if clash_field.name == rel_query_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse query name for '%s' clashes with field name '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Rename field '%s', or add/change a related_name \"\n-                              \"argument to the definition for field '%s'.\") % (clash_name, field_name),\n+                        \"Reverse query name for '%s' clashes with field name '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Rename field '%s', or add/change a related_name \"\n+                            \"argument to the definition for field '%s'.\"\n+                        )\n+                        % (clash_name, field_name),\n                         obj=self,\n-                        id='fields.E303',\n+                        id=\"fields.E303\",\n                     )\n                 )\n \n@@ -255,15 +296,20 @@ class RelatedField(FieldCacheMixin, Field):\n         for clash_field in potential_clashes:\n             clash_name = \"%s.%s\" % (  # i. e. \"Model.m2m\"\n                 clash_field.related_model._meta.object_name,\n-                clash_field.field.name)\n+                clash_field.field.name,\n+            )\n             if not rel_is_hidden and clash_field.get_accessor_name() == rel_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse accessor for '%s' clashes with reverse accessor for '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Add or change a related_name argument \"\n-                              \"to the definition for '%s' or '%s'.\") % (field_name, clash_name),\n+                        \"Reverse accessor for '%s' clashes with reverse accessor for '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Add or change a related_name argument \"\n+                            \"to the definition for '%s' or '%s'.\"\n+                        )\n+                        % (field_name, clash_name),\n                         obj=self,\n-                        id='fields.E304',\n+                        id=\"fields.E304\",\n                     )\n                 )\n \n@@ -272,10 +318,13 @@ class RelatedField(FieldCacheMixin, Field):\n                     checks.Error(\n                         \"Reverse query name for '%s' clashes with reverse query name for '%s'.\"\n                         % (field_name, clash_name),\n-                        hint=(\"Add or change a related_name argument \"\n-                              \"to the definition for '%s' or '%s'.\") % (field_name, clash_name),\n+                        hint=(\n+                            \"Add or change a related_name argument \"\n+                            \"to the definition for '%s' or '%s'.\"\n+                        )\n+                        % (field_name, clash_name),\n                         obj=self,\n-                        id='fields.E305',\n+                        id=\"fields.E305\",\n                     )\n                 )\n \n@@ -287,7 +336,6 @@ class RelatedField(FieldCacheMixin, Field):\n         return None\n \n     def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n-\n         super().contribute_to_class(cls, name, private_only=private_only, **kwargs)\n \n         self.opts = cls._meta\n@@ -299,32 +347,35 @@ class RelatedField(FieldCacheMixin, Field):\n                 related_name = self.opts.default_related_name\n             if related_name:\n                 related_name = related_name % {\n-                    'class': cls.__name__.lower(),\n-                    'model_name': cls._meta.model_name.lower(),\n-                    'app_label': cls._meta.app_label.lower()\n+                    \"class\": cls.__name__.lower(),\n+                    \"model_name\": cls._meta.model_name.lower(),\n+                    \"app_label\": cls._meta.app_label.lower(),\n                 }\n                 self.remote_field.related_name = related_name\n \n             if self.remote_field.related_query_name:\n                 related_query_name = self.remote_field.related_query_name % {\n-                    'class': cls.__name__.lower(),\n-                    'app_label': cls._meta.app_label.lower(),\n+                    \"class\": cls.__name__.lower(),\n+                    \"app_label\": cls._meta.app_label.lower(),\n                 }\n                 self.remote_field.related_query_name = related_query_name\n \n             def resolve_related_class(model, related, field):\n                 field.remote_field.model = related\n                 field.do_related_class(related, model)\n-            lazy_related_operation(resolve_related_class, cls, self.remote_field.model, field=self)\n+\n+            lazy_related_operation(\n+                resolve_related_class, cls, self.remote_field.model, field=self\n+            )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.remote_field.limit_choices_to:\n-            kwargs['limit_choices_to'] = self.remote_field.limit_choices_to\n+            kwargs[\"limit_choices_to\"] = self.remote_field.limit_choices_to\n         if self.remote_field.related_name is not None:\n-            kwargs['related_name'] = self.remote_field.related_name\n+            kwargs[\"related_name\"] = self.remote_field.related_name\n         if self.remote_field.related_query_name is not None:\n-            kwargs['related_query_name'] = self.remote_field.related_query_name\n+            kwargs[\"related_query_name\"] = self.remote_field.related_query_name\n         return name, path, args, kwargs\n \n     def get_forward_related_filter(self, obj):\n@@ -336,7 +387,7 @@ class RelatedField(FieldCacheMixin, Field):\n         self.related_field.model.\n         \"\"\"\n         return {\n-            '%s__%s' % (self.name, rh_field.name): getattr(obj, rh_field.attname)\n+            \"%s__%s\" % (self.name, rh_field.name): getattr(obj, rh_field.attname)\n             for _, rh_field in self.related_fields\n         }\n \n@@ -375,9 +426,10 @@ class RelatedField(FieldCacheMixin, Field):\n         return None\n \n     def set_attributes_from_rel(self):\n-        self.name = (\n-            self.name or\n-            (self.remote_field.model._meta.model_name + '_' + self.remote_field.model._meta.pk.name)\n+        self.name = self.name or (\n+            self.remote_field.model._meta.model_name\n+            + \"_\"\n+            + self.remote_field.model._meta.pk.name\n         )\n         if self.verbose_name is None:\n             self.verbose_name = self.remote_field.model._meta.verbose_name\n@@ -407,14 +459,16 @@ class RelatedField(FieldCacheMixin, Field):\n         being constructed.\n         \"\"\"\n         defaults = {}\n-        if hasattr(self.remote_field, 'get_related_field'):\n+        if hasattr(self.remote_field, \"get_related_field\"):\n             # If this is a callable, do not invoke it here. Just pass\n             # it in the defaults for when the form class will later be\n             # instantiated.\n             limit_choices_to = self.remote_field.limit_choices_to\n-            defaults.update({\n-                'limit_choices_to': limit_choices_to,\n-            })\n+            defaults.update(\n+                {\n+                    \"limit_choices_to\": limit_choices_to,\n+                }\n+            )\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -423,7 +477,11 @@ class RelatedField(FieldCacheMixin, Field):\n         Define the name that can be used to identify this related object in a\n         table-spanning query.\n         \"\"\"\n-        return self.remote_field.related_query_name or self.remote_field.related_name or self.opts.model_name\n+        return (\n+            self.remote_field.related_query_name\n+            or self.remote_field.related_name\n+            or self.opts.model_name\n+        )\n \n     @property\n     def target_field(self):\n@@ -434,7 +492,8 @@ class RelatedField(FieldCacheMixin, Field):\n         target_fields = self.get_path_info()[-1].target_fields\n         if len(target_fields) > 1:\n             raise exceptions.FieldError(\n-                \"The relation has multiple target fields, but only single target field was asked for\")\n+                \"The relation has multiple target fields, but only single target field was asked for\"\n+            )\n         return target_fields[0]\n \n     def get_cache_name(self):\n@@ -457,13 +516,24 @@ class ForeignObject(RelatedField):\n     forward_related_accessor_class = ForwardManyToOneDescriptor\n     rel_class = ForeignObjectRel\n \n-    def __init__(self, to, on_delete, from_fields, to_fields, rel=None, related_name=None,\n-                 related_query_name=None, limit_choices_to=None, parent_link=False,\n-                 swappable=True, **kwargs):\n-\n+    def __init__(\n+        self,\n+        to,\n+        on_delete,\n+        from_fields,\n+        to_fields,\n+        rel=None,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        swappable=True,\n+        **kwargs,\n+    ):\n         if rel is None:\n             rel = self.rel_class(\n-                self, to,\n+                self,\n+                to,\n                 related_name=related_name,\n                 related_query_name=related_query_name,\n                 limit_choices_to=limit_choices_to,\n@@ -501,7 +571,7 @@ class ForeignObject(RelatedField):\n                             \"model '%s'.\"\n                             % (to_field, self.remote_field.model._meta.label),\n                             obj=self,\n-                            id='fields.E312',\n+                            id=\"fields.E312\",\n                         )\n                     )\n         return errors\n@@ -522,21 +592,22 @@ class ForeignObject(RelatedField):\n         unique_foreign_fields = {\n             frozenset([f.name])\n             for f in self.remote_field.model._meta.get_fields()\n-            if getattr(f, 'unique', False)\n+            if getattr(f, \"unique\", False)\n         }\n-        unique_foreign_fields.update({\n-            frozenset(ut)\n-            for ut in self.remote_field.model._meta.unique_together\n-        })\n-        unique_foreign_fields.update({\n-            frozenset(uc.fields)\n-            for uc in self.remote_field.model._meta.total_unique_constraints\n-        })\n+        unique_foreign_fields.update(\n+            {frozenset(ut) for ut in self.remote_field.model._meta.unique_together}\n+        )\n+        unique_foreign_fields.update(\n+            {\n+                frozenset(uc.fields)\n+                for uc in self.remote_field.model._meta.total_unique_constraints\n+            }\n+        )\n         foreign_fields = {f.name for f in self.foreign_related_fields}\n         has_unique_constraint = any(u <= foreign_fields for u in unique_foreign_fields)\n \n         if not has_unique_constraint and len(self.foreign_related_fields) > 1:\n-            field_combination = ', '.join(\n+            field_combination = \", \".join(\n                 \"'%s'\" % rel_field.name for rel_field in self.foreign_related_fields\n             )\n             model_name = self.remote_field.model.__name__\n@@ -545,13 +616,13 @@ class ForeignObject(RelatedField):\n                     \"No subset of the fields %s on model '%s' is unique.\"\n                     % (field_combination, model_name),\n                     hint=(\n-                        'Mark a single field as unique=True or add a set of '\n-                        'fields to a unique constraint (via unique_together '\n-                        'or a UniqueConstraint (without condition) in the '\n-                        'model Meta.constraints).'\n+                        \"Mark a single field as unique=True or add a set of \"\n+                        \"fields to a unique constraint (via unique_together \"\n+                        \"or a UniqueConstraint (without condition) in the \"\n+                        \"model Meta.constraints).\"\n                     ),\n                     obj=self,\n-                    id='fields.E310',\n+                    id=\"fields.E310\",\n                 )\n             ]\n         elif not has_unique_constraint:\n@@ -562,12 +633,12 @@ class ForeignObject(RelatedField):\n                     \"'%s.%s' must be unique because it is referenced by \"\n                     \"a foreign key.\" % (model_name, field_name),\n                     hint=(\n-                        'Add unique=True to this field or add a '\n-                        'UniqueConstraint (without condition) in the model '\n-                        'Meta.constraints.'\n+                        \"Add unique=True to this field or add a \"\n+                        \"UniqueConstraint (without condition) in the model \"\n+                        \"Meta.constraints.\"\n                     ),\n                     obj=self,\n-                    id='fields.E311',\n+                    id=\"fields.E311\",\n                 )\n             ]\n         else:\n@@ -575,17 +646,17 @@ class ForeignObject(RelatedField):\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        kwargs['on_delete'] = self.remote_field.on_delete\n-        kwargs['from_fields'] = self.from_fields\n-        kwargs['to_fields'] = self.to_fields\n+        kwargs[\"on_delete\"] = self.remote_field.on_delete\n+        kwargs[\"from_fields\"] = self.from_fields\n+        kwargs[\"to_fields\"] = self.to_fields\n \n         if self.remote_field.parent_link:\n-            kwargs['parent_link'] = self.remote_field.parent_link\n+            kwargs[\"parent_link\"] = self.remote_field.parent_link\n         # Work out string form of \"to\"\n         if isinstance(self.remote_field.model, str):\n-            kwargs['to'] = self.remote_field.model\n+            kwargs[\"to\"] = self.remote_field.model\n         else:\n-            kwargs['to'] = \"%s.%s\" % (\n+            kwargs[\"to\"] = \"%s.%s\" % (\n                 self.remote_field.model._meta.app_label,\n                 self.remote_field.model._meta.object_name,\n             )\n@@ -594,25 +665,29 @@ class ForeignObject(RelatedField):\n         swappable_setting = self.swappable_setting\n         if swappable_setting is not None:\n             # If it's already a settings reference, error\n-            if hasattr(kwargs['to'], \"setting_name\"):\n-                if kwargs['to'].setting_name != swappable_setting:\n+            if hasattr(kwargs[\"to\"], \"setting_name\"):\n+                if kwargs[\"to\"].setting_name != swappable_setting:\n                     raise ValueError(\n                         \"Cannot deconstruct a ForeignKey pointing to a model \"\n                         \"that is swapped in place of more than one model (%s and %s)\"\n-                        % (kwargs['to'].setting_name, swappable_setting)\n+                        % (kwargs[\"to\"].setting_name, swappable_setting)\n                     )\n             # Set it\n-            kwargs['to'] = SettingsReference(\n-                kwargs['to'],\n+            kwargs[\"to\"] = SettingsReference(\n+                kwargs[\"to\"],\n                 swappable_setting,\n             )\n         return name, path, args, kwargs\n \n     def resolve_related_fields(self):\n         if not self.from_fields or len(self.from_fields) != len(self.to_fields):\n-            raise ValueError('Foreign Object from and to fields must be the same non-zero length')\n+            raise ValueError(\n+                \"Foreign Object from and to fields must be the same non-zero length\"\n+            )\n         if isinstance(self.remote_field.model, str):\n-            raise ValueError('Related model %r cannot be resolved' % self.remote_field.model)\n+            raise ValueError(\n+                \"Related model %r cannot be resolved\" % self.remote_field.model\n+            )\n         related_fields = []\n         for index in range(len(self.from_fields)):\n             from_field_name = self.from_fields[index]\n@@ -622,8 +697,11 @@ class ForeignObject(RelatedField):\n                 if from_field_name == RECURSIVE_RELATIONSHIP_CONSTANT\n                 else self.opts.get_field(from_field_name)\n             )\n-            to_field = (self.remote_field.model._meta.pk if to_field_name is None\n-                        else self.remote_field.model._meta.get_field(to_field_name))\n+            to_field = (\n+                self.remote_field.model._meta.pk\n+                if to_field_name is None\n+                else self.remote_field.model._meta.get_field(to_field_name)\n+            )\n             related_fields.append((from_field, to_field))\n         return related_fields\n \n@@ -641,7 +719,9 @@ class ForeignObject(RelatedField):\n \n     @cached_property\n     def foreign_related_fields(self):\n-        return tuple(rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field)\n+        return tuple(\n+            rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field\n+        )\n \n     def get_local_related_value(self, instance):\n         return self.get_instance_value_for_fields(instance, self.local_related_fields)\n@@ -659,9 +739,11 @@ class ForeignObject(RelatedField):\n             # instance.pk (that is, parent_ptr_id) when asked for instance.id.\n             if field.primary_key:\n                 possible_parent_link = opts.get_ancestor_link(field.model)\n-                if (not possible_parent_link or\n-                        possible_parent_link.primary_key or\n-                        possible_parent_link.model._meta.abstract):\n+                if (\n+                    not possible_parent_link\n+                    or possible_parent_link.primary_key\n+                    or possible_parent_link.model._meta.abstract\n+                ):\n                     ret.append(instance.pk)\n                     continue\n             ret.append(getattr(instance, field.attname))\n@@ -673,7 +755,9 @@ class ForeignObject(RelatedField):\n \n     def get_joining_columns(self, reverse_join=False):\n         source = self.reverse_related_fields if reverse_join else self.related_fields\n-        return tuple((lhs_field.column, rhs_field.column) for lhs_field, rhs_field in source)\n+        return tuple(\n+            (lhs_field.column, rhs_field.column) for lhs_field, rhs_field in source\n+        )\n \n     def get_reverse_joining_columns(self):\n         return self.get_joining_columns(reverse_join=True)\n@@ -711,36 +795,40 @@ class ForeignObject(RelatedField):\n         \"\"\"Get path from this field to the related model.\"\"\"\n         opts = self.remote_field.model._meta\n         from_opts = self.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=self.foreign_related_fields,\n-            join_field=self,\n-            m2m=False,\n-            direct=True,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=self.foreign_related_fields,\n+                join_field=self,\n+                m2m=False,\n+                direct=True,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     def get_reverse_path_info(self, filtered_relation=None):\n         \"\"\"Get path from the related model to this field's model.\"\"\"\n         opts = self.model._meta\n         from_opts = self.remote_field.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=(opts.pk,),\n-            join_field=self.remote_field,\n-            m2m=not self.unique,\n-            direct=False,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=(opts.pk,),\n+                join_field=self.remote_field,\n+                m2m=not self.unique,\n+                direct=False,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     @classmethod\n     @functools.lru_cache(maxsize=None)\n     def get_lookups(cls):\n         bases = inspect.getmro(cls)\n-        bases = bases[:bases.index(ForeignObject) + 1]\n-        class_lookups = [parent.__dict__.get('class_lookups', {}) for parent in bases]\n+        bases = bases[: bases.index(ForeignObject) + 1]\n+        class_lookups = [parent.__dict__.get(\"class_lookups\", {}) for parent in bases]\n         return cls.merge_dicts(class_lookups)\n \n     def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n@@ -750,13 +838,22 @@ class ForeignObject(RelatedField):\n     def contribute_to_related_class(self, cls, related):\n         # Internal FK's - i.e., those with a related name ending with '+' -\n         # and swapped models don't get a related descriptor.\n-        if not self.remote_field.is_hidden() and not related.related_model._meta.swapped:\n-            setattr(cls._meta.concrete_model, related.get_accessor_name(), self.related_accessor_class(related))\n+        if (\n+            not self.remote_field.is_hidden()\n+            and not related.related_model._meta.swapped\n+        ):\n+            setattr(\n+                cls._meta.concrete_model,\n+                related.get_accessor_name(),\n+                self.related_accessor_class(related),\n+            )\n             # While 'limit_choices_to' might be a callable, simply pass\n             # it along for later - this is too early because it's still\n             # model load time.\n             if self.remote_field.limit_choices_to:\n-                cls._meta.related_fkey_lookups.append(self.remote_field.limit_choices_to)\n+                cls._meta.related_fkey_lookups.append(\n+                    self.remote_field.limit_choices_to\n+                )\n \n \n ForeignObject.register_lookup(RelatedIn)\n@@ -776,6 +873,7 @@ class ForeignKey(ForeignObject):\n     By default ForeignKey will target the pk of the remote model but this\n     behavior can be changed by using the ``to_field`` argument.\n     \"\"\"\n+\n     descriptor_class = ForeignKeyDeferredAttribute\n     # Field flags\n     many_to_many = False\n@@ -787,20 +885,31 @@ class ForeignKey(ForeignObject):\n \n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('%(model)s instance with %(field)s %(value)r does not exist.')\n+        \"invalid\": _(\"%(model)s instance with %(field)s %(value)r does not exist.\")\n     }\n     description = _(\"Foreign Key (type determined by related field)\")\n \n-    def __init__(self, to, on_delete, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, parent_link=False, to_field=None,\n-                 db_constraint=True, **kwargs):\n+    def __init__(\n+        self,\n+        to,\n+        on_delete,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        to_field=None,\n+        db_constraint=True,\n+        **kwargs,\n+    ):\n         try:\n             to._meta.model_name\n         except AttributeError:\n             assert isinstance(to, str), (\n                 \"%s(%r) is invalid. First parameter to ForeignKey must be \"\n-                \"either a model, a model name, or the string %r\" % (\n-                    self.__class__.__name__, to,\n+                \"either a model, a model name, or the string %r\"\n+                % (\n+                    self.__class__.__name__,\n+                    to,\n                     RECURSIVE_RELATIONSHIP_CONSTANT,\n                 )\n             )\n@@ -810,17 +919,19 @@ class ForeignKey(ForeignObject):\n             # be correct until contribute_to_class is called. Refs #12190.\n             to_field = to_field or (to._meta.pk and to._meta.pk.name)\n         if not callable(on_delete):\n-            raise TypeError('on_delete must be callable.')\n+            raise TypeError(\"on_delete must be callable.\")\n \n-        kwargs['rel'] = self.rel_class(\n-            self, to, to_field,\n+        kwargs[\"rel\"] = self.rel_class(\n+            self,\n+            to,\n+            to_field,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n             parent_link=parent_link,\n             on_delete=on_delete,\n         )\n-        kwargs.setdefault('db_index', True)\n+        kwargs.setdefault(\"db_index\", True)\n \n         super().__init__(\n             to,\n@@ -839,54 +950,60 @@ class ForeignKey(ForeignObject):\n         ]\n \n     def _check_on_delete(self):\n-        on_delete = getattr(self.remote_field, 'on_delete', None)\n+        on_delete = getattr(self.remote_field, \"on_delete\", None)\n         if on_delete == SET_NULL and not self.null:\n             return [\n                 checks.Error(\n-                    'Field specifies on_delete=SET_NULL, but cannot be null.',\n-                    hint='Set null=True argument on the field, or change the on_delete rule.',\n+                    \"Field specifies on_delete=SET_NULL, but cannot be null.\",\n+                    hint=\"Set null=True argument on the field, or change the on_delete rule.\",\n                     obj=self,\n-                    id='fields.E320',\n+                    id=\"fields.E320\",\n                 )\n             ]\n         elif on_delete == SET_DEFAULT and not self.has_default():\n             return [\n                 checks.Error(\n-                    'Field specifies on_delete=SET_DEFAULT, but has no default value.',\n-                    hint='Set a default value, or change the on_delete rule.',\n+                    \"Field specifies on_delete=SET_DEFAULT, but has no default value.\",\n+                    hint=\"Set a default value, or change the on_delete rule.\",\n                     obj=self,\n-                    id='fields.E321',\n+                    id=\"fields.E321\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_unique(self, **kwargs):\n-        return [\n-            checks.Warning(\n-                'Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.',\n-                hint='ForeignKey(unique=True) is usually better served by a OneToOneField.',\n-                obj=self,\n-                id='fields.W342',\n-            )\n-        ] if self.unique else []\n+        return (\n+            [\n+                checks.Warning(\n+                    \"Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.\",\n+                    hint=\"ForeignKey(unique=True) is usually better served by a OneToOneField.\",\n+                    obj=self,\n+                    id=\"fields.W342\",\n+                )\n+            ]\n+            if self.unique\n+            else []\n+        )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['to_fields']\n-        del kwargs['from_fields']\n+        del kwargs[\"to_fields\"]\n+        del kwargs[\"from_fields\"]\n         # Handle the simpler arguments\n         if self.db_index:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         else:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         if self.db_constraint is not True:\n-            kwargs['db_constraint'] = self.db_constraint\n+            kwargs[\"db_constraint\"] = self.db_constraint\n         # Rel needs more work.\n         to_meta = getattr(self.remote_field.model, \"_meta\", None)\n         if self.remote_field.field_name and (\n-                not to_meta or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)):\n-            kwargs['to_field'] = self.remote_field.field_name\n+            not to_meta\n+            or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)\n+        ):\n+            kwargs[\"to_field\"] = self.remote_field.field_name\n         return name, path, args, kwargs\n \n     def to_python(self, value):\n@@ -900,15 +1017,17 @@ class ForeignKey(ForeignObject):\n         \"\"\"Get path from the related model to this field's model.\"\"\"\n         opts = self.model._meta\n         from_opts = self.remote_field.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=(opts.pk,),\n-            join_field=self.remote_field,\n-            m2m=not self.unique,\n-            direct=False,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=(opts.pk,),\n+                join_field=self.remote_field,\n+                m2m=not self.unique,\n+                direct=False,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     def validate(self, value, model_instance):\n         if self.remote_field.parent_link:\n@@ -924,21 +1043,27 @@ class ForeignKey(ForeignObject):\n         qs = qs.complex_filter(self.get_limit_choices_to())\n         if not qs.exists():\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n                 params={\n-                    'model': self.remote_field.model._meta.verbose_name, 'pk': value,\n-                    'field': self.remote_field.field_name, 'value': value,\n+                    \"model\": self.remote_field.model._meta.verbose_name,\n+                    \"pk\": value,\n+                    \"field\": self.remote_field.field_name,\n+                    \"value\": value,\n                 },  # 'pk' is included for backwards compatibility\n             )\n \n     def resolve_related_fields(self):\n         related_fields = super().resolve_related_fields()\n         for from_field, to_field in related_fields:\n-            if to_field and to_field.model != self.remote_field.model._meta.concrete_model:\n+            if (\n+                to_field\n+                and to_field.model != self.remote_field.model._meta.concrete_model\n+            ):\n                 raise exceptions.FieldError(\n                     \"'%s.%s' refers to field '%s' which is not local to model \"\n-                    \"'%s'.\" % (\n+                    \"'%s'.\"\n+                    % (\n                         self.model._meta.label,\n                         self.name,\n                         to_field.name,\n@@ -948,7 +1073,7 @@ class ForeignKey(ForeignObject):\n         return related_fields\n \n     def get_attname(self):\n-        return '%s_id' % self.name\n+        return \"%s_id\" % self.name\n \n     def get_attname_column(self):\n         attname = self.get_attname()\n@@ -963,9 +1088,13 @@ class ForeignKey(ForeignObject):\n         return field_default\n \n     def get_db_prep_save(self, value, connection):\n-        if value is None or (value == '' and\n-                             (not self.target_field.empty_strings_allowed or\n-                              connection.features.interprets_empty_strings_as_nulls)):\n+        if value is None or (\n+            value == \"\"\n+            and (\n+                not self.target_field.empty_strings_allowed\n+                or connection.features.interprets_empty_strings_as_nulls\n+            )\n+        ):\n             return None\n         else:\n             return self.target_field.get_db_prep_save(value, connection=connection)\n@@ -983,16 +1112,20 @@ class ForeignKey(ForeignObject):\n \n     def formfield(self, *, using=None, **kwargs):\n         if isinstance(self.remote_field.model, str):\n-            raise ValueError(\"Cannot create form field for %r yet, because \"\n-                             \"its related model %r has not been loaded yet\" %\n-                             (self.name, self.remote_field.model))\n-        return super().formfield(**{\n-            'form_class': forms.ModelChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n-            'to_field_name': self.remote_field.field_name,\n-            **kwargs,\n-            'blank': self.blank,\n-        })\n+            raise ValueError(\n+                \"Cannot create form field for %r yet, because \"\n+                \"its related model %r has not been loaded yet\"\n+                % (self.name, self.remote_field.model)\n+            )\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.ModelChoiceField,\n+                \"queryset\": self.remote_field.model._default_manager.using(using),\n+                \"to_field_name\": self.remote_field.field_name,\n+                **kwargs,\n+                \"blank\": self.blank,\n+            }\n+        )\n \n     def db_check(self, connection):\n         return []\n@@ -1020,7 +1153,7 @@ class ForeignKey(ForeignObject):\n             while isinstance(output_field, ForeignKey):\n                 output_field = output_field.target_field\n                 if output_field is self:\n-                    raise ValueError('Cannot resolve output_field.')\n+                    raise ValueError(\"Cannot resolve output_field.\")\n         return super().get_col(alias, output_field)\n \n \n@@ -1045,13 +1178,13 @@ class OneToOneField(ForeignKey):\n     description = _(\"One-to-one relationship\")\n \n     def __init__(self, to, on_delete, to_field=None, **kwargs):\n-        kwargs['unique'] = True\n+        kwargs[\"unique\"] = True\n         super().__init__(to, on_delete, to_field=to_field, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if \"unique\" in kwargs:\n-            del kwargs['unique']\n+            del kwargs[\"unique\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n@@ -1081,44 +1214,54 @@ def create_many_to_many_intermediary_model(field, klass):\n         through._meta.managed = model._meta.managed or related._meta.managed\n \n     to_model = resolve_relation(klass, field.remote_field.model)\n-    name = '%s_%s' % (klass._meta.object_name, field.name)\n+    name = \"%s_%s\" % (klass._meta.object_name, field.name)\n     lazy_related_operation(set_managed, klass, to_model, name)\n \n     to = make_model_tuple(to_model)[1]\n     from_ = klass._meta.model_name\n     if to == from_:\n-        to = 'to_%s' % to\n-        from_ = 'from_%s' % from_\n-\n-    meta = type('Meta', (), {\n-        'db_table': field._get_m2m_db_table(klass._meta),\n-        'auto_created': klass,\n-        'app_label': klass._meta.app_label,\n-        'db_tablespace': klass._meta.db_tablespace,\n-        'unique_together': (from_, to),\n-        'verbose_name': _('%(from)s-%(to)s relationship') % {'from': from_, 'to': to},\n-        'verbose_name_plural': _('%(from)s-%(to)s relationships') % {'from': from_, 'to': to},\n-        'apps': field.model._meta.apps,\n-    })\n+        to = \"to_%s\" % to\n+        from_ = \"from_%s\" % from_\n+\n+    meta = type(\n+        \"Meta\",\n+        (),\n+        {\n+            \"db_table\": field._get_m2m_db_table(klass._meta),\n+            \"auto_created\": klass,\n+            \"app_label\": klass._meta.app_label,\n+            \"db_tablespace\": klass._meta.db_tablespace,\n+            \"unique_together\": (from_, to),\n+            \"verbose_name\": _(\"%(from)s-%(to)s relationship\")\n+            % {\"from\": from_, \"to\": to},\n+            \"verbose_name_plural\": _(\"%(from)s-%(to)s relationships\")\n+            % {\"from\": from_, \"to\": to},\n+            \"apps\": field.model._meta.apps,\n+        },\n+    )\n     # Construct and return the new class.\n-    return type(name, (models.Model,), {\n-        'Meta': meta,\n-        '__module__': klass.__module__,\n-        from_: models.ForeignKey(\n-            klass,\n-            related_name='%s+' % name,\n-            db_tablespace=field.db_tablespace,\n-            db_constraint=field.remote_field.db_constraint,\n-            on_delete=CASCADE,\n-        ),\n-        to: models.ForeignKey(\n-            to_model,\n-            related_name='%s+' % name,\n-            db_tablespace=field.db_tablespace,\n-            db_constraint=field.remote_field.db_constraint,\n-            on_delete=CASCADE,\n-        )\n-    })\n+    return type(\n+        name,\n+        (models.Model,),\n+        {\n+            \"Meta\": meta,\n+            \"__module__\": klass.__module__,\n+            from_: models.ForeignKey(\n+                klass,\n+                related_name=\"%s+\" % name,\n+                db_tablespace=field.db_tablespace,\n+                db_constraint=field.remote_field.db_constraint,\n+                on_delete=CASCADE,\n+            ),\n+            to: models.ForeignKey(\n+                to_model,\n+                related_name=\"%s+\" % name,\n+                db_tablespace=field.db_tablespace,\n+                db_constraint=field.remote_field.db_constraint,\n+                on_delete=CASCADE,\n+            ),\n+        },\n+    )\n \n \n class ManyToManyField(RelatedField):\n@@ -1141,29 +1284,40 @@ class ManyToManyField(RelatedField):\n \n     description = _(\"Many-to-many relationship\")\n \n-    def __init__(self, to, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, symmetrical=None, through=None,\n-                 through_fields=None, db_constraint=True, db_table=None,\n-                 swappable=True, **kwargs):\n+    def __init__(\n+        self,\n+        to,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        symmetrical=None,\n+        through=None,\n+        through_fields=None,\n+        db_constraint=True,\n+        db_table=None,\n+        swappable=True,\n+        **kwargs,\n+    ):\n         try:\n             to._meta\n         except AttributeError:\n             assert isinstance(to, str), (\n                 \"%s(%r) is invalid. First parameter to ManyToManyField must be \"\n-                \"either a model, a model name, or the string %r\" %\n-                (self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT)\n+                \"either a model, a model name, or the string %r\"\n+                % (self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT)\n             )\n \n         if symmetrical is None:\n-            symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n+            symmetrical = to == RECURSIVE_RELATIONSHIP_CONSTANT\n \n         if through is not None:\n             assert db_table is None, (\n                 \"Cannot specify a db_table if an intermediary model is used.\"\n             )\n \n-        kwargs['rel'] = self.rel_class(\n-            self, to,\n+        kwargs[\"rel\"] = self.rel_class(\n+            self,\n+            to,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n@@ -1172,7 +1326,7 @@ class ManyToManyField(RelatedField):\n             through_fields=through_fields,\n             db_constraint=db_constraint,\n         )\n-        self.has_null_arg = 'null' in kwargs\n+        self.has_null_arg = \"null\" in kwargs\n \n         super().__init__(**kwargs)\n \n@@ -1192,9 +1346,9 @@ class ManyToManyField(RelatedField):\n         if self.unique:\n             return [\n                 checks.Error(\n-                    'ManyToManyFields cannot be unique.',\n+                    \"ManyToManyFields cannot be unique.\",\n                     obj=self,\n-                    id='fields.E330',\n+                    id=\"fields.E330\",\n                 )\n             ]\n         return []\n@@ -1205,50 +1359,57 @@ class ManyToManyField(RelatedField):\n         if self.has_null_arg:\n             warnings.append(\n                 checks.Warning(\n-                    'null has no effect on ManyToManyField.',\n+                    \"null has no effect on ManyToManyField.\",\n                     obj=self,\n-                    id='fields.W340',\n+                    id=\"fields.W340\",\n                 )\n             )\n \n         if self._validators:\n             warnings.append(\n                 checks.Warning(\n-                    'ManyToManyField does not support validators.',\n+                    \"ManyToManyField does not support validators.\",\n                     obj=self,\n-                    id='fields.W341',\n+                    id=\"fields.W341\",\n                 )\n             )\n-        if (self.remote_field.limit_choices_to and self.remote_field.through and\n-                not self.remote_field.through._meta.auto_created):\n+        if (\n+            self.remote_field.limit_choices_to\n+            and self.remote_field.through\n+            and not self.remote_field.through._meta.auto_created\n+        ):\n             warnings.append(\n                 checks.Warning(\n-                    'limit_choices_to has no effect on ManyToManyField '\n-                    'with a through model.',\n+                    \"limit_choices_to has no effect on ManyToManyField \"\n+                    \"with a through model.\",\n                     obj=self,\n-                    id='fields.W343',\n+                    id=\"fields.W343\",\n                 )\n             )\n \n         return warnings\n \n     def _check_relationship_model(self, from_model=None, **kwargs):\n-        if hasattr(self.remote_field.through, '_meta'):\n+        if hasattr(self.remote_field.through, \"_meta\"):\n             qualified_model_name = \"%s.%s\" % (\n-                self.remote_field.through._meta.app_label, self.remote_field.through.__name__)\n+                self.remote_field.through._meta.app_label,\n+                self.remote_field.through.__name__,\n+            )\n         else:\n             qualified_model_name = self.remote_field.through\n \n         errors = []\n \n-        if self.remote_field.through not in self.opts.apps.get_models(include_auto_created=True):\n+        if self.remote_field.through not in self.opts.apps.get_models(\n+            include_auto_created=True\n+        ):\n             # The relationship model is not installed.\n             errors.append(\n                 checks.Error(\n                     \"Field specifies a many-to-many relation through model \"\n                     \"'%s', which has not been installed.\" % qualified_model_name,\n                     obj=self,\n-                    id='fields.E331',\n+                    id=\"fields.E331\",\n                 )\n             )\n \n@@ -1270,7 +1431,7 @@ class ManyToManyField(RelatedField):\n             # Count foreign keys in intermediate model\n             if self_referential:\n                 seen_self = sum(\n-                    from_model == getattr(field.remote_field, 'model', None)\n+                    from_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n \n@@ -1281,41 +1442,46 @@ class ManyToManyField(RelatedField):\n                             \"'%s', but it has more than two foreign keys \"\n                             \"to '%s', which is ambiguous. You must specify \"\n                             \"which two foreign keys Django should use via the \"\n-                            \"through_fields keyword argument.\" % (self, from_model_name),\n+                            \"through_fields keyword argument.\"\n+                            % (self, from_model_name),\n                             hint=\"Use through_fields to specify which two foreign keys Django should use.\",\n                             obj=self.remote_field.through,\n-                            id='fields.E333',\n+                            id=\"fields.E333\",\n                         )\n                     )\n \n             else:\n                 # Count foreign keys in relationship model\n                 seen_from = sum(\n-                    from_model == getattr(field.remote_field, 'model', None)\n+                    from_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n                 seen_to = sum(\n-                    to_model == getattr(field.remote_field, 'model', None)\n+                    to_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n \n                 if seen_from > 1 and not self.remote_field.through_fields:\n                     errors.append(\n                         checks.Error(\n-                            (\"The model is used as an intermediate model by \"\n-                             \"'%s', but it has more than one foreign key \"\n-                             \"from '%s', which is ambiguous. You must specify \"\n-                             \"which foreign key Django should use via the \"\n-                             \"through_fields keyword argument.\") % (self, from_model_name),\n+                            (\n+                                \"The model is used as an intermediate model by \"\n+                                \"'%s', but it has more than one foreign key \"\n+                                \"from '%s', which is ambiguous. You must specify \"\n+                                \"which foreign key Django should use via the \"\n+                                \"through_fields keyword argument.\"\n+                            )\n+                            % (self, from_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n-                            ) % (\n+                                \"If you want to create a recursive relationship, \"\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n+                            )\n+                            % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n                             ),\n                             obj=self,\n-                            id='fields.E334',\n+                            id=\"fields.E334\",\n                         )\n                     )\n \n@@ -1328,14 +1494,15 @@ class ManyToManyField(RelatedField):\n                             \"which foreign key Django should use via the \"\n                             \"through_fields keyword argument.\" % (self, to_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n-                            ) % (\n+                                \"If you want to create a recursive relationship, \"\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n+                            )\n+                            % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n                             ),\n                             obj=self,\n-                            id='fields.E335',\n+                            id=\"fields.E335\",\n                         )\n                     )\n \n@@ -1343,11 +1510,10 @@ class ManyToManyField(RelatedField):\n                     errors.append(\n                         checks.Error(\n                             \"The model is used as an intermediate model by \"\n-                            \"'%s', but it does not have a foreign key to '%s' or '%s'.\" % (\n-                                self, from_model_name, to_model_name\n-                            ),\n+                            \"'%s', but it does not have a foreign key to '%s' or '%s'.\"\n+                            % (self, from_model_name, to_model_name),\n                             obj=self.remote_field.through,\n-                            id='fields.E336',\n+                            id=\"fields.E336\",\n                         )\n                     )\n \n@@ -1355,8 +1521,11 @@ class ManyToManyField(RelatedField):\n         if self.remote_field.through_fields is not None:\n             # Validate that we're given an iterable of at least two items\n             # and that none of them is \"falsy\".\n-            if not (len(self.remote_field.through_fields) >= 2 and\n-                    self.remote_field.through_fields[0] and self.remote_field.through_fields[1]):\n+            if not (\n+                len(self.remote_field.through_fields) >= 2\n+                and self.remote_field.through_fields[0]\n+                and self.remote_field.through_fields[1]\n+            ):\n                 errors.append(\n                     checks.Error(\n                         \"Field specifies 'through_fields' but does not provide \"\n@@ -1364,7 +1533,7 @@ class ManyToManyField(RelatedField):\n                         \"for the relation through model '%s'.\" % qualified_model_name,\n                         hint=\"Make sure you specify 'through_fields' as through_fields=('field1', 'field2')\",\n                         obj=self,\n-                        id='fields.E337',\n+                        id=\"fields.E337\",\n                     )\n                 )\n \n@@ -1378,20 +1547,33 @@ class ManyToManyField(RelatedField):\n                     \"where the field is attached to.\"\n                 )\n \n-                source, through, target = from_model, self.remote_field.through, self.remote_field.model\n-                source_field_name, target_field_name = self.remote_field.through_fields[:2]\n-\n-                for field_name, related_model in ((source_field_name, source),\n-                                                  (target_field_name, target)):\n-\n+                source, through, target = (\n+                    from_model,\n+                    self.remote_field.through,\n+                    self.remote_field.model,\n+                )\n+                source_field_name, target_field_name = self.remote_field.through_fields[\n+                    :2\n+                ]\n+\n+                for field_name, related_model in (\n+                    (source_field_name, source),\n+                    (target_field_name, target),\n+                ):\n                     possible_field_names = []\n                     for f in through._meta.fields:\n-                        if hasattr(f, 'remote_field') and getattr(f.remote_field, 'model', None) == related_model:\n+                        if (\n+                            hasattr(f, \"remote_field\")\n+                            and getattr(f.remote_field, \"model\", None) == related_model\n+                        ):\n                             possible_field_names.append(f.name)\n                     if possible_field_names:\n-                        hint = \"Did you mean one of the following foreign keys to '%s': %s?\" % (\n-                            related_model._meta.object_name,\n-                            ', '.join(possible_field_names),\n+                        hint = (\n+                            \"Did you mean one of the following foreign keys to '%s': %s?\"\n+                            % (\n+                                related_model._meta.object_name,\n+                                \", \".join(possible_field_names),\n+                            )\n                         )\n                     else:\n                         hint = None\n@@ -1405,28 +1587,36 @@ class ManyToManyField(RelatedField):\n                                 % (qualified_model_name, field_name),\n                                 hint=hint,\n                                 obj=self,\n-                                id='fields.E338',\n+                                id=\"fields.E338\",\n                             )\n                         )\n                     else:\n-                        if not (hasattr(field, 'remote_field') and\n-                                getattr(field.remote_field, 'model', None) == related_model):\n+                        if not (\n+                            hasattr(field, \"remote_field\")\n+                            and getattr(field.remote_field, \"model\", None)\n+                            == related_model\n+                        ):\n                             errors.append(\n                                 checks.Error(\n-                                    \"'%s.%s' is not a foreign key to '%s'.\" % (\n-                                        through._meta.object_name, field_name,\n+                                    \"'%s.%s' is not a foreign key to '%s'.\"\n+                                    % (\n+                                        through._meta.object_name,\n+                                        field_name,\n                                         related_model._meta.object_name,\n                                     ),\n                                     hint=hint,\n                                     obj=self,\n-                                    id='fields.E339',\n+                                    id=\"fields.E339\",\n                                 )\n                             )\n \n         return errors\n \n     def _check_table_uniqueness(self, **kwargs):\n-        if isinstance(self.remote_field.through, str) or not self.remote_field.through._meta.managed:\n+        if (\n+            isinstance(self.remote_field.through, str)\n+            or not self.remote_field.through._meta.managed\n+        ):\n             return []\n         registered_tables = {\n             model._meta.db_table: model\n@@ -1437,25 +1627,31 @@ class ManyToManyField(RelatedField):\n         model = registered_tables.get(m2m_db_table)\n         # The second condition allows multiple m2m relations on a model if\n         # some point to a through model that proxies another through model.\n-        if model and model._meta.concrete_model != self.remote_field.through._meta.concrete_model:\n+        if (\n+            model\n+            and model._meta.concrete_model\n+            != self.remote_field.through._meta.concrete_model\n+        ):\n             if model._meta.auto_created:\n+\n                 def _get_field_name(model):\n                     for field in model._meta.auto_created._meta.many_to_many:\n                         if field.remote_field.through is model:\n                             return field.name\n+\n                 opts = model._meta.auto_created._meta\n-                clashing_obj = '%s.%s' % (opts.label, _get_field_name(model))\n+                clashing_obj = \"%s.%s\" % (opts.label, _get_field_name(model))\n             else:\n                 clashing_obj = model._meta.label\n             if settings.DATABASE_ROUTERS:\n-                error_class, error_id = checks.Warning, 'fields.W344'\n+                error_class, error_id = checks.Warning, \"fields.W344\"\n                 error_hint = (\n-                    'You have configured settings.DATABASE_ROUTERS. Verify '\n-                    'that the table of %r is correctly routed to a separate '\n-                    'database.' % clashing_obj\n+                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n+                    \"that the table of %r is correctly routed to a separate \"\n+                    \"database.\" % clashing_obj\n                 )\n             else:\n-                error_class, error_id = checks.Error, 'fields.E340'\n+                error_class, error_id = checks.Error, \"fields.E340\"\n                 error_hint = None\n             return [\n                 error_class(\n@@ -1472,22 +1668,22 @@ class ManyToManyField(RelatedField):\n         name, path, args, kwargs = super().deconstruct()\n         # Handle the simpler arguments.\n         if self.db_table is not None:\n-            kwargs['db_table'] = self.db_table\n+            kwargs[\"db_table\"] = self.db_table\n         if self.remote_field.db_constraint is not True:\n-            kwargs['db_constraint'] = self.remote_field.db_constraint\n+            kwargs[\"db_constraint\"] = self.remote_field.db_constraint\n         # Rel needs more work.\n         if isinstance(self.remote_field.model, str):\n-            kwargs['to'] = self.remote_field.model\n+            kwargs[\"to\"] = self.remote_field.model\n         else:\n-            kwargs['to'] = \"%s.%s\" % (\n+            kwargs[\"to\"] = \"%s.%s\" % (\n                 self.remote_field.model._meta.app_label,\n                 self.remote_field.model._meta.object_name,\n             )\n-        if getattr(self.remote_field, 'through', None) is not None:\n+        if getattr(self.remote_field, \"through\", None) is not None:\n             if isinstance(self.remote_field.through, str):\n-                kwargs['through'] = self.remote_field.through\n+                kwargs[\"through\"] = self.remote_field.through\n             elif not self.remote_field.through._meta.auto_created:\n-                kwargs['through'] = \"%s.%s\" % (\n+                kwargs[\"through\"] = \"%s.%s\" % (\n                     self.remote_field.through._meta.app_label,\n                     self.remote_field.through._meta.object_name,\n                 )\n@@ -1496,16 +1692,16 @@ class ManyToManyField(RelatedField):\n         swappable_setting = self.swappable_setting\n         if swappable_setting is not None:\n             # If it's already a settings reference, error.\n-            if hasattr(kwargs['to'], \"setting_name\"):\n-                if kwargs['to'].setting_name != swappable_setting:\n+            if hasattr(kwargs[\"to\"], \"setting_name\"):\n+                if kwargs[\"to\"].setting_name != swappable_setting:\n                     raise ValueError(\n                         \"Cannot deconstruct a ManyToManyField pointing to a \"\n                         \"model that is swapped in place of more than one model \"\n-                        \"(%s and %s)\" % (kwargs['to'].setting_name, swappable_setting)\n+                        \"(%s and %s)\" % (kwargs[\"to\"].setting_name, swappable_setting)\n                     )\n \n-            kwargs['to'] = SettingsReference(\n-                kwargs['to'],\n+            kwargs[\"to\"] = SettingsReference(\n+                kwargs[\"to\"],\n                 swappable_setting,\n             )\n         return name, path, args, kwargs\n@@ -1552,7 +1748,7 @@ class ManyToManyField(RelatedField):\n         elif self.db_table:\n             return self.db_table\n         else:\n-            m2m_table_name = '%s_%s' % (utils.strip_quotes(opts.db_table), self.name)\n+            m2m_table_name = \"%s_%s\" % (utils.strip_quotes(opts.db_table), self.name)\n             return utils.truncate_name(m2m_table_name, connection.ops.max_name_length())\n \n     def _get_m2m_attr(self, related, attr):\n@@ -1560,7 +1756,7 @@ class ManyToManyField(RelatedField):\n         Function that can be curried to provide the source accessor or DB\n         column name for the m2m table.\n         \"\"\"\n-        cache_attr = '_m2m_%s_cache' % attr\n+        cache_attr = \"_m2m_%s_cache\" % attr\n         if hasattr(self, cache_attr):\n             return getattr(self, cache_attr)\n         if self.remote_field.through_fields is not None:\n@@ -1568,8 +1764,11 @@ class ManyToManyField(RelatedField):\n         else:\n             link_field_name = None\n         for f in self.remote_field.through._meta.fields:\n-            if (f.is_relation and f.remote_field.model == related.related_model and\n-                    (link_field_name is None or link_field_name == f.name)):\n+            if (\n+                f.is_relation\n+                and f.remote_field.model == related.related_model\n+                and (link_field_name is None or link_field_name == f.name)\n+            ):\n                 setattr(self, cache_attr, getattr(f, attr))\n                 return getattr(self, cache_attr)\n \n@@ -1578,7 +1777,7 @@ class ManyToManyField(RelatedField):\n         Function that can be curried to provide the related accessor or DB\n         column name for the m2m table.\n         \"\"\"\n-        cache_attr = '_m2m_reverse_%s_cache' % attr\n+        cache_attr = \"_m2m_reverse_%s_cache\" % attr\n         if hasattr(self, cache_attr):\n             return getattr(self, cache_attr)\n         found = False\n@@ -1611,8 +1810,8 @@ class ManyToManyField(RelatedField):\n         # automatically. The funky name reduces the chance of an accidental\n         # clash.\n         if self.remote_field.symmetrical and (\n-            self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT or\n-            self.remote_field.model == cls._meta.object_name\n+            self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT\n+            or self.remote_field.model == cls._meta.object_name\n         ):\n             self.remote_field.related_name = \"%s_rel_+\" % name\n         elif self.remote_field.is_hidden():\n@@ -1630,11 +1829,17 @@ class ManyToManyField(RelatedField):\n         #  3) The class owning the m2m field has been swapped out.\n         if not cls._meta.abstract:\n             if self.remote_field.through:\n+\n                 def resolve_through_model(_, model, field):\n                     field.remote_field.through = model\n-                lazy_related_operation(resolve_through_model, cls, self.remote_field.through, field=self)\n+\n+                lazy_related_operation(\n+                    resolve_through_model, cls, self.remote_field.through, field=self\n+                )\n             elif not cls._meta.swapped:\n-                self.remote_field.through = create_many_to_many_intermediary_model(self, cls)\n+                self.remote_field.through = create_many_to_many_intermediary_model(\n+                    self, cls\n+                )\n \n         # Add the descriptor for the m2m relation.\n         setattr(cls, self.name, ManyToManyDescriptor(self.remote_field, reverse=False))\n@@ -1645,19 +1850,30 @@ class ManyToManyField(RelatedField):\n     def contribute_to_related_class(self, cls, related):\n         # Internal M2Ms (i.e., those with a related name ending with '+')\n         # and swapped models don't get a related descriptor.\n-        if not self.remote_field.is_hidden() and not related.related_model._meta.swapped:\n-            setattr(cls, related.get_accessor_name(), ManyToManyDescriptor(self.remote_field, reverse=True))\n+        if (\n+            not self.remote_field.is_hidden()\n+            and not related.related_model._meta.swapped\n+        ):\n+            setattr(\n+                cls,\n+                related.get_accessor_name(),\n+                ManyToManyDescriptor(self.remote_field, reverse=True),\n+            )\n \n         # Set up the accessors for the column names on the m2m table.\n-        self.m2m_column_name = partial(self._get_m2m_attr, related, 'column')\n-        self.m2m_reverse_name = partial(self._get_m2m_reverse_attr, related, 'column')\n+        self.m2m_column_name = partial(self._get_m2m_attr, related, \"column\")\n+        self.m2m_reverse_name = partial(self._get_m2m_reverse_attr, related, \"column\")\n \n-        self.m2m_field_name = partial(self._get_m2m_attr, related, 'name')\n-        self.m2m_reverse_field_name = partial(self._get_m2m_reverse_attr, related, 'name')\n+        self.m2m_field_name = partial(self._get_m2m_attr, related, \"name\")\n+        self.m2m_reverse_field_name = partial(\n+            self._get_m2m_reverse_attr, related, \"name\"\n+        )\n \n-        get_m2m_rel = partial(self._get_m2m_attr, related, 'remote_field')\n+        get_m2m_rel = partial(self._get_m2m_attr, related, \"remote_field\")\n         self.m2m_target_field_name = lambda: get_m2m_rel().field_name\n-        get_m2m_reverse_rel = partial(self._get_m2m_reverse_attr, related, 'remote_field')\n+        get_m2m_reverse_rel = partial(\n+            self._get_m2m_reverse_attr, related, \"remote_field\"\n+        )\n         self.m2m_reverse_target_field_name = lambda: get_m2m_reverse_rel().field_name\n \n     def set_attributes_from_rel(self):\n@@ -1671,17 +1887,17 @@ class ManyToManyField(RelatedField):\n \n     def formfield(self, *, using=None, **kwargs):\n         defaults = {\n-            'form_class': forms.ModelMultipleChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n+            \"form_class\": forms.ModelMultipleChoiceField,\n+            \"queryset\": self.remote_field.model._default_manager.using(using),\n             **kwargs,\n         }\n         # If initial is passed in, it's a list of related objects, but the\n         # MultipleChoiceField takes a list of IDs.\n-        if defaults.get('initial') is not None:\n-            initial = defaults['initial']\n+        if defaults.get(\"initial\") is not None:\n+            initial = defaults[\"initial\"]\n             if callable(initial):\n                 initial = initial()\n-            defaults['initial'] = [i.pk for i in initial]\n+            defaults[\"initial\"] = [i.pk for i in initial]\n         return super().formfield(**defaults)\n \n     def db_check(self, connection):\n"}
{"instance_id": "django__django-12589", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": ""}
{"instance_id": "django__django-12700", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex e6b7d4d821..12cbe9c5db 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -22,7 +22,7 @@ from django.utils.version import get_docs_version\n # works even if the template loader is broken.\n DEBUG_ENGINE = Engine(\n     debug=True,\n-    libraries={'i18n': 'django.templatetags.i18n'},\n+    libraries={\"i18n\": \"django.templatetags.i18n\"},\n )\n \n CURRENT_DIR = Path(__file__).parent\n@@ -35,6 +35,7 @@ class CallableSettingWrapper:\n     * Not to break the debug page if the callable forbidding to set attributes\n       (#23070).\n     \"\"\"\n+\n     def __init__(self, callable_setting):\n         self._wrapped = callable_setting\n \n@@ -48,12 +49,14 @@ def technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n     the values returned from sys.exc_info() and friends.\n     \"\"\"\n     reporter = get_exception_reporter_class(request)(request, exc_type, exc_value, tb)\n-    if request.accepts('text/html'):\n+    if request.accepts(\"text/html\"):\n         html = reporter.get_traceback_html()\n-        return HttpResponse(html, status=status_code, content_type='text/html')\n+        return HttpResponse(html, status=status_code, content_type=\"text/html\")\n     else:\n         text = reporter.get_traceback_text()\n-        return HttpResponse(text, status=status_code, content_type='text/plain; charset=utf-8')\n+        return HttpResponse(\n+            text, status=status_code, content_type=\"text/plain; charset=utf-8\"\n+        )\n \n \n @functools.lru_cache()\n@@ -64,12 +67,16 @@ def get_default_exception_reporter_filter():\n \n def get_exception_reporter_filter(request):\n     default_filter = get_default_exception_reporter_filter()\n-    return getattr(request, 'exception_reporter_filter', default_filter)\n+    return getattr(request, \"exception_reporter_filter\", default_filter)\n \n \n def get_exception_reporter_class(request):\n-    default_exception_reporter_class = import_string(settings.DEFAULT_EXCEPTION_REPORTER)\n-    return getattr(request, 'exception_reporter_class', default_exception_reporter_class)\n+    default_exception_reporter_class = import_string(\n+        settings.DEFAULT_EXCEPTION_REPORTER\n+    )\n+    return getattr(\n+        request, \"exception_reporter_class\", default_exception_reporter_class\n+    )\n \n \n class SafeExceptionReporterFilter:\n@@ -77,8 +84,11 @@ class SafeExceptionReporterFilter:\n     Use annotations made by the sensitive_post_parameters and\n     sensitive_variables decorators to filter out sensitive information.\n     \"\"\"\n-    cleansed_substitute = '********************'\n-    hidden_settings = _lazy_re_compile('API|TOKEN|KEY|SECRET|PASS|SIGNATURE', flags=re.I)\n+\n+    cleansed_substitute = \"********************\"\n+    hidden_settings = _lazy_re_compile(\n+        \"API|TOKEN|KEY|SECRET|PASS|SIGNATURE\", flags=re.I\n+    )\n \n     def cleanse_setting(self, key, value):\n         \"\"\"\n@@ -90,6 +100,10 @@ class SafeExceptionReporterFilter:\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple, set, frozenset)):\n+                cleansed = type(value)(\n+                    self.cleanse_setting(key, item) for item in value\n+                )\n             else:\n                 cleansed = value\n         except TypeError:\n@@ -116,7 +130,7 @@ class SafeExceptionReporterFilter:\n         \"\"\"\n         Return a dictionary of request.META with sensitive values redacted.\n         \"\"\"\n-        if not hasattr(request, 'META'):\n+        if not hasattr(request, \"META\"):\n             return {}\n         return {k: self.cleanse_setting(k, v) for k, v in request.META.items()}\n \n@@ -135,7 +149,7 @@ class SafeExceptionReporterFilter:\n         This mitigates leaking sensitive POST parameters if something like\n         request.POST['nonexistent_key'] throws an exception (#21098).\n         \"\"\"\n-        sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n+        sensitive_post_parameters = getattr(request, \"sensitive_post_parameters\", [])\n         if self.is_active(request) and sensitive_post_parameters:\n             multivaluedict = multivaluedict.copy()\n             for param in sensitive_post_parameters:\n@@ -151,10 +165,12 @@ class SafeExceptionReporterFilter:\n         if request is None:\n             return {}\n         else:\n-            sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n+            sensitive_post_parameters = getattr(\n+                request, \"sensitive_post_parameters\", []\n+            )\n             if self.is_active(request) and sensitive_post_parameters:\n                 cleansed = request.POST.copy()\n-                if sensitive_post_parameters == '__ALL__':\n+                if sensitive_post_parameters == \"__ALL__\":\n                     # Cleanse all parameters.\n                     for k in cleansed:\n                         cleansed[k] = self.cleansed_substitute\n@@ -175,7 +191,7 @@ class SafeExceptionReporterFilter:\n             # MultiValueDicts will have a return value.\n             is_multivalue_dict = isinstance(value, MultiValueDict)\n         except Exception as e:\n-            return '{!r} while evaluating {!r}'.format(e, value)\n+            return \"{!r} while evaluating {!r}\".format(e, value)\n \n         if is_multivalue_dict:\n             # Cleanse MultiValueDicts (request.POST is the one we usually care about)\n@@ -192,18 +208,20 @@ class SafeExceptionReporterFilter:\n         current_frame = tb_frame.f_back\n         sensitive_variables = None\n         while current_frame is not None:\n-            if (current_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n-                    'sensitive_variables_wrapper' in current_frame.f_locals):\n+            if (\n+                current_frame.f_code.co_name == \"sensitive_variables_wrapper\"\n+                and \"sensitive_variables_wrapper\" in current_frame.f_locals\n+            ):\n                 # The sensitive_variables decorator was used, so we take note\n                 # of the sensitive variables' names.\n-                wrapper = current_frame.f_locals['sensitive_variables_wrapper']\n-                sensitive_variables = getattr(wrapper, 'sensitive_variables', None)\n+                wrapper = current_frame.f_locals[\"sensitive_variables_wrapper\"]\n+                sensitive_variables = getattr(wrapper, \"sensitive_variables\", None)\n                 break\n             current_frame = current_frame.f_back\n \n         cleansed = {}\n         if self.is_active(request) and sensitive_variables:\n-            if sensitive_variables == '__ALL__':\n+            if sensitive_variables == \"__ALL__\":\n                 # Cleanse all variables\n                 for name in tb_frame.f_locals:\n                     cleansed[name] = self.cleansed_substitute\n@@ -221,20 +239,23 @@ class SafeExceptionReporterFilter:\n             for name, value in tb_frame.f_locals.items():\n                 cleansed[name] = self.cleanse_special_types(request, value)\n \n-        if (tb_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n-                'sensitive_variables_wrapper' in tb_frame.f_locals):\n+        if (\n+            tb_frame.f_code.co_name == \"sensitive_variables_wrapper\"\n+            and \"sensitive_variables_wrapper\" in tb_frame.f_locals\n+        ):\n             # For good measure, obfuscate the decorated function's arguments in\n             # the sensitive_variables decorator's frame, in case the variables\n             # associated with those arguments were meant to be obfuscated from\n             # the decorated function's frame.\n-            cleansed['func_args'] = self.cleansed_substitute\n-            cleansed['func_kwargs'] = self.cleansed_substitute\n+            cleansed[\"func_args\"] = self.cleansed_substitute\n+            cleansed[\"func_kwargs\"] = self.cleansed_substitute\n \n         return cleansed.items()\n \n \n class ExceptionReporter:\n     \"\"\"Organize and coordinate reporting on exceptions.\"\"\"\n+\n     def __init__(self, request, exc_type, exc_value, tb, is_email=False):\n         self.request = request\n         self.filter = get_exception_reporter_filter(self.request)\n@@ -243,7 +264,7 @@ class ExceptionReporter:\n         self.tb = tb\n         self.is_email = is_email\n \n-        self.template_info = getattr(self.exc_value, 'template_debug', None)\n+        self.template_info = getattr(self.exc_value, \"template_debug\", None)\n         self.template_does_not_exist = False\n         self.postmortem = None\n \n@@ -255,26 +276,27 @@ class ExceptionReporter:\n \n         frames = self.get_traceback_frames()\n         for i, frame in enumerate(frames):\n-            if 'vars' in frame:\n+            if \"vars\" in frame:\n                 frame_vars = []\n-                for k, v in frame['vars']:\n+                for k, v in frame[\"vars\"]:\n                     v = pprint(v)\n                     # Trim large blobs of data\n                     if len(v) > 4096:\n-                        v = '%s\u2026 <trimmed %d bytes string>' % (v[0:4096], len(v))\n+                        v = \"%s\u2026 <trimmed %d bytes string>\" % (v[0:4096], len(v))\n                     frame_vars.append((k, v))\n-                frame['vars'] = frame_vars\n+                frame[\"vars\"] = frame_vars\n             frames[i] = frame\n \n-        unicode_hint = ''\n+        unicode_hint = \"\"\n         if self.exc_type and issubclass(self.exc_type, UnicodeError):\n-            start = getattr(self.exc_value, 'start', None)\n-            end = getattr(self.exc_value, 'end', None)\n+            start = getattr(self.exc_value, \"start\", None)\n+            end = getattr(self.exc_value, \"end\", None)\n             if start is not None and end is not None:\n                 unicode_str = self.exc_value.args[1]\n                 unicode_hint = force_str(\n-                    unicode_str[max(start - 5, 0):min(end + 5, len(unicode_str))],\n-                    'ascii', errors='replace'\n+                    unicode_str[max(start - 5, 0) : min(end + 5, len(unicode_str))],\n+                    \"ascii\",\n+                    errors=\"replace\",\n                 )\n         from django import get_version\n \n@@ -286,56 +308,62 @@ class ExceptionReporter:\n             except Exception:\n                 # request.user may raise OperationalError if the database is\n                 # unavailable, for example.\n-                user_str = '[unable to retrieve the current user]'\n+                user_str = \"[unable to retrieve the current user]\"\n \n         c = {\n-            'is_email': self.is_email,\n-            'unicode_hint': unicode_hint,\n-            'frames': frames,\n-            'request': self.request,\n-            'request_meta': self.filter.get_safe_request_meta(self.request),\n-            'user_str': user_str,\n-            'filtered_POST_items': list(self.filter.get_post_parameters(self.request).items()),\n-            'settings': self.filter.get_safe_settings(),\n-            'sys_executable': sys.executable,\n-            'sys_version_info': '%d.%d.%d' % sys.version_info[0:3],\n-            'server_time': timezone.now(),\n-            'django_version_info': get_version(),\n-            'sys_path': sys.path,\n-            'template_info': self.template_info,\n-            'template_does_not_exist': self.template_does_not_exist,\n-            'postmortem': self.postmortem,\n+            \"is_email\": self.is_email,\n+            \"unicode_hint\": unicode_hint,\n+            \"frames\": frames,\n+            \"request\": self.request,\n+            \"request_meta\": self.filter.get_safe_request_meta(self.request),\n+            \"user_str\": user_str,\n+            \"filtered_POST_items\": list(\n+                self.filter.get_post_parameters(self.request).items()\n+            ),\n+            \"settings\": self.filter.get_safe_settings(),\n+            \"sys_executable\": sys.executable,\n+            \"sys_version_info\": \"%d.%d.%d\" % sys.version_info[0:3],\n+            \"server_time\": timezone.now(),\n+            \"django_version_info\": get_version(),\n+            \"sys_path\": sys.path,\n+            \"template_info\": self.template_info,\n+            \"template_does_not_exist\": self.template_does_not_exist,\n+            \"postmortem\": self.postmortem,\n         }\n         if self.request is not None:\n-            c['request_GET_items'] = self.request.GET.items()\n-            c['request_FILES_items'] = self.request.FILES.items()\n-            c['request_COOKIES_items'] = self.request.COOKIES.items()\n+            c[\"request_GET_items\"] = self.request.GET.items()\n+            c[\"request_FILES_items\"] = self.request.FILES.items()\n+            c[\"request_COOKIES_items\"] = self.request.COOKIES.items()\n         # Check whether exception info is available\n         if self.exc_type:\n-            c['exception_type'] = self.exc_type.__name__\n+            c[\"exception_type\"] = self.exc_type.__name__\n         if self.exc_value:\n-            c['exception_value'] = str(self.exc_value)\n+            c[\"exception_value\"] = str(self.exc_value)\n         if frames:\n-            c['lastframe'] = frames[-1]\n+            c[\"lastframe\"] = frames[-1]\n         return c\n \n     def get_traceback_html(self):\n         \"\"\"Return HTML version of debug 500 HTTP error page.\"\"\"\n-        with Path(CURRENT_DIR, 'templates', 'technical_500.html').open(encoding='utf-8') as fh:\n+        with Path(CURRENT_DIR, \"templates\", \"technical_500.html\").open(\n+            encoding=\"utf-8\"\n+        ) as fh:\n             t = DEBUG_ENGINE.from_string(fh.read())\n         c = Context(self.get_traceback_data(), use_l10n=False)\n         return t.render(c)\n \n     def get_traceback_text(self):\n         \"\"\"Return plain text version of debug 500 HTTP error page.\"\"\"\n-        with Path(CURRENT_DIR, 'templates', 'technical_500.txt').open(encoding='utf-8') as fh:\n+        with Path(CURRENT_DIR, \"templates\", \"technical_500.txt\").open(\n+            encoding=\"utf-8\"\n+        ) as fh:\n             t = DEBUG_ENGINE.from_string(fh.read())\n         c = Context(self.get_traceback_data(), autoescape=False, use_l10n=False)\n         return t.render(c)\n \n     def _get_source(self, filename, loader, module_name):\n         source = None\n-        if hasattr(loader, 'get_source'):\n+        if hasattr(loader, \"get_source\"):\n             try:\n                 source = loader.get_source(module_name)\n             except ImportError:\n@@ -344,13 +372,15 @@ class ExceptionReporter:\n                 source = source.splitlines()\n         if source is None:\n             try:\n-                with open(filename, 'rb') as fp:\n+                with open(filename, \"rb\") as fp:\n                     source = fp.read().splitlines()\n             except OSError:\n                 pass\n         return source\n \n-    def _get_lines_from_file(self, filename, lineno, context_lines, loader=None, module_name=None):\n+    def _get_lines_from_file(\n+        self, filename, lineno, context_lines, loader=None, module_name=None\n+    ):\n         \"\"\"\n         Return context_lines before and after lineno from file.\n         Return (pre_context_lineno, pre_context, context_line, post_context).\n@@ -363,15 +393,15 @@ class ExceptionReporter:\n         # apply tokenize.detect_encoding to decode the source into a\n         # string, then we should do that ourselves.\n         if isinstance(source[0], bytes):\n-            encoding = 'ascii'\n+            encoding = \"ascii\"\n             for line in source[:2]:\n                 # File coding may be specified. Match pattern from PEP-263\n                 # (https://www.python.org/dev/peps/pep-0263/)\n-                match = re.search(br'coding[:=]\\s*([-\\w.]+)', line)\n+                match = re.search(rb\"coding[:=]\\s*([-\\w.]+)\", line)\n                 if match:\n-                    encoding = match.group(1).decode('ascii')\n+                    encoding = match.group(1).decode(\"ascii\")\n                     break\n-            source = [str(sline, encoding, 'replace') for sline in source]\n+            source = [str(sline, encoding, \"replace\") for sline in source]\n \n         lower_bound = max(0, lineno - context_lines)\n         upper_bound = lineno + context_lines\n@@ -379,15 +409,15 @@ class ExceptionReporter:\n         try:\n             pre_context = source[lower_bound:lineno]\n             context_line = source[lineno]\n-            post_context = source[lineno + 1:upper_bound]\n+            post_context = source[lineno + 1 : upper_bound]\n         except IndexError:\n             return None, [], None, []\n         return lower_bound, pre_context, context_line, post_context\n \n     def get_traceback_frames(self):\n         def explicit_or_implicit_cause(exc_value):\n-            explicit = getattr(exc_value, '__cause__', None)\n-            implicit = getattr(exc_value, '__context__', None)\n+            explicit = getattr(exc_value, \"__cause__\", None)\n+            implicit = getattr(exc_value, \"__context__\", None)\n             return explicit or implicit\n \n         # Get the exception and all its causes\n@@ -412,37 +442,47 @@ class ExceptionReporter:\n         while tb is not None:\n             # Support for __traceback_hide__ which is used by a few libraries\n             # to hide internal frames.\n-            if tb.tb_frame.f_locals.get('__traceback_hide__'):\n+            if tb.tb_frame.f_locals.get(\"__traceback_hide__\"):\n                 tb = tb.tb_next\n                 continue\n             filename = tb.tb_frame.f_code.co_filename\n             function = tb.tb_frame.f_code.co_name\n             lineno = tb.tb_lineno - 1\n-            loader = tb.tb_frame.f_globals.get('__loader__')\n-            module_name = tb.tb_frame.f_globals.get('__name__') or ''\n-            pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file(\n-                filename, lineno, 7, loader, module_name,\n+            loader = tb.tb_frame.f_globals.get(\"__loader__\")\n+            module_name = tb.tb_frame.f_globals.get(\"__name__\") or \"\"\n+            pre_context_lineno, pre_context, context_line, post_context = (\n+                self._get_lines_from_file(\n+                    filename,\n+                    lineno,\n+                    7,\n+                    loader,\n+                    module_name,\n+                )\n             )\n             if pre_context_lineno is None:\n                 pre_context_lineno = lineno\n                 pre_context = []\n-                context_line = '<source code not available>'\n+                context_line = \"<source code not available>\"\n                 post_context = []\n-            frames.append({\n-                'exc_cause': explicit_or_implicit_cause(exc_value),\n-                'exc_cause_explicit': getattr(exc_value, '__cause__', True),\n-                'tb': tb,\n-                'type': 'django' if module_name.startswith('django.') else 'user',\n-                'filename': filename,\n-                'function': function,\n-                'lineno': lineno + 1,\n-                'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame),\n-                'id': id(tb),\n-                'pre_context': pre_context,\n-                'context_line': context_line,\n-                'post_context': post_context,\n-                'pre_context_lineno': pre_context_lineno + 1,\n-            })\n+            frames.append(\n+                {\n+                    \"exc_cause\": explicit_or_implicit_cause(exc_value),\n+                    \"exc_cause_explicit\": getattr(exc_value, \"__cause__\", True),\n+                    \"tb\": tb,\n+                    \"type\": \"django\" if module_name.startswith(\"django.\") else \"user\",\n+                    \"filename\": filename,\n+                    \"function\": function,\n+                    \"lineno\": lineno + 1,\n+                    \"vars\": self.filter.get_traceback_frame_variables(\n+                        self.request, tb.tb_frame\n+                    ),\n+                    \"id\": id(tb),\n+                    \"pre_context\": pre_context,\n+                    \"context_line\": context_line,\n+                    \"post_context\": post_context,\n+                    \"pre_context_lineno\": pre_context_lineno + 1,\n+                }\n+            )\n \n             # If the traceback for current exception is consumed, try the\n             # other exception.\n@@ -458,28 +498,30 @@ class ExceptionReporter:\n def technical_404_response(request, exception):\n     \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n     try:\n-        error_url = exception.args[0]['path']\n+        error_url = exception.args[0][\"path\"]\n     except (IndexError, TypeError, KeyError):\n         error_url = request.path_info[1:]  # Trim leading slash\n \n     try:\n-        tried = exception.args[0]['tried']\n+        tried = exception.args[0][\"tried\"]\n     except (IndexError, TypeError, KeyError):\n         tried = []\n     else:\n-        if (not tried or (                  # empty URLconf\n-            request.path == '/' and\n-            len(tried) == 1 and             # default URLconf\n-            len(tried[0]) == 1 and\n-            getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n-        )):\n+        if not tried or (  # empty URLconf\n+            request.path == \"/\"\n+            and len(tried) == 1  # default URLconf\n+            and len(tried[0]) == 1\n+            and getattr(tried[0][0], \"app_name\", \"\")\n+            == getattr(tried[0][0], \"namespace\", \"\")\n+            == \"admin\"\n+        ):\n             return default_urlconf(request)\n \n-    urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n+    urlconf = getattr(request, \"urlconf\", settings.ROOT_URLCONF)\n     if isinstance(urlconf, types.ModuleType):\n         urlconf = urlconf.__name__\n \n-    caller = ''\n+    caller = \"\"\n     try:\n         resolver_match = resolve(request.path)\n     except Http404:\n@@ -487,37 +529,45 @@ def technical_404_response(request, exception):\n     else:\n         obj = resolver_match.func\n \n-        if hasattr(obj, '__name__'):\n+        if hasattr(obj, \"__name__\"):\n             caller = obj.__name__\n-        elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n+        elif hasattr(obj, \"__class__\") and hasattr(obj.__class__, \"__name__\"):\n             caller = obj.__class__.__name__\n \n-        if hasattr(obj, '__module__'):\n+        if hasattr(obj, \"__module__\"):\n             module = obj.__module__\n-            caller = '%s.%s' % (module, caller)\n+            caller = \"%s.%s\" % (module, caller)\n \n-    with Path(CURRENT_DIR, 'templates', 'technical_404.html').open(encoding='utf-8') as fh:\n+    with Path(CURRENT_DIR, \"templates\", \"technical_404.html\").open(\n+        encoding=\"utf-8\"\n+    ) as fh:\n         t = DEBUG_ENGINE.from_string(fh.read())\n     reporter_filter = get_default_exception_reporter_filter()\n-    c = Context({\n-        'urlconf': urlconf,\n-        'root_urlconf': settings.ROOT_URLCONF,\n-        'request_path': error_url,\n-        'urlpatterns': tried,\n-        'reason': str(exception),\n-        'request': request,\n-        'settings': reporter_filter.get_safe_settings(),\n-        'raising_view_name': caller,\n-    })\n-    return HttpResponseNotFound(t.render(c), content_type='text/html')\n+    c = Context(\n+        {\n+            \"urlconf\": urlconf,\n+            \"root_urlconf\": settings.ROOT_URLCONF,\n+            \"request_path\": error_url,\n+            \"urlpatterns\": tried,\n+            \"reason\": str(exception),\n+            \"request\": request,\n+            \"settings\": reporter_filter.get_safe_settings(),\n+            \"raising_view_name\": caller,\n+        }\n+    )\n+    return HttpResponseNotFound(t.render(c), content_type=\"text/html\")\n \n \n def default_urlconf(request):\n     \"\"\"Create an empty URLconf 404 error response.\"\"\"\n-    with Path(CURRENT_DIR, 'templates', 'default_urlconf.html').open(encoding='utf-8') as fh:\n+    with Path(CURRENT_DIR, \"templates\", \"default_urlconf.html\").open(\n+        encoding=\"utf-8\"\n+    ) as fh:\n         t = DEBUG_ENGINE.from_string(fh.read())\n-    c = Context({\n-        'version': get_docs_version(),\n-    })\n+    c = Context(\n+        {\n+            \"version\": get_docs_version(),\n+        }\n+    )\n \n-    return HttpResponse(t.render(c), content_type='text/html')\n+    return HttpResponse(t.render(c), content_type=\"text/html\")\n"}
{"instance_id": "django__django-12708", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..4e3490228a 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -2,14 +2,18 @@ import logging\n from datetime import datetime\n \n from django.db.backends.ddl_references import (\n-    Columns, ForeignKeyName, IndexName, Statement, Table,\n+    Columns,\n+    ForeignKeyName,\n+    IndexName,\n+    Statement,\n+    Table,\n )\n from django.db.backends.utils import names_digest, split_identifier\n from django.db.models import Index\n from django.db.transaction import TransactionManagementError, atomic\n from django.utils import timezone\n \n-logger = logging.getLogger('django.db.backends.schema')\n+logger = logging.getLogger(\"django.db.backends.schema\")\n \n \n def _is_relevant_relation(relation, altered_field):\n@@ -36,8 +40,16 @@ def _related_non_m2m_objects(old_field, new_field):\n     # Filter out m2m objects from reverse relations.\n     # Return (old_relation, new_relation) tuples.\n     return zip(\n-        (obj for obj in _all_related_fields(old_field.model) if _is_relevant_relation(obj, old_field)),\n-        (obj for obj in _all_related_fields(new_field.model) if _is_relevant_relation(obj, new_field)),\n+        (\n+            obj\n+            for obj in _all_related_fields(old_field.model)\n+            if _is_relevant_relation(obj, old_field)\n+        ),\n+        (\n+            obj\n+            for obj in _all_related_fields(new_field.model)\n+            if _is_relevant_relation(obj, new_field)\n+        ),\n     )\n \n \n@@ -62,8 +74,12 @@ class BaseDatabaseSchemaEditor:\n     sql_alter_column_default = \"ALTER COLUMN %(column)s SET DEFAULT %(default)s\"\n     sql_alter_column_no_default = \"ALTER COLUMN %(column)s DROP DEFAULT\"\n     sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE\"\n-    sql_rename_column = \"ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s\"\n-    sql_update_with_default = \"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"\n+    sql_rename_column = (\n+        \"ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s\"\n+    )\n+    sql_update_with_default = (\n+        \"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"\n+    )\n \n     sql_unique_constraint = \"UNIQUE (%(columns)s)\"\n     sql_check_constraint = \"CHECK (%(check)s)\"\n@@ -73,7 +89,9 @@ class BaseDatabaseSchemaEditor:\n     sql_create_check = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)\"\n     sql_delete_check = sql_delete_constraint\n \n-    sql_create_unique = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s UNIQUE (%(columns)s)\"\n+    sql_create_unique = (\n+        \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s UNIQUE (%(columns)s)\"\n+    )\n     sql_delete_unique = sql_delete_constraint\n \n     sql_create_fk = (\n@@ -84,14 +102,20 @@ class BaseDatabaseSchemaEditor:\n     sql_create_column_inline_fk = None\n     sql_delete_fk = sql_delete_constraint\n \n-    sql_create_index = \"CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s%(condition)s\"\n-    sql_create_unique_index = \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)%(condition)s\"\n+    sql_create_index = (\n+        \"CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s%(condition)s\"\n+    )\n+    sql_create_unique_index = (\n+        \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)%(condition)s\"\n+    )\n     sql_delete_index = \"DROP INDEX %(name)s\"\n \n-    sql_create_pk = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"\n+    sql_create_pk = (\n+        \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"\n+    )\n     sql_delete_pk = sql_delete_constraint\n \n-    sql_delete_procedure = 'DROP PROCEDURE %(procedure)s'\n+    sql_delete_procedure = \"DROP PROCEDURE %(procedure)s\"\n \n     def __init__(self, connection, collect_sql=False, atomic=True):\n         self.connection = connection\n@@ -122,7 +146,11 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"Execute the given SQL statement, with optional parameters.\"\"\"\n         # Don't perform the transactional DDL check if SQL is being collected\n         # as it's not going to be executed anyway.\n-        if not self.collect_sql and self.connection.in_atomic_block and not self.connection.features.can_rollback_ddl:\n+        if (\n+            not self.collect_sql\n+            and self.connection.in_atomic_block\n+            and not self.connection.features.can_rollback_ddl\n+        ):\n             raise TransactionManagementError(\n                 \"Executing DDL statements while in a transaction on databases \"\n                 \"that can't perform a rollback is prohibited.\"\n@@ -130,11 +158,15 @@ class BaseDatabaseSchemaEditor:\n         # Account for non-string statement objects.\n         sql = str(sql)\n         # Log the command we're running, then run it\n-        logger.debug(\"%s; (params %r)\", sql, params, extra={'params': params, 'sql': sql})\n+        logger.debug(\n+            \"%s; (params %r)\", sql, params, extra={\"params\": params, \"sql\": sql}\n+        )\n         if self.collect_sql:\n             ending = \"\" if sql.endswith(\";\") else \";\"\n             if params is not None:\n-                self.collected_sql.append((sql % tuple(map(self.quote_value, params))) + ending)\n+                self.collected_sql.append(\n+                    (sql % tuple(map(self.quote_value, params))) + ending\n+                )\n             else:\n                 self.collected_sql.append(sql + ending)\n         else:\n@@ -161,44 +193,66 @@ class BaseDatabaseSchemaEditor:\n                 continue\n             # Check constraints can go on the column SQL here.\n             db_params = field.db_parameters(connection=self.connection)\n-            if db_params['check']:\n-                definition += ' ' + self.sql_check_constraint % db_params\n+            if db_params[\"check\"]:\n+                definition += \" \" + self.sql_check_constraint % db_params\n             # Autoincrement SQL (for backends with inline variant).\n             col_type_suffix = field.db_type_suffix(connection=self.connection)\n             if col_type_suffix:\n-                definition += ' %s' % col_type_suffix\n+                definition += \" %s\" % col_type_suffix\n             params.extend(extra_params)\n             # FK.\n             if field.remote_field and field.db_constraint:\n                 to_table = field.remote_field.model._meta.db_table\n-                to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column\n+                to_column = field.remote_field.model._meta.get_field(\n+                    field.remote_field.field_name\n+                ).column\n                 if self.sql_create_inline_fk:\n-                    definition += ' ' + self.sql_create_inline_fk % {\n-                        'to_table': self.quote_name(to_table),\n-                        'to_column': self.quote_name(to_column),\n+                    definition += \" \" + self.sql_create_inline_fk % {\n+                        \"to_table\": self.quote_name(to_table),\n+                        \"to_column\": self.quote_name(to_column),\n                     }\n                 elif self.connection.features.supports_foreign_keys:\n-                    self.deferred_sql.append(self._create_fk_sql(model, field, '_fk_%(to_table)s_%(to_column)s'))\n+                    self.deferred_sql.append(\n+                        self._create_fk_sql(\n+                            model, field, \"_fk_%(to_table)s_%(to_column)s\"\n+                        )\n+                    )\n             # Add the SQL to our big list.\n-            column_sqls.append('%s %s' % (\n-                self.quote_name(field.column),\n-                definition,\n-            ))\n+            column_sqls.append(\n+                \"%s %s\"\n+                % (\n+                    self.quote_name(field.column),\n+                    definition,\n+                )\n+            )\n             # Autoincrement SQL (for backends with post table definition\n             # variant).\n-            if field.get_internal_type() in ('AutoField', 'BigAutoField', 'SmallAutoField'):\n-                autoinc_sql = self.connection.ops.autoinc_sql(model._meta.db_table, field.column)\n+            if field.get_internal_type() in (\n+                \"AutoField\",\n+                \"BigAutoField\",\n+                \"SmallAutoField\",\n+            ):\n+                autoinc_sql = self.connection.ops.autoinc_sql(\n+                    model._meta.db_table, field.column\n+                )\n                 if autoinc_sql:\n                     self.deferred_sql.extend(autoinc_sql)\n-        constraints = [constraint.constraint_sql(model, self) for constraint in model._meta.constraints]\n+        constraints = [\n+            constraint.constraint_sql(model, self)\n+            for constraint in model._meta.constraints\n+        ]\n         sql = self.sql_create_table % {\n-            'table': self.quote_name(model._meta.db_table),\n-            'definition': ', '.join(constraint for constraint in (*column_sqls, *constraints) if constraint),\n+            \"table\": self.quote_name(model._meta.db_table),\n+            \"definition\": \", \".join(\n+                constraint for constraint in (*column_sqls, *constraints) if constraint\n+            ),\n         }\n         if model._meta.db_tablespace:\n-            tablespace_sql = self.connection.ops.tablespace_sql(model._meta.db_tablespace)\n+            tablespace_sql = self.connection.ops.tablespace_sql(\n+                model._meta.db_tablespace\n+            )\n             if tablespace_sql:\n-                sql += ' ' + tablespace_sql\n+                sql += \" \" + tablespace_sql\n         return sql, params\n \n     # Field <-> database mapping functions\n@@ -210,7 +264,7 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"\n         # Get the column's type and use that as the basis of the SQL\n         db_params = field.db_parameters(connection=self.connection)\n-        sql = db_params['type']\n+        sql = db_params[\"type\"]\n         params = []\n         # Check for fields that aren't actually columns (e.g. M2M)\n         if sql is None:\n@@ -221,7 +275,7 @@ class BaseDatabaseSchemaEditor:\n         include_default = include_default and not self.skip_default(field)\n         if include_default:\n             default_value = self.effective_default(field)\n-            column_default = ' DEFAULT ' + self._column_default_sql(field)\n+            column_default = \" DEFAULT \" + self._column_default_sql(field)\n             if default_value is not None:\n                 if self.connection.features.requires_literal_defaults:\n                     # Some databases can't take defaults as a parameter (oracle)\n@@ -233,8 +287,11 @@ class BaseDatabaseSchemaEditor:\n                     params += [default_value]\n         # Oracle treats the empty string ('') as null, so coerce the null\n         # option whenever '' is a possible value.\n-        if (field.empty_strings_allowed and not field.primary_key and\n-                self.connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            field.empty_strings_allowed\n+            and not field.primary_key\n+            and self.connection.features.interprets_empty_strings_as_nulls\n+        ):\n             null = True\n         if null and not self.connection.features.implied_column_null:\n             sql += \" NULL\"\n@@ -247,7 +304,11 @@ class BaseDatabaseSchemaEditor:\n             sql += \" UNIQUE\"\n         # Optionally add the tablespace if it's an implicitly indexed column\n         tablespace = field.db_tablespace or model._meta.db_tablespace\n-        if tablespace and self.connection.features.supports_tablespaces and field.unique:\n+        if (\n+            tablespace\n+            and self.connection.features.supports_tablespaces\n+            and field.unique\n+        ):\n             sql += \" %s\" % self.connection.ops.tablespace_sql(tablespace, inline=True)\n         # Return the sql\n         return sql, params\n@@ -264,8 +325,8 @@ class BaseDatabaseSchemaEditor:\n         Only used for backends which have requires_literal_defaults feature\n         \"\"\"\n         raise NotImplementedError(\n-            'subclasses of BaseDatabaseSchemaEditor for backends which have '\n-            'requires_literal_defaults must provide a prepare_default() method'\n+            \"subclasses of BaseDatabaseSchemaEditor for backends which have \"\n+            \"requires_literal_defaults must provide a prepare_default() method\"\n         )\n \n     def _column_default_sql(self, field):\n@@ -273,7 +334,7 @@ class BaseDatabaseSchemaEditor:\n         Return the SQL to use in a DEFAULT clause. The resulting string should\n         contain a '%s' placeholder for a default value.\n         \"\"\"\n-        return '%s'\n+        return \"%s\"\n \n     @staticmethod\n     def _effective_default(field):\n@@ -282,17 +343,17 @@ class BaseDatabaseSchemaEditor:\n             default = field.get_default()\n         elif not field.null and field.blank and field.empty_strings_allowed:\n             if field.get_internal_type() == \"BinaryField\":\n-                default = b''\n+                default = b\"\"\n             else:\n-                default = ''\n-        elif getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False):\n+                default = \"\"\n+        elif getattr(field, \"auto_now\", False) or getattr(field, \"auto_now_add\", False):\n             default = datetime.now()\n             internal_type = field.get_internal_type()\n-            if internal_type == 'DateField':\n+            if internal_type == \"DateField\":\n                 default = default.date()\n-            elif internal_type == 'TimeField':\n+            elif internal_type == \"TimeField\":\n                 default = default.time()\n-            elif internal_type == 'DateTimeField':\n+            elif internal_type == \"DateTimeField\":\n                 default = timezone.now()\n         else:\n             default = None\n@@ -339,12 +400,17 @@ class BaseDatabaseSchemaEditor:\n                 self.delete_model(field.remote_field.through)\n \n         # Delete the table\n-        self.execute(self.sql_delete_table % {\n-            \"table\": self.quote_name(model._meta.db_table),\n-        })\n+        self.execute(\n+            self.sql_delete_table\n+            % {\n+                \"table\": self.quote_name(model._meta.db_table),\n+            }\n+        )\n         # Remove all deferred statements referencing the deleted table.\n         for sql in list(self.deferred_sql):\n-            if isinstance(sql, Statement) and sql.references_table(model._meta.db_table):\n+            if isinstance(sql, Statement) and sql.references_table(\n+                model._meta.db_table\n+            ):\n                 self.deferred_sql.remove(sql)\n \n     def add_index(self, model, index):\n@@ -377,7 +443,9 @@ class BaseDatabaseSchemaEditor:\n         news = {tuple(fields) for fields in new_unique_together}\n         # Deleted uniques\n         for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'unique': True}, self.sql_delete_unique)\n+            self._delete_composed_index(\n+                model, fields, {\"unique\": True}, self.sql_delete_unique\n+            )\n         # Created uniques\n         for fields in news.difference(olds):\n             columns = [model._meta.get_field(field).column for field in fields]\n@@ -393,38 +461,51 @@ class BaseDatabaseSchemaEditor:\n         news = {tuple(fields) for fields in new_index_together}\n         # Deleted indexes\n         for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n+            self._delete_composed_index(\n+                model, fields, {\"index\": True, \"unique\": False}, self.sql_delete_index\n+            )\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n             self.execute(self._create_index_sql(model, fields, suffix=\"_idx\"))\n \n     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):\n-        meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n+        meta_constraint_names = {\n+            constraint.name for constraint in model._meta.constraints\n+        }\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n         constraint_names = self._constraint_names(\n-            model, columns, exclude=meta_constraint_names | meta_index_names,\n-            **constraint_kwargs\n+            model,\n+            columns,\n+            exclude=meta_constraint_names | meta_index_names,\n+            **constraint_kwargs,\n         )\n         if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n+            raise ValueError(\n+                \"Found wrong number (%s) of constraints for %s(%s)\"\n+                % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                    \", \".join(columns),\n+                )\n+            )\n         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\n-        if (old_db_table == new_db_table or\n-            (self.connection.features.ignores_table_name_case and\n-                old_db_table.lower() == new_db_table.lower())):\n+        if old_db_table == new_db_table or (\n+            self.connection.features.ignores_table_name_case\n+            and old_db_table.lower() == new_db_table.lower()\n+        ):\n             return\n-        self.execute(self.sql_rename_table % {\n-            \"old_table\": self.quote_name(old_db_table),\n-            \"new_table\": self.quote_name(new_db_table),\n-        })\n+        self.execute(\n+            self.sql_rename_table\n+            % {\n+                \"old_table\": self.quote_name(old_db_table),\n+                \"new_table\": self.quote_name(new_db_table),\n+            }\n+        )\n         # Rename all references to the old table name.\n         for sql in self.deferred_sql:\n             if isinstance(sql, Statement):\n@@ -432,11 +513,14 @@ class BaseDatabaseSchemaEditor:\n \n     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):\n         \"\"\"Move a model's table between tablespaces.\"\"\"\n-        self.execute(self.sql_retablespace_table % {\n-            \"table\": self.quote_name(model._meta.db_table),\n-            \"old_tablespace\": self.quote_name(old_db_tablespace),\n-            \"new_tablespace\": self.quote_name(new_db_tablespace),\n-        })\n+        self.execute(\n+            self.sql_retablespace_table\n+            % {\n+                \"table\": self.quote_name(model._meta.db_table),\n+                \"old_tablespace\": self.quote_name(old_db_tablespace),\n+                \"new_tablespace\": self.quote_name(new_db_tablespace),\n+            }\n+        )\n \n     def add_field(self, model, field):\n         \"\"\"\n@@ -453,24 +537,32 @@ class BaseDatabaseSchemaEditor:\n             return\n         # Check constraints can go on the column SQL here\n         db_params = field.db_parameters(connection=self.connection)\n-        if db_params['check']:\n+        if db_params[\"check\"]:\n             definition += \" \" + self.sql_check_constraint % db_params\n-        if field.remote_field and self.connection.features.supports_foreign_keys and field.db_constraint:\n-            constraint_suffix = '_fk_%(to_table)s_%(to_column)s'\n+        if (\n+            field.remote_field\n+            and self.connection.features.supports_foreign_keys\n+            and field.db_constraint\n+        ):\n+            constraint_suffix = \"_fk_%(to_table)s_%(to_column)s\"\n             # Add FK constraint inline, if supported.\n             if self.sql_create_column_inline_fk:\n                 to_table = field.remote_field.model._meta.db_table\n-                to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column\n+                to_column = field.remote_field.model._meta.get_field(\n+                    field.remote_field.field_name\n+                ).column\n                 definition += \" \" + self.sql_create_column_inline_fk % {\n-                    'name': self._fk_constraint_name(model, field, constraint_suffix),\n-                    'column': self.quote_name(field.column),\n-                    'to_table': self.quote_name(to_table),\n-                    'to_column': self.quote_name(to_column),\n-                    'deferrable': self.connection.ops.deferrable_sql()\n+                    \"name\": self._fk_constraint_name(model, field, constraint_suffix),\n+                    \"column\": self.quote_name(field.column),\n+                    \"to_table\": self.quote_name(to_table),\n+                    \"to_column\": self.quote_name(to_column),\n+                    \"deferrable\": self.connection.ops.deferrable_sql(),\n                 }\n             # Otherwise, add FK constraints later.\n             else:\n-                self.deferred_sql.append(self._create_fk_sql(model, field, constraint_suffix))\n+                self.deferred_sql.append(\n+                    self._create_fk_sql(model, field, constraint_suffix)\n+                )\n         # Build the SQL and run it\n         sql = self.sql_create_column % {\n             \"table\": self.quote_name(model._meta.db_table),\n@@ -481,7 +573,9 @@ class BaseDatabaseSchemaEditor:\n         # Drop the default if we need to\n         # (Django usually does not use in-database defaults)\n         if not self.skip_default(field) and self.effective_default(field) is not None:\n-            changes_sql, params = self._alter_column_default_sql(model, None, field, drop=True)\n+            changes_sql, params = self._alter_column_default_sql(\n+                model, None, field, drop=True\n+            )\n             sql = self.sql_alter_column % {\n                 \"table\": self.quote_name(model._meta.db_table),\n                 \"changes\": changes_sql,\n@@ -502,7 +596,7 @@ class BaseDatabaseSchemaEditor:\n         if field.many_to_many and field.remote_field.through._meta.auto_created:\n             return self.delete_model(field.remote_field.through)\n         # It might not actually have a column behind it\n-        if field.db_parameters(connection=self.connection)['type'] is None:\n+        if field.db_parameters(connection=self.connection)[\"type\"] is None:\n             return\n         # Drop any FK constraints, MySQL requires explicit deletion\n         if field.remote_field:\n@@ -520,7 +614,9 @@ class BaseDatabaseSchemaEditor:\n             self.connection.close()\n         # Remove all deferred statements referencing the deleted column.\n         for sql in list(self.deferred_sql):\n-            if isinstance(sql, Statement) and sql.references_column(model._meta.db_table, field.column):\n+            if isinstance(sql, Statement) and sql.references_column(\n+                model._meta.db_table, field.column\n+            ):\n                 self.deferred_sql.remove(sql)\n \n     def alter_field(self, model, old_field, new_field, strict=False):\n@@ -533,25 +629,38 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"\n         # Ensure this field is even column-based\n         old_db_params = old_field.db_parameters(connection=self.connection)\n-        old_type = old_db_params['type']\n+        old_type = old_db_params[\"type\"]\n         new_db_params = new_field.db_parameters(connection=self.connection)\n-        new_type = new_db_params['type']\n-        if ((old_type is None and old_field.remote_field is None) or\n-                (new_type is None and new_field.remote_field is None)):\n+        new_type = new_db_params[\"type\"]\n+        if (old_type is None and old_field.remote_field is None) or (\n+            new_type is None and new_field.remote_field is None\n+        ):\n             raise ValueError(\n                 \"Cannot alter field %s into %s - they do not properly define \"\n-                \"db_type (are you using a badly-written custom field?)\" %\n-                (old_field, new_field),\n+                \"db_type (are you using a badly-written custom field?)\"\n+                % (old_field, new_field),\n             )\n-        elif old_type is None and new_type is None and (\n-                old_field.remote_field.through and new_field.remote_field.through and\n-                old_field.remote_field.through._meta.auto_created and\n-                new_field.remote_field.through._meta.auto_created):\n+        elif (\n+            old_type is None\n+            and new_type is None\n+            and (\n+                old_field.remote_field.through\n+                and new_field.remote_field.through\n+                and old_field.remote_field.through._meta.auto_created\n+                and new_field.remote_field.through._meta.auto_created\n+            )\n+        ):\n             return self._alter_many_to_many(model, old_field, new_field, strict)\n-        elif old_type is None and new_type is None and (\n-                old_field.remote_field.through and new_field.remote_field.through and\n-                not old_field.remote_field.through._meta.auto_created and\n-                not new_field.remote_field.through._meta.auto_created):\n+        elif (\n+            old_type is None\n+            and new_type is None\n+            and (\n+                old_field.remote_field.through\n+                and new_field.remote_field.through\n+                and not old_field.remote_field.through._meta.auto_created\n+                and not new_field.remote_field.through._meta.auto_created\n+            )\n+        ):\n             # Both sides have through models; this is a no-op.\n             return\n         elif old_type is None or new_type is None:\n@@ -561,52 +670,86 @@ class BaseDatabaseSchemaEditor:\n                 \"through= on M2M fields)\" % (old_field, new_field)\n             )\n \n-        self._alter_field(model, old_field, new_field, old_type, new_type,\n-                          old_db_params, new_db_params, strict)\n+        self._alter_field(\n+            model,\n+            old_field,\n+            new_field,\n+            old_type,\n+            new_type,\n+            old_db_params,\n+            new_db_params,\n+            strict,\n+        )\n \n-    def _alter_field(self, model, old_field, new_field, old_type, new_type,\n-                     old_db_params, new_db_params, strict=False):\n+    def _alter_field(\n+        self,\n+        model,\n+        old_field,\n+        new_field,\n+        old_type,\n+        new_type,\n+        old_db_params,\n+        new_db_params,\n+        strict=False,\n+    ):\n         \"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"\n         # Drop any FK constraints, we'll remake them later\n         fks_dropped = set()\n         if (\n-            self.connection.features.supports_foreign_keys and\n-            old_field.remote_field and\n-            old_field.db_constraint\n+            self.connection.features.supports_foreign_keys\n+            and old_field.remote_field\n+            and old_field.db_constraint\n         ):\n-            fk_names = self._constraint_names(model, [old_field.column], foreign_key=True)\n+            fk_names = self._constraint_names(\n+                model, [old_field.column], foreign_key=True\n+            )\n             if strict and len(fk_names) != 1:\n-                raise ValueError(\"Found wrong number (%s) of foreign key constraints for %s.%s\" % (\n-                    len(fk_names),\n-                    model._meta.db_table,\n-                    old_field.column,\n-                ))\n+                raise ValueError(\n+                    \"Found wrong number (%s) of foreign key constraints for %s.%s\"\n+                    % (\n+                        len(fk_names),\n+                        model._meta.db_table,\n+                        old_field.column,\n+                    )\n+                )\n             for fk_name in fk_names:\n                 fks_dropped.add((old_field.column,))\n                 self.execute(self._delete_fk_sql(model, fk_name))\n         # Has unique been removed?\n-        if old_field.unique and (not new_field.unique or self._field_became_primary_key(old_field, new_field)):\n+        if old_field.unique and (\n+            not new_field.unique or self._field_became_primary_key(old_field, new_field)\n+        ):\n             # Find the unique constraint for this field\n-            meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n+            meta_constraint_names = {\n+                constraint.name for constraint in model._meta.constraints\n+            }\n             constraint_names = self._constraint_names(\n-                model, [old_field.column], unique=True, primary_key=False,\n+                model,\n+                [old_field.column],\n+                unique=True,\n+                primary_key=False,\n                 exclude=meta_constraint_names,\n             )\n             if strict and len(constraint_names) != 1:\n-                raise ValueError(\"Found wrong number (%s) of unique constraints for %s.%s\" % (\n-                    len(constraint_names),\n-                    model._meta.db_table,\n-                    old_field.column,\n-                ))\n+                raise ValueError(\n+                    \"Found wrong number (%s) of unique constraints for %s.%s\"\n+                    % (\n+                        len(constraint_names),\n+                        model._meta.db_table,\n+                        old_field.column,\n+                    )\n+                )\n             for constraint_name in constraint_names:\n                 self.execute(self._delete_unique_sql(model, constraint_name))\n         # Drop incoming FK constraints if the field is a primary key or unique,\n         # which might be a to_field target, and things are going to change.\n         drop_foreign_keys = (\n-            self.connection.features.supports_foreign_keys and (\n-                (old_field.primary_key and new_field.primary_key) or\n-                (old_field.unique and new_field.unique)\n-            ) and old_type != new_type\n+            self.connection.features.supports_foreign_keys\n+            and (\n+                (old_field.primary_key and new_field.primary_key)\n+                or (old_field.unique and new_field.unique)\n+            )\n+            and old_type != new_type\n         )\n         if drop_foreign_keys:\n             # '_meta.related_field' also contains M2M reverse fields, these\n@@ -627,13 +770,20 @@ class BaseDatabaseSchemaEditor:\n         # True               | False            | False              | False\n         # True               | False            | False              | True\n         # True               | False            | True               | True\n-        if old_field.db_index and not old_field.unique and (not new_field.db_index or new_field.unique):\n+        if (\n+            old_field.db_index\n+            and not old_field.unique\n+            and (not new_field.db_index or new_field.unique)\n+        ):\n             # Find the index for this field\n             meta_index_names = {index.name for index in model._meta.indexes}\n             # Retrieve only BTREE indexes since this is what's created with\n             # db_index=True.\n             index_names = self._constraint_names(\n-                model, [old_field.column], index=True, type_=Index.suffix,\n+                model,\n+                [old_field.column],\n+                index=True,\n+                type_=Index.suffix,\n                 exclude=meta_index_names,\n             )\n             for index_name in index_names:\n@@ -642,34 +792,49 @@ class BaseDatabaseSchemaEditor:\n                 # is to look at its name (refs #28053).\n                 self.execute(self._delete_index_sql(model, index_name))\n         # Change check constraints?\n-        if old_db_params['check'] != new_db_params['check'] and old_db_params['check']:\n-            meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n+        if old_db_params[\"check\"] != new_db_params[\"check\"] and old_db_params[\"check\"]:\n+            meta_constraint_names = {\n+                constraint.name for constraint in model._meta.constraints\n+            }\n             constraint_names = self._constraint_names(\n-                model, [old_field.column], check=True,\n+                model,\n+                [old_field.column],\n+                check=True,\n                 exclude=meta_constraint_names,\n             )\n             if strict and len(constraint_names) != 1:\n-                raise ValueError(\"Found wrong number (%s) of check constraints for %s.%s\" % (\n-                    len(constraint_names),\n-                    model._meta.db_table,\n-                    old_field.column,\n-                ))\n+                raise ValueError(\n+                    \"Found wrong number (%s) of check constraints for %s.%s\"\n+                    % (\n+                        len(constraint_names),\n+                        model._meta.db_table,\n+                        old_field.column,\n+                    )\n+                )\n             for constraint_name in constraint_names:\n                 self.execute(self._delete_check_sql(model, constraint_name))\n         # Have they renamed the column?\n         if old_field.column != new_field.column:\n-            self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type))\n+            self.execute(\n+                self._rename_field_sql(\n+                    model._meta.db_table, old_field, new_field, new_type\n+                )\n+            )\n             # Rename all references to the renamed column.\n             for sql in self.deferred_sql:\n                 if isinstance(sql, Statement):\n-                    sql.rename_column_references(model._meta.db_table, old_field.column, new_field.column)\n+                    sql.rename_column_references(\n+                        model._meta.db_table, old_field.column, new_field.column\n+                    )\n         # Next, start accumulating actions to do\n         actions = []\n         null_actions = []\n         post_actions = []\n         # Type change?\n         if old_type != new_type:\n-            fragment, other_actions = self._alter_column_type_sql(model, old_field, new_field, new_type)\n+            fragment, other_actions = self._alter_column_type_sql(\n+                model, old_field, new_field, new_type\n+            )\n             actions.append(fragment)\n             post_actions.extend(other_actions)\n         # When changing a column NULL constraint to NOT NULL with a given\n@@ -684,21 +849,22 @@ class BaseDatabaseSchemaEditor:\n             old_default = self.effective_default(old_field)\n             new_default = self.effective_default(new_field)\n             if (\n-                not self.skip_default(new_field) and\n-                old_default != new_default and\n-                new_default is not None\n+                not self.skip_default(new_field)\n+                and old_default != new_default\n+                and new_default is not None\n             ):\n                 needs_database_default = True\n-                actions.append(self._alter_column_default_sql(model, old_field, new_field))\n+                actions.append(\n+                    self._alter_column_default_sql(model, old_field, new_field)\n+                )\n         # Nullability change?\n         if old_field.null != new_field.null:\n             fragment = self._alter_column_null_sql(model, old_field, new_field)\n             if fragment:\n                 null_actions.append(fragment)\n         # Only if we have a default and there is a change from NULL to NOT NULL\n-        four_way_default_alteration = (\n-            new_field.has_default() and\n-            (old_field.null and not new_field.null)\n+        four_way_default_alteration = new_field.has_default() and (\n+            old_field.null and not new_field.null\n         )\n         if actions or null_actions:\n             if not four_way_default_alteration:\n@@ -712,7 +878,8 @@ class BaseDatabaseSchemaEditor:\n             # Apply those actions\n             for sql, params in actions:\n                 self.execute(\n-                    self.sql_alter_column % {\n+                    self.sql_alter_column\n+                    % {\n                         \"table\": self.quote_name(model._meta.db_table),\n                         \"changes\": sql,\n                     },\n@@ -721,7 +888,8 @@ class BaseDatabaseSchemaEditor:\n             if four_way_default_alteration:\n                 # Update existing rows with default value\n                 self.execute(\n-                    self.sql_update_with_default % {\n+                    self.sql_update_with_default\n+                    % {\n                         \"table\": self.quote_name(model._meta.db_table),\n                         \"column\": self.quote_name(new_field.column),\n                         \"default\": \"%s\",\n@@ -732,7 +900,8 @@ class BaseDatabaseSchemaEditor:\n                 # now\n                 for sql, params in null_actions:\n                     self.execute(\n-                        self.sql_alter_column % {\n+                        self.sql_alter_column\n+                        % {\n                             \"table\": self.quote_name(model._meta.db_table),\n                             \"changes\": sql,\n                         },\n@@ -756,7 +925,11 @@ class BaseDatabaseSchemaEditor:\n         # False              | False            | True               | False\n         # False              | True             | True               | False\n         # True               | True             | True               | False\n-        if (not old_field.db_index or old_field.unique) and new_field.db_index and not new_field.unique:\n+        if (\n+            (not old_field.db_index or old_field.unique)\n+            and new_field.db_index\n+            and not new_field.unique\n+        ):\n             self.execute(self._create_index_sql(model, [new_field]))\n         # Type alteration on primary key? Then we need to alter the column\n         # referring to us.\n@@ -772,12 +945,13 @@ class BaseDatabaseSchemaEditor:\n         # Handle our type alters on the other end of rels from the PK stuff above\n         for old_rel, new_rel in rels_to_update:\n             rel_db_params = new_rel.field.db_parameters(connection=self.connection)\n-            rel_type = rel_db_params['type']\n+            rel_type = rel_db_params[\"type\"]\n             fragment, other_actions = self._alter_column_type_sql(\n                 new_rel.related_model, old_rel.field, new_rel.field, rel_type\n             )\n             self.execute(\n-                self.sql_alter_column % {\n+                self.sql_alter_column\n+                % {\n                     \"table\": self.quote_name(new_rel.related_model._meta.db_table),\n                     \"changes\": fragment[0],\n                 },\n@@ -786,23 +960,38 @@ class BaseDatabaseSchemaEditor:\n             for sql, params in other_actions:\n                 self.execute(sql, params)\n         # Does it have a foreign key?\n-        if (self.connection.features.supports_foreign_keys and new_field.remote_field and\n-                (fks_dropped or not old_field.remote_field or not old_field.db_constraint) and\n-                new_field.db_constraint):\n-            self.execute(self._create_fk_sql(model, new_field, \"_fk_%(to_table)s_%(to_column)s\"))\n+        if (\n+            self.connection.features.supports_foreign_keys\n+            and new_field.remote_field\n+            and (\n+                fks_dropped or not old_field.remote_field or not old_field.db_constraint\n+            )\n+            and new_field.db_constraint\n+        ):\n+            self.execute(\n+                self._create_fk_sql(model, new_field, \"_fk_%(to_table)s_%(to_column)s\")\n+            )\n         # Rebuild FKs that pointed to us if we previously had to drop them\n         if drop_foreign_keys:\n             for rel in new_field.model._meta.related_objects:\n                 if _is_relevant_relation(rel, new_field) and rel.field.db_constraint:\n-                    self.execute(self._create_fk_sql(rel.related_model, rel.field, \"_fk\"))\n+                    self.execute(\n+                        self._create_fk_sql(rel.related_model, rel.field, \"_fk\")\n+                    )\n         # Does it have check constraints we need to add?\n-        if old_db_params['check'] != new_db_params['check'] and new_db_params['check']:\n-            constraint_name = self._create_index_name(model._meta.db_table, [new_field.column], suffix='_check')\n-            self.execute(self._create_check_sql(model, constraint_name, new_db_params['check']))\n+        if old_db_params[\"check\"] != new_db_params[\"check\"] and new_db_params[\"check\"]:\n+            constraint_name = self._create_index_name(\n+                model._meta.db_table, [new_field.column], suffix=\"_check\"\n+            )\n+            self.execute(\n+                self._create_check_sql(model, constraint_name, new_db_params[\"check\"])\n+            )\n         # Drop the default if we need to\n         # (Django usually does not use in-database defaults)\n         if needs_database_default:\n-            changes_sql, params = self._alter_column_default_sql(model, old_field, new_field, drop=True)\n+            changes_sql, params = self._alter_column_default_sql(\n+                model, old_field, new_field, drop=True\n+            )\n             sql = self.sql_alter_column % {\n                 \"table\": self.quote_name(model._meta.db_table),\n                 \"changes\": changes_sql,\n@@ -819,17 +1008,24 @@ class BaseDatabaseSchemaEditor:\n         Return a (sql, params) fragment to set a column to null or non-null\n         as required by new_field, or None if no changes are required.\n         \"\"\"\n-        if (self.connection.features.interprets_empty_strings_as_nulls and\n-                new_field.get_internal_type() in (\"CharField\", \"TextField\")):\n+        if (\n+            self.connection.features.interprets_empty_strings_as_nulls\n+            and new_field.get_internal_type() in (\"CharField\", \"TextField\")\n+        ):\n             # The field is nullable in the database anyway, leave it alone.\n             return\n         else:\n             new_db_params = new_field.db_parameters(connection=self.connection)\n-            sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null\n+            sql = (\n+                self.sql_alter_column_null\n+                if new_field.null\n+                else self.sql_alter_column_not_null\n+            )\n             return (\n-                sql % {\n-                    'column': self.quote_name(new_field.column),\n-                    'type': new_db_params['type'],\n+                sql\n+                % {\n+                    \"column\": self.quote_name(new_field.column),\n+                    \"type\": new_db_params[\"type\"],\n                 },\n                 [],\n             )\n@@ -855,12 +1051,15 @@ class BaseDatabaseSchemaEditor:\n             params = []\n \n         new_db_params = new_field.db_parameters(connection=self.connection)\n-        sql = self.sql_alter_column_no_default if drop else self.sql_alter_column_default\n+        sql = (\n+            self.sql_alter_column_no_default if drop else self.sql_alter_column_default\n+        )\n         return (\n-            sql % {\n-                'column': self.quote_name(new_field.column),\n-                'type': new_db_params['type'],\n-                'default': default,\n+            sql\n+            % {\n+                \"column\": self.quote_name(new_field.column),\n+                \"type\": new_db_params[\"type\"],\n+                \"default\": default,\n             },\n             params,\n         )\n@@ -877,7 +1076,8 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"\n         return (\n             (\n-                self.sql_alter_column_type % {\n+                self.sql_alter_column_type\n+                % {\n                     \"column\": self.quote_name(new_field.column),\n                     \"type\": new_type,\n                 },\n@@ -889,16 +1089,26 @@ class BaseDatabaseSchemaEditor:\n     def _alter_many_to_many(self, model, old_field, new_field, strict):\n         \"\"\"Alter M2Ms to repoint their to= endpoints.\"\"\"\n         # Rename the through table\n-        if old_field.remote_field.through._meta.db_table != new_field.remote_field.through._meta.db_table:\n-            self.alter_db_table(old_field.remote_field.through, old_field.remote_field.through._meta.db_table,\n-                                new_field.remote_field.through._meta.db_table)\n+        if (\n+            old_field.remote_field.through._meta.db_table\n+            != new_field.remote_field.through._meta.db_table\n+        ):\n+            self.alter_db_table(\n+                old_field.remote_field.through,\n+                old_field.remote_field.through._meta.db_table,\n+                new_field.remote_field.through._meta.db_table,\n+            )\n         # Repoint the FK to the other side\n         self.alter_field(\n             new_field.remote_field.through,\n             # We need the field that points to the target model, so we can tell alter_field to change it -\n             # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)\n-            old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()),\n-            new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()),\n+            old_field.remote_field.through._meta.get_field(\n+                old_field.m2m_reverse_field_name()\n+            ),\n+            new_field.remote_field.through._meta.get_field(\n+                new_field.m2m_reverse_field_name()\n+            ),\n         )\n         self.alter_field(\n             new_field.remote_field.through,\n@@ -915,19 +1125,22 @@ class BaseDatabaseSchemaEditor:\n         and a unique digest and suffix.\n         \"\"\"\n         _, table_name = split_identifier(table_name)\n-        hash_suffix_part = '%s%s' % (names_digest(table_name, *column_names, length=8), suffix)\n+        hash_suffix_part = \"%s%s\" % (\n+            names_digest(table_name, *column_names, length=8),\n+            suffix,\n+        )\n         max_length = self.connection.ops.max_name_length() or 200\n         # If everything fits into max_length, use that name.\n-        index_name = '%s_%s_%s' % (table_name, '_'.join(column_names), hash_suffix_part)\n+        index_name = \"%s_%s_%s\" % (table_name, \"_\".join(column_names), hash_suffix_part)\n         if len(index_name) <= max_length:\n             return index_name\n         # Shorten a long suffix.\n         if len(hash_suffix_part) > max_length / 3:\n-            hash_suffix_part = hash_suffix_part[:max_length // 3]\n+            hash_suffix_part = hash_suffix_part[: max_length // 3]\n         other_length = (max_length - len(hash_suffix_part)) // 2 - 1\n-        index_name = '%s_%s_%s' % (\n+        index_name = \"%s_%s_%s\" % (\n             table_name[:other_length],\n-            '_'.join(column_names)[:other_length],\n+            \"_\".join(column_names)[:other_length],\n             hash_suffix_part,\n         )\n         # Prepend D if needed to prevent the name from starting with an\n@@ -943,18 +1156,31 @@ class BaseDatabaseSchemaEditor:\n             elif model._meta.db_tablespace:\n                 db_tablespace = model._meta.db_tablespace\n         if db_tablespace is not None:\n-            return ' ' + self.connection.ops.tablespace_sql(db_tablespace)\n-        return ''\n-\n-    def _create_index_sql(self, model, fields, *, name=None, suffix='', using='',\n-                          db_tablespace=None, col_suffixes=(), sql=None, opclasses=(),\n-                          condition=None):\n+            return \" \" + self.connection.ops.tablespace_sql(db_tablespace)\n+        return \"\"\n+\n+    def _create_index_sql(\n+        self,\n+        model,\n+        fields,\n+        *,\n+        name=None,\n+        suffix=\"\",\n+        using=\"\",\n+        db_tablespace=None,\n+        col_suffixes=(),\n+        sql=None,\n+        opclasses=(),\n+        condition=None,\n+    ):\n         \"\"\"\n         Return the SQL statement to create the index for one or several fields.\n         `sql` can be specified if the syntax differs from the standard (GIS\n         indexes, ...).\n         \"\"\"\n-        tablespace_sql = self._get_index_tablespace_sql(model, fields, db_tablespace=db_tablespace)\n+        tablespace_sql = self._get_index_tablespace_sql(\n+            model, fields, db_tablespace=db_tablespace\n+        )\n         columns = [field.column for field in fields]\n         sql_create_index = sql or self.sql_create_index\n         table = model._meta.db_table\n@@ -972,7 +1198,7 @@ class BaseDatabaseSchemaEditor:\n             using=using,\n             columns=self._index_columns(table, columns, col_suffixes, opclasses),\n             extra=tablespace_sql,\n-            condition=(' WHERE ' + condition) if condition else '',\n+            condition=(\" WHERE \" + condition) if condition else \"\",\n         )\n \n     def _delete_index_sql(self, model, name, sql=None):\n@@ -1037,7 +1263,11 @@ class BaseDatabaseSchemaEditor:\n         name = self._fk_constraint_name(model, field, suffix)\n         column = Columns(model._meta.db_table, [field.column], self.quote_name)\n         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)\n-        to_column = Columns(field.target_field.model._meta.db_table, [field.target_field.column], self.quote_name)\n+        to_column = Columns(\n+            field.target_field.model._meta.db_table,\n+            [field.target_field.column],\n+            self.quote_name,\n+        )\n         deferrable = self.connection.ops.deferrable_sql()\n         return Statement(\n             self.sql_create_fk,\n@@ -1074,11 +1304,11 @@ class BaseDatabaseSchemaEditor:\n                 self.deferred_sql.append(sql)\n             return None\n         constraint = self.sql_unique_constraint % {\n-            'columns': ', '.join(map(self.quote_name, fields)),\n+            \"columns\": \", \".join(map(self.quote_name, fields)),\n         }\n         return self.sql_constraint % {\n-            'name': self.quote_name(name),\n-            'constraint': constraint,\n+            \"name\": self.quote_name(name),\n+            \"constraint\": constraint,\n         }\n \n     def _create_unique_sql(self, model, columns, name=None, condition=None):\n@@ -1087,18 +1317,22 @@ class BaseDatabaseSchemaEditor:\n \n         table = Table(model._meta.db_table, self.quote_name)\n         if name is None:\n-            name = IndexName(model._meta.db_table, columns, '_uniq', create_unique_name)\n+            name = IndexName(model._meta.db_table, columns, \"_uniq\", create_unique_name)\n         else:\n             name = self.quote_name(name)\n         columns = Columns(table, columns, self.quote_name)\n         if condition:\n-            return Statement(\n-                self.sql_create_unique_index,\n-                table=table,\n-                name=name,\n-                columns=columns,\n-                condition=' WHERE ' + condition,\n-            ) if self.connection.features.supports_partial_indexes else None\n+            return (\n+                Statement(\n+                    self.sql_create_unique_index,\n+                    table=table,\n+                    name=name,\n+                    columns=columns,\n+                    condition=\" WHERE \" + condition,\n+                )\n+                if self.connection.features.supports_partial_indexes\n+                else None\n+            )\n         else:\n             return Statement(\n                 self.sql_create_unique,\n@@ -1111,14 +1345,15 @@ class BaseDatabaseSchemaEditor:\n         if condition:\n             return (\n                 self._delete_constraint_sql(self.sql_delete_index, model, name)\n-                if self.connection.features.supports_partial_indexes else None\n+                if self.connection.features.supports_partial_indexes\n+                else None\n             )\n         return self._delete_constraint_sql(self.sql_delete_unique, model, name)\n \n     def _check_sql(self, name, check):\n         return self.sql_constraint % {\n-            'name': self.quote_name(name),\n-            'constraint': self.sql_check_constraint % {'check': check},\n+            \"name\": self.quote_name(name),\n+            \"constraint\": self.sql_check_constraint % {\"check\": check},\n         }\n \n     def _create_check_sql(self, model, name, check):\n@@ -1139,9 +1374,18 @@ class BaseDatabaseSchemaEditor:\n             name=self.quote_name(name),\n         )\n \n-    def _constraint_names(self, model, column_names=None, unique=None,\n-                          primary_key=None, index=None, foreign_key=None,\n-                          check=None, type_=None, exclude=None):\n+    def _constraint_names(\n+        self,\n+        model,\n+        column_names=None,\n+        unique=None,\n+        primary_key=None,\n+        index=None,\n+        foreign_key=None,\n+        check=None,\n+        type_=None,\n+        exclude=None,\n+    ):\n         \"\"\"Return all constraint names matching the columns and conditions.\"\"\"\n         if column_names is not None:\n             column_names = [\n@@ -1149,21 +1393,23 @@ class BaseDatabaseSchemaEditor:\n                 for name in column_names\n             ]\n         with self.connection.cursor() as cursor:\n-            constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table)\n+            constraints = self.connection.introspection.get_constraints(\n+                cursor, model._meta.db_table\n+            )\n         result = []\n         for name, infodict in constraints.items():\n-            if column_names is None or column_names == infodict['columns']:\n-                if unique is not None and infodict['unique'] != unique:\n+            if column_names is None or column_names == infodict[\"columns\"]:\n+                if unique is not None and infodict[\"unique\"] != unique:\n                     continue\n-                if primary_key is not None and infodict['primary_key'] != primary_key:\n+                if primary_key is not None and infodict[\"primary_key\"] != primary_key:\n                     continue\n-                if index is not None and infodict['index'] != index:\n+                if index is not None and infodict[\"index\"] != index:\n                     continue\n-                if check is not None and infodict['check'] != check:\n+                if check is not None and infodict[\"check\"] != check:\n                     continue\n-                if foreign_key is not None and not infodict['foreign_key']:\n+                if foreign_key is not None and not infodict[\"foreign_key\"]:\n                     continue\n-                if type_ is not None and infodict['type'] != type_:\n+                if type_ is not None and infodict[\"type\"] != type_:\n                     continue\n                 if not exclude or name not in exclude:\n                     result.append(name)\n@@ -1172,10 +1418,13 @@ class BaseDatabaseSchemaEditor:\n     def _delete_primary_key(self, model, strict=False):\n         constraint_names = self._constraint_names(model, primary_key=True)\n         if strict and len(constraint_names) != 1:\n-            raise ValueError('Found wrong number (%s) of PK constraints for %s' % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-            ))\n+            raise ValueError(\n+                \"Found wrong number (%s) of PK constraints for %s\"\n+                % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                )\n+            )\n         for constraint_name in constraint_names:\n             self.execute(self._delete_primary_key_sql(model, constraint_name))\n \n@@ -1184,7 +1433,9 @@ class BaseDatabaseSchemaEditor:\n             self.sql_create_pk,\n             table=Table(model._meta.db_table, self.quote_name),\n             name=self.quote_name(\n-                self._create_index_name(model._meta.db_table, [field.column], suffix=\"_pk\")\n+                self._create_index_name(\n+                    model._meta.db_table, [field.column], suffix=\"_pk\"\n+                )\n             ),\n             columns=Columns(model._meta.db_table, [field.column], self.quote_name),\n         )\n@@ -1194,7 +1445,7 @@ class BaseDatabaseSchemaEditor:\n \n     def remove_procedure(self, procedure_name, param_types=()):\n         sql = self.sql_delete_procedure % {\n-            'procedure': self.quote_name(procedure_name),\n-            'param_types': ','.join(param_types),\n+            \"procedure\": self.quote_name(procedure_name),\n+            \"param_types\": \",\".join(param_types),\n         }\n         self.execute(sql)\n"}
{"instance_id": "django__django-12747", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 16dff6a1cd..76f4e0bb84 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -22,8 +22,11 @@ class RestrictedError(IntegrityError):\n \n def CASCADE(collector, field, sub_objs, using):\n     collector.collect(\n-        sub_objs, source=field.remote_field.model, source_attr=field.name,\n-        nullable=field.null, fail_on_restricted=False,\n+        sub_objs,\n+        source=field.remote_field.model,\n+        source_attr=field.name,\n+        nullable=field.null,\n+        fail_on_restricted=False,\n     )\n     if field.null and not connections[using].features.can_defer_constraint_checks:\n         collector.add_field_update(field, None, sub_objs)\n@@ -32,10 +35,13 @@ def CASCADE(collector, field, sub_objs, using):\n def PROTECT(collector, field, sub_objs, using):\n     raise ProtectedError(\n         \"Cannot delete some instances of model '%s' because they are \"\n-        \"referenced through a protected foreign key: '%s.%s'\" % (\n-            field.remote_field.model.__name__, sub_objs[0].__class__.__name__, field.name\n+        \"referenced through a protected foreign key: '%s.%s'\"\n+        % (\n+            field.remote_field.model.__name__,\n+            sub_objs[0].__class__.__name__,\n+            field.name,\n         ),\n-        sub_objs\n+        sub_objs,\n     )\n \n \n@@ -46,12 +52,15 @@ def RESTRICT(collector, field, sub_objs, using):\n \n def SET(value):\n     if callable(value):\n+\n         def set_on_delete(collector, field, sub_objs, using):\n             collector.add_field_update(field, value(), sub_objs)\n     else:\n+\n         def set_on_delete(collector, field, sub_objs, using):\n             collector.add_field_update(field, value, sub_objs)\n-    set_on_delete.deconstruct = lambda: ('django.db.models.SET', (value,), {})\n+\n+    set_on_delete.deconstruct = lambda: (\"django.db.models.SET\", (value,), {})\n     return set_on_delete\n \n \n@@ -71,7 +80,8 @@ def get_candidate_relations_to_delete(opts):\n     # The candidate relations are the ones that come from N-1 and 1-1 relations.\n     # N-N  (i.e., many-to-many) relations aren't candidates for deletion.\n     return (\n-        f for f in opts.get_fields(include_hidden=True)\n+        f\n+        for f in opts.get_fields(include_hidden=True)\n         if f.auto_created and not f.concrete and (f.one_to_one or f.one_to_many)\n     )\n \n@@ -123,7 +133,9 @@ class Collector:\n     def add_dependency(self, model, dependency, reverse_dependency=False):\n         if reverse_dependency:\n             model, dependency = dependency, model\n-        self.dependencies[model._meta.concrete_model].add(dependency._meta.concrete_model)\n+        self.dependencies[model._meta.concrete_model].add(\n+            dependency._meta.concrete_model\n+        )\n         self.data.setdefault(dependency, self.data.default_factory())\n \n     def add_field_update(self, field, value, objs):\n@@ -150,17 +162,21 @@ class Collector:\n \n     def clear_restricted_objects_from_queryset(self, model, qs):\n         if model in self.restricted_objects:\n-            objs = set(qs.filter(pk__in=[\n-                obj.pk\n-                for objs in self.restricted_objects[model].values() for obj in objs\n-            ]))\n+            objs = set(\n+                qs.filter(\n+                    pk__in=[\n+                        obj.pk\n+                        for objs in self.restricted_objects[model].values()\n+                        for obj in objs\n+                    ]\n+                )\n+            )\n             self.clear_restricted_objects_from_set(model, objs)\n \n     def _has_signal_listeners(self, model):\n-        return (\n-            signals.pre_delete.has_listeners(model) or\n-            signals.post_delete.has_listeners(model)\n-        )\n+        return signals.pre_delete.has_listeners(\n+            model\n+        ) or signals.post_delete.has_listeners(model)\n \n     def can_fast_delete(self, objs, from_field=None):\n         \"\"\"\n@@ -175,9 +191,9 @@ class Collector:\n         \"\"\"\n         if from_field and from_field.remote_field.on_delete is not CASCADE:\n             return False\n-        if hasattr(objs, '_meta'):\n+        if hasattr(objs, \"_meta\"):\n             model = objs._meta.model\n-        elif hasattr(objs, 'model') and hasattr(objs, '_raw_delete'):\n+        elif hasattr(objs, \"model\") and hasattr(objs, \"_raw_delete\"):\n             model = objs.model\n         else:\n             return False\n@@ -187,14 +203,22 @@ class Collector:\n         # parent when parent delete is cascading to child.\n         opts = model._meta\n         return (\n-            all(link == from_field for link in opts.concrete_model._meta.parents.values()) and\n+            all(\n+                link == from_field\n+                for link in opts.concrete_model._meta.parents.values()\n+            )\n+            and\n             # Foreign keys pointing to this model.\n             all(\n                 related.field.remote_field.on_delete is DO_NOTHING\n                 for related in get_candidate_relations_to_delete(opts)\n-            ) and (\n+            )\n+            and (\n                 # Something like generic foreign key.\n-                not any(hasattr(field, 'bulk_related_objects') for field in opts.private_fields)\n+                not any(\n+                    hasattr(field, \"bulk_related_objects\")\n+                    for field in opts.private_fields\n+                )\n             )\n         )\n \n@@ -204,16 +228,27 @@ class Collector:\n         \"\"\"\n         field_names = [field.name for field in fields]\n         conn_batch_size = max(\n-            connections[self.using].ops.bulk_batch_size(field_names, objs), 1)\n+            connections[self.using].ops.bulk_batch_size(field_names, objs), 1\n+        )\n         if len(objs) > conn_batch_size:\n-            return [objs[i:i + conn_batch_size]\n-                    for i in range(0, len(objs), conn_batch_size)]\n+            return [\n+                objs[i : i + conn_batch_size]\n+                for i in range(0, len(objs), conn_batch_size)\n+            ]\n         else:\n             return [objs]\n \n-    def collect(self, objs, source=None, nullable=False, collect_related=True,\n-                source_attr=None, reverse_dependency=False, keep_parents=False,\n-                fail_on_restricted=True):\n+    def collect(\n+        self,\n+        objs,\n+        source=None,\n+        nullable=False,\n+        collect_related=True,\n+        source_attr=None,\n+        reverse_dependency=False,\n+        keep_parents=False,\n+        fail_on_restricted=True,\n+    ):\n         \"\"\"\n         Add 'objs' to the collection of objects to be deleted as well as all\n         parent instances.  'objs' must be a homogeneous iterable collection of\n@@ -240,8 +275,9 @@ class Collector:\n         if self.can_fast_delete(objs):\n             self.fast_deletes.append(objs)\n             return\n-        new_objs = self.add(objs, source, nullable,\n-                            reverse_dependency=reverse_dependency)\n+        new_objs = self.add(\n+            objs, source, nullable, reverse_dependency=reverse_dependency\n+        )\n         if not new_objs:\n             return\n \n@@ -254,11 +290,14 @@ class Collector:\n             for ptr in concrete_model._meta.parents.values():\n                 if ptr:\n                     parent_objs = [getattr(obj, ptr.name) for obj in new_objs]\n-                    self.collect(parent_objs, source=model,\n-                                 source_attr=ptr.remote_field.related_name,\n-                                 collect_related=False,\n-                                 reverse_dependency=True,\n-                                 fail_on_restricted=False)\n+                    self.collect(\n+                        parent_objs,\n+                        source=model,\n+                        source_attr=ptr.remote_field.related_name,\n+                        collect_related=False,\n+                        reverse_dependency=True,\n+                        fail_on_restricted=False,\n+                    )\n         if not collect_related:\n             return\n \n@@ -286,11 +325,18 @@ class Collector:\n                 # relationships are select_related as interactions between both\n                 # features are hard to get right. This should only happen in\n                 # the rare cases where .related_objects is overridden anyway.\n-                if not (sub_objs.query.select_related or self._has_signal_listeners(related_model)):\n-                    referenced_fields = set(chain.from_iterable(\n-                        (rf.attname for rf in rel.field.foreign_related_fields)\n-                        for rel in get_candidate_relations_to_delete(related_model._meta)\n-                    ))\n+                if not (\n+                    sub_objs.query.select_related\n+                    or self._has_signal_listeners(related_model)\n+                ):\n+                    referenced_fields = set(\n+                        chain.from_iterable(\n+                            (rf.attname for rf in rel.field.foreign_related_fields)\n+                            for rel in get_candidate_relations_to_delete(\n+                                related_model._meta\n+                            )\n+                        )\n+                    )\n                     sub_objs = sub_objs.only(*tuple(referenced_fields))\n                 if sub_objs:\n                     try:\n@@ -300,10 +346,11 @@ class Collector:\n                         protected_objects[key] += error.protected_objects\n         if protected_objects:\n             raise ProtectedError(\n-                'Cannot delete some instances of model %r because they are '\n-                'referenced through protected foreign keys: %s.' % (\n+                \"Cannot delete some instances of model %r because they are \"\n+                \"referenced through protected foreign keys: %s.\"\n+                % (\n                     model.__name__,\n-                    ', '.join(protected_objects),\n+                    \", \".join(protected_objects),\n                 ),\n                 chain.from_iterable(protected_objects.values()),\n             )\n@@ -313,10 +360,12 @@ class Collector:\n                 sub_objs = self.related_objects(related_model, related_fields, batch)\n                 self.fast_deletes.append(sub_objs)\n         for field in model._meta.private_fields:\n-            if hasattr(field, 'bulk_related_objects'):\n+            if hasattr(field, \"bulk_related_objects\"):\n                 # It's something like generic foreign key.\n                 sub_objs = field.bulk_related_objects(new_objs, self.using)\n-                self.collect(sub_objs, source=model, nullable=True, fail_on_restricted=False)\n+                self.collect(\n+                    sub_objs, source=model, nullable=True, fail_on_restricted=False\n+                )\n \n         if fail_on_restricted:\n             # Raise an error if collected restricted objects (RESTRICT) aren't\n@@ -334,11 +383,12 @@ class Collector:\n                             restricted_objects[key] += objs\n                 if restricted_objects:\n                     raise RestrictedError(\n-                        'Cannot delete some instances of model %r because '\n-                        'they are referenced through restricted foreign keys: '\n-                        '%s.' % (\n+                        \"Cannot delete some instances of model %r because \"\n+                        \"they are referenced through restricted foreign keys: \"\n+                        \"%s.\"\n+                        % (\n                             model.__name__,\n-                            ', '.join(restricted_objects),\n+                            \", \".join(restricted_objects),\n                         ),\n                         chain.from_iterable(restricted_objects.values()),\n                     )\n@@ -347,10 +397,13 @@ class Collector:\n         \"\"\"\n         Get a QuerySet of the related model to objs via related fields.\n         \"\"\"\n-        predicate = reduce(operator.or_, (\n-            query_utils.Q(**{'%s__in' % related_field.name: objs})\n-            for related_field in related_fields\n-        ))\n+        predicate = reduce(\n+            operator.or_,\n+            (\n+                query_utils.Q(**{\"%s__in\" % related_field.name: objs})\n+                for related_field in related_fields\n+            ),\n+        )\n         return related_model._base_manager.using(self.using).filter(predicate)\n \n     def instances_with_model(self):\n@@ -393,7 +446,9 @@ class Collector:\n             instance = list(instances)[0]\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n-                    count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                    count = sql.DeleteQuery(model).delete_batch(\n+                        [instance.pk], self.using\n+                    )\n                 setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n@@ -408,14 +463,16 @@ class Collector:\n             # fast deletes\n             for qs in self.fast_deletes:\n                 count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                if count:\n+                    deleted_counter[qs.model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n                 for (field, value), instances in instances_for_fieldvalues.items():\n                     query = sql.UpdateQuery(model)\n-                    query.update_batch([obj.pk for obj in instances],\n-                                       {field.name: value}, self.using)\n+                    query.update_batch(\n+                        [obj.pk for obj in instances], {field.name: value}, self.using\n+                    )\n \n             # reverse instance collections\n             for instances in self.data.values():\n@@ -426,7 +483,8 @@ class Collector:\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n-                deleted_counter[model._meta.label] += count\n+                if count:\n+                    deleted_counter[model._meta.label] += count\n \n                 if not model._meta.auto_created:\n                     for obj in instances:\n"}
{"instance_id": "django__django-12856", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 7bb3fa4706..4487f77c07 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1866,6 +1866,9 @@ class Model(metaclass=ModelBase):\n     @classmethod\n     def _check_constraints(cls, databases):\n         errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                errors.extend(cls._check_local_fields(constraint.fields, 'constraints'))\n         for db in databases:\n             if not router.allow_migrate_model(db, cls):\n                 continue\n"}
{"instance_id": "django__django-12908", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex e0eeccefa6..4cdb69c98e 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -13,8 +13,12 @@ import django\n from django.conf import settings\n from django.core import exceptions\n from django.db import (\n-    DJANGO_VERSION_PICKLE_KEY, IntegrityError, NotSupportedError, connections,\n-    router, transaction,\n+    DJANGO_VERSION_PICKLE_KEY,\n+    IntegrityError,\n+    NotSupportedError,\n+    connections,\n+    router,\n+    transaction,\n )\n from django.db.models import AutoField, DateField, DateTimeField, sql\n from django.db.models.constants import LOOKUP_SEP\n@@ -35,7 +39,9 @@ REPR_OUTPUT_SIZE = 20\n \n \n class BaseIterable:\n-    def __init__(self, queryset, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n+    def __init__(\n+        self, queryset, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE\n+    ):\n         self.queryset = queryset\n         self.chunked_fetch = chunked_fetch\n         self.chunk_size = chunk_size\n@@ -50,25 +56,40 @@ class ModelIterable(BaseIterable):\n         compiler = queryset.query.get_compiler(using=db)\n         # Execute the query. This will also fill compiler.select, klass_info,\n         # and annotations.\n-        results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n-        select, klass_info, annotation_col_map = (compiler.select, compiler.klass_info,\n-                                                  compiler.annotation_col_map)\n-        model_cls = klass_info['model']\n-        select_fields = klass_info['select_fields']\n+        results = compiler.execute_sql(\n+            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n+        )\n+        select, klass_info, annotation_col_map = (\n+            compiler.select,\n+            compiler.klass_info,\n+            compiler.annotation_col_map,\n+        )\n+        model_cls = klass_info[\"model\"]\n+        select_fields = klass_info[\"select_fields\"]\n         model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1\n-        init_list = [f[0].target.attname\n-                     for f in select[model_fields_start:model_fields_end]]\n+        init_list = [\n+            f[0].target.attname for f in select[model_fields_start:model_fields_end]\n+        ]\n         related_populators = get_related_populators(klass_info, select, db)\n         known_related_objects = [\n-            (field, related_objs, operator.attrgetter(*[\n-                field.attname\n-                if from_field == 'self' else\n-                queryset.model._meta.get_field(from_field).attname\n-                for from_field in field.from_fields\n-            ])) for field, related_objs in queryset._known_related_objects.items()\n+            (\n+                field,\n+                related_objs,\n+                operator.attrgetter(\n+                    *[\n+                        field.attname\n+                        if from_field == \"self\"\n+                        else queryset.model._meta.get_field(from_field).attname\n+                        for from_field in field.from_fields\n+                    ]\n+                ),\n+            )\n+            for field, related_objs in queryset._known_related_objects.items()\n         ]\n         for row in compiler.results_iter(results):\n-            obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end])\n+            obj = model_cls.from_db(\n+                db, init_list, row[model_fields_start:model_fields_end]\n+            )\n             for rel_populator in related_populators:\n                 rel_populator.populate(row, obj)\n             if annotation_col_map:\n@@ -108,7 +129,9 @@ class ValuesIterable(BaseIterable):\n             *query.annotation_select,\n         ]\n         indexes = range(len(names))\n-        for row in compiler.results_iter(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size):\n+        for row in compiler.results_iter(\n+            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n+        ):\n             yield {names[i]: row[i] for i in indexes}\n \n \n@@ -130,16 +153,25 @@ class ValuesListIterable(BaseIterable):\n                 *query.values_select,\n                 *query.annotation_select,\n             ]\n-            fields = [*queryset._fields, *(f for f in query.annotation_select if f not in queryset._fields)]\n+            fields = [\n+                *queryset._fields,\n+                *(f for f in query.annotation_select if f not in queryset._fields),\n+            ]\n             if fields != names:\n                 # Reorder according to fields.\n                 index_map = {name: idx for idx, name in enumerate(names)}\n                 rowfactory = operator.itemgetter(*[index_map[f] for f in fields])\n                 return map(\n                     rowfactory,\n-                    compiler.results_iter(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n+                    compiler.results_iter(\n+                        chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n+                    ),\n                 )\n-        return compiler.results_iter(tuple_expected=True, chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n+        return compiler.results_iter(\n+            tuple_expected=True,\n+            chunked_fetch=self.chunked_fetch,\n+            chunk_size=self.chunk_size,\n+        )\n \n \n class NamedValuesListIterable(ValuesListIterable):\n@@ -153,7 +185,7 @@ class NamedValuesListIterable(ValuesListIterable):\n     def create_namedtuple_class(*names):\n         # Cache namedtuple() with @lru_cache() since it's too slow to be\n         # called for every QuerySet evaluation.\n-        return namedtuple('Row', names)\n+        return namedtuple(\"Row\", names)\n \n     def __iter__(self):\n         queryset = self.queryset\n@@ -161,7 +193,11 @@ class NamedValuesListIterable(ValuesListIterable):\n             names = queryset._fields\n         else:\n             query = queryset.query\n-            names = [*query.extra_select, *query.values_select, *query.annotation_select]\n+            names = [\n+                *query.extra_select,\n+                *query.values_select,\n+                *query.annotation_select,\n+            ]\n         tuple_class = self.create_namedtuple_class(*names)\n         new = tuple.__new__\n         for row in super().__iter__():\n@@ -177,7 +213,9 @@ class FlatValuesListIterable(BaseIterable):\n     def __iter__(self):\n         queryset = self.queryset\n         compiler = queryset.query.get_compiler(queryset.db)\n-        for row in compiler.results_iter(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size):\n+        for row in compiler.results_iter(\n+            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n+        ):\n             yield row[0]\n \n \n@@ -215,9 +253,11 @@ class QuerySet:\n     def as_manager(cls):\n         # Address the circular dependency between `Queryset` and `Manager`.\n         from django.db.models.manager import Manager\n+\n         manager = Manager.from_queryset(cls)()\n         manager._built_with_as_manager = True\n         return manager\n+\n     as_manager.queryset_only = True\n     as_manager = classmethod(as_manager)\n \n@@ -229,7 +269,7 @@ class QuerySet:\n         \"\"\"Don't populate the QuerySet's cache.\"\"\"\n         obj = self.__class__()\n         for k, v in self.__dict__.items():\n-            if k == '_result_cache':\n+            if k == \"_result_cache\":\n                 obj.__dict__[k] = None\n             else:\n                 obj.__dict__[k] = copy.deepcopy(v, memo)\n@@ -260,10 +300,10 @@ class QuerySet:\n         self.__dict__.update(state)\n \n     def __repr__(self):\n-        data = list(self[:REPR_OUTPUT_SIZE + 1])\n+        data = list(self[: REPR_OUTPUT_SIZE + 1])\n         if len(data) > REPR_OUTPUT_SIZE:\n             data[-1] = \"...(remaining elements truncated)...\"\n-        return '<%s %r>' % (self.__class__.__name__, data)\n+        return \"<%s %r>\" % (self.__class__.__name__, data)\n \n     def __len__(self):\n         self._fetch_all()\n@@ -295,13 +335,14 @@ class QuerySet:\n         \"\"\"Retrieve an item or slice from the set of results.\"\"\"\n         if not isinstance(k, (int, slice)):\n             raise TypeError(\n-                'QuerySet indices must be integers or slices, not %s.'\n+                \"QuerySet indices must be integers or slices, not %s.\"\n                 % type(k).__name__\n             )\n-        assert ((not isinstance(k, slice) and (k >= 0)) or\n-                (isinstance(k, slice) and (k.start is None or k.start >= 0) and\n-                 (k.stop is None or k.stop >= 0))), \\\n-            \"Negative indexing is not supported.\"\n+        assert (not isinstance(k, slice) and (k >= 0)) or (\n+            isinstance(k, slice)\n+            and (k.start is None or k.start >= 0)\n+            and (k.stop is None or k.stop >= 0)\n+        ), \"Negative indexing is not supported.\"\n \n         if self._result_cache is not None:\n             return self._result_cache[k]\n@@ -317,7 +358,7 @@ class QuerySet:\n             else:\n                 stop = None\n             qs.query.set_limits(start, stop)\n-            return list(qs)[::k.step] if k.step else qs\n+            return list(qs)[:: k.step] if k.step else qs\n \n         qs = self._chain()\n         qs.query.set_limits(k, k + 1)\n@@ -344,11 +385,15 @@ class QuerySet:\n             return other\n         if isinstance(other, EmptyQuerySet):\n             return self\n-        query = self if self.query.can_filter() else self.model._base_manager.filter(pk__in=self.values('pk'))\n+        query = (\n+            self\n+            if self.query.can_filter()\n+            else self.model._base_manager.filter(pk__in=self.values(\"pk\"))\n+        )\n         combined = query._chain()\n         combined._merge_known_related_objects(other)\n         if not other.query.can_filter():\n-            other = other.model._base_manager.filter(pk__in=other.values('pk'))\n+            other = other.model._base_manager.filter(pk__in=other.values(\"pk\"))\n         combined.query.combine(other.query, sql.OR)\n         return combined\n \n@@ -357,7 +402,9 @@ class QuerySet:\n     ####################################\n \n     def _iterator(self, use_chunked_fetch, chunk_size):\n-        yield from self._iterable_class(self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size)\n+        yield from self._iterable_class(\n+            self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size\n+        )\n \n     def iterator(self, chunk_size=2000):\n         \"\"\"\n@@ -365,8 +412,10 @@ class QuerySet:\n         database.\n         \"\"\"\n         if chunk_size <= 0:\n-            raise ValueError('Chunk size must be strictly positive.')\n-        use_chunked_fetch = not connections[self.db].settings_dict.get('DISABLE_SERVER_SIDE_CURSORS')\n+            raise ValueError(\"Chunk size must be strictly positive.\")\n+        use_chunked_fetch = not connections[self.db].settings_dict.get(\n+            \"DISABLE_SERVER_SIDE_CURSORS\"\n+        )\n         return self._iterator(use_chunked_fetch, chunk_size)\n \n     def aggregate(self, *args, **kwargs):\n@@ -379,7 +428,9 @@ class QuerySet:\n         \"\"\"\n         if self.query.distinct_fields:\n             raise NotImplementedError(\"aggregate() + distinct(fields) not implemented.\")\n-        self._validate_values_are_expressions((*args, *kwargs.values()), method_name='aggregate')\n+        self._validate_values_are_expressions(\n+            (*args, *kwargs.values()), method_name=\"aggregate\"\n+        )\n         for arg in args:\n             # The default_alias property raises TypeError if default_alias\n             # can't be set automatically or AttributeError if it isn't an\n@@ -391,7 +442,7 @@ class QuerySet:\n             kwargs[arg.default_alias] = arg\n \n         query = self.query.chain()\n-        for (alias, aggregate_expr) in kwargs.items():\n+        for alias, aggregate_expr in kwargs.items():\n             query.add_annotation(aggregate_expr, alias, is_summary=True)\n             if not query.annotations[alias].contains_aggregate:\n                 raise TypeError(\"%s is not an aggregate expression\" % alias)\n@@ -419,7 +470,10 @@ class QuerySet:\n         if self.query.can_filter() and not self.query.distinct_fields:\n             clone = clone.order_by()\n         limit = None\n-        if not clone.query.select_for_update or connections[clone.db].features.supports_select_for_update_with_limit:\n+        if (\n+            not clone.query.select_for_update\n+            or connections[clone.db].features.supports_select_for_update_with_limit\n+        ):\n             limit = MAX_GET_RESULTS\n             clone.query.set_limits(high=limit)\n         num = len(clone)\n@@ -427,13 +481,13 @@ class QuerySet:\n             return clone._result_cache[0]\n         if not num:\n             raise self.model.DoesNotExist(\n-                \"%s matching query does not exist.\" %\n-                self.model._meta.object_name\n+                \"%s matching query does not exist.\" % self.model._meta.object_name\n             )\n         raise self.model.MultipleObjectsReturned(\n-            'get() returned more than one %s -- it returned %s!' % (\n+            \"get() returned more than one %s -- it returned %s!\"\n+            % (\n                 self.model._meta.object_name,\n-                num if not limit or num < limit else 'more than %s' % (limit - 1),\n+                num if not limit or num < limit else \"more than %s\" % (limit - 1),\n             )\n         )\n \n@@ -492,7 +546,10 @@ class QuerySet:\n             objs_with_pk, objs_without_pk = partition(lambda o: o.pk is None, objs)\n             if objs_with_pk:\n                 returned_columns = self._batched_insert(\n-                    objs_with_pk, fields, batch_size, ignore_conflicts=ignore_conflicts,\n+                    objs_with_pk,\n+                    fields,\n+                    batch_size,\n+                    ignore_conflicts=ignore_conflicts,\n                 )\n                 for obj_with_pk, results in zip(objs_with_pk, returned_columns):\n                     for result, field in zip(results, opts.db_returning_fields):\n@@ -504,9 +561,15 @@ class QuerySet:\n             if objs_without_pk:\n                 fields = [f for f in fields if not isinstance(f, AutoField)]\n                 returned_columns = self._batched_insert(\n-                    objs_without_pk, fields, batch_size, ignore_conflicts=ignore_conflicts,\n+                    objs_without_pk,\n+                    fields,\n+                    batch_size,\n+                    ignore_conflicts=ignore_conflicts,\n                 )\n-                if connection.features.can_return_rows_from_bulk_insert and not ignore_conflicts:\n+                if (\n+                    connection.features.can_return_rows_from_bulk_insert\n+                    and not ignore_conflicts\n+                ):\n                     assert len(returned_columns) == len(objs_without_pk)\n                 for obj_without_pk, results in zip(objs_without_pk, returned_columns):\n                     for result, field in zip(results, opts.db_returning_fields):\n@@ -521,25 +584,27 @@ class QuerySet:\n         Update the given fields in each of the given objects in the database.\n         \"\"\"\n         if batch_size is not None and batch_size < 0:\n-            raise ValueError('Batch size must be a positive integer.')\n+            raise ValueError(\"Batch size must be a positive integer.\")\n         if not fields:\n-            raise ValueError('Field names must be given to bulk_update().')\n+            raise ValueError(\"Field names must be given to bulk_update().\")\n         objs = tuple(objs)\n         if any(obj.pk is None for obj in objs):\n-            raise ValueError('All bulk_update() objects must have a primary key set.')\n+            raise ValueError(\"All bulk_update() objects must have a primary key set.\")\n         fields = [self.model._meta.get_field(name) for name in fields]\n         if any(not f.concrete or f.many_to_many for f in fields):\n-            raise ValueError('bulk_update() can only be used with concrete fields.')\n+            raise ValueError(\"bulk_update() can only be used with concrete fields.\")\n         if any(f.primary_key for f in fields):\n-            raise ValueError('bulk_update() cannot be used with primary key fields.')\n+            raise ValueError(\"bulk_update() cannot be used with primary key fields.\")\n         if not objs:\n             return\n         # PK is used twice in the resulting update query, once in the filter\n         # and once in the WHEN. Each field will also have one CAST.\n-        max_batch_size = connections[self.db].ops.bulk_batch_size(['pk', 'pk'] + fields, objs)\n+        max_batch_size = connections[self.db].ops.bulk_batch_size(\n+            [\"pk\", \"pk\"] + fields, objs\n+        )\n         batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         requires_casting = connections[self.db].features.requires_casted_case_in_updates\n-        batches = (objs[i:i + batch_size] for i in range(0, len(objs), batch_size))\n+        batches = (objs[i : i + batch_size] for i in range(0, len(objs), batch_size))\n         updates = []\n         for batch_objs in batches:\n             update_kwargs = {}\n@@ -558,6 +623,7 @@ class QuerySet:\n         with transaction.atomic(using=self.db, savepoint=False):\n             for pks, update_kwargs in updates:\n                 self.filter(pk__in=pks).update(**update_kwargs)\n+\n     bulk_update.alters_data = True\n \n     def get_or_create(self, defaults=None, **kwargs):\n@@ -591,7 +657,9 @@ class QuerySet:\n                 params = self._extract_model_params(defaults, **kwargs)\n                 # Lock the row so that a concurrent update is blocked until\n                 # after update_or_create() has performed its save.\n-                obj, created = self._create_object_from_params(kwargs, params, lock=True)\n+                obj, created = self._create_object_from_params(\n+                    kwargs, params, lock=True\n+                )\n                 if created:\n                     return obj, created\n             for k, v in resolve_callables(defaults):\n@@ -636,10 +704,12 @@ class QuerySet:\n                     invalid_params.append(param)\n         if invalid_params:\n             raise exceptions.FieldError(\n-                \"Invalid field name(s) for model %s: '%s'.\" % (\n+                \"Invalid field name(s) for model %s: '%s'.\"\n+                % (\n                     self.model._meta.object_name,\n                     \"', '\".join(sorted(invalid_params)),\n-                ))\n+                )\n+            )\n         return params\n \n     def _earliest(self, *fields):\n@@ -650,7 +720,7 @@ class QuerySet:\n         if fields:\n             order_by = fields\n         else:\n-            order_by = getattr(self.model._meta, 'get_latest_by')\n+            order_by = getattr(self.model._meta, \"get_latest_by\")\n             if order_by and not isinstance(order_by, (tuple, list)):\n                 order_by = (order_by,)\n         if order_by is None:\n@@ -659,8 +729,9 @@ class QuerySet:\n                 \"arguments or 'get_latest_by' in the model's Meta.\"\n             )\n \n-        assert not self.query.is_sliced, \\\n+        assert not self.query.is_sliced, (\n             \"Cannot change a query once a slice has been taken.\"\n+        )\n         obj = self._chain()\n         obj.query.set_limits(high=1)\n         obj.query.clear_ordering(force_empty=True)\n@@ -675,21 +746,20 @@ class QuerySet:\n \n     def first(self):\n         \"\"\"Return the first object of a query or None if no match is found.\"\"\"\n-        for obj in (self if self.ordered else self.order_by('pk'))[:1]:\n+        for obj in (self if self.ordered else self.order_by(\"pk\"))[:1]:\n             return obj\n \n     def last(self):\n         \"\"\"Return the last object of a query or None if no match is found.\"\"\"\n-        for obj in (self.reverse() if self.ordered else self.order_by('-pk'))[:1]:\n+        for obj in (self.reverse() if self.ordered else self.order_by(\"-pk\"))[:1]:\n             return obj\n \n-    def in_bulk(self, id_list=None, *, field_name='pk'):\n+    def in_bulk(self, id_list=None, *, field_name=\"pk\"):\n         \"\"\"\n         Return a dictionary mapping each of the given IDs to the object with\n         that ID. If `id_list` isn't provided, evaluate the entire QuerySet.\n         \"\"\"\n-        assert not self.query.is_sliced, \\\n-            \"Cannot use 'limit' or 'offset' with in_bulk\"\n+        assert not self.query.is_sliced, \"Cannot use 'limit' or 'offset' with in_bulk\"\n         opts = self.model._meta\n         unique_fields = [\n             constraint.fields[0]\n@@ -697,15 +767,18 @@ class QuerySet:\n             if len(constraint.fields) == 1\n         ]\n         if (\n-            field_name != 'pk' and\n-            not opts.get_field(field_name).unique and\n-            field_name not in unique_fields\n+            field_name != \"pk\"\n+            and not opts.get_field(field_name).unique\n+            and field_name not in unique_fields\n         ):\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+            raise ValueError(\n+                \"in_bulk()'s field_name must be a unique field but %r isn't.\"\n+                % field_name\n+            )\n         if id_list is not None:\n             if not id_list:\n                 return {}\n-            filter_key = '{}__in'.format(field_name)\n+            filter_key = \"{}__in\".format(field_name)\n             batch_size = connections[self.db].features.max_query_params\n             id_list = tuple(id_list)\n             # If the database has a limit on the number of query parameters\n@@ -713,7 +786,7 @@ class QuerySet:\n             if batch_size and batch_size < len(id_list):\n                 qs = ()\n                 for offset in range(0, len(id_list), batch_size):\n-                    batch = id_list[offset:offset + batch_size]\n+                    batch = id_list[offset : offset + batch_size]\n                     qs += tuple(self.filter(**{filter_key: batch}).order_by())\n             else:\n                 qs = self.filter(**{filter_key: id_list}).order_by()\n@@ -723,9 +796,8 @@ class QuerySet:\n \n     def delete(self):\n         \"\"\"Delete the records in the current QuerySet.\"\"\"\n-        self._not_support_combined_queries('delete')\n-        assert not self.query.is_sliced, \\\n-            \"Cannot use 'limit' or 'offset' with delete.\"\n+        self._not_support_combined_queries(\"delete\")\n+        assert not self.query.is_sliced, \"Cannot use 'limit' or 'offset' with delete.\"\n \n         if self._fields is not None:\n             raise TypeError(\"Cannot call delete() after .values() or .values_list()\")\n@@ -765,6 +837,7 @@ class QuerySet:\n             with cursor:\n                 return cursor.rowcount\n         return 0\n+\n     _raw_delete.alters_data = True\n \n     def update(self, **kwargs):\n@@ -772,9 +845,10 @@ class QuerySet:\n         Update all elements in the current QuerySet, setting all the given\n         fields to the appropriate values.\n         \"\"\"\n-        self._not_support_combined_queries('update')\n-        assert not self.query.is_sliced, \\\n+        self._not_support_combined_queries(\"update\")\n+        assert not self.query.is_sliced, (\n             \"Cannot update a query once a slice has been taken.\"\n+        )\n         self._for_write = True\n         query = self.query.chain(sql.UpdateQuery)\n         query.add_update_values(kwargs)\n@@ -784,6 +858,7 @@ class QuerySet:\n             rows = query.get_compiler(self.db).execute_sql(CURSOR)\n         self._result_cache = None\n         return rows\n+\n     update.alters_data = True\n \n     def _update(self, values):\n@@ -793,14 +868,16 @@ class QuerySet:\n         code (it requires too much poking around at model internals to be\n         useful at that level).\n         \"\"\"\n-        assert not self.query.is_sliced, \\\n+        assert not self.query.is_sliced, (\n             \"Cannot update a query once a slice has been taken.\"\n+        )\n         query = self.query.chain(sql.UpdateQuery)\n         query.add_update_fields(values)\n         # Clear any annotations so that they won't be present in subqueries.\n         query.annotations = {}\n         self._result_cache = None\n         return query.get_compiler(self.db).execute_sql(CURSOR)\n+\n     _update.alters_data = True\n     _update.queryset_only = False\n \n@@ -824,7 +901,13 @@ class QuerySet:\n     def raw(self, raw_query, params=None, translations=None, using=None):\n         if using is None:\n             using = self.db\n-        qs = RawQuerySet(raw_query, model=self.model, params=params, translations=translations, using=using)\n+        qs = RawQuerySet(\n+            raw_query,\n+            model=self.model,\n+            params=params,\n+            translations=translations,\n+            using=using,\n+        )\n         qs._prefetch_related_lookups = self._prefetch_related_lookups[:]\n         return qs\n \n@@ -846,15 +929,19 @@ class QuerySet:\n         if flat and named:\n             raise TypeError(\"'flat' and 'named' can't be used together.\")\n         if flat and len(fields) > 1:\n-            raise TypeError(\"'flat' is not valid when values_list is called with more than one field.\")\n+            raise TypeError(\n+                \"'flat' is not valid when values_list is called with more than one field.\"\n+            )\n \n-        field_names = {f for f in fields if not hasattr(f, 'resolve_expression')}\n+        field_names = {f for f in fields if not hasattr(f, \"resolve_expression\")}\n         _fields = []\n         expressions = {}\n         counter = 1\n         for field in fields:\n-            if hasattr(field, 'resolve_expression'):\n-                field_id_prefix = getattr(field, 'default_alias', field.__class__.__name__.lower())\n+            if hasattr(field, \"resolve_expression\"):\n+                field_id_prefix = getattr(\n+                    field, \"default_alias\", field.__class__.__name__.lower()\n+                )\n                 while True:\n                     field_id = field_id_prefix + str(counter)\n                     counter += 1\n@@ -867,54 +954,64 @@ class QuerySet:\n \n         clone = self._values(*_fields, **expressions)\n         clone._iterable_class = (\n-            NamedValuesListIterable if named\n-            else FlatValuesListIterable if flat\n+            NamedValuesListIterable\n+            if named\n+            else FlatValuesListIterable\n+            if flat\n             else ValuesListIterable\n         )\n         return clone\n \n-    def dates(self, field_name, kind, order='ASC'):\n+    def dates(self, field_name, kind, order=\"ASC\"):\n         \"\"\"\n         Return a list of date objects representing all available dates for\n         the given field_name, scoped to 'kind'.\n         \"\"\"\n-        assert kind in ('year', 'month', 'week', 'day'), \\\n+        assert kind in (\"year\", \"month\", \"week\", \"day\"), (\n             \"'kind' must be one of 'year', 'month', 'week', or 'day'.\"\n-        assert order in ('ASC', 'DESC'), \\\n-            \"'order' must be either 'ASC' or 'DESC'.\"\n-        return self.annotate(\n-            datefield=Trunc(field_name, kind, output_field=DateField()),\n-            plain_field=F(field_name)\n-        ).values_list(\n-            'datefield', flat=True\n-        ).distinct().filter(plain_field__isnull=False).order_by(('-' if order == 'DESC' else '') + 'datefield')\n+        )\n+        assert order in (\"ASC\", \"DESC\"), \"'order' must be either 'ASC' or 'DESC'.\"\n+        return (\n+            self.annotate(\n+                datefield=Trunc(field_name, kind, output_field=DateField()),\n+                plain_field=F(field_name),\n+            )\n+            .values_list(\"datefield\", flat=True)\n+            .distinct()\n+            .filter(plain_field__isnull=False)\n+            .order_by((\"-\" if order == \"DESC\" else \"\") + \"datefield\")\n+        )\n \n-    def datetimes(self, field_name, kind, order='ASC', tzinfo=None, is_dst=None):\n+    def datetimes(self, field_name, kind, order=\"ASC\", tzinfo=None, is_dst=None):\n         \"\"\"\n         Return a list of datetime objects representing all available\n         datetimes for the given field_name, scoped to 'kind'.\n         \"\"\"\n-        assert kind in ('year', 'month', 'week', 'day', 'hour', 'minute', 'second'), \\\n+        assert kind in (\"year\", \"month\", \"week\", \"day\", \"hour\", \"minute\", \"second\"), (\n             \"'kind' must be one of 'year', 'month', 'week', 'day', 'hour', 'minute', or 'second'.\"\n-        assert order in ('ASC', 'DESC'), \\\n-            \"'order' must be either 'ASC' or 'DESC'.\"\n+        )\n+        assert order in (\"ASC\", \"DESC\"), \"'order' must be either 'ASC' or 'DESC'.\"\n         if settings.USE_TZ:\n             if tzinfo is None:\n                 tzinfo = timezone.get_current_timezone()\n         else:\n             tzinfo = None\n-        return self.annotate(\n-            datetimefield=Trunc(\n-                field_name,\n-                kind,\n-                output_field=DateTimeField(),\n-                tzinfo=tzinfo,\n-                is_dst=is_dst,\n-            ),\n-            plain_field=F(field_name)\n-        ).values_list(\n-            'datetimefield', flat=True\n-        ).distinct().filter(plain_field__isnull=False).order_by(('-' if order == 'DESC' else '') + 'datetimefield')\n+        return (\n+            self.annotate(\n+                datetimefield=Trunc(\n+                    field_name,\n+                    kind,\n+                    output_field=DateTimeField(),\n+                    tzinfo=tzinfo,\n+                    is_dst=is_dst,\n+                ),\n+                plain_field=F(field_name),\n+            )\n+            .values_list(\"datetimefield\", flat=True)\n+            .distinct()\n+            .filter(plain_field__isnull=False)\n+            .order_by((\"-\" if order == \"DESC\" else \"\") + \"datetimefield\")\n+        )\n \n     def none(self):\n         \"\"\"Return an empty QuerySet.\"\"\"\n@@ -938,7 +1035,7 @@ class QuerySet:\n         Return a new QuerySet instance with the args ANDed to the existing\n         set.\n         \"\"\"\n-        self._not_support_combined_queries('filter')\n+        self._not_support_combined_queries(\"filter\")\n         return self._filter_or_exclude(False, *args, **kwargs)\n \n     def exclude(self, *args, **kwargs):\n@@ -946,13 +1043,14 @@ class QuerySet:\n         Return a new QuerySet instance with NOT (args) ANDed to the existing\n         set.\n         \"\"\"\n-        self._not_support_combined_queries('exclude')\n+        self._not_support_combined_queries(\"exclude\")\n         return self._filter_or_exclude(True, *args, **kwargs)\n \n     def _filter_or_exclude(self, negate, *args, **kwargs):\n         if args or kwargs:\n-            assert not self.query.is_sliced, \\\n+            assert not self.query.is_sliced, (\n                 \"Cannot filter a query once a slice has been taken.\"\n+            )\n \n         clone = self._chain()\n         if self._defer_next_filter:\n@@ -991,7 +1089,9 @@ class QuerySet:\n         # Clear limits and ordering so they can be reapplied\n         clone.query.clear_ordering(True)\n         clone.query.clear_limits()\n-        clone.query.combined_queries = (self.query,) + tuple(qs.query for qs in other_qs)\n+        clone.query.combined_queries = (self.query,) + tuple(\n+            qs.query for qs in other_qs\n+        )\n         clone.query.combinator = combinator\n         clone.query.combinator_all = all\n         return clone\n@@ -1000,8 +1100,8 @@ class QuerySet:\n         # If the query is an EmptyQuerySet, combine all nonempty querysets.\n         if isinstance(self, EmptyQuerySet):\n             qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]\n-            return qs[0]._combinator_query('union', *qs[1:], all=all) if qs else self\n-        return self._combinator_query('union', *other_qs, all=all)\n+            return qs[0]._combinator_query(\"union\", *qs[1:], all=all) if qs else self\n+        return self._combinator_query(\"union\", *other_qs, all=all)\n \n     def intersection(self, *other_qs):\n         # If any query is an EmptyQuerySet, return it.\n@@ -1010,13 +1110,13 @@ class QuerySet:\n         for other in other_qs:\n             if isinstance(other, EmptyQuerySet):\n                 return other\n-        return self._combinator_query('intersection', *other_qs)\n+        return self._combinator_query(\"intersection\", *other_qs)\n \n     def difference(self, *other_qs):\n         # If the query is an EmptyQuerySet, return it.\n         if isinstance(self, EmptyQuerySet):\n             return self\n-        return self._combinator_query('difference', *other_qs)\n+        return self._combinator_query(\"difference\", *other_qs)\n \n     def select_for_update(self, nowait=False, skip_locked=False, of=()):\n         \"\"\"\n@@ -1024,7 +1124,7 @@ class QuerySet:\n         FOR UPDATE lock.\n         \"\"\"\n         if nowait and skip_locked:\n-            raise ValueError('The nowait option cannot be used with skip_locked.')\n+            raise ValueError(\"The nowait option cannot be used with skip_locked.\")\n         obj = self._chain()\n         obj._for_write = True\n         obj.query.select_for_update = True\n@@ -1042,9 +1142,11 @@ class QuerySet:\n \n         If select_related(None) is called, clear the list.\n         \"\"\"\n-        self._not_support_combined_queries('select_related')\n+        self._not_support_combined_queries(\"select_related\")\n         if self._fields is not None:\n-            raise TypeError(\"Cannot call select_related() after .values() or .values_list()\")\n+            raise TypeError(\n+                \"Cannot call select_related() after .values() or .values_list()\"\n+            )\n \n         obj = self._chain()\n         if fields == (None,):\n@@ -1064,7 +1166,7 @@ class QuerySet:\n         When prefetch_related() is called more than once, append to the list of\n         prefetch lookups. If prefetch_related(None) is called, clear the list.\n         \"\"\"\n-        self._not_support_combined_queries('prefetch_related')\n+        self._not_support_combined_queries(\"prefetch_related\")\n         clone = self._chain()\n         if lookups == (None,):\n             clone._prefetch_related_lookups = ()\n@@ -1074,7 +1176,9 @@ class QuerySet:\n                     lookup = lookup.prefetch_to\n                 lookup = lookup.split(LOOKUP_SEP, 1)[0]\n                 if lookup in self.query._filtered_relations:\n-                    raise ValueError('prefetch_related() is not supported with FilteredRelation.')\n+                    raise ValueError(\n+                        \"prefetch_related() is not supported with FilteredRelation.\"\n+                    )\n             clone._prefetch_related_lookups = clone._prefetch_related_lookups + lookups\n         return clone\n \n@@ -1083,16 +1187,19 @@ class QuerySet:\n         Return a query set in which the returned objects have been annotated\n         with extra data or aggregations.\n         \"\"\"\n-        self._not_support_combined_queries('annotate')\n-        self._validate_values_are_expressions(args + tuple(kwargs.values()), method_name='annotate')\n+        self._not_support_combined_queries(\"annotate\")\n+        self._validate_values_are_expressions(\n+            args + tuple(kwargs.values()), method_name=\"annotate\"\n+        )\n         annotations = {}\n         for arg in args:\n             # The default_alias property may raise a TypeError.\n             try:\n                 if arg.default_alias in kwargs:\n-                    raise ValueError(\"The named annotation '%s' conflicts with the \"\n-                                     \"default name for another annotation.\"\n-                                     % arg.default_alias)\n+                    raise ValueError(\n+                        \"The named annotation '%s' conflicts with the \"\n+                        \"default name for another annotation.\" % arg.default_alias\n+                    )\n             except TypeError:\n                 raise TypeError(\"Complex annotations require an alias\")\n             annotations[arg.default_alias] = arg\n@@ -1101,15 +1208,20 @@ class QuerySet:\n         clone = self._chain()\n         names = self._fields\n         if names is None:\n-            names = set(chain.from_iterable(\n-                (field.name, field.attname) if hasattr(field, 'attname') else (field.name,)\n-                for field in self.model._meta.get_fields()\n-            ))\n+            names = set(\n+                chain.from_iterable(\n+                    (field.name, field.attname)\n+                    if hasattr(field, \"attname\")\n+                    else (field.name,)\n+                    for field in self.model._meta.get_fields()\n+                )\n+            )\n \n         for alias, annotation in annotations.items():\n             if alias in names:\n-                raise ValueError(\"The annotation '%s' conflicts with a field on \"\n-                                 \"the model.\" % alias)\n+                raise ValueError(\n+                    \"The annotation '%s' conflicts with a field on the model.\" % alias\n+                )\n             if isinstance(annotation, FilteredRelation):\n                 clone.query.add_filtered_relation(annotation, alias)\n             else:\n@@ -1127,8 +1239,9 @@ class QuerySet:\n \n     def order_by(self, *field_names):\n         \"\"\"Return a new QuerySet instance with the ordering changed.\"\"\"\n-        assert not self.query.is_sliced, \\\n+        assert not self.query.is_sliced, (\n             \"Cannot reorder a query once a slice has been taken.\"\n+        )\n         obj = self._chain()\n         obj.query.clear_ordering(force_empty=False)\n         obj.query.add_ordering(*field_names)\n@@ -1138,18 +1251,28 @@ class QuerySet:\n         \"\"\"\n         Return a new QuerySet instance that will select only distinct results.\n         \"\"\"\n-        assert not self.query.is_sliced, \\\n+        assert not self.query.is_sliced, (\n             \"Cannot create distinct fields once a slice has been taken.\"\n+        )\n+        self._not_support_combined_queries(\"distinct\")\n         obj = self._chain()\n         obj.query.add_distinct_fields(*field_names)\n         return obj\n \n-    def extra(self, select=None, where=None, params=None, tables=None,\n-              order_by=None, select_params=None):\n+    def extra(\n+        self,\n+        select=None,\n+        where=None,\n+        params=None,\n+        tables=None,\n+        order_by=None,\n+        select_params=None,\n+    ):\n         \"\"\"Add extra SQL fragments to the query.\"\"\"\n-        self._not_support_combined_queries('extra')\n-        assert not self.query.is_sliced, \\\n+        self._not_support_combined_queries(\"extra\")\n+        assert not self.query.is_sliced, (\n             \"Cannot change a query once a slice has been taken\"\n+        )\n         clone = self._chain()\n         clone.query.add_extra(select, select_params, where, params, tables, order_by)\n         return clone\n@@ -1157,7 +1280,7 @@ class QuerySet:\n     def reverse(self):\n         \"\"\"Reverse the ordering of the QuerySet.\"\"\"\n         if self.query.is_sliced:\n-            raise TypeError('Cannot reverse a query once a slice has been taken.')\n+            raise TypeError(\"Cannot reverse a query once a slice has been taken.\")\n         clone = self._chain()\n         clone.query.standard_ordering = not clone.query.standard_ordering\n         return clone\n@@ -1169,7 +1292,7 @@ class QuerySet:\n         The only exception to this is if None is passed in as the only\n         parameter, in which case removal all deferrals.\n         \"\"\"\n-        self._not_support_combined_queries('defer')\n+        self._not_support_combined_queries(\"defer\")\n         if self._fields is not None:\n             raise TypeError(\"Cannot call defer() after .values() or .values_list()\")\n         clone = self._chain()\n@@ -1185,7 +1308,7 @@ class QuerySet:\n         method and that are not already specified as deferred are loaded\n         immediately when the queryset is evaluated.\n         \"\"\"\n-        self._not_support_combined_queries('only')\n+        self._not_support_combined_queries(\"only\")\n         if self._fields is not None:\n             raise TypeError(\"Cannot call only() after .values() or .values_list()\")\n         if fields == (None,):\n@@ -1195,7 +1318,7 @@ class QuerySet:\n         for field in fields:\n             field = field.split(LOOKUP_SEP, 1)[0]\n             if field in self.query._filtered_relations:\n-                raise ValueError('only() is not supported with FilteredRelation.')\n+                raise ValueError(\"only() is not supported with FilteredRelation.\")\n         clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n         return clone\n@@ -1236,7 +1359,15 @@ class QuerySet:\n     # PRIVATE METHODS #\n     ###################\n \n-    def _insert(self, objs, fields, returning_fields=None, raw=False, using=None, ignore_conflicts=False):\n+    def _insert(\n+        self,\n+        objs,\n+        fields,\n+        returning_fields=None,\n+        raw=False,\n+        using=None,\n+        ignore_conflicts=False,\n+    ):\n         \"\"\"\n         Insert a new record for the given model. This provides an interface to\n         the InsertQuery class and is how Model.save() is implemented.\n@@ -1247,6 +1378,7 @@ class QuerySet:\n         query = sql.InsertQuery(self.model, ignore_conflicts=ignore_conflicts)\n         query.insert_values(fields, objs, raw=raw)\n         return query.get_compiler(using=using).execute_sql(returning_fields)\n+\n     _insert.alters_data = True\n     _insert.queryset_only = False\n \n@@ -1254,22 +1386,36 @@ class QuerySet:\n         \"\"\"\n         Helper method for bulk_create() to insert objs one batch at a time.\n         \"\"\"\n-        if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n-            raise NotSupportedError('This database backend does not support ignoring conflicts.')\n+        if (\n+            ignore_conflicts\n+            and not connections[self.db].features.supports_ignore_conflicts\n+        ):\n+            raise NotSupportedError(\n+                \"This database backend does not support ignoring conflicts.\"\n+            )\n         ops = connections[self.db].ops\n         max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n         batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n-        for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n+        for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n             if bulk_return and not ignore_conflicts:\n-                inserted_rows.extend(self._insert(\n-                    item, fields=fields, using=self.db,\n-                    returning_fields=self.model._meta.db_returning_fields,\n-                    ignore_conflicts=ignore_conflicts,\n-                ))\n+                inserted_rows.extend(\n+                    self._insert(\n+                        item,\n+                        fields=fields,\n+                        using=self.db,\n+                        returning_fields=self.model._meta.db_returning_fields,\n+                        ignore_conflicts=ignore_conflicts,\n+                    )\n+                )\n             else:\n-                self._insert(item, fields=fields, using=self.db, ignore_conflicts=ignore_conflicts)\n+                self._insert(\n+                    item,\n+                    fields=fields,\n+                    using=self.db,\n+                    ignore_conflicts=ignore_conflicts,\n+                )\n         return inserted_rows\n \n     def _chain(self, **kwargs):\n@@ -1289,7 +1435,12 @@ class QuerySet:\n         Return a copy of the current QuerySet. A lightweight alternative\n         to deepcopy().\n         \"\"\"\n-        c = self.__class__(model=self.model, query=self.query.chain(), using=self._db, hints=self._hints)\n+        c = self.__class__(\n+            model=self.model,\n+            query=self.query.chain(),\n+            using=self._db,\n+            hints=self._hints,\n+        )\n         c._sticky_filter = self._sticky_filter\n         c._for_write = self._for_write\n         c._prefetch_related_lookups = self._prefetch_related_lookups[:]\n@@ -1321,9 +1472,10 @@ class QuerySet:\n     def _merge_sanity_check(self, other):\n         \"\"\"Check that two QuerySet classes may be merged.\"\"\"\n         if self._fields is not None and (\n-                set(self.query.values_select) != set(other.query.values_select) or\n-                set(self.query.extra_select) != set(other.query.extra_select) or\n-                set(self.query.annotation_select) != set(other.query.annotation_select)):\n+            set(self.query.values_select) != set(other.query.values_select)\n+            or set(self.query.extra_select) != set(other.query.extra_select)\n+            or set(self.query.annotation_select) != set(other.query.annotation_select)\n+        ):\n             raise TypeError(\n                 \"Merging '%s' classes must involve the same values in each case.\"\n                 % self.__class__.__name__\n@@ -1340,10 +1492,11 @@ class QuerySet:\n         if self._fields and len(self._fields) > 1:\n             # values() queryset can only be used as nested queries\n             # if they are set up to select only a single field.\n-            raise TypeError('Cannot use multi-field values as a filter value.')\n+            raise TypeError(\"Cannot use multi-field values as a filter value.\")\n         query = self.query.resolve_expression(*args, **kwargs)\n         query._db = self._db\n         return query\n+\n     resolve_expression.queryset_only = True\n \n     def _add_hints(self, **hints):\n@@ -1363,19 +1516,22 @@ class QuerySet:\n \n     @staticmethod\n     def _validate_values_are_expressions(values, method_name):\n-        invalid_args = sorted(str(arg) for arg in values if not hasattr(arg, 'resolve_expression'))\n+        invalid_args = sorted(\n+            str(arg) for arg in values if not hasattr(arg, \"resolve_expression\")\n+        )\n         if invalid_args:\n             raise TypeError(\n-                'QuerySet.%s() received non-expression(s): %s.' % (\n+                \"QuerySet.%s() received non-expression(s): %s.\"\n+                % (\n                     method_name,\n-                    ', '.join(invalid_args),\n+                    \", \".join(invalid_args),\n                 )\n             )\n \n     def _not_support_combined_queries(self, operation_name):\n         if self.query.combinator:\n             raise NotSupportedError(\n-                'Calling QuerySet.%s() after %s() is not supported.'\n+                \"Calling QuerySet.%s() after %s() is not supported.\"\n                 % (operation_name, self.query.combinator)\n             )\n \n@@ -1400,8 +1556,17 @@ class RawQuerySet:\n     Provide an iterator which converts the results of raw SQL queries into\n     annotated model instances.\n     \"\"\"\n-    def __init__(self, raw_query, model=None, query=None, params=None,\n-                 translations=None, using=None, hints=None):\n+\n+    def __init__(\n+        self,\n+        raw_query,\n+        model=None,\n+        query=None,\n+        params=None,\n+        translations=None,\n+        using=None,\n+        hints=None,\n+    ):\n         self.raw_query = raw_query\n         self.model = model\n         self._db = using\n@@ -1416,10 +1581,17 @@ class RawQuerySet:\n     def resolve_model_init_order(self):\n         \"\"\"Resolve the init field names and value positions.\"\"\"\n         converter = connections[self.db].introspection.identifier_converter\n-        model_init_fields = [f for f in self.model._meta.fields if converter(f.column) in self.columns]\n-        annotation_fields = [(column, pos) for pos, column in enumerate(self.columns)\n-                             if column not in self.model_fields]\n-        model_init_order = [self.columns.index(converter(f.column)) for f in model_init_fields]\n+        model_init_fields = [\n+            f for f in self.model._meta.fields if converter(f.column) in self.columns\n+        ]\n+        annotation_fields = [\n+            (column, pos)\n+            for pos, column in enumerate(self.columns)\n+            if column not in self.model_fields\n+        ]\n+        model_init_order = [\n+            self.columns.index(converter(f.column)) for f in model_init_fields\n+        ]\n         model_init_names = [f.attname for f in model_init_fields]\n         return model_init_names, model_init_order, annotation_fields\n \n@@ -1439,8 +1611,13 @@ class RawQuerySet:\n     def _clone(self):\n         \"\"\"Same as QuerySet._clone()\"\"\"\n         c = self.__class__(\n-            self.raw_query, model=self.model, query=self.query, params=self.params,\n-            translations=self.translations, using=self._db, hints=self._hints\n+            self.raw_query,\n+            model=self.model,\n+            query=self.query,\n+            params=self.params,\n+            translations=self.translations,\n+            using=self._db,\n+            hints=self._hints,\n         )\n         c._prefetch_related_lookups = self._prefetch_related_lookups[:]\n         return c\n@@ -1466,23 +1643,25 @@ class RawQuerySet:\n     def iterator(self):\n         # Cache some things for performance reasons outside the loop.\n         db = self.db\n-        compiler = connections[db].ops.compiler('SQLCompiler')(\n+        compiler = connections[db].ops.compiler(\"SQLCompiler\")(\n             self.query, connections[db], db\n         )\n \n         query = iter(self.query)\n \n         try:\n-            model_init_names, model_init_pos, annotation_fields = self.resolve_model_init_order()\n+            model_init_names, model_init_pos, annotation_fields = (\n+                self.resolve_model_init_order()\n+            )\n             if self.model._meta.pk.attname not in model_init_names:\n                 raise exceptions.FieldDoesNotExist(\n-                    'Raw query must include the primary key'\n+                    \"Raw query must include the primary key\"\n                 )\n             model_cls = self.model\n             fields = [self.model_fields.get(c) for c in self.columns]\n-            converters = compiler.get_converters([\n-                f.get_col(f.model._meta.db_table) if f else None for f in fields\n-            ])\n+            converters = compiler.get_converters(\n+                [f.get_col(f.model._meta.db_table) if f else None for f in fields]\n+            )\n             if converters:\n                 query = compiler.apply_converters(query, converters)\n             for values in query:\n@@ -1495,7 +1674,7 @@ class RawQuerySet:\n                 yield instance\n         finally:\n             # Done iterating the Query. If it has its own cursor, close it.\n-            if hasattr(self.query, 'cursor') and self.query.cursor:\n+            if hasattr(self.query, \"cursor\") and self.query.cursor:\n                 self.query.cursor.close()\n \n     def __repr__(self):\n@@ -1512,9 +1691,11 @@ class RawQuerySet:\n     def using(self, alias):\n         \"\"\"Select the database this RawQuerySet should execute against.\"\"\"\n         return RawQuerySet(\n-            self.raw_query, model=self.model,\n+            self.raw_query,\n+            model=self.model,\n             query=self.query.chain(using=alias),\n-            params=self.params, translations=self.translations,\n+            params=self.params,\n+            translations=self.translations,\n             using=alias,\n         )\n \n@@ -1526,7 +1707,7 @@ class RawQuerySet:\n         \"\"\"\n         columns = self.query.get_columns()\n         # Adjust any column names which don't match field names\n-        for (query_name, model_name) in self.translations.items():\n+        for query_name, model_name in self.translations.items():\n             # Ignore translations for nonexistent column names\n             try:\n                 index = columns.index(query_name)\n@@ -1554,17 +1735,19 @@ class Prefetch:\n         # `prefetch_to` is the path to the attribute that stores the result.\n         self.prefetch_to = lookup\n         if queryset is not None and (\n-            isinstance(queryset, RawQuerySet) or (\n-                hasattr(queryset, '_iterable_class') and\n-                not issubclass(queryset._iterable_class, ModelIterable)\n+            isinstance(queryset, RawQuerySet)\n+            or (\n+                hasattr(queryset, \"_iterable_class\")\n+                and not issubclass(queryset._iterable_class, ModelIterable)\n             )\n         ):\n             raise ValueError(\n-                'Prefetch querysets cannot use raw(), values(), and '\n-                'values_list().'\n+                \"Prefetch querysets cannot use raw(), values(), and values_list().\"\n             )\n         if to_attr:\n-            self.prefetch_to = LOOKUP_SEP.join(lookup.split(LOOKUP_SEP)[:-1] + [to_attr])\n+            self.prefetch_to = LOOKUP_SEP.join(\n+                lookup.split(LOOKUP_SEP)[:-1] + [to_attr]\n+            )\n \n         self.queryset = queryset\n         self.to_attr = to_attr\n@@ -1573,7 +1756,7 @@ class Prefetch:\n         obj_dict = self.__dict__.copy()\n         if self.queryset is not None:\n             # Prevent the QuerySet from being evaluated\n-            obj_dict['queryset'] = self.queryset._chain(\n+            obj_dict[\"queryset\"] = self.queryset._chain(\n                 _result_cache=[],\n                 _prefetch_done=True,\n             )\n@@ -1584,7 +1767,7 @@ class Prefetch:\n         self.prefetch_to = prefix + LOOKUP_SEP + self.prefetch_to\n \n     def get_current_prefetch_to(self, level):\n-        return LOOKUP_SEP.join(self.prefetch_to.split(LOOKUP_SEP)[:level + 1])\n+        return LOOKUP_SEP.join(self.prefetch_to.split(LOOKUP_SEP)[: level + 1])\n \n     def get_current_to_attr(self, level):\n         parts = self.prefetch_to.split(LOOKUP_SEP)\n@@ -1629,7 +1812,7 @@ def prefetch_related_objects(model_instances, *related_lookups):\n     # We need to be able to dynamically add to the list of prefetch_related\n     # lookups that we look up (see below).  So we need some book keeping to\n     # ensure we don't do duplicate work.\n-    done_queries = {}    # dictionary of things like 'foo__bar': [results]\n+    done_queries = {}  # dictionary of things like 'foo__bar': [results]\n \n     auto_lookups = set()  # we add to this as we go through.\n     followed_descriptors = set()  # recursion protection\n@@ -1639,8 +1822,11 @@ def prefetch_related_objects(model_instances, *related_lookups):\n         lookup = all_lookups.pop()\n         if lookup.prefetch_to in done_queries:\n             if lookup.queryset is not None:\n-                raise ValueError(\"'%s' lookup was already seen with a different queryset. \"\n-                                 \"You may need to adjust the ordering of your lookups.\" % lookup.prefetch_to)\n+                raise ValueError(\n+                    \"'%s' lookup was already seen with a different queryset. \"\n+                    \"You may need to adjust the ordering of your lookups.\"\n+                    % lookup.prefetch_to\n+                )\n \n             continue\n \n@@ -1666,7 +1852,7 @@ def prefetch_related_objects(model_instances, *related_lookups):\n                 # Since prefetching can re-use instances, it is possible to have\n                 # the same instance multiple times in obj_list, so obj might\n                 # already be prepared.\n-                if not hasattr(obj, '_prefetched_objects_cache'):\n+                if not hasattr(obj, \"_prefetched_objects_cache\"):\n                     try:\n                         obj._prefetched_objects_cache = {}\n                     except (AttributeError, TypeError):\n@@ -1686,30 +1872,48 @@ def prefetch_related_objects(model_instances, *related_lookups):\n             # of prefetch_related), so what applies to first object applies to all.\n             first_obj = obj_list[0]\n             to_attr = lookup.get_current_to_attr(level)[0]\n-            prefetcher, descriptor, attr_found, is_fetched = get_prefetcher(first_obj, through_attr, to_attr)\n+            prefetcher, descriptor, attr_found, is_fetched = get_prefetcher(\n+                first_obj, through_attr, to_attr\n+            )\n \n             if not attr_found:\n-                raise AttributeError(\"Cannot find '%s' on %s object, '%s' is an invalid \"\n-                                     \"parameter to prefetch_related()\" %\n-                                     (through_attr, first_obj.__class__.__name__, lookup.prefetch_through))\n+                raise AttributeError(\n+                    \"Cannot find '%s' on %s object, '%s' is an invalid \"\n+                    \"parameter to prefetch_related()\"\n+                    % (\n+                        through_attr,\n+                        first_obj.__class__.__name__,\n+                        lookup.prefetch_through,\n+                    )\n+                )\n \n             if level == len(through_attrs) - 1 and prefetcher is None:\n                 # Last one, this *must* resolve to something that supports\n                 # prefetching, otherwise there is no point adding it and the\n                 # developer asking for it has made a mistake.\n-                raise ValueError(\"'%s' does not resolve to an item that supports \"\n-                                 \"prefetching - this is an invalid parameter to \"\n-                                 \"prefetch_related().\" % lookup.prefetch_through)\n+                raise ValueError(\n+                    \"'%s' does not resolve to an item that supports \"\n+                    \"prefetching - this is an invalid parameter to \"\n+                    \"prefetch_related().\" % lookup.prefetch_through\n+                )\n \n             if prefetcher is not None and not is_fetched:\n-                obj_list, additional_lookups = prefetch_one_level(obj_list, prefetcher, lookup, level)\n+                obj_list, additional_lookups = prefetch_one_level(\n+                    obj_list, prefetcher, lookup, level\n+                )\n                 # We need to ensure we don't keep adding lookups from the\n                 # same relationships to stop infinite recursion. So, if we\n                 # are already on an automatically added lookup, don't add\n                 # the new lookups from relationships we've seen already.\n-                if not (prefetch_to in done_queries and lookup in auto_lookups and descriptor in followed_descriptors):\n+                if not (\n+                    prefetch_to in done_queries\n+                    and lookup in auto_lookups\n+                    and descriptor in followed_descriptors\n+                ):\n                     done_queries[prefetch_to] = obj_list\n-                    new_lookups = normalize_prefetch_lookups(reversed(additional_lookups), prefetch_to)\n+                    new_lookups = normalize_prefetch_lookups(\n+                        reversed(additional_lookups), prefetch_to\n+                    )\n                     auto_lookups.update(new_lookups)\n                     all_lookups.extend(new_lookups)\n                 followed_descriptors.add(descriptor)\n@@ -1723,7 +1927,7 @@ def prefetch_related_objects(model_instances, *related_lookups):\n                 # that we can continue with nullable or reverse relations.\n                 new_obj_list = []\n                 for obj in obj_list:\n-                    if through_attr in getattr(obj, '_prefetched_objects_cache', ()):\n+                    if through_attr in getattr(obj, \"_prefetched_objects_cache\", ()):\n                         # If related objects have been prefetched, use the\n                         # cache rather than the object's through_attr.\n                         new_obj = list(obj._prefetched_objects_cache.get(through_attr))\n@@ -1768,7 +1972,7 @@ def get_prefetcher(instance, through_attr, to_attr):\n         if rel_obj_descriptor:\n             # singly related object, descriptor object has the\n             # get_prefetch_queryset() method.\n-            if hasattr(rel_obj_descriptor, 'get_prefetch_queryset'):\n+            if hasattr(rel_obj_descriptor, \"get_prefetch_queryset\"):\n                 prefetcher = rel_obj_descriptor\n                 if rel_obj_descriptor.is_cached(instance):\n                     is_fetched = True\n@@ -1777,12 +1981,14 @@ def get_prefetcher(instance, through_attr, to_attr):\n                 # the attribute on the instance rather than the class to\n                 # support many related managers\n                 rel_obj = getattr(instance, through_attr)\n-                if hasattr(rel_obj, 'get_prefetch_queryset'):\n+                if hasattr(rel_obj, \"get_prefetch_queryset\"):\n                     prefetcher = rel_obj\n                 if through_attr != to_attr:\n                     # Special case cached_property instances because hasattr\n                     # triggers attribute computation and assignment.\n-                    if isinstance(getattr(instance.__class__, to_attr, None), cached_property):\n+                    if isinstance(\n+                        getattr(instance.__class__, to_attr, None), cached_property\n+                    ):\n                         is_fetched = to_attr in instance.__dict__\n                     else:\n                         is_fetched = hasattr(instance, to_attr)\n@@ -1815,7 +2021,8 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     # in a dictionary.\n \n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n-        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n+        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level))\n+    )\n     # We have to handle the possibility that the QuerySet we just got back\n     # contains some prefetch_related lookups. We don't want to trigger the\n     # prefetch_related functionality by evaluating the query. Rather, we need\n@@ -1823,8 +2030,8 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n     additional_lookups = [\n-        copy.copy(additional_lookup) for additional_lookup\n-        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+        copy.copy(additional_lookup)\n+        for additional_lookup in getattr(rel_qs, \"_prefetch_related_lookups\", ())\n     ]\n     if additional_lookups:\n         # Don't need to clone because the manager should have given us a fresh\n@@ -1850,7 +2057,7 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         except exceptions.FieldDoesNotExist:\n             pass\n         else:\n-            msg = 'to_attr={} conflicts with a field on the {} model.'\n+            msg = \"to_attr={} conflicts with a field on the {} model.\"\n             raise ValueError(msg.format(to_attr, model.__name__))\n \n     # Whether or not we're prefetching the last part of the lookup.\n@@ -1906,6 +2113,7 @@ class RelatedPopulator:\n     method gets row and from_obj as input and populates the select_related()\n     model instance.\n     \"\"\"\n+\n     def __init__(self, klass_info, select, db):\n         self.db = db\n         # Pre-compute needed attributes. The attributes are:\n@@ -1931,32 +2139,40 @@ class RelatedPopulator:\n         #  - local_setter, remote_setter: Methods to set cached values on\n         #    the object being populated and on the remote object. Usually\n         #    these are Field.set_cached_value() methods.\n-        select_fields = klass_info['select_fields']\n-        from_parent = klass_info['from_parent']\n+        select_fields = klass_info[\"select_fields\"]\n+        from_parent = klass_info[\"from_parent\"]\n         if not from_parent:\n             self.cols_start = select_fields[0]\n             self.cols_end = select_fields[-1] + 1\n             self.init_list = [\n-                f[0].target.attname for f in select[self.cols_start:self.cols_end]\n+                f[0].target.attname for f in select[self.cols_start : self.cols_end]\n             ]\n             self.reorder_for_init = None\n         else:\n-            attname_indexes = {select[idx][0].target.attname: idx for idx in select_fields}\n-            model_init_attnames = (f.attname for f in klass_info['model']._meta.concrete_fields)\n-            self.init_list = [attname for attname in model_init_attnames if attname in attname_indexes]\n-            self.reorder_for_init = operator.itemgetter(*[attname_indexes[attname] for attname in self.init_list])\n+            attname_indexes = {\n+                select[idx][0].target.attname: idx for idx in select_fields\n+            }\n+            model_init_attnames = (\n+                f.attname for f in klass_info[\"model\"]._meta.concrete_fields\n+            )\n+            self.init_list = [\n+                attname for attname in model_init_attnames if attname in attname_indexes\n+            ]\n+            self.reorder_for_init = operator.itemgetter(\n+                *[attname_indexes[attname] for attname in self.init_list]\n+            )\n \n-        self.model_cls = klass_info['model']\n+        self.model_cls = klass_info[\"model\"]\n         self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n         self.related_populators = get_related_populators(klass_info, select, self.db)\n-        self.local_setter = klass_info['local_setter']\n-        self.remote_setter = klass_info['remote_setter']\n+        self.local_setter = klass_info[\"local_setter\"]\n+        self.remote_setter = klass_info[\"remote_setter\"]\n \n     def populate(self, row, from_obj):\n         if self.reorder_for_init:\n             obj_data = self.reorder_for_init(row)\n         else:\n-            obj_data = row[self.cols_start:self.cols_end]\n+            obj_data = row[self.cols_start : self.cols_end]\n         if obj_data[self.pk_idx] is None:\n             obj = None\n         else:\n@@ -1970,7 +2186,7 @@ class RelatedPopulator:\n \n def get_related_populators(klass_info, select, db):\n     iterators = []\n-    related_klass_infos = klass_info.get('related_klass_infos', [])\n+    related_klass_infos = klass_info.get(\"related_klass_infos\", [])\n     for rel_klass_info in related_klass_infos:\n         rel_cls = RelatedPopulator(rel_klass_info, select, db)\n         iterators.append(rel_cls)\n"}
{"instance_id": "django__django-12915", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/staticfiles/handlers.py b/django/contrib/staticfiles/handlers.py\nindex 711d8864ad..45212072de 100644\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -14,6 +14,7 @@ class StaticFilesHandlerMixin:\n     \"\"\"\n     Common methods used by WSGI and ASGI handlers.\n     \"\"\"\n+\n     # May be used to differentiate between handler types (e.g. in a\n     # request_finished signal)\n     handles_files = True\n@@ -39,7 +40,7 @@ class StaticFilesHandlerMixin:\n         \"\"\"\n         Return the relative path to the media file on disk for the given URL.\n         \"\"\"\n-        relative_url = url[len(self.base_url[2]):]\n+        relative_url = url[len(self.base_url[2]) :]\n         return url2pathname(relative_url)\n \n     def serve(self, request):\n@@ -58,6 +59,7 @@ class StaticFilesHandler(StaticFilesHandlerMixin, WSGIHandler):\n     WSGI middleware that intercepts calls to the static files directory, as\n     defined by the STATIC_URL setting, and serves those files.\n     \"\"\"\n+\n     def __init__(self, application):\n         self.application = application\n         self.base_url = urlparse(self.get_base_url())\n@@ -74,13 +76,15 @@ class ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n     ASGI application which wraps another and intercepts requests for static\n     files, passing them off to Django's static file serving.\n     \"\"\"\n+\n     def __init__(self, application):\n         self.application = application\n         self.base_url = urlparse(self.get_base_url())\n+        super().__init__()\n \n     async def __call__(self, scope, receive, send):\n         # Only even look at HTTP requests\n-        if scope['type'] == 'http' and self._should_handle(scope['path']):\n+        if scope[\"type\"] == \"http\" and self._should_handle(scope[\"path\"]):\n             # Serve static content\n             # (the one thing super() doesn't do is __call__, apparently)\n             return await super().__call__(scope, receive, send)\n"}
{"instance_id": "django__django-12983", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex fb5f6298c4..b4a9e32674 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -18,11 +18,11 @@ def capfirst(x):\n \n \n # Set up regular expressions\n-re_words = _lazy_re_compile(r'<[^>]+?>|([^<>\\s]+)', re.S)\n-re_chars = _lazy_re_compile(r'<[^>]+?>|(.)', re.S)\n-re_tag = _lazy_re_compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\n-re_newlines = _lazy_re_compile(r'\\r\\n|\\r')  # Used in normalize_newlines\n-re_camel_case = _lazy_re_compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n+re_words = _lazy_re_compile(r\"<[^>]+?>|([^<>\\s]+)\", re.S)\n+re_chars = _lazy_re_compile(r\"<[^>]+?>|(.)\", re.S)\n+re_tag = _lazy_re_compile(r\"<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>\", re.S)\n+re_newlines = _lazy_re_compile(r\"\\r\\n|\\r\")  # Used in normalize_newlines\n+re_camel_case = _lazy_re_compile(r\"(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))\")\n \n \n @keep_lazy_text\n@@ -37,46 +37,49 @@ def wrap(text, width):\n     Don't wrap long words, thus the output text may have lines longer than\n     ``width``.\n     \"\"\"\n+\n     def _generator():\n         for line in text.splitlines(True):  # True keeps trailing linebreaks\n-            max_width = min((line.endswith('\\n') and width + 1 or width), width)\n+            max_width = min((line.endswith(\"\\n\") and width + 1 or width), width)\n             while len(line) > max_width:\n-                space = line[:max_width + 1].rfind(' ') + 1\n+                space = line[: max_width + 1].rfind(\" \") + 1\n                 if space == 0:\n-                    space = line.find(' ') + 1\n+                    space = line.find(\" \") + 1\n                     if space == 0:\n                         yield line\n-                        line = ''\n+                        line = \"\"\n                         break\n-                yield '%s\\n' % line[:space - 1]\n+                yield \"%s\\n\" % line[: space - 1]\n                 line = line[space:]\n-                max_width = min((line.endswith('\\n') and width + 1 or width), width)\n+                max_width = min((line.endswith(\"\\n\") and width + 1 or width), width)\n             if line:\n                 yield line\n-    return ''.join(_generator())\n+\n+    return \"\".join(_generator())\n \n \n class Truncator(SimpleLazyObject):\n     \"\"\"\n     An object used to truncate text, either by characters or words.\n     \"\"\"\n+\n     def __init__(self, text):\n         super().__init__(lambda: str(text))\n \n     def add_truncation_text(self, text, truncate=None):\n         if truncate is None:\n             truncate = pgettext(\n-                'String to return when truncating text',\n-                '%(truncated_text)s\u2026')\n-        if '%(truncated_text)s' in truncate:\n-            return truncate % {'truncated_text': text}\n+                \"String to return when truncating text\", \"%(truncated_text)s\u2026\"\n+            )\n+        if \"%(truncated_text)s\" in truncate:\n+            return truncate % {\"truncated_text\": text}\n         # The truncation text didn't contain the %(truncated_text)s string\n         # replacement argument so just append it to the text.\n         if text.endswith(truncate):\n             # But don't append the truncation text if the current text already\n             # ends in this.\n             return text\n-        return '%s%s' % (text, truncate)\n+        return \"%s%s\" % (text, truncate)\n \n     def chars(self, num, truncate=None, html=False):\n         \"\"\"\n@@ -88,11 +91,11 @@ class Truncator(SimpleLazyObject):\n         \"\"\"\n         self._setup()\n         length = int(num)\n-        text = unicodedata.normalize('NFC', self._wrapped)\n+        text = unicodedata.normalize(\"NFC\", self._wrapped)\n \n         # Calculate the length to truncate to (max length - end_text length)\n         truncate_len = length\n-        for char in self.add_truncation_text('', truncate):\n+        for char in self.add_truncation_text(\"\", truncate):\n             if not unicodedata.combining(char):\n                 truncate_len -= 1\n                 if truncate_len == 0:\n@@ -115,8 +118,7 @@ class Truncator(SimpleLazyObject):\n                 end_index = i\n             if s_len > length:\n                 # Return the truncated string\n-                return self.add_truncation_text(text[:end_index or 0],\n-                                                truncate)\n+                return self.add_truncation_text(text[: end_index or 0], truncate)\n \n         # Return the original string since no truncation was necessary\n         return text\n@@ -142,8 +144,8 @@ class Truncator(SimpleLazyObject):\n         words = self._wrapped.split()\n         if len(words) > length:\n             words = words[:length]\n-            return self.add_truncation_text(' '.join(words), truncate)\n-        return ' '.join(words)\n+            return self.add_truncation_text(\" \".join(words), truncate)\n+        return \" \".join(words)\n \n     def _truncate_html(self, length, truncate, text, truncate_len, words):\n         \"\"\"\n@@ -154,11 +156,18 @@ class Truncator(SimpleLazyObject):\n         Preserve newlines in the HTML.\n         \"\"\"\n         if words and length <= 0:\n-            return ''\n+            return \"\"\n \n         html4_singlets = (\n-            'br', 'col', 'link', 'base', 'img',\n-            'param', 'area', 'hr', 'input'\n+            \"br\",\n+            \"col\",\n+            \"link\",\n+            \"base\",\n+            \"img\",\n+            \"param\",\n+            \"area\",\n+            \"hr\",\n+            \"input\",\n         )\n \n         # Count non-HTML chars/words and keep note of open tags\n@@ -200,7 +209,7 @@ class Truncator(SimpleLazyObject):\n                 else:\n                     # SGML: An end tag closes, back to the matching start tag,\n                     # all unclosed intervening start tags with omitted end tags\n-                    open_tags = open_tags[i + 1:]\n+                    open_tags = open_tags[i + 1 :]\n             else:\n                 # Add it to the start of the open tags list\n                 open_tags.insert(0, tagname)\n@@ -208,12 +217,12 @@ class Truncator(SimpleLazyObject):\n         if current_len <= length:\n             return text\n         out = text[:end_text_pos]\n-        truncate_text = self.add_truncation_text('', truncate)\n+        truncate_text = self.add_truncation_text(\"\", truncate)\n         if truncate_text:\n             out += truncate_text\n         # Close any tags still open\n         for tag in open_tags:\n-            out += '</%s>' % tag\n+            out += \"</%s>\" % tag\n         # Return string\n         return out\n \n@@ -228,12 +237,12 @@ def get_valid_filename(s):\n     >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n     'johns_portrait_in_2004.jpg'\n     \"\"\"\n-    s = str(s).strip().replace(' ', '_')\n-    return re.sub(r'(?u)[^-\\w.]', '', s)\n+    s = str(s).strip().replace(\" \", \"_\")\n+    return re.sub(r\"(?u)[^-\\w.]\", \"\", s)\n \n \n @keep_lazy_text\n-def get_text_list(list_, last_word=gettext_lazy('or')):\n+def get_text_list(list_, last_word=gettext_lazy(\"or\")):\n     \"\"\"\n     >>> get_text_list(['a', 'b', 'c', 'd'])\n     'a, b, c or d'\n@@ -247,38 +256,62 @@ def get_text_list(list_, last_word=gettext_lazy('or')):\n     ''\n     \"\"\"\n     if not list_:\n-        return ''\n+        return \"\"\n     if len(list_) == 1:\n         return str(list_[0])\n-    return '%s %s %s' % (\n+    return \"%s %s %s\" % (\n         # Translators: This string is used as a separator between list elements\n-        _(', ').join(str(i) for i in list_[:-1]), str(last_word), str(list_[-1])\n+        _(\", \").join(str(i) for i in list_[:-1]),\n+        str(last_word),\n+        str(list_[-1]),\n     )\n \n \n @keep_lazy_text\n def normalize_newlines(text):\n     \"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"\n-    return re_newlines.sub('\\n', str(text))\n+    return re_newlines.sub(\"\\n\", str(text))\n \n \n @keep_lazy_text\n def phone2numeric(phone):\n     \"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"\n     char2number = {\n-        'a': '2', 'b': '2', 'c': '2', 'd': '3', 'e': '3', 'f': '3', 'g': '4',\n-        'h': '4', 'i': '4', 'j': '5', 'k': '5', 'l': '5', 'm': '6', 'n': '6',\n-        'o': '6', 'p': '7', 'q': '7', 'r': '7', 's': '7', 't': '8', 'u': '8',\n-        'v': '8', 'w': '9', 'x': '9', 'y': '9', 'z': '9',\n+        \"a\": \"2\",\n+        \"b\": \"2\",\n+        \"c\": \"2\",\n+        \"d\": \"3\",\n+        \"e\": \"3\",\n+        \"f\": \"3\",\n+        \"g\": \"4\",\n+        \"h\": \"4\",\n+        \"i\": \"4\",\n+        \"j\": \"5\",\n+        \"k\": \"5\",\n+        \"l\": \"5\",\n+        \"m\": \"6\",\n+        \"n\": \"6\",\n+        \"o\": \"6\",\n+        \"p\": \"7\",\n+        \"q\": \"7\",\n+        \"r\": \"7\",\n+        \"s\": \"7\",\n+        \"t\": \"8\",\n+        \"u\": \"8\",\n+        \"v\": \"8\",\n+        \"w\": \"9\",\n+        \"x\": \"9\",\n+        \"y\": \"9\",\n+        \"z\": \"9\",\n     }\n-    return ''.join(char2number.get(c, c) for c in phone.lower())\n+    return \"\".join(char2number.get(c, c) for c in phone.lower())\n \n \n # From http://www.xhaus.com/alan/python/httpcomp.html#gzip\n # Used with permission.\n def compress_string(s):\n     zbuf = BytesIO()\n-    with GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n+    with GzipFile(mode=\"wb\", compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n         zfile.write(s)\n     return zbuf.getvalue()\n \n@@ -294,7 +327,7 @@ class StreamingBuffer(BytesIO):\n # Like compress_string, but for iterators of strings.\n def compress_sequence(sequence):\n     buf = StreamingBuffer()\n-    with GzipFile(mode='wb', compresslevel=6, fileobj=buf, mtime=0) as zfile:\n+    with GzipFile(mode=\"wb\", compresslevel=6, fileobj=buf, mtime=0) as zfile:\n         # Output headers...\n         yield buf.read()\n         for item in sequence:\n@@ -307,7 +340,8 @@ def compress_sequence(sequence):\n \n # Expression to match some_token and some_token=\"with spaces\" (and similarly\n # for single-quoted strings).\n-smart_split_re = _lazy_re_compile(r\"\"\"\n+smart_split_re = _lazy_re_compile(\n+    r\"\"\"\n     ((?:\n         [^\\s'\"]*\n         (?:\n@@ -315,7 +349,9 @@ smart_split_re = _lazy_re_compile(r\"\"\"\n             [^\\s'\"]*\n         )+\n     ) | \\S+)\n-\"\"\", re.VERBOSE)\n+\"\"\",\n+    re.VERBOSE,\n+)\n \n \n def smart_split(text):\n@@ -339,10 +375,10 @@ def smart_split(text):\n \n def _replace_entity(match):\n     text = match[1]\n-    if text[0] == '#':\n+    if text[0] == \"#\":\n         text = text[1:]\n         try:\n-            if text[0] in 'xX':\n+            if text[0] in \"xX\":\n                 c = int(text[1:], 16)\n             else:\n                 c = int(text)\n@@ -362,9 +398,10 @@ _entity_re = _lazy_re_compile(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\")\n @keep_lazy_text\n def unescape_entities(text):\n     warnings.warn(\n-        'django.utils.text.unescape_entities() is deprecated in favor of '\n-        'html.unescape().',\n-        RemovedInDjango40Warning, stacklevel=2,\n+        \"django.utils.text.unescape_entities() is deprecated in favor of \"\n+        \"html.unescape().\",\n+        RemovedInDjango40Warning,\n+        stacklevel=2,\n     )\n     return _entity_re.sub(_replace_entity, str(text))\n \n@@ -387,7 +424,7 @@ def unescape_string_literal(s):\n     if s[0] not in \"\\\"'\" or s[-1] != s[0]:\n         raise ValueError(\"Not a string literal: %r\" % s)\n     quote = s[0]\n-    return s[1:-1].replace(r'\\%s' % quote, quote).replace(r'\\\\', '\\\\')\n+    return s[1:-1].replace(r\"\\%s\" % quote, quote).replace(r\"\\\\\", \"\\\\\")\n \n \n @keep_lazy_text\n@@ -399,18 +436,22 @@ def slugify(value, allow_unicode=False):\n     \"\"\"\n     value = str(value)\n     if allow_unicode:\n-        value = unicodedata.normalize('NFKC', value)\n+        value = unicodedata.normalize(\"NFKC\", value)\n     else:\n-        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n-    value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+        value = (\n+            unicodedata.normalize(\"NFKD\", value)\n+            .encode(\"ascii\", \"ignore\")\n+            .decode(\"ascii\")\n+        )\n+    value = re.sub(r\"[^\\w\\s-]\", \"\", value.lower()).strip(\"-_\")\n+    return re.sub(r\"[-\\s]+\", \"-\", value).strip(\"-_\")\n \n \n def camel_case_to_spaces(value):\n     \"\"\"\n     Split CamelCase and convert to lowercase. Strip surrounding whitespace.\n     \"\"\"\n-    return re_camel_case.sub(r' \\1', value).strip().lower()\n+    return re_camel_case.sub(r\" \\1\", value).strip().lower()\n \n \n def _format_lazy(format_string, *args, **kwargs):\n"}
{"instance_id": "django__django-13028", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..23a2831078 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -6,6 +6,7 @@ themselves do not have to (and could be backed by things other than SQL\n databases). The abstraction barrier only works one way: this module has to know\n all about the internals of models in order to get the information it needs.\n \"\"\"\n+\n import copy\n import difflib\n import functools\n@@ -18,7 +19,9 @@ from itertools import chain, count, product\n from string import ascii_uppercase\n \n from django.core.exceptions import (\n-    EmptyResultSet, FieldDoesNotExist, FieldError,\n+    EmptyResultSet,\n+    FieldDoesNotExist,\n+    FieldError,\n )\n from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n from django.db.models.aggregates import Count\n@@ -28,27 +31,37 @@ from django.db.models.fields import Field\n from django.db.models.fields.related_lookups import MultiColSource\n from django.db.models.lookups import Lookup\n from django.db.models.query_utils import (\n-    Q, check_rel_lookup_compatibility, refs_expression,\n+    Q,\n+    check_rel_lookup_compatibility,\n+    refs_expression,\n )\n from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\n from django.db.models.sql.datastructures import (\n-    BaseTable, Empty, Join, MultiJoin,\n+    BaseTable,\n+    Empty,\n+    Join,\n+    MultiJoin,\n )\n from django.db.models.sql.where import (\n-    AND, OR, ExtraWhere, NothingNode, WhereNode,\n+    AND,\n+    OR,\n+    ExtraWhere,\n+    NothingNode,\n+    WhereNode,\n )\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import cached_property\n from django.utils.tree import Node\n \n-__all__ = ['Query', 'RawQuery']\n+__all__ = [\"Query\", \"RawQuery\"]\n \n \n def get_field_names_from_opts(opts):\n-    return set(chain.from_iterable(\n-        (f.name, f.attname) if f.concrete else (f.name,)\n-        for f in opts.get_fields()\n-    ))\n+    return set(\n+        chain.from_iterable(\n+            (f.name, f.attname) if f.concrete else (f.name,) for f in opts.get_fields()\n+        )\n+    )\n \n \n def get_children_from_q(q):\n@@ -60,8 +73,8 @@ def get_children_from_q(q):\n \n \n JoinInfo = namedtuple(\n-    'JoinInfo',\n-    ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')\n+    \"JoinInfo\",\n+    (\"final_field\", \"targets\", \"opts\", \"joins\", \"path\", \"transform_function\"),\n )\n \n \n@@ -90,8 +103,7 @@ class RawQuery:\n         if self.cursor is None:\n             self._execute_query()\n         converter = connections[self.using].introspection.identifier_converter\n-        return [converter(column_meta[0])\n-                for column_meta in self.cursor.description]\n+        return [converter(column_meta[0]) for column_meta in self.cursor.description]\n \n     def __iter__(self):\n         # Always execute a new query for a new iterator.\n@@ -136,10 +148,10 @@ class RawQuery:\n class Query(BaseExpression):\n     \"\"\"A single SQL query.\"\"\"\n \n-    alias_prefix = 'T'\n+    alias_prefix = \"T\"\n     subq_aliases = frozenset([alias_prefix])\n \n-    compiler = 'SQLCompiler'\n+    compiler = \"SQLCompiler\"\n \n     def __init__(self, model, where=WhereNode, alias_cols=True):\n         self.model = model\n@@ -157,7 +169,7 @@ class Query(BaseExpression):\n         # aliases too.\n         # Map external tables to whether they are aliased.\n         self.external_aliases = {}\n-        self.table_map = {}     # Maps table names to list of aliases.\n+        self.table_map = {}  # Maps table names to list of aliases.\n         self.default_cols = True\n         self.default_ordering = True\n         self.standard_ordering = True\n@@ -233,13 +245,15 @@ class Query(BaseExpression):\n     def output_field(self):\n         if len(self.select) == 1:\n             select = self.select[0]\n-            return getattr(select, 'target', None) or select.field\n+            return getattr(select, \"target\", None) or select.field\n         elif len(self.annotation_select) == 1:\n             return next(iter(self.annotation_select.values())).output_field\n \n     @property\n     def has_select_fields(self):\n-        return bool(self.select or self.annotation_select_mask or self.extra_select_mask)\n+        return bool(\n+            self.select or self.annotation_select_mask or self.extra_select_mask\n+        )\n \n     @cached_property\n     def base_table(self):\n@@ -324,7 +338,7 @@ class Query(BaseExpression):\n             # Use deepcopy because select_related stores fields in nested\n             # dicts.\n             obj.select_related = copy.deepcopy(obj.select_related)\n-        if 'subq_aliases' in self.__dict__:\n+        if \"subq_aliases\" in self.__dict__:\n             obj.subq_aliases = self.subq_aliases.copy()\n         obj.used_aliases = self.used_aliases.copy()\n         obj._filtered_relations = self._filtered_relations.copy()\n@@ -346,7 +360,7 @@ class Query(BaseExpression):\n         if not obj.filter_is_sticky:\n             obj.used_aliases = set()\n         obj.filter_is_sticky = False\n-        if hasattr(obj, '_setup_query'):\n+        if hasattr(obj, \"_setup_query\"):\n             obj._setup_query()\n         return obj\n \n@@ -396,11 +410,13 @@ class Query(BaseExpression):\n                         break\n                 else:\n                     # An expression that is not selected the subquery.\n-                    if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):\n+                    if isinstance(expr, Col) or (\n+                        expr.contains_aggregate and not expr.is_summary\n+                    ):\n                         # Reference column or another aggregate. Select it\n                         # under a non-conflicting alias.\n                         col_cnt += 1\n-                        col_alias = '__col%d' % col_cnt\n+                        col_alias = \"__col%d\" % col_cnt\n                         self.annotations[col_alias] = expr\n                         self.append_annotation_mask([col_alias])\n                         new_expr = Ref(col_alias, expr)\n@@ -419,8 +435,8 @@ class Query(BaseExpression):\n         if not self.annotation_select:\n             return {}\n         existing_annotations = [\n-            annotation for alias, annotation\n-            in self.annotations.items()\n+            annotation\n+            for alias, annotation in self.annotations.items()\n             if alias not in added_aggregate_names\n         ]\n         # Decide if we need to use a subquery.\n@@ -434,9 +450,15 @@ class Query(BaseExpression):\n         # those operations must be done in a subquery so that the query\n         # aggregates on the limit and/or distinct results instead of applying\n         # the distinct and limit after the aggregation.\n-        if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or\n-                self.distinct or self.combinator):\n+        if (\n+            isinstance(self.group_by, tuple)\n+            or self.is_sliced\n+            or existing_annotations\n+            or self.distinct\n+            or self.combinator\n+        ):\n             from django.db.models.sql.subqueries import AggregateQuery\n+\n             outer_query = AggregateQuery(self.model)\n             inner_query = self.clone()\n             inner_query.select_for_update = False\n@@ -454,15 +476,18 @@ class Query(BaseExpression):\n                 # clearing the select clause can alter results if distinct is\n                 # used.\n                 has_existing_aggregate_annotations = any(\n-                    annotation for annotation in existing_annotations\n-                    if getattr(annotation, 'contains_aggregate', True)\n+                    annotation\n+                    for annotation in existing_annotations\n+                    if getattr(annotation, \"contains_aggregate\", True)\n                 )\n                 if inner_query.default_cols and has_existing_aggregate_annotations:\n-                    inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                    inner_query.group_by = (\n+                        self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n+                    )\n                 inner_query.default_cols = False\n \n-            relabels = {t: 'subquery' for t in inner_query.alias_map}\n-            relabels[None] = 'subquery'\n+            relabels = {t: \"subquery\" for t in inner_query.alias_map}\n+            relabels[None] = \"subquery\"\n             # Remove any aggregates marked for reduction from the subquery\n             # and move them to the outer AggregateQuery.\n             col_cnt = 0\n@@ -470,23 +495,28 @@ class Query(BaseExpression):\n                 annotation_select_mask = inner_query.annotation_select_mask\n                 if expression.is_summary:\n                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)\n-                    outer_query.annotations[alias] = expression.relabeled_clone(relabels)\n+                    outer_query.annotations[alias] = expression.relabeled_clone(\n+                        relabels\n+                    )\n                     del inner_query.annotations[alias]\n                     annotation_select_mask.remove(alias)\n                 # Make sure the annotation_select wont use cached results.\n                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)\n-            if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:\n+            if (\n+                inner_query.select == ()\n+                and not inner_query.default_cols\n+                and not inner_query.annotation_select_mask\n+            ):\n                 # In case of Model.objects[0:3].count(), there would be no\n                 # field selected in the inner query, yet we must use a subquery.\n                 # So, make sure at least one field is selected.\n-                inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                inner_query.select = (\n+                    self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n+                )\n             try:\n                 outer_query.add_subquery(inner_query, using)\n             except EmptyResultSet:\n-                return {\n-                    alias: None\n-                    for alias in outer_query.annotation_select\n-                }\n+                return {alias: None for alias in outer_query.annotation_select}\n         else:\n             outer_query = self\n             self.select = ()\n@@ -512,8 +542,8 @@ class Query(BaseExpression):\n         Perform a COUNT() query using the current filter constraints.\n         \"\"\"\n         obj = self.clone()\n-        obj.add_annotation(Count('*'), alias='__count', is_summary=True)\n-        number = obj.get_aggregation(using, ['__count'])['__count']\n+        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n+        number = obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n         if number is None:\n             number = 0\n         return number\n@@ -525,7 +555,9 @@ class Query(BaseExpression):\n         q = self.clone()\n         if not q.distinct:\n             if q.group_by is True:\n-                q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)\n+                q.add_fields(\n+                    (f.attname for f in self.model._meta.concrete_fields), False\n+                )\n                 # Disable GROUP BY aliases to avoid orphaning references to the\n                 # SELECT clause which is about to be cleared.\n                 q.set_group_by(allow_aliases=False)\n@@ -541,7 +573,7 @@ class Query(BaseExpression):\n         q.explain_format = format\n         q.explain_options = options\n         compiler = q.get_compiler(using=using)\n-        return '\\n'.join(compiler.explain_query())\n+        return \"\\n\".join(compiler.explain_query())\n \n     def combine(self, rhs, connector):\n         \"\"\"\n@@ -552,18 +584,20 @@ class Query(BaseExpression):\n         The 'connector' parameter describes how to connect filters from the\n         'rhs' query.\n         \"\"\"\n-        assert self.model == rhs.model, \\\n+        assert self.model == rhs.model, (\n             \"Cannot combine queries on two different base models.\"\n-        assert not self.is_sliced, \\\n-            \"Cannot combine queries once a slice has been taken.\"\n-        assert self.distinct == rhs.distinct, \\\n+        )\n+        assert not self.is_sliced, \"Cannot combine queries once a slice has been taken.\"\n+        assert self.distinct == rhs.distinct, (\n             \"Cannot combine a unique query with a non-unique query.\"\n-        assert self.distinct_fields == rhs.distinct_fields, \\\n+        )\n+        assert self.distinct_fields == rhs.distinct_fields, (\n             \"Cannot combine queries with different distinct fields.\"\n+        )\n \n         # Work out how to relabel the rhs aliases, if necessary.\n         change_map = {}\n-        conjunction = (connector == AND)\n+        conjunction = connector == AND\n \n         # Determine which existing joins can be reused. When combining the\n         # query with AND we must recreate all joins for m2m filters. When\n@@ -583,7 +617,8 @@ class Query(BaseExpression):\n         self.get_initial_alias()\n         joinpromoter = JoinPromoter(connector, 2, False)\n         joinpromoter.add_votes(\n-            j for j in self.alias_map if self.alias_map[j].join_type == INNER)\n+            j for j in self.alias_map if self.alias_map[j].join_type == INNER\n+        )\n         rhs_votes = set()\n         # Now, add the joins from rhs query into the new query (skipping base\n         # table).\n@@ -628,7 +663,9 @@ class Query(BaseExpression):\n             # really make sense (or return consistent value sets). Not worth\n             # the extra complexity when you can write a real query instead.\n             if self.extra and rhs.extra:\n-                raise ValueError(\"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\")\n+                raise ValueError(\n+                    \"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\"\n+                )\n         self.extra.update(rhs.extra)\n         extra_select_mask = set()\n         if self.extra_select_mask is not None:\n@@ -746,11 +783,13 @@ class Query(BaseExpression):\n \n         # Create a new alias for this table.\n         if alias_list:\n-            alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)\n+            alias = \"%s%d\" % (self.alias_prefix, len(self.alias_map) + 1)\n             alias_list.append(alias)\n         else:\n             # The first occurrence of a table uses the table name directly.\n-            alias = filtered_relation.alias if filtered_relation is not None else table_name\n+            alias = (\n+                filtered_relation.alias if filtered_relation is not None else table_name\n+            )\n             self.table_map[table_name] = [alias]\n         self.alias_refcount[alias] = 1\n         return alias, True\n@@ -785,16 +824,19 @@ class Query(BaseExpression):\n             # Only the first alias (skipped above) should have None join_type\n             assert self.alias_map[alias].join_type is not None\n             parent_alias = self.alias_map[alias].parent_alias\n-            parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n+            parent_louter = (\n+                parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n+            )\n             already_louter = self.alias_map[alias].join_type == LOUTER\n-            if ((self.alias_map[alias].nullable or parent_louter) and\n-                    not already_louter):\n+            if (self.alias_map[alias].nullable or parent_louter) and not already_louter:\n                 self.alias_map[alias] = self.alias_map[alias].promote()\n                 # Join type of 'alias' changed, so re-examine all aliases that\n                 # refer to this one.\n                 aliases.extend(\n-                    join for join in self.alias_map\n-                    if self.alias_map[join].parent_alias == alias and join not in aliases\n+                    join\n+                    for join in self.alias_map\n+                    if self.alias_map[join].parent_alias == alias\n+                    and join not in aliases\n                 )\n \n     def demote_joins(self, aliases):\n@@ -837,10 +879,13 @@ class Query(BaseExpression):\n         # \"group by\" and \"where\".\n         self.where.relabel_aliases(change_map)\n         if isinstance(self.group_by, tuple):\n-            self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])\n+            self.group_by = tuple(\n+                [col.relabeled_clone(change_map) for col in self.group_by]\n+            )\n         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n         self.annotations = self.annotations and {\n-            key: col.relabeled_clone(change_map) for key, col in self.annotations.items()\n+            key: col.relabeled_clone(change_map)\n+            for key, col in self.annotations.items()\n         }\n \n         # 2. Rename the alias in the internal table/alias datastructures.\n@@ -871,6 +916,7 @@ class Query(BaseExpression):\n         conflict. Even tables that previously had no alias will get an alias\n         after this call.\n         \"\"\"\n+\n         def prefix_gen():\n             \"\"\"\n             Generate a sequence of characters in alphabetical order:\n@@ -884,9 +930,9 @@ class Query(BaseExpression):\n             prefix = chr(ord(self.alias_prefix) + 1)\n             yield prefix\n             for n in count(1):\n-                seq = alphabet[alphabet.index(prefix):] if prefix else alphabet\n+                seq = alphabet[alphabet.index(prefix) :] if prefix else alphabet\n                 for s in product(seq, repeat=n):\n-                    yield ''.join(s)\n+                    yield \"\".join(s)\n                 prefix = None\n \n         if self.alias_prefix != outer_query.alias_prefix:\n@@ -904,14 +950,16 @@ class Query(BaseExpression):\n                 break\n             if pos > local_recursion_limit:\n                 raise RecursionError(\n-                    'Maximum recursion depth exceeded: too many subqueries.'\n+                    \"Maximum recursion depth exceeded: too many subqueries.\"\n                 )\n         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])\n         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)\n-        self.change_aliases({\n-            alias: '%s%d' % (self.alias_prefix, pos)\n-            for pos, alias in enumerate(self.alias_map)\n-        })\n+        self.change_aliases(\n+            {\n+                alias: \"%s%d\" % (self.alias_prefix, pos)\n+                for pos, alias in enumerate(self.alias_map)\n+            }\n+        )\n \n     def get_initial_alias(self):\n         \"\"\"\n@@ -951,12 +999,14 @@ class Query(BaseExpression):\n         \"\"\"\n         if reuse_with_filtered_relation and reuse:\n             reuse_aliases = [\n-                a for a, j in self.alias_map.items()\n+                a\n+                for a, j in self.alias_map.items()\n                 if a in reuse and j.equals(join, with_filtered_relation=False)\n             ]\n         else:\n             reuse_aliases = [\n-                a for a, j in self.alias_map.items()\n+                a\n+                for a, j in self.alias_map.items()\n                 if (reuse is None or a in reuse) and j == join\n             ]\n         if reuse_aliases:\n@@ -970,7 +1020,9 @@ class Query(BaseExpression):\n             return reuse_alias\n \n         # No reuse is possible, so we need a new alias.\n-        alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)\n+        alias, _ = self.table_alias(\n+            join.table_name, create=True, filtered_relation=join.filtered_relation\n+        )\n         if join.join_type:\n             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n                 join_type = LOUTER\n@@ -1016,8 +1068,9 @@ class Query(BaseExpression):\n \n     def add_annotation(self, annotation, alias, is_summary=False):\n         \"\"\"Add a single annotation expression to the Query.\"\"\"\n-        annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,\n-                                                   summarize=is_summary)\n+        annotation = annotation.resolve_expression(\n+            self, allow_joins=True, reuse=None, summarize=is_summary\n+        )\n         self.append_annotation_mask([alias])\n         self.annotations[alias] = annotation\n \n@@ -1028,41 +1081,47 @@ class Query(BaseExpression):\n         clone.subquery = True\n         # It's safe to drop ordering if the queryset isn't using slicing,\n         # distinct(*fields) or select_for_update().\n-        if (self.low_mark == 0 and self.high_mark is None and\n-                not self.distinct_fields and\n-                not self.select_for_update):\n+        if (\n+            self.low_mark == 0\n+            and self.high_mark is None\n+            and not self.distinct_fields\n+            and not self.select_for_update\n+        ):\n             clone.clear_ordering(True)\n         clone.where.resolve_expression(query, *args, **kwargs)\n         for key, value in clone.annotations.items():\n             resolved = value.resolve_expression(query, *args, **kwargs)\n-            if hasattr(resolved, 'external_aliases'):\n+            if hasattr(resolved, \"external_aliases\"):\n                 resolved.external_aliases.update(clone.external_aliases)\n             clone.annotations[key] = resolved\n         # Outer query's aliases are considered external.\n         for alias, table in query.alias_map.items():\n             clone.external_aliases[alias] = (\n-                (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or\n-                (isinstance(table, BaseTable) and table.table_name != table.table_alias)\n+                isinstance(table, Join)\n+                and table.join_field.related_model._meta.db_table != alias\n+            ) or (\n+                isinstance(table, BaseTable) and table.table_name != table.table_alias\n             )\n         return clone\n \n     def get_external_cols(self):\n         exprs = chain(self.annotations.values(), self.where.children)\n         return [\n-            col for col in self._gen_cols(exprs)\n-            if col.alias in self.external_aliases\n+            col for col in self._gen_cols(exprs) if col.alias in self.external_aliases\n         ]\n \n     def as_sql(self, compiler, connection):\n         sql, params = self.get_compiler(connection=connection).as_sql()\n         if self.subquery:\n-            sql = '(%s)' % sql\n+            sql = \"(%s)\" % sql\n         return sql, params\n \n     def resolve_lookup_value(self, value, can_reuse, allow_joins):\n-        if hasattr(value, 'resolve_expression'):\n+        if hasattr(value, \"resolve_expression\"):\n             value = value.resolve_expression(\n-                self, reuse=can_reuse, allow_joins=allow_joins,\n+                self,\n+                reuse=can_reuse,\n+                allow_joins=allow_joins,\n             )\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n@@ -1079,15 +1138,17 @@ class Query(BaseExpression):\n         \"\"\"\n         lookup_splitted = lookup.split(LOOKUP_SEP)\n         if self.annotations:\n-            expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)\n+            expression, expression_lookups = refs_expression(\n+                lookup_splitted, self.annotations\n+            )\n             if expression:\n                 return expression_lookups, (), expression\n         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n-        field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]\n+        field_parts = lookup_splitted[0 : len(lookup_splitted) - len(lookup_parts)]\n         if len(lookup_parts) > 1 and not field_parts:\n             raise FieldError(\n-                'Invalid lookup \"%s\" for model %s\".' %\n-                (lookup, self.get_meta().model.__name__)\n+                'Invalid lookup \"%s\" for model %s\".'\n+                % (lookup, self.get_meta().model.__name__)\n             )\n         return lookup_parts, field_parts, False\n \n@@ -1096,11 +1157,12 @@ class Query(BaseExpression):\n         Check whether the object passed while querying is of the correct type.\n         If not, raise a ValueError specifying the wrong object.\n         \"\"\"\n-        if hasattr(value, '_meta'):\n+        if hasattr(value, \"_meta\"):\n             if not check_rel_lookup_compatibility(value._meta.model, opts, field):\n                 raise ValueError(\n-                    'Cannot query \"%s\": Must be \"%s\" instance.' %\n-                    (value, opts.object_name))\n+                    'Cannot query \"%s\": Must be \"%s\" instance.'\n+                    % (value, opts.object_name)\n+                )\n \n     def check_related_objects(self, field, value, opts):\n         \"\"\"Check the type of object passed to query relations.\"\"\"\n@@ -1110,26 +1172,30 @@ class Query(BaseExpression):\n             # opts would be Author's (from the author field) and value.model\n             # would be Author.objects.all() queryset's .model (Author also).\n             # The field is the related field on the lhs side.\n-            if (isinstance(value, Query) and not value.has_select_fields and\n-                    not check_rel_lookup_compatibility(value.model, opts, field)):\n+            if (\n+                isinstance(value, Query)\n+                and not value.has_select_fields\n+                and not check_rel_lookup_compatibility(value.model, opts, field)\n+            ):\n                 raise ValueError(\n-                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".' %\n-                    (value.model._meta.object_name, opts.object_name)\n+                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".'\n+                    % (value.model._meta.object_name, opts.object_name)\n                 )\n-            elif hasattr(value, '_meta'):\n+            elif hasattr(value, \"_meta\"):\n                 self.check_query_object_type(value, opts, field)\n-            elif hasattr(value, '__iter__'):\n+            elif hasattr(value, \"__iter__\"):\n                 for v in value:\n                     self.check_query_object_type(v, opts, field)\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, \"resolve_expression\") and not getattr(\n+            expression.__class__, \"filterable\", True\n+        ):\n             raise NotSupportedError(\n-                expression.__class__.__name__ + ' is disallowed in the filter '\n-                'clause.'\n+                expression.__class__.__name__ + \" is disallowed in the filter clause.\"\n             )\n-        if hasattr(expression, 'get_source_expressions'):\n+        if hasattr(expression, \"get_source_expressions\"):\n             for expr in expression.get_source_expressions():\n                 self.check_filterable(expr)\n \n@@ -1143,7 +1209,7 @@ class Query(BaseExpression):\n         and get_transform().\n         \"\"\"\n         # __exact is the default lookup if one isn't given.\n-        *transforms, lookup_name = lookups or ['exact']\n+        *transforms, lookup_name = lookups or [\"exact\"]\n         for name in transforms:\n             lhs = self.try_transform(lhs, name)\n         # First try get_lookup() so that the lookup takes precedence if the lhs\n@@ -1151,11 +1217,13 @@ class Query(BaseExpression):\n         lookup_class = lhs.get_lookup(lookup_name)\n         if not lookup_class:\n             if lhs.field.is_relation:\n-                raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))\n+                raise FieldError(\n+                    \"Related Field got invalid lookup: {}\".format(lookup_name)\n+                )\n             # A lookup wasn't found. Try to interpret the name as a transform\n             # and do an Exact lookup against it.\n             lhs = self.try_transform(lhs, lookup_name)\n-            lookup_name = 'exact'\n+            lookup_name = \"exact\"\n             lookup_class = lhs.get_lookup(lookup_name)\n             if not lookup_class:\n                 return\n@@ -1164,17 +1232,20 @@ class Query(BaseExpression):\n         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n         # uses of None as a query value unless the lookup supports it.\n         if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n-            if lookup_name not in ('exact', 'iexact'):\n+            if lookup_name not in (\"exact\", \"iexact\"):\n                 raise ValueError(\"Cannot use None as a query value\")\n-            return lhs.get_lookup('isnull')(lhs, True)\n+            return lhs.get_lookup(\"isnull\")(lhs, True)\n \n         # For Oracle '' is equivalent to null. The check must be done at this\n         # stage because join promotion can't be done in the compiler. Using\n         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n         # A similar thing is done in is_nullable(), too.\n-        if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and\n-                lookup_name == 'exact' and lookup.rhs == ''):\n-            return lhs.get_lookup('isnull')(lhs, True)\n+        if (\n+            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n+            and lookup_name == \"exact\"\n+            and lookup.rhs == \"\"\n+        ):\n+            return lhs.get_lookup(\"isnull\")(lhs, True)\n \n         return lookup\n \n@@ -1188,19 +1259,29 @@ class Query(BaseExpression):\n             return transform_class(lhs)\n         else:\n             output_field = lhs.output_field.__class__\n-            suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())\n+            suggested_lookups = difflib.get_close_matches(\n+                name, output_field.get_lookups()\n+            )\n             if suggested_lookups:\n-                suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)\n+                suggestion = \", perhaps you meant %s?\" % \" or \".join(suggested_lookups)\n             else:\n-                suggestion = '.'\n+                suggestion = \".\"\n             raise FieldError(\n                 \"Unsupported lookup '%s' for %s or join on the field not \"\n                 \"permitted%s\" % (name, output_field.__name__, suggestion)\n             )\n \n-    def build_filter(self, filter_expr, branch_negated=False, current_negated=False,\n-                     can_reuse=None, allow_joins=True, split_subq=True,\n-                     reuse_with_filtered_relation=False, check_filterable=True):\n+    def build_filter(\n+        self,\n+        filter_expr,\n+        branch_negated=False,\n+        current_negated=False,\n+        can_reuse=None,\n+        allow_joins=True,\n+        split_subq=True,\n+        reuse_with_filtered_relation=False,\n+        check_filterable=True,\n+    ):\n         \"\"\"\n         Build a WhereNode for a single filter clause but don't add it\n         to this Query. Query.add_q() will then add this filter to the where\n@@ -1241,11 +1322,13 @@ class Query(BaseExpression):\n                 split_subq=split_subq,\n                 check_filterable=check_filterable,\n             )\n-        if hasattr(filter_expr, 'resolve_expression'):\n-            if not getattr(filter_expr, 'conditional', False):\n-                raise TypeError('Cannot filter against a non-conditional expression.')\n+        if hasattr(filter_expr, \"resolve_expression\"):\n+            if not getattr(filter_expr, \"conditional\", False):\n+                raise TypeError(\"Cannot filter against a non-conditional expression.\")\n             condition = self.build_lookup(\n-                ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True\n+                [\"exact\"],\n+                filter_expr.resolve_expression(self, allow_joins=allow_joins),\n+                True,\n             )\n             clause = self.where_class()\n             clause.add(condition, AND)\n@@ -1263,7 +1346,9 @@ class Query(BaseExpression):\n \n         pre_joins = self.alias_refcount.copy()\n         value = self.resolve_lookup_value(value, can_reuse, allow_joins)\n-        used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}\n+        used_joins = {\n+            k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)\n+        }\n \n         if check_filterable:\n             self.check_filterable(value)\n@@ -1280,7 +1365,11 @@ class Query(BaseExpression):\n \n         try:\n             join_info = self.setup_joins(\n-                parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,\n+                parts,\n+                opts,\n+                alias,\n+                can_reuse=can_reuse,\n+                allow_many=allow_many,\n                 reuse_with_filtered_relation=reuse_with_filtered_relation,\n             )\n \n@@ -1298,7 +1387,9 @@ class Query(BaseExpression):\n         # Update used_joins before trimming since they are reused to determine\n         # which joins could be later promoted to INNER.\n         used_joins.update(join_info.joins)\n-        targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)\n+        targets, alias, join_list = self.trim_joins(\n+            join_info.targets, join_info.joins, join_info.path\n+        )\n         if can_reuse is not None:\n             can_reuse.update(join_list)\n \n@@ -1306,11 +1397,15 @@ class Query(BaseExpression):\n             # No support for transforms for relational fields\n             num_lookups = len(lookups)\n             if num_lookups > 1:\n-                raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))\n+                raise FieldError(\n+                    \"Related Field got invalid lookup: {}\".format(lookups[0])\n+                )\n             if len(targets) == 1:\n                 col = self._get_col(targets[0], join_info.final_field, alias)\n             else:\n-                col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)\n+                col = MultiColSource(\n+                    alias, targets, join_info.targets, join_info.final_field\n+                )\n         else:\n             col = self._get_col(targets[0], join_info.final_field, alias)\n \n@@ -1318,12 +1413,19 @@ class Query(BaseExpression):\n         lookup_type = condition.lookup_name\n         clause.add(condition, AND)\n \n-        require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated\n-        if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:\n+        require_outer = (\n+            lookup_type == \"isnull\" and condition.rhs is True and not current_negated\n+        )\n+        if (\n+            current_negated\n+            and (lookup_type != \"isnull\" or condition.rhs is False)\n+            and condition.rhs is not None\n+        ):\n             require_outer = True\n-            if (lookup_type != 'isnull' and (\n-                    self.is_nullable(targets[0]) or\n-                    self.alias_map[join_list[-1]].join_type == LOUTER)):\n+            if lookup_type != \"isnull\" and (\n+                self.is_nullable(targets[0])\n+                or self.alias_map[join_list[-1]].join_type == LOUTER\n+            ):\n                 # The condition added here will be SQL like this:\n                 # NOT (col IS NOT NULL), where the first NOT is added in\n                 # upper layers of code. The reason for addition is that if col\n@@ -1333,7 +1435,7 @@ class Query(BaseExpression):\n                 # (col IS NULL OR col != someval)\n                 #   <=>\n                 # NOT (col IS NOT NULL AND col = someval).\n-                lookup_class = targets[0].get_lookup('isnull')\n+                lookup_class = targets[0].get_lookup(\"isnull\")\n                 col = self._get_col(targets[0], join_info.targets[0], alias)\n                 clause.add(lookup_class(col, False), AND)\n         return clause, used_joins if not require_outer else ()\n@@ -1352,7 +1454,9 @@ class Query(BaseExpression):\n         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if\n         # rel_a doesn't produce any rows, then the whole condition must fail.\n         # So, demotion is OK.\n-        existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}\n+        existing_inner = {\n+            a for a in self.alias_map if self.alias_map[a].join_type == INNER\n+        }\n         clause, _ = self._add_q(q_object, self.used_aliases)\n         if clause:\n             self.where.add(clause, AND)\n@@ -1361,21 +1465,33 @@ class Query(BaseExpression):\n     def build_where(self, filter_expr):\n         return self.build_filter(filter_expr, allow_joins=False)[0]\n \n-    def _add_q(self, q_object, used_aliases, branch_negated=False,\n-               current_negated=False, allow_joins=True, split_subq=True,\n-               check_filterable=True):\n+    def _add_q(\n+        self,\n+        q_object,\n+        used_aliases,\n+        branch_negated=False,\n+        current_negated=False,\n+        allow_joins=True,\n+        split_subq=True,\n+        check_filterable=True,\n+    ):\n         \"\"\"Add a Q-object to the current filter.\"\"\"\n         connector = q_object.connector\n         current_negated = current_negated ^ q_object.negated\n         branch_negated = branch_negated or q_object.negated\n-        target_clause = self.where_class(connector=connector,\n-                                         negated=q_object.negated)\n-        joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)\n+        target_clause = self.where_class(connector=connector, negated=q_object.negated)\n+        joinpromoter = JoinPromoter(\n+            q_object.connector, len(q_object.children), current_negated\n+        )\n         for child in q_object.children:\n             child_clause, needed_inner = self.build_filter(\n-                child, can_reuse=used_aliases, branch_negated=branch_negated,\n-                current_negated=current_negated, allow_joins=allow_joins,\n-                split_subq=split_subq, check_filterable=check_filterable,\n+                child,\n+                can_reuse=used_aliases,\n+                branch_negated=branch_negated,\n+                current_negated=current_negated,\n+                allow_joins=allow_joins,\n+                split_subq=split_subq,\n+                check_filterable=check_filterable,\n             )\n             joinpromoter.add_votes(needed_inner)\n             if child_clause:\n@@ -1383,7 +1499,9 @@ class Query(BaseExpression):\n         needed_inner = joinpromoter.update_join_types(self)\n         return target_clause, needed_inner\n \n-    def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):\n+    def build_filtered_relation_q(\n+        self, q_object, reuse, branch_negated=False, current_negated=False\n+    ):\n         \"\"\"Add a FilteredRelation object to the current filter.\"\"\"\n         connector = q_object.connector\n         current_negated ^= q_object.negated\n@@ -1392,14 +1510,19 @@ class Query(BaseExpression):\n         for child in q_object.children:\n             if isinstance(child, Node):\n                 child_clause = self.build_filtered_relation_q(\n-                    child, reuse=reuse, branch_negated=branch_negated,\n+                    child,\n+                    reuse=reuse,\n+                    branch_negated=branch_negated,\n                     current_negated=current_negated,\n                 )\n             else:\n                 child_clause, _ = self.build_filter(\n-                    child, can_reuse=reuse, branch_negated=branch_negated,\n+                    child,\n+                    can_reuse=reuse,\n+                    branch_negated=branch_negated,\n                     current_negated=current_negated,\n-                    allow_joins=True, split_subq=False,\n+                    allow_joins=True,\n+                    split_subq=False,\n                     reuse_with_filtered_relation=True,\n                 )\n             target_clause.add(child_clause, connector)\n@@ -1436,7 +1559,7 @@ class Query(BaseExpression):\n         path, names_with_path = [], []\n         for pos, name in enumerate(names):\n             cur_names_with_path = (name, [])\n-            if name == 'pk':\n+            if name == \"pk\":\n                 name = opts.pk.name\n \n             field = None\n@@ -1471,13 +1594,17 @@ class Query(BaseExpression):\n                 # one step.\n                 pos -= 1\n                 if pos == -1 or fail_on_missing:\n-                    available = sorted([\n-                        *get_field_names_from_opts(opts),\n-                        *self.annotation_select,\n-                        *self._filtered_relations,\n-                    ])\n-                    raise FieldError(\"Cannot resolve keyword '%s' into field. \"\n-                                     \"Choices are: %s\" % (name, \", \".join(available)))\n+                    available = sorted(\n+                        [\n+                            *get_field_names_from_opts(opts),\n+                            *self.annotation_select,\n+                            *self._filtered_relations,\n+                        ]\n+                    )\n+                    raise FieldError(\n+                        \"Cannot resolve keyword '%s' into field. \"\n+                        \"Choices are: %s\" % (name, \", \".join(available))\n+                    )\n                 break\n             # Check if we need any joins for concrete inheritance cases (the\n             # field lives in parent, but we are currently in one of its\n@@ -1488,12 +1615,12 @@ class Query(BaseExpression):\n                     path.extend(path_to_parent)\n                     cur_names_with_path[1].extend(path_to_parent)\n                     opts = path_to_parent[-1].to_opts\n-            if hasattr(field, 'get_path_info'):\n+            if hasattr(field, \"get_path_info\"):\n                 pathinfos = field.get_path_info(filtered_relation)\n                 if not allow_many:\n                     for inner_pos, p in enumerate(pathinfos):\n                         if p.m2m:\n-                            cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])\n+                            cur_names_with_path[1].extend(pathinfos[0 : inner_pos + 1])\n                             names_with_path.append(cur_names_with_path)\n                             raise MultiJoin(pos + 1, names_with_path)\n                 last = pathinfos[-1]\n@@ -1510,12 +1637,20 @@ class Query(BaseExpression):\n                 if fail_on_missing and pos + 1 != len(names):\n                     raise FieldError(\n                         \"Cannot resolve keyword %r into field. Join on '%s'\"\n-                        \" not permitted.\" % (names[pos + 1], name))\n+                        \" not permitted.\" % (names[pos + 1], name)\n+                    )\n                 break\n-        return path, final_field, targets, names[pos + 1:]\n-\n-    def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,\n-                    reuse_with_filtered_relation=False):\n+        return path, final_field, targets, names[pos + 1 :]\n+\n+    def setup_joins(\n+        self,\n+        names,\n+        opts,\n+        alias,\n+        can_reuse=None,\n+        allow_many=True,\n+        reuse_with_filtered_relation=False,\n+    ):\n         \"\"\"\n         Compute the necessary table joins for the passage through the fields\n         given in 'names'. 'opts' is the Options class for the current model\n@@ -1561,7 +1696,10 @@ class Query(BaseExpression):\n         for pivot in range(len(names), 0, -1):\n             try:\n                 path, final_field, targets, rest = self.names_to_path(\n-                    names[:pivot], opts, allow_many, fail_on_missing=True,\n+                    names[:pivot],\n+                    opts,\n+                    allow_many,\n+                    fail_on_missing=True,\n                 )\n             except FieldError as exc:\n                 if pivot == 1:\n@@ -1576,6 +1714,7 @@ class Query(BaseExpression):\n                 transforms = names[pivot:]\n                 break\n         for name in transforms:\n+\n             def transform(field, alias, *, name, previous):\n                 try:\n                     wrapped = previous(field, alias)\n@@ -1586,7 +1725,10 @@ class Query(BaseExpression):\n                         raise last_field_exception\n                     else:\n                         raise\n-            final_transformer = functools.partial(transform, name=name, previous=final_transformer)\n+\n+            final_transformer = functools.partial(\n+                transform, name=name, previous=final_transformer\n+            )\n         # Then, add the path to the query's joins. Note that we can't trim\n         # joins at this stage - we will need the information about join type\n         # of the trimmed joins.\n@@ -1603,12 +1745,18 @@ class Query(BaseExpression):\n             else:\n                 nullable = True\n             connection = Join(\n-                opts.db_table, alias, table_alias, INNER, join.join_field,\n-                nullable, filtered_relation=filtered_relation,\n+                opts.db_table,\n+                alias,\n+                table_alias,\n+                INNER,\n+                join.join_field,\n+                nullable,\n+                filtered_relation=filtered_relation,\n             )\n             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None\n             alias = self.join(\n-                connection, reuse=reuse,\n+                connection,\n+                reuse=reuse,\n                 reuse_with_filtered_relation=reuse_with_filtered_relation,\n             )\n             joins.append(alias)\n@@ -1639,7 +1787,11 @@ class Query(BaseExpression):\n             cur_targets = {t.column for t in targets}\n             if not cur_targets.issubset(join_targets):\n                 break\n-            targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}\n+            targets_dict = {\n+                r[1].column: r[0]\n+                for r in info.join_field.related_fields\n+                if r[1].column in cur_targets\n+            }\n             targets = tuple(targets_dict[t.column] for t in targets)\n             self.unref_alias(joins.pop())\n         return targets, joins[-1], joins\n@@ -1665,8 +1817,7 @@ class Query(BaseExpression):\n                 for alias in self._gen_col_aliases([annotation]):\n                     if isinstance(self.alias_map[alias], Join):\n                         raise FieldError(\n-                            'Joined field references are not permitted in '\n-                            'this query'\n+                            \"Joined field references are not permitted in this query\"\n                         )\n             if summarize:\n                 # Summarize currently means we are doing an aggregate() query\n@@ -1678,13 +1829,20 @@ class Query(BaseExpression):\n                 return annotation\n         else:\n             field_list = name.split(LOOKUP_SEP)\n-            join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)\n-            targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)\n+            join_info = self.setup_joins(\n+                field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse\n+            )\n+            targets, final_alias, join_list = self.trim_joins(\n+                join_info.targets, join_info.joins, join_info.path\n+            )\n             if not allow_joins and len(join_list) > 1:\n-                raise FieldError('Joined field references are not permitted in this query')\n+                raise FieldError(\n+                    \"Joined field references are not permitted in this query\"\n+                )\n             if len(targets) > 1:\n-                raise FieldError(\"Referencing multicolumn fields with F() objects \"\n-                                 \"isn't supported\")\n+                raise FieldError(\n+                    \"Referencing multicolumn fields with F() objects isn't supported\"\n+                )\n             # Verify that the last lookup in name is a field or a transform:\n             # transform_function() raises FieldError if not.\n             join_info.transform_function(targets[0], final_alias)\n@@ -1733,7 +1891,7 @@ class Query(BaseExpression):\n         select_field = col.target\n         alias = col.alias\n         if self.is_nullable(select_field):\n-            lookup_class = select_field.get_lookup('isnull')\n+            lookup_class = select_field.get_lookup(\"isnull\")\n             lookup = lookup_class(select_field.get_col(alias), False)\n             query.where.add(lookup, AND)\n         if alias in can_reuse:\n@@ -1741,21 +1899,26 @@ class Query(BaseExpression):\n             # Need to add a restriction so that outer query's filters are in effect for\n             # the subquery, too.\n             query.bump_prefix(self)\n-            lookup_class = select_field.get_lookup('exact')\n+            lookup_class = select_field.get_lookup(\"exact\")\n             # Note that the query.select[0].alias is different from alias\n             # due to bump_prefix above.\n-            lookup = lookup_class(pk.get_col(query.select[0].alias),\n-                                  pk.get_col(alias))\n+            lookup = lookup_class(pk.get_col(query.select[0].alias), pk.get_col(alias))\n             query.where.add(lookup, AND)\n             query.external_aliases[alias] = True\n \n         condition, needed_inner = self.build_filter(\n-            ('%s__in' % trimmed_prefix, query),\n-            current_negated=True, branch_negated=True, can_reuse=can_reuse)\n+            (\"%s__in\" % trimmed_prefix, query),\n+            current_negated=True,\n+            branch_negated=True,\n+            can_reuse=can_reuse,\n+        )\n         if contains_louter:\n             or_null_condition, _ = self.build_filter(\n-                ('%s__isnull' % trimmed_prefix, True),\n-                current_negated=True, branch_negated=True, can_reuse=can_reuse)\n+                (\"%s__isnull\" % trimmed_prefix, True),\n+                current_negated=True,\n+                branch_negated=True,\n+                can_reuse=can_reuse,\n+            )\n             condition.add(or_null_condition, OR)\n             # Note that the end result will be:\n             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.\n@@ -1831,8 +1994,8 @@ class Query(BaseExpression):\n         self.values_select = ()\n \n     def add_select_col(self, col):\n-        self.select += col,\n-        self.values_select += col.output_field.name,\n+        self.select += (col,)\n+        self.values_select += (col.output_field.name,)\n \n     def set_select(self, cols):\n         self.default_cols = False\n@@ -1858,7 +2021,9 @@ class Query(BaseExpression):\n             for name in field_names:\n                 # Join promotion note - we must not remove any rows here, so\n                 # if there is no existing joins, use outer join.\n-                join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)\n+                join_info = self.setup_joins(\n+                    name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m\n+                )\n                 targets, final_alias, joins = self.trim_joins(\n                     join_info.targets,\n                     join_info.joins,\n@@ -1876,12 +2041,18 @@ class Query(BaseExpression):\n                 # from the model on which the lookup failed.\n                 raise\n             else:\n-                names = sorted([\n-                    *get_field_names_from_opts(opts), *self.extra,\n-                    *self.annotation_select, *self._filtered_relations\n-                ])\n-                raise FieldError(\"Cannot resolve keyword %r into field. \"\n-                                 \"Choices are: %s\" % (name, \", \".join(names)))\n+                names = sorted(\n+                    [\n+                        *get_field_names_from_opts(opts),\n+                        *self.extra,\n+                        *self.annotation_select,\n+                        *self._filtered_relations,\n+                    ]\n+                )\n+                raise FieldError(\n+                    \"Cannot resolve keyword %r into field. \"\n+                    \"Choices are: %s\" % (name, \", \".join(names))\n+                )\n \n     def add_ordering(self, *ordering):\n         \"\"\"\n@@ -1895,18 +2066,18 @@ class Query(BaseExpression):\n         errors = []\n         for item in ordering:\n             if isinstance(item, str):\n-                if '.' in item:\n+                if \".\" in item:\n                     warnings.warn(\n-                        'Passing column raw column aliases to order_by() is '\n-                        'deprecated. Wrap %r in a RawSQL expression before '\n-                        'passing it to order_by().' % item,\n+                        \"Passing column raw column aliases to order_by() is \"\n+                        \"deprecated. Wrap %r in a RawSQL expression before \"\n+                        \"passing it to order_by().\" % item,\n                         category=RemovedInDjango40Warning,\n                         stacklevel=3,\n                     )\n                     continue\n-                if item == '?':\n+                if item == \"?\":\n                     continue\n-                if item.startswith('-'):\n+                if item.startswith(\"-\"):\n                     item = item[1:]\n                 if item in self.annotations:\n                     continue\n@@ -1915,15 +2086,15 @@ class Query(BaseExpression):\n                 # names_to_path() validates the lookup. A descriptive\n                 # FieldError will be raise if it's not.\n                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n-            elif not hasattr(item, 'resolve_expression'):\n+            elif not hasattr(item, \"resolve_expression\"):\n                 errors.append(item)\n-            if getattr(item, 'contains_aggregate', False):\n+            if getattr(item, \"contains_aggregate\", False):\n                 raise FieldError(\n-                    'Using an aggregate in order_by() without also including '\n-                    'it in annotate() is not allowed: %s' % item\n+                    \"Using an aggregate in order_by() without also including \"\n+                    \"it in annotate() is not allowed: %s\" % item\n                 )\n         if errors:\n-            raise FieldError('Invalid order_by arguments: %s' % errors)\n+            raise FieldError(\"Invalid order_by arguments: %s\" % errors)\n         if ordering:\n             self.order_by += ordering\n         else:\n@@ -1955,21 +2126,20 @@ class Query(BaseExpression):\n             for join in list(self.alias_map.values())[1:]:  # Skip base table.\n                 model = join.join_field.related_model\n                 if model not in seen_models:\n-                    column_names.update({\n-                        field.column\n-                        for field in model._meta.local_concrete_fields\n-                    })\n+                    column_names.update(\n+                        {field.column for field in model._meta.local_concrete_fields}\n+                    )\n                     seen_models.add(model)\n \n         group_by = list(self.select)\n         if self.annotation_select:\n             for alias, annotation in self.annotation_select.items():\n                 signature = inspect.signature(annotation.get_group_by_cols)\n-                if 'alias' not in signature.parameters:\n+                if \"alias\" not in signature.parameters:\n                     annotation_class = annotation.__class__\n                     msg = (\n-                        '`alias=None` must be added to the signature of '\n-                        '%s.%s.get_group_by_cols().'\n+                        \"`alias=None` must be added to the signature of \"\n+                        \"%s.%s.get_group_by_cols().\"\n                     ) % (annotation_class.__module__, annotation_class.__qualname__)\n                     warnings.warn(msg, category=RemovedInDjango40Warning)\n                     group_by_cols = annotation.get_group_by_cols()\n@@ -2016,7 +2186,7 @@ class Query(BaseExpression):\n                 entry_params = []\n                 pos = entry.find(\"%s\")\n                 while pos != -1:\n-                    if pos == 0 or entry[pos - 1] != '%':\n+                    if pos == 0 or entry[pos - 1] != \"%\":\n                         entry_params.append(next(param_iter))\n                     pos = entry.find(\"%s\", pos + 2)\n                 select_pairs[name] = (entry, entry_params)\n@@ -2064,8 +2234,8 @@ class Query(BaseExpression):\n         \"\"\"\n         existing, defer = self.deferred_loading\n         field_names = set(field_names)\n-        if 'pk' in field_names:\n-            field_names.remove('pk')\n+        if \"pk\" in field_names:\n+            field_names.remove(\"pk\")\n             field_names.add(self.get_meta().pk.name)\n \n         if defer:\n@@ -2151,7 +2321,9 @@ class Query(BaseExpression):\n         # Selected annotations must be known before setting the GROUP BY\n         # clause.\n         if self.group_by is True:\n-            self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)\n+            self.add_fields(\n+                (f.attname for f in self.model._meta.concrete_fields), False\n+            )\n             # Disable GROUP BY aliases to avoid orphaning references to the\n             # SELECT clause which is about to be cleared.\n             self.set_group_by(allow_aliases=False)\n@@ -2181,7 +2353,8 @@ class Query(BaseExpression):\n             return {}\n         elif self.annotation_select_mask is not None:\n             self._annotation_select_cache = {\n-                k: v for k, v in self.annotations.items()\n+                k: v\n+                for k, v in self.annotations.items()\n                 if k in self.annotation_select_mask\n             }\n             return self._annotation_select_cache\n@@ -2196,8 +2369,7 @@ class Query(BaseExpression):\n             return {}\n         elif self.extra_select_mask is not None:\n             self._extra_select_cache = {\n-                k: v for k, v in self.extra.items()\n-                if k in self.extra_select_mask\n+                k: v for k, v in self.extra.items() if k in self.extra_select_mask\n             }\n             return self._extra_select_cache\n         else:\n@@ -2224,8 +2396,7 @@ class Query(BaseExpression):\n         # the lookup part of the query. That is, avoid trimming\n         # joins generated for F() expressions.\n         lookup_tables = [\n-            t for t in self.alias_map\n-            if t in self._lookup_joins or t == self.base_table\n+            t for t in self.alias_map if t in self._lookup_joins or t == self.base_table\n         ]\n         for trimmed_paths, path in enumerate(all_paths):\n             if path.m2m:\n@@ -2244,8 +2415,7 @@ class Query(BaseExpression):\n                 break\n             trimmed_prefix.append(name)\n             paths_in_prefix -= len(path)\n-        trimmed_prefix.append(\n-            join_field.foreign_related_fields[0].name)\n+        trimmed_prefix.append(join_field.foreign_related_fields[0].name)\n         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)\n         # Lets still see if we can trim the first join from the inner query\n         # (that is, self). We can't do this for:\n@@ -2259,7 +2429,8 @@ class Query(BaseExpression):\n             select_alias = lookup_tables[trimmed_paths + 1]\n             self.unref_alias(lookup_tables[trimmed_paths])\n             extra_restriction = join_field.get_extra_restriction(\n-                self.where_class, None, lookup_tables[trimmed_paths + 1])\n+                self.where_class, None, lookup_tables[trimmed_paths + 1]\n+            )\n             if extra_restriction:\n                 self.where.add(extra_restriction, AND)\n         else:\n@@ -2272,7 +2443,9 @@ class Query(BaseExpression):\n         # But the first entry in the query's FROM clause must not be a JOIN.\n         for table in self.alias_map:\n             if self.alias_refcount[table] > 0:\n-                self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)\n+                self.alias_map[table] = BaseTable(\n+                    self.alias_map[table].table_name, table\n+                )\n                 break\n         self.set_select([f.get_col(select_alias) for f in select_fields])\n         return trimmed_prefix, contains_louter\n@@ -2291,12 +2464,12 @@ class Query(BaseExpression):\n         # is_nullable() is needed to the compiler stage, but that is not easy\n         # to do currently.\n         return (\n-            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and\n-            field.empty_strings_allowed\n+            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n+            and field.empty_strings_allowed\n         ) or field.null\n \n \n-def get_order_dir(field, default='ASC'):\n+def get_order_dir(field, default=\"ASC\"):\n     \"\"\"\n     Return the field name and direction for an order specification. For\n     example, '-foo' is returned as ('foo', 'DESC').\n@@ -2305,7 +2478,7 @@ def get_order_dir(field, default='ASC'):\n     prefix) should sort. The '-' prefix always sorts the opposite way.\n     \"\"\"\n     dirn = ORDER_DIR[default]\n-    if field[0] == '-':\n+    if field[0] == \"-\":\n         return field[1:], dirn[1]\n     return field, dirn[0]\n \n@@ -2379,7 +2552,7 @@ class JoinPromoter:\n             # to rel_a would remove a valid match from the query. So, we need\n             # to promote any existing INNER to LOUTER (it is possible this\n             # promotion in turn will be demoted later on).\n-            if self.effective_connector == 'OR' and votes < self.num_children:\n+            if self.effective_connector == \"OR\" and votes < self.num_children:\n                 to_promote.add(table)\n             # If connector is AND and there is a filter that can match only\n             # when there is a joinable row, then use INNER. For example, in\n@@ -2391,8 +2564,9 @@ class JoinPromoter:\n             #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)\n             # then if rel_a doesn't produce any rows, the whole condition\n             # can't match. Hence we can safely use INNER join.\n-            if self.effective_connector == 'AND' or (\n-                    self.effective_connector == 'OR' and votes == self.num_children):\n+            if self.effective_connector == \"AND\" or (\n+                self.effective_connector == \"OR\" and votes == self.num_children\n+            ):\n                 to_demote.add(table)\n             # Finally, what happens in cases where we have:\n             #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0\n"}
{"instance_id": "django__django-13033", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..edc283d94c 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,7 @@ class SQLCompiler:\n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless it is the pk\n         # shortcut or the attribute name of the field that is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != pieces[-1] and pieces[-1] != 'pk':\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n"}
{"instance_id": "django__django-13158", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 686e75c979..3ca2cf72b8 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -10,7 +10,12 @@ from django.db.models.expressions import F, OrderBy, Random, RawSQL, Ref, Value\n from django.db.models.functions import Cast\n from django.db.models.query_utils import Q, select_related_descend\n from django.db.models.sql.constants import (\n-    CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n+    CURSOR,\n+    GET_ITERATOR_CHUNK_SIZE,\n+    MULTI,\n+    NO_RESULTS,\n+    ORDER_DIR,\n+    SINGLE,\n )\n from django.db.models.sql.query import Query, get_order_dir\n from django.db.transaction import TransactionManagementError\n@@ -22,7 +27,7 @@ from django.utils.regex_helper import _lazy_re_compile\n class SQLCompiler:\n     # Multiline ordering SQL clause may appear from RawSQL.\n     ordering_parts = _lazy_re_compile(\n-        r'^(.*)\\s(?:ASC|DESC).*',\n+        r\"^(.*)\\s(?:ASC|DESC).*\",\n         re.MULTILINE | re.DOTALL,\n     )\n \n@@ -30,7 +35,7 @@ class SQLCompiler:\n         self.query = query\n         self.connection = connection\n         self.using = using\n-        self.quote_cache = {'*': '*'}\n+        self.quote_cache = {\"*\": \"*\"}\n         # The select, klass_info, and annotations are needed by QuerySet.iterator()\n         # these are set as a side-effect of executing the query. Note that we calculate\n         # separately a list of extra select columns needed for grammatical correctness\n@@ -107,16 +112,14 @@ class SQLCompiler:\n             # when  we have public API way of forcing the GROUP BY clause.\n             # Converts string references to expressions.\n             for expr in self.query.group_by:\n-                if not hasattr(expr, 'as_sql'):\n+                if not hasattr(expr, \"as_sql\"):\n                     expressions.append(self.query.resolve_ref(expr))\n                 else:\n                     expressions.append(expr)\n         # Note that even if the group_by is set, it is only the minimal\n         # set to group by. So, we need to add cols in select, order_by, and\n         # having into the select in any case.\n-        ref_sources = {\n-            expr.source for expr in expressions if isinstance(expr, Ref)\n-        }\n+        ref_sources = {expr.source for expr in expressions if isinstance(expr, Ref)}\n         for expr, _, _ in select:\n             # Skip members of the select clause that are already included\n             # by reference.\n@@ -157,8 +160,10 @@ class SQLCompiler:\n             for expr in expressions:\n                 # Is this a reference to query's base table primary key? If the\n                 # expression isn't a Col-like, then skip the expression.\n-                if (getattr(expr, 'target', None) == self.query.model._meta.pk and\n-                        getattr(expr, 'alias', None) == self.query.base_table):\n+                if (\n+                    getattr(expr, \"target\", None) == self.query.model._meta.pk\n+                    and getattr(expr, \"alias\", None) == self.query.base_table\n+                ):\n                     pk = expr\n                     break\n             # If the main model's primary key is in the query, group by that\n@@ -166,13 +171,17 @@ class SQLCompiler:\n             # that don't have a primary key included in the grouped columns.\n             if pk:\n                 pk_aliases = {\n-                    expr.alias for expr in expressions\n-                    if hasattr(expr, 'target') and expr.target.primary_key\n+                    expr.alias\n+                    for expr in expressions\n+                    if hasattr(expr, \"target\") and expr.target.primary_key\n                 }\n                 expressions = [pk] + [\n-                    expr for expr in expressions\n-                    if expr in having or (\n-                        getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases\n+                    expr\n+                    for expr in expressions\n+                    if expr in having\n+                    or (\n+                        getattr(expr, \"alias\", None) is not None\n+                        and expr.alias not in pk_aliases\n                     )\n                 ]\n         elif self.connection.features.allows_group_by_selected_pks:\n@@ -183,16 +192,21 @@ class SQLCompiler:\n             # Unmanaged models are excluded because they could be representing\n             # database views on which the optimization might not be allowed.\n             pks = {\n-                expr for expr in expressions\n+                expr\n+                for expr in expressions\n                 if (\n-                    hasattr(expr, 'target') and\n-                    expr.target.primary_key and\n-                    self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)\n+                    hasattr(expr, \"target\")\n+                    and expr.target.primary_key\n+                    and self.connection.features.allows_group_by_selected_pks_on_model(\n+                        expr.target.model\n+                    )\n                 )\n             }\n             aliases = {expr.alias for expr in pks}\n             expressions = [\n-                expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases\n+                expr\n+                for expr in expressions\n+                if expr in pks or getattr(expr, \"alias\", None) not in aliases\n             ]\n         return expressions\n \n@@ -236,8 +250,8 @@ class SQLCompiler:\n                 select.append((col, None))\n                 select_idx += 1\n             klass_info = {\n-                'model': self.query.model,\n-                'select_fields': select_list,\n+                \"model\": self.query.model,\n+                \"select_fields\": select_list,\n             }\n         for alias, annotation in self.query.annotation_select.items():\n             annotations[alias] = select_idx\n@@ -246,14 +260,16 @@ class SQLCompiler:\n \n         if self.query.select_related:\n             related_klass_infos = self.get_related_selections(select)\n-            klass_info['related_klass_infos'] = related_klass_infos\n+            klass_info[\"related_klass_infos\"] = related_klass_infos\n \n             def get_select_from_parent(klass_info):\n-                for ki in klass_info['related_klass_infos']:\n-                    if ki['from_parent']:\n-                        ki['select_fields'] = (klass_info['select_fields'] +\n-                                               ki['select_fields'])\n+                for ki in klass_info[\"related_klass_infos\"]:\n+                    if ki[\"from_parent\"]:\n+                        ki[\"select_fields\"] = (\n+                            klass_info[\"select_fields\"] + ki[\"select_fields\"]\n+                        )\n                     get_select_from_parent(ki)\n+\n             get_select_from_parent(klass_info)\n \n         ret = []\n@@ -262,7 +278,7 @@ class SQLCompiler:\n                 sql, params = self.compile(col)\n             except EmptyResultSet:\n                 # Select a predicate that's always False.\n-                sql, params = '0', ()\n+                sql, params = \"0\", ()\n             else:\n                 sql, params = col.select_format(self, sql, params)\n             ret.append((col, (sql, params), alias))\n@@ -289,13 +305,13 @@ class SQLCompiler:\n         else:\n             ordering = []\n         if self.query.standard_ordering:\n-            asc, desc = ORDER_DIR['ASC']\n+            asc, desc = ORDER_DIR[\"ASC\"]\n         else:\n-            asc, desc = ORDER_DIR['DESC']\n+            asc, desc = ORDER_DIR[\"DESC\"]\n \n         order_by = []\n         for field in ordering:\n-            if hasattr(field, 'resolve_expression'):\n+            if hasattr(field, \"resolve_expression\"):\n                 if isinstance(field, Value):\n                     # output_field must be resolved for constants.\n                     field = Cast(field, field.output_field)\n@@ -306,18 +322,24 @@ class SQLCompiler:\n                     field.reverse_ordering()\n                 order_by.append((field, False))\n                 continue\n-            if field == '?':  # random\n+            if field == \"?\":  # random\n                 order_by.append((OrderBy(Random()), False))\n                 continue\n \n             col, order = get_order_dir(field, asc)\n-            descending = order == 'DESC'\n+            descending = order == \"DESC\"\n \n             if col in self.query.annotation_select:\n                 # Reference to expression in SELECT clause\n-                order_by.append((\n-                    OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),\n-                    True))\n+                order_by.append(\n+                    (\n+                        OrderBy(\n+                            Ref(col, self.query.annotation_select[col]),\n+                            descending=descending,\n+                        ),\n+                        True,\n+                    )\n+                )\n                 continue\n             if col in self.query.annotations:\n                 # References to an expression which is masked out of the SELECT\n@@ -329,31 +351,51 @@ class SQLCompiler:\n                 order_by.append((OrderBy(expr, descending=descending), False))\n                 continue\n \n-            if '.' in field:\n+            if \".\" in field:\n                 # This came in through an extra(order_by=...) addition. Pass it\n                 # on verbatim.\n-                table, col = col.split('.', 1)\n-                order_by.append((\n-                    OrderBy(\n-                        RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),\n-                        descending=descending\n-                    ), False))\n+                table, col = col.split(\".\", 1)\n+                order_by.append(\n+                    (\n+                        OrderBy(\n+                            RawSQL(\n+                                \"%s.%s\" % (self.quote_name_unless_alias(table), col), []\n+                            ),\n+                            descending=descending,\n+                        ),\n+                        False,\n+                    )\n+                )\n                 continue\n \n             if not self.query.extra or col not in self.query.extra:\n                 # 'col' is of the form 'field' or 'field1__field2' or\n                 # '-field1__field2__field', etc.\n-                order_by.extend(self.find_ordering_name(\n-                    field, self.query.get_meta(), default_order=asc))\n+                order_by.extend(\n+                    self.find_ordering_name(\n+                        field, self.query.get_meta(), default_order=asc\n+                    )\n+                )\n             else:\n                 if col not in self.query.extra_select:\n-                    order_by.append((\n-                        OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n-                        False))\n+                    order_by.append(\n+                        (\n+                            OrderBy(\n+                                RawSQL(*self.query.extra[col]), descending=descending\n+                            ),\n+                            False,\n+                        )\n+                    )\n                 else:\n-                    order_by.append((\n-                        OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),\n-                        True))\n+                    order_by.append(\n+                        (\n+                            OrderBy(\n+                                Ref(col, RawSQL(*self.query.extra[col])),\n+                                descending=descending,\n+                            ),\n+                            True,\n+                        )\n+                    )\n         result = []\n         seen = set()\n \n@@ -373,15 +415,19 @@ class SQLCompiler:\n                     ):\n                         continue\n                     if src == sel_expr:\n-                        resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])\n+                        resolved.set_source_expressions([RawSQL(\"%d\" % (idx + 1), ())])\n                         break\n                 else:\n                     if col_alias:\n-                        raise DatabaseError('ORDER BY term does not match any column in the result set.')\n+                        raise DatabaseError(\n+                            \"ORDER BY term does not match any column in the result set.\"\n+                        )\n                     # Add column used in ORDER BY clause without an alias to\n                     # the selected columns.\n                     self.query.add_select_col(src)\n-                    resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])\n+                    resolved.set_source_expressions(\n+                        [RawSQL(\"%d\" % len(self.query.select), ())]\n+                    )\n             sql, params = self.compile(resolved)\n             # Don't add the same column twice, but the order direction is\n             # not taken into account so we strip it. When this entire method\n@@ -413,9 +459,14 @@ class SQLCompiler:\n         \"\"\"\n         if name in self.quote_cache:\n             return self.quote_cache[name]\n-        if ((name in self.query.alias_map and name not in self.query.table_map) or\n-                name in self.query.extra_select or (\n-                    self.query.external_aliases.get(name) and name not in self.query.table_map)):\n+        if (\n+            (name in self.query.alias_map and name not in self.query.table_map)\n+            or name in self.query.extra_select\n+            or (\n+                self.query.external_aliases.get(name)\n+                and name not in self.query.table_map\n+            )\n+        ):\n             self.quote_cache[name] = name\n             return name\n         r = self.connection.ops.quote_name(name)\n@@ -423,7 +474,7 @@ class SQLCompiler:\n         return r\n \n     def compile(self, node):\n-        vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)\n+        vendor_impl = getattr(node, \"as_\" + self.connection.vendor, None)\n         if vendor_impl:\n             sql, params = vendor_impl(self, self.connection)\n         else:\n@@ -434,14 +485,19 @@ class SQLCompiler:\n         features = self.connection.features\n         compilers = [\n             query.get_compiler(self.using, self.connection)\n-            for query in self.query.combined_queries if not query.is_empty()\n+            for query in self.query.combined_queries\n+            if not query.is_empty()\n         ]\n         if not features.supports_slicing_ordering_in_compound:\n             for query, compiler in zip(self.query.combined_queries, compilers):\n                 if query.low_mark or query.high_mark:\n-                    raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n+                    raise DatabaseError(\n+                        \"LIMIT/OFFSET not allowed in subqueries of compound statements.\"\n+                    )\n                 if compiler.get_order_by():\n-                    raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n+                    raise DatabaseError(\n+                        \"ORDER BY not allowed in subqueries of compound statements.\"\n+                    )\n         parts = ()\n         for compiler in compilers:\n             try:\n@@ -450,36 +506,40 @@ class SQLCompiler:\n                 # the query on all combined queries, if not already set.\n                 if not compiler.query.values_select and self.query.values_select:\n                     compiler.query = compiler.query.clone()\n-                    compiler.query.set_values((\n-                        *self.query.extra_select,\n-                        *self.query.values_select,\n-                        *self.query.annotation_select,\n-                    ))\n+                    compiler.query.set_values(\n+                        (\n+                            *self.query.extra_select,\n+                            *self.query.values_select,\n+                            *self.query.annotation_select,\n+                        )\n+                    )\n                 part_sql, part_args = compiler.as_sql()\n                 if compiler.query.combinator:\n                     # Wrap in a subquery if wrapping in parentheses isn't\n                     # supported.\n                     if not features.supports_parentheses_in_compound:\n-                        part_sql = 'SELECT * FROM ({})'.format(part_sql)\n+                        part_sql = \"SELECT * FROM ({})\".format(part_sql)\n                     # Add parentheses when combining with compound query if not\n                     # already added for all compound queries.\n                     elif not features.supports_slicing_ordering_in_compound:\n-                        part_sql = '({})'.format(part_sql)\n+                        part_sql = \"({})\".format(part_sql)\n                 parts += ((part_sql, part_args),)\n             except EmptyResultSet:\n                 # Omit the empty queryset with UNION and with DIFFERENCE if the\n                 # first queryset is nonempty.\n-                if combinator == 'union' or (combinator == 'difference' and parts):\n+                if combinator == \"union\" or (combinator == \"difference\" and parts):\n                     continue\n                 raise\n         if not parts:\n             raise EmptyResultSet\n         combinator_sql = self.connection.ops.set_operators[combinator]\n-        if all and combinator == 'union':\n-            combinator_sql += ' ALL'\n-        braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n-        sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n-        result = [' {} '.format(combinator_sql).join(sql_parts)]\n+        if all and combinator == \"union\":\n+            combinator_sql += \" ALL\"\n+        braces = \"({})\" if features.supports_slicing_ordering_in_compound else \"{}\"\n+        sql_parts, args_parts = zip(\n+            *((braces.format(sql), args) for sql, args in parts)\n+        )\n+        result = [\" {} \".format(combinator_sql).join(sql_parts)]\n         params = []\n         for part in args_parts:\n             params.extend(part)\n@@ -498,21 +558,35 @@ class SQLCompiler:\n             extra_select, order_by, group_by = self.pre_sql_setup()\n             for_update_part = None\n             # Is a LIMIT/OFFSET clause needed?\n-            with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n+            with_limit_offset = with_limits and (\n+                self.query.high_mark is not None or self.query.low_mark\n+            )\n             combinator = self.query.combinator\n             features = self.connection.features\n             if combinator:\n-                if not getattr(features, 'supports_select_{}'.format(combinator)):\n-                    raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n-                result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n+                if not getattr(features, \"supports_select_{}\".format(combinator)):\n+                    raise NotSupportedError(\n+                        \"{} is not supported on this database backend.\".format(\n+                            combinator\n+                        )\n+                    )\n+                if self.query.is_empty():\n+                    raise EmptyResultSet\n+                result, params = self.get_combinator_sql(\n+                    combinator, self.query.combinator_all\n+                )\n             else:\n                 distinct_fields, distinct_params = self.get_distinct()\n                 # This must come after 'select', 'ordering', and 'distinct'\n                 # (see docstring of get_from_clause() for details).\n                 from_, f_params = self.get_from_clause()\n-                where, w_params = self.compile(self.where) if self.where is not None else (\"\", [])\n-                having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n-                result = ['SELECT']\n+                where, w_params = (\n+                    self.compile(self.where) if self.where is not None else (\"\", [])\n+                )\n+                having, h_params = (\n+                    self.compile(self.having) if self.having is not None else (\"\", [])\n+                )\n+                result = [\"SELECT\"]\n                 params = []\n \n                 if self.query.distinct:\n@@ -527,24 +601,35 @@ class SQLCompiler:\n                 col_idx = 1\n                 for _, (s_sql, s_params), alias in self.select + extra_select:\n                     if alias:\n-                        s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n+                        s_sql = \"%s AS %s\" % (\n+                            s_sql,\n+                            self.connection.ops.quote_name(alias),\n+                        )\n                     elif with_col_aliases:\n-                        s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)\n+                        s_sql = \"%s AS %s\" % (s_sql, \"Col%d\" % col_idx)\n                         col_idx += 1\n                     params.extend(s_params)\n                     out_cols.append(s_sql)\n \n-                result += [', '.join(out_cols), 'FROM', *from_]\n+                result += [\", \".join(out_cols), \"FROM\", *from_]\n                 params.extend(f_params)\n \n-                if self.query.select_for_update and self.connection.features.has_select_for_update:\n+                if (\n+                    self.query.select_for_update\n+                    and self.connection.features.has_select_for_update\n+                ):\n                     if self.connection.get_autocommit():\n-                        raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n+                        raise TransactionManagementError(\n+                            \"select_for_update cannot be used outside of a transaction.\"\n+                        )\n \n-                    if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n+                    if (\n+                        with_limit_offset\n+                        and not self.connection.features.supports_select_for_update_with_limit\n+                    ):\n                         raise NotSupportedError(\n-                            'LIMIT/OFFSET is not supported with '\n-                            'select_for_update on this database backend.'\n+                            \"LIMIT/OFFSET is not supported with \"\n+                            \"select_for_update on this database backend.\"\n                         )\n                     nowait = self.query.select_for_update_nowait\n                     skip_locked = self.query.select_for_update_skip_locked\n@@ -553,16 +638,31 @@ class SQLCompiler:\n                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the\n                     # backend doesn't support it, raise NotSupportedError to\n                     # prevent a possible deadlock.\n-                    if nowait and not self.connection.features.has_select_for_update_nowait:\n-                        raise NotSupportedError('NOWAIT is not supported on this database backend.')\n-                    elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n-                        raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n+                    if (\n+                        nowait\n+                        and not self.connection.features.has_select_for_update_nowait\n+                    ):\n+                        raise NotSupportedError(\n+                            \"NOWAIT is not supported on this database backend.\"\n+                        )\n+                    elif (\n+                        skip_locked\n+                        and not self.connection.features.has_select_for_update_skip_locked\n+                    ):\n+                        raise NotSupportedError(\n+                            \"SKIP LOCKED is not supported on this database backend.\"\n+                        )\n                     elif of and not self.connection.features.has_select_for_update_of:\n-                        raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n-                    elif no_key and not self.connection.features.has_select_for_no_key_update:\n                         raise NotSupportedError(\n-                            'FOR NO KEY UPDATE is not supported on this '\n-                            'database backend.'\n+                            \"FOR UPDATE OF is not supported on this database backend.\"\n+                        )\n+                    elif (\n+                        no_key\n+                        and not self.connection.features.has_select_for_no_key_update\n+                    ):\n+                        raise NotSupportedError(\n+                            \"FOR NO KEY UPDATE is not supported on this \"\n+                            \"database backend.\"\n                         )\n                     for_update_part = self.connection.ops.for_update_sql(\n                         nowait=nowait,\n@@ -575,7 +675,7 @@ class SQLCompiler:\n                     result.append(for_update_part)\n \n                 if where:\n-                    result.append('WHERE %s' % where)\n+                    result.append(\"WHERE %s\" % where)\n                     params.extend(w_params)\n \n                 grouping = []\n@@ -584,30 +684,38 @@ class SQLCompiler:\n                     params.extend(g_params)\n                 if grouping:\n                     if distinct_fields:\n-                        raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n+                        raise NotImplementedError(\n+                            \"annotate() + distinct(fields) is not implemented.\"\n+                        )\n                     order_by = order_by or self.connection.ops.force_no_ordering()\n-                    result.append('GROUP BY %s' % ', '.join(grouping))\n+                    result.append(\"GROUP BY %s\" % \", \".join(grouping))\n                     if self._meta_ordering:\n                         order_by = None\n                 if having:\n-                    result.append('HAVING %s' % having)\n+                    result.append(\"HAVING %s\" % having)\n                     params.extend(h_params)\n \n             if self.query.explain_query:\n-                result.insert(0, self.connection.ops.explain_query_prefix(\n-                    self.query.explain_format,\n-                    **self.query.explain_options\n-                ))\n+                result.insert(\n+                    0,\n+                    self.connection.ops.explain_query_prefix(\n+                        self.query.explain_format, **self.query.explain_options\n+                    ),\n+                )\n \n             if order_by:\n                 ordering = []\n                 for _, (o_sql, o_params, _) in order_by:\n                     ordering.append(o_sql)\n                     params.extend(o_params)\n-                result.append('ORDER BY %s' % ', '.join(ordering))\n+                result.append(\"ORDER BY %s\" % \", \".join(ordering))\n \n             if with_limit_offset:\n-                result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n+                result.append(\n+                    self.connection.ops.limit_offset_sql(\n+                        self.query.low_mark, self.query.high_mark\n+                    )\n+                )\n \n             if for_update_part and not self.connection.features.for_update_after_from:\n                 result.append(for_update_part)\n@@ -623,23 +731,30 @@ class SQLCompiler:\n                 sub_params = []\n                 for index, (select, _, alias) in enumerate(self.select, start=1):\n                     if not alias and with_col_aliases:\n-                        alias = 'col%d' % index\n+                        alias = \"col%d\" % index\n                     if alias:\n-                        sub_selects.append(\"%s.%s\" % (\n-                            self.connection.ops.quote_name('subquery'),\n-                            self.connection.ops.quote_name(alias),\n-                        ))\n+                        sub_selects.append(\n+                            \"%s.%s\"\n+                            % (\n+                                self.connection.ops.quote_name(\"subquery\"),\n+                                self.connection.ops.quote_name(alias),\n+                            )\n+                        )\n                     else:\n-                        select_clone = select.relabeled_clone({select.alias: 'subquery'})\n-                        subselect, subparams = select_clone.as_sql(self, self.connection)\n+                        select_clone = select.relabeled_clone(\n+                            {select.alias: \"subquery\"}\n+                        )\n+                        subselect, subparams = select_clone.as_sql(\n+                            self, self.connection\n+                        )\n                         sub_selects.append(subselect)\n                         sub_params.extend(subparams)\n-                return 'SELECT %s FROM (%s) subquery' % (\n-                    ', '.join(sub_selects),\n-                    ' '.join(result),\n+                return \"SELECT %s FROM (%s) subquery\" % (\n+                    \", \".join(sub_selects),\n+                    \" \".join(result),\n                 ), tuple(sub_params + params)\n \n-            return ' '.join(result), tuple(params)\n+            return \" \".join(result), tuple(params)\n         finally:\n             # Finally do cleanup - get rid of the joins we created above.\n             self.query.reset_refcounts(refcounts_before)\n@@ -672,8 +787,13 @@ class SQLCompiler:\n             # will assign None if the field belongs to this model.\n             if model == opts.model:\n                 model = None\n-            if from_parent and model is not None and issubclass(\n-                    from_parent._meta.concrete_model, model._meta.concrete_model):\n+            if (\n+                from_parent\n+                and model is not None\n+                and issubclass(\n+                    from_parent._meta.concrete_model, model._meta.concrete_model\n+                )\n+            ):\n                 # Avoid loading data for already loaded parents.\n                 # We end up here in the case select_related() resolution\n                 # proceeds from parent model to child model. In that case the\n@@ -682,8 +802,7 @@ class SQLCompiler:\n                 continue\n             if field.model in only_load and field.attname not in only_load[field.model]:\n                 continue\n-            alias = self.query.join_parent_model(opts, model, start_alias,\n-                                                 seen_models)\n+            alias = self.query.join_parent_model(opts, model, start_alias, seen_models)\n             column = field.get_col(alias)\n             result.append(column)\n         return result\n@@ -701,7 +820,9 @@ class SQLCompiler:\n \n         for name in self.query.distinct_fields:\n             parts = name.split(LOOKUP_SEP)\n-            _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n+            _, targets, alias, joins, path, _, transform_function = self._setup_joins(\n+                parts, opts, None\n+            )\n             targets, alias, _ = self.query.trim_joins(targets, joins, path)\n             for target in targets:\n                 if name in self.query.annotation_select:\n@@ -712,46 +833,57 @@ class SQLCompiler:\n                     params.append(p)\n         return result, params\n \n-    def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n-                           already_seen=None):\n+    def find_ordering_name(\n+        self, name, opts, alias=None, default_order=\"ASC\", already_seen=None\n+    ):\n         \"\"\"\n         Return the table alias (the name might be ambiguous, the alias will\n         not be) and column name for ordering by the given 'name' parameter.\n         The 'name' is of the form 'field1__field2__...__fieldN'.\n         \"\"\"\n         name, order = get_order_dir(name, default_order)\n-        descending = order == 'DESC'\n+        descending = order == \"DESC\"\n         pieces = name.split(LOOKUP_SEP)\n-        field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n+        field, targets, alias, joins, path, opts, transform_function = (\n+            self._setup_joins(pieces, opts, alias)\n+        )\n \n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless it is the pk\n         # shortcut or the attribute name of the field that is specified.\n         if (\n-            field.is_relation and\n-            opts.ordering and\n-            getattr(field, 'attname', None) != pieces[-1] and\n-            name != 'pk'\n+            field.is_relation\n+            and opts.ordering\n+            and getattr(field, \"attname\", None) != pieces[-1]\n+            and name != \"pk\"\n         ):\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n-            join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n+            join_tuple = tuple(\n+                getattr(self.query.alias_map[j], \"join_cols\", None) for j in joins\n+            )\n             if join_tuple in already_seen:\n-                raise FieldError('Infinite loop caused by ordering.')\n+                raise FieldError(\"Infinite loop caused by ordering.\")\n             already_seen.add(join_tuple)\n \n             results = []\n             for item in opts.ordering:\n-                if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n+                if hasattr(item, \"resolve_expression\") and not isinstance(\n+                    item, OrderBy\n+                ):\n                     item = item.desc() if descending else item.asc()\n                 if isinstance(item, OrderBy):\n                     results.append((item, False))\n                     continue\n-                results.extend(self.find_ordering_name(item, opts, alias,\n-                                                       order, already_seen))\n+                results.extend(\n+                    self.find_ordering_name(item, opts, alias, order, already_seen)\n+                )\n             return results\n         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n-        return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]\n+        return [\n+            (OrderBy(transform_function(t, alias), descending=descending), False)\n+            for t in targets\n+        ]\n \n     def _setup_joins(self, pieces, opts, alias):\n         \"\"\"\n@@ -762,7 +894,9 @@ class SQLCompiler:\n         match. Executing SQL where this is not true is an error.\n         \"\"\"\n         alias = alias or self.query.get_initial_alias()\n-        field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)\n+        field, targets, opts, joins, path, transform_function = self.query.setup_joins(\n+            pieces, opts, alias\n+        )\n         alias = joins[-1]\n         return field, targets, alias, joins, path, opts, transform_function\n \n@@ -796,25 +930,39 @@ class SQLCompiler:\n             # Only add the alias if it's not already present (the table_alias()\n             # call increments the refcount, so an alias refcount of one means\n             # this is the only reference).\n-            if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:\n-                result.append(', %s' % self.quote_name_unless_alias(alias))\n+            if (\n+                alias not in self.query.alias_map\n+                or self.query.alias_refcount[alias] == 1\n+            ):\n+                result.append(\", %s\" % self.quote_name_unless_alias(alias))\n         return result, params\n \n-    def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,\n-                               requested=None, restricted=None):\n+    def get_related_selections(\n+        self,\n+        select,\n+        opts=None,\n+        root_alias=None,\n+        cur_depth=1,\n+        requested=None,\n+        restricted=None,\n+    ):\n         \"\"\"\n         Fill in the information needed for a select_related query. The current\n         depth is measured as the number of connections away from the root model\n         (for example, cur_depth=1 means we are looking at models with direct\n         connections to the root model).\n         \"\"\"\n+\n         def _get_field_choices():\n             direct_choices = (f.name for f in opts.fields if f.is_relation)\n             reverse_choices = (\n                 f.field.related_query_name()\n-                for f in opts.related_objects if f.field.unique\n+                for f in opts.related_objects\n+                if f.field.unique\n+            )\n+            return chain(\n+                direct_choices, reverse_choices, self.query._filtered_relations\n             )\n-            return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n \n         related_klass_infos = []\n         if not restricted and cur_depth > self.query.max_depth:\n@@ -835,7 +983,7 @@ class SQLCompiler:\n                 requested = self.query.select_related\n \n         def get_related_klass_infos(klass_info, related_klass_infos):\n-            klass_info['related_klass_infos'] = related_klass_infos\n+            klass_info[\"related_klass_infos\"] = related_klass_infos\n \n         for f in opts.fields:\n             field_model = f.model._meta.concrete_model\n@@ -849,37 +997,48 @@ class SQLCompiler:\n                     if next or f.name in requested:\n                         raise FieldError(\n                             \"Non-relational field given in select_related: '%s'. \"\n-                            \"Choices are: %s\" % (\n+                            \"Choices are: %s\"\n+                            % (\n                                 f.name,\n-                                \", \".join(_get_field_choices()) or '(none)',\n+                                \", \".join(_get_field_choices()) or \"(none)\",\n                             )\n                         )\n             else:\n                 next = False\n \n-            if not select_related_descend(f, restricted, requested,\n-                                          only_load.get(field_model)):\n+            if not select_related_descend(\n+                f, restricted, requested, only_load.get(field_model)\n+            ):\n                 continue\n             klass_info = {\n-                'model': f.remote_field.model,\n-                'field': f,\n-                'reverse': False,\n-                'local_setter': f.set_cached_value,\n-                'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,\n-                'from_parent': False,\n+                \"model\": f.remote_field.model,\n+                \"field\": f,\n+                \"reverse\": False,\n+                \"local_setter\": f.set_cached_value,\n+                \"remote_setter\": f.remote_field.set_cached_value\n+                if f.unique\n+                else lambda x, y: None,\n+                \"from_parent\": False,\n             }\n             related_klass_infos.append(klass_info)\n             select_fields = []\n-            _, _, _, joins, _, _ = self.query.setup_joins(\n-                [f.name], opts, root_alias)\n+            _, _, _, joins, _, _ = self.query.setup_joins([f.name], opts, root_alias)\n             alias = joins[-1]\n-            columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)\n+            columns = self.get_default_columns(\n+                start_alias=alias, opts=f.remote_field.model._meta\n+            )\n             for col in columns:\n                 select_fields.append(len(select))\n                 select.append((col, None))\n-            klass_info['select_fields'] = select_fields\n+            klass_info[\"select_fields\"] = select_fields\n             next_klass_infos = self.get_related_selections(\n-                select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)\n+                select,\n+                f.remote_field.model._meta,\n+                alias,\n+                cur_depth + 1,\n+                next,\n+                restricted,\n+            )\n             get_related_klass_infos(klass_info, next_klass_infos)\n \n         if restricted:\n@@ -889,36 +1048,40 @@ class SQLCompiler:\n                 if o.field.unique and not o.many_to_many\n             ]\n             for f, model in related_fields:\n-                if not select_related_descend(f, restricted, requested,\n-                                              only_load.get(model), reverse=True):\n+                if not select_related_descend(\n+                    f, restricted, requested, only_load.get(model), reverse=True\n+                ):\n                     continue\n \n                 related_field_name = f.related_query_name()\n                 fields_found.add(related_field_name)\n \n-                join_info = self.query.setup_joins([related_field_name], opts, root_alias)\n+                join_info = self.query.setup_joins(\n+                    [related_field_name], opts, root_alias\n+                )\n                 alias = join_info.joins[-1]\n                 from_parent = issubclass(model, opts.model) and model is not opts.model\n                 klass_info = {\n-                    'model': model,\n-                    'field': f,\n-                    'reverse': True,\n-                    'local_setter': f.remote_field.set_cached_value,\n-                    'remote_setter': f.set_cached_value,\n-                    'from_parent': from_parent,\n+                    \"model\": model,\n+                    \"field\": f,\n+                    \"reverse\": True,\n+                    \"local_setter\": f.remote_field.set_cached_value,\n+                    \"remote_setter\": f.set_cached_value,\n+                    \"from_parent\": from_parent,\n                 }\n                 related_klass_infos.append(klass_info)\n                 select_fields = []\n                 columns = self.get_default_columns(\n-                    start_alias=alias, opts=model._meta, from_parent=opts.model)\n+                    start_alias=alias, opts=model._meta, from_parent=opts.model\n+                )\n                 for col in columns:\n                     select_fields.append(len(select))\n                     select.append((col, None))\n-                klass_info['select_fields'] = select_fields\n+                klass_info[\"select_fields\"] = select_fields\n                 next = requested.get(f.related_query_name(), {})\n                 next_klass_infos = self.get_related_selections(\n-                    select, model._meta, alias, cur_depth + 1,\n-                    next, restricted)\n+                    select, model._meta, alias, cur_depth + 1, next, restricted\n+                )\n                 get_related_klass_infos(klass_info, next_klass_infos)\n \n             def local_setter(obj, from_obj):\n@@ -935,32 +1098,40 @@ class SQLCompiler:\n                     break\n                 if name in self.query._filtered_relations:\n                     fields_found.add(name)\n-                    f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)\n+                    f, _, join_opts, joins, _, _ = self.query.setup_joins(\n+                        [name], opts, root_alias\n+                    )\n                     model = join_opts.model\n                     alias = joins[-1]\n-                    from_parent = issubclass(model, opts.model) and model is not opts.model\n+                    from_parent = (\n+                        issubclass(model, opts.model) and model is not opts.model\n+                    )\n                     klass_info = {\n-                        'model': model,\n-                        'field': f,\n-                        'reverse': True,\n-                        'local_setter': local_setter,\n-                        'remote_setter': partial(remote_setter, name),\n-                        'from_parent': from_parent,\n+                        \"model\": model,\n+                        \"field\": f,\n+                        \"reverse\": True,\n+                        \"local_setter\": local_setter,\n+                        \"remote_setter\": partial(remote_setter, name),\n+                        \"from_parent\": from_parent,\n                     }\n                     related_klass_infos.append(klass_info)\n                     select_fields = []\n                     columns = self.get_default_columns(\n-                        start_alias=alias, opts=model._meta,\n+                        start_alias=alias,\n+                        opts=model._meta,\n                         from_parent=opts.model,\n                     )\n                     for col in columns:\n                         select_fields.append(len(select))\n                         select.append((col, None))\n-                    klass_info['select_fields'] = select_fields\n+                    klass_info[\"select_fields\"] = select_fields\n                     next_requested = requested.get(name, {})\n                     next_klass_infos = self.get_related_selections(\n-                        select, opts=model._meta, root_alias=alias,\n-                        cur_depth=cur_depth + 1, requested=next_requested,\n+                        select,\n+                        opts=model._meta,\n+                        root_alias=alias,\n+                        cur_depth=cur_depth + 1,\n+                        requested=next_requested,\n                         restricted=restricted,\n                     )\n                     get_related_klass_infos(klass_info, next_klass_infos)\n@@ -968,10 +1139,11 @@ class SQLCompiler:\n             if fields_not_found:\n                 invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n                 raise FieldError(\n-                    'Invalid field name(s) given in select_related: %s. '\n-                    'Choices are: %s' % (\n-                        ', '.join(invalid_fields),\n-                        ', '.join(_get_field_choices()) or '(none)',\n+                    \"Invalid field name(s) given in select_related: %s. \"\n+                    \"Choices are: %s\"\n+                    % (\n+                        \", \".join(invalid_fields),\n+                        \", \".join(_get_field_choices()) or \"(none)\",\n                     )\n                 )\n         return related_klass_infos\n@@ -981,20 +1153,21 @@ class SQLCompiler:\n         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n         the query.\n         \"\"\"\n+\n         def _get_parent_klass_info(klass_info):\n-            for parent_model, parent_link in klass_info['model']._meta.parents.items():\n+            for parent_model, parent_link in klass_info[\"model\"]._meta.parents.items():\n                 parent_list = parent_model._meta.get_parent_list()\n                 yield {\n-                    'model': parent_model,\n-                    'field': parent_link,\n-                    'reverse': False,\n-                    'select_fields': [\n+                    \"model\": parent_model,\n+                    \"field\": parent_link,\n+                    \"reverse\": False,\n+                    \"select_fields\": [\n                         select_index\n-                        for select_index in klass_info['select_fields']\n+                        for select_index in klass_info[\"select_fields\"]\n                         # Selected columns from a model or its parents.\n                         if (\n-                            self.select[select_index][0].target.model == parent_model or\n-                            self.select[select_index][0].target.model in parent_list\n+                            self.select[select_index][0].target.model == parent_model\n+                            or self.select[select_index][0].target.model in parent_list\n                         )\n                     ],\n                 }\n@@ -1007,8 +1180,8 @@ class SQLCompiler:\n             select_fields is filled recursively, so it also contains fields\n             from the parent models.\n             \"\"\"\n-            for select_index in klass_info['select_fields']:\n-                if self.select[select_index][0].target.model == klass_info['model']:\n+            for select_index in klass_info[\"select_fields\"]:\n+                if self.select[select_index][0].target.model == klass_info[\"model\"]:\n                     return self.select[select_index][0]\n \n         def _get_field_choices():\n@@ -1018,10 +1191,10 @@ class SQLCompiler:\n                 parent_path, klass_info = queue.popleft()\n                 if parent_path is None:\n                     path = []\n-                    yield 'self'\n+                    yield \"self\"\n                 else:\n-                    field = klass_info['field']\n-                    if klass_info['reverse']:\n+                    field = klass_info[\"field\"]\n+                    if klass_info[\"reverse\"]:\n                         field = field.remote_field\n                     path = parent_path + [field.name]\n                     yield LOOKUP_SEP.join(path)\n@@ -1031,23 +1204,24 @@ class SQLCompiler:\n                 )\n                 queue.extend(\n                     (path, klass_info)\n-                    for klass_info in klass_info.get('related_klass_infos', [])\n+                    for klass_info in klass_info.get(\"related_klass_infos\", [])\n                 )\n+\n         result = []\n         invalid_names = []\n         for name in self.query.select_for_update_of:\n             klass_info = self.klass_info\n-            if name == 'self':\n+            if name == \"self\":\n                 col = _get_first_selected_col_from_model(klass_info)\n             else:\n                 for part in name.split(LOOKUP_SEP):\n                     klass_infos = (\n-                        *klass_info.get('related_klass_infos', []),\n+                        *klass_info.get(\"related_klass_infos\", []),\n                         *_get_parent_klass_info(klass_info),\n                     )\n                     for related_klass_info in klass_infos:\n-                        field = related_klass_info['field']\n-                        if related_klass_info['reverse']:\n+                        field = related_klass_info[\"field\"]\n+                        if related_klass_info[\"reverse\"]:\n                             field = field.remote_field\n                         if field.name == part:\n                             klass_info = related_klass_info\n@@ -1066,11 +1240,12 @@ class SQLCompiler:\n                     result.append(self.quote_name_unless_alias(col.alias))\n         if invalid_names:\n             raise FieldError(\n-                'Invalid field name(s) given in select_for_update(of=(...)): %s. '\n-                'Only relational fields followed in the query are allowed. '\n-                'Choices are: %s.' % (\n-                    ', '.join(invalid_names),\n-                    ', '.join(_get_field_choices()),\n+                \"Invalid field name(s) given in select_for_update(of=(...)): %s. \"\n+                \"Only relational fields followed in the query are allowed. \"\n+                \"Choices are: %s.\"\n+                % (\n+                    \", \".join(invalid_names),\n+                    \", \".join(_get_field_choices()),\n                 )\n             )\n         return result\n@@ -1106,12 +1281,19 @@ class SQLCompiler:\n                 row[pos] = value\n             yield row\n \n-    def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,\n-                     chunk_size=GET_ITERATOR_CHUNK_SIZE):\n+    def results_iter(\n+        self,\n+        results=None,\n+        tuple_expected=False,\n+        chunked_fetch=False,\n+        chunk_size=GET_ITERATOR_CHUNK_SIZE,\n+    ):\n         \"\"\"Return an iterator over the results from executing this query.\"\"\"\n         if results is None:\n-            results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n-        fields = [s[0] for s in self.select[0:self.col_count]]\n+            results = self.execute_sql(\n+                MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size\n+            )\n+        fields = [s[0] for s in self.select[0 : self.col_count]]\n         converters = self.get_converters(fields)\n         rows = chain.from_iterable(results)\n         if converters:\n@@ -1126,11 +1308,13 @@ class SQLCompiler:\n         versions of \"query has any results.\"\n         \"\"\"\n         # This is always executed on a query clone, so we can modify self.query\n-        self.query.add_extra({'a': 1}, None, None, None, None, None)\n-        self.query.set_extra_mask(['a'])\n+        self.query.add_extra({\"a\": 1}, None, None, None, None, None)\n+        self.query.set_extra_mask([\"a\"])\n         return bool(self.execute_sql(SINGLE))\n \n-    def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n+    def execute_sql(\n+        self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE\n+    ):\n         \"\"\"\n         Run the query against the database and return the result(s). The\n         return value is a single data item if result_type is SINGLE, or an\n@@ -1171,7 +1355,7 @@ class SQLCompiler:\n             try:\n                 val = cursor.fetchone()\n                 if val:\n-                    return val[0:self.col_count]\n+                    return val[0 : self.col_count]\n                 return val\n             finally:\n                 # done with the cursor\n@@ -1181,7 +1365,8 @@ class SQLCompiler:\n             return\n \n         result = cursor_iter(\n-            cursor, self.connection.features.empty_fetchmany_value,\n+            cursor,\n+            self.connection.features.empty_fetchmany_value,\n             self.col_count if self.has_extra_select else None,\n             chunk_size,\n         )\n@@ -1203,12 +1388,11 @@ class SQLCompiler:\n \n         for index, select_col in enumerate(self.query.select):\n             lhs_sql, lhs_params = self.compile(select_col)\n-            rhs = '%s.%s' % (qn(alias), qn2(columns[index]))\n-            self.query.where.add(\n-                RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')\n+            rhs = \"%s.%s\" % (qn(alias), qn2(columns[index]))\n+            self.query.where.add(RawSQL(\"%s = %s\" % (lhs_sql, rhs), lhs_params), \"AND\")\n \n         sql, params = self.as_sql()\n-        return 'EXISTS (%s)' % sql, params\n+        return \"EXISTS (%s)\" % sql, params\n \n     def explain_query(self):\n         result = list(self.execute_sql())\n@@ -1216,7 +1400,7 @@ class SQLCompiler:\n         # tuples with integers and strings. Flatten them out into strings.\n         for row in result[0]:\n             if not isinstance(row, str):\n-                yield ' '.join(str(c) for c in row)\n+                yield \" \".join(str(c) for c in row)\n             else:\n                 yield row\n \n@@ -1237,16 +1421,16 @@ class SQLInsertCompiler(SQLCompiler):\n         if field is None:\n             # A field value of None means the value is raw.\n             sql, params = val, []\n-        elif hasattr(val, 'as_sql'):\n+        elif hasattr(val, \"as_sql\"):\n             # This is an expression, let's compile it.\n             sql, params = self.compile(val)\n-        elif hasattr(field, 'get_placeholder'):\n+        elif hasattr(field, \"get_placeholder\"):\n             # Some fields (e.g. geo fields) need special munging before\n             # they can be inserted.\n             sql, params = field.get_placeholder(val, self, self.connection), [val]\n         else:\n             # Return the common case for the placeholder\n-            sql, params = '%s', [val]\n+            sql, params = \"%s\", [val]\n \n         # The following hook is only used by Oracle Spatial, which sometimes\n         # needs to yield 'NULL' and [] as its placeholder and params instead\n@@ -1262,24 +1446,26 @@ class SQLInsertCompiler(SQLCompiler):\n         Prepare a value to be used in a query by resolving it if it is an\n         expression and otherwise calling the field's get_db_prep_save().\n         \"\"\"\n-        if hasattr(value, 'resolve_expression'):\n-            value = value.resolve_expression(self.query, allow_joins=False, for_save=True)\n+        if hasattr(value, \"resolve_expression\"):\n+            value = value.resolve_expression(\n+                self.query, allow_joins=False, for_save=True\n+            )\n             # Don't allow values containing Col expressions. They refer to\n             # existing columns on a row, but in the case of insert the row\n             # doesn't exist yet.\n             if value.contains_column_references:\n                 raise ValueError(\n                     'Failed to insert expression \"%s\" on %s. F() expressions '\n-                    'can only be used to update, not to insert.' % (value, field)\n+                    \"can only be used to update, not to insert.\" % (value, field)\n                 )\n             if value.contains_aggregate:\n                 raise FieldError(\n-                    'Aggregate functions are not allowed in this query '\n-                    '(%s=%r).' % (field.name, value)\n+                    \"Aggregate functions are not allowed in this query \"\n+                    \"(%s=%r).\" % (field.name, value)\n                 )\n             if value.contains_over_clause:\n                 raise FieldError(\n-                    'Window expressions are not allowed in this query (%s=%r).'\n+                    \"Window expressions are not allowed in this query (%s=%r).\"\n                     % (field.name, value)\n                 )\n         else:\n@@ -1335,35 +1521,49 @@ class SQLInsertCompiler(SQLCompiler):\n         # going to be column names (so we can avoid the extra overhead).\n         qn = self.connection.ops.quote_name\n         opts = self.query.get_meta()\n-        insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)\n-        result = ['%s %s' % (insert_statement, qn(opts.db_table))]\n+        insert_statement = self.connection.ops.insert_statement(\n+            ignore_conflicts=self.query.ignore_conflicts\n+        )\n+        result = [\"%s %s\" % (insert_statement, qn(opts.db_table))]\n         fields = self.query.fields or [opts.pk]\n-        result.append('(%s)' % ', '.join(qn(f.column) for f in fields))\n+        result.append(\"(%s)\" % \", \".join(qn(f.column) for f in fields))\n \n         if self.query.fields:\n             value_rows = [\n-                [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]\n+                [\n+                    self.prepare_value(field, self.pre_save_val(field, obj))\n+                    for field in fields\n+                ]\n                 for obj in self.query.objs\n             ]\n         else:\n             # An empty object.\n-            value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]\n+            value_rows = [\n+                [self.connection.ops.pk_default_value()] for _ in self.query.objs\n+            ]\n             fields = [None]\n \n         # Currently the backends just accept values when generating bulk\n         # queries and generate their own placeholders. Doing that isn't\n         # necessary and it should be possible to use placeholders and\n         # expressions in bulk inserts too.\n-        can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)\n+        can_bulk = (\n+            not self.returning_fields and self.connection.features.has_bulk_insert\n+        )\n \n         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n \n         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(\n             ignore_conflicts=self.query.ignore_conflicts\n         )\n-        if self.returning_fields and self.connection.features.can_return_columns_from_insert:\n+        if (\n+            self.returning_fields\n+            and self.connection.features.can_return_columns_from_insert\n+        ):\n             if self.connection.features.can_return_rows_from_bulk_insert:\n-                result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n+                result.append(\n+                    self.connection.ops.bulk_insert_sql(fields, placeholder_rows)\n+                )\n                 params = param_rows\n             else:\n                 result.append(\"VALUES (%s)\" % \", \".join(placeholder_rows[0]))\n@@ -1372,7 +1572,9 @@ class SQLInsertCompiler(SQLCompiler):\n                 result.append(ignore_conflicts_suffix_sql)\n             # Skip empty r_sql to allow subclasses to customize behavior for\n             # 3rd party backends. Refs #19096.\n-            r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)\n+            r_sql, self.returning_params = self.connection.ops.return_insert_columns(\n+                self.returning_fields\n+            )\n             if r_sql:\n                 result.append(r_sql)\n                 params += [self.returning_params]\n@@ -1393,8 +1595,9 @@ class SQLInsertCompiler(SQLCompiler):\n \n     def execute_sql(self, returning_fields=None):\n         assert not (\n-            returning_fields and len(self.query.objs) != 1 and\n-            not self.connection.features.can_return_rows_from_bulk_insert\n+            returning_fields\n+            and len(self.query.objs) != 1\n+            and not self.connection.features.can_return_rows_from_bulk_insert\n         )\n         self.returning_fields = returning_fields\n         with self.connection.cursor() as cursor:\n@@ -1402,14 +1605,27 @@ class SQLInsertCompiler(SQLCompiler):\n                 cursor.execute(sql, params)\n             if not self.returning_fields:\n                 return []\n-            if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n+            if (\n+                self.connection.features.can_return_rows_from_bulk_insert\n+                and len(self.query.objs) > 1\n+            ):\n                 return self.connection.ops.fetch_returned_insert_rows(cursor)\n             if self.connection.features.can_return_columns_from_insert:\n                 assert len(self.query.objs) == 1\n-                return [self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)]\n-            return [(self.connection.ops.last_insert_id(\n-                cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column\n-            ),)]\n+                return [\n+                    self.connection.ops.fetch_returned_insert_columns(\n+                        cursor, self.returning_params\n+                    )\n+                ]\n+            return [\n+                (\n+                    self.connection.ops.last_insert_id(\n+                        cursor,\n+                        self.query.get_meta().db_table,\n+                        self.query.get_meta().pk.column,\n+                    ),\n+                )\n+            ]\n \n \n class SQLDeleteCompiler(SQLCompiler):\n@@ -1420,13 +1636,11 @@ class SQLDeleteCompiler(SQLCompiler):\n         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n \n     def _as_sql(self, query):\n-        result = [\n-            'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)\n-        ]\n+        result = [\"DELETE FROM %s\" % self.quote_name_unless_alias(query.base_table)]\n         where, params = self.compile(query.where)\n         if where:\n-            result.append('WHERE %s' % where)\n-        return ' '.join(result), tuple(params)\n+            result.append(\"WHERE %s\" % where)\n+        return \" \".join(result), tuple(params)\n \n     def as_sql(self):\n         \"\"\"\n@@ -1439,9 +1653,7 @@ class SQLDeleteCompiler(SQLCompiler):\n         innerq.__class__ = Query\n         innerq.clear_select_clause()\n         pk = self.query.model._meta.pk\n-        innerq.select = [\n-            pk.get_col(self.query.get_initial_alias())\n-        ]\n+        innerq.select = [pk.get_col(self.query.get_initial_alias())]\n         outerq = Query(self.query.model)\n         outerq.where = self.query.where_class()\n         outerq.add_q(Q(pk__in=innerq))\n@@ -1456,23 +1668,25 @@ class SQLUpdateCompiler(SQLCompiler):\n         \"\"\"\n         self.pre_sql_setup()\n         if not self.query.values:\n-            return '', ()\n+            return \"\", ()\n         qn = self.quote_name_unless_alias\n         values, update_params = [], []\n         for field, model, val in self.query.values:\n-            if hasattr(val, 'resolve_expression'):\n-                val = val.resolve_expression(self.query, allow_joins=False, for_save=True)\n+            if hasattr(val, \"resolve_expression\"):\n+                val = val.resolve_expression(\n+                    self.query, allow_joins=False, for_save=True\n+                )\n                 if val.contains_aggregate:\n                     raise FieldError(\n-                        'Aggregate functions are not allowed in this query '\n-                        '(%s=%r).' % (field.name, val)\n+                        \"Aggregate functions are not allowed in this query \"\n+                        \"(%s=%r).\" % (field.name, val)\n                     )\n                 if val.contains_over_clause:\n                     raise FieldError(\n-                        'Window expressions are not allowed in this query '\n-                        '(%s=%r).' % (field.name, val)\n+                        \"Window expressions are not allowed in this query \"\n+                        \"(%s=%r).\" % (field.name, val)\n                     )\n-            elif hasattr(val, 'prepare_database_save'):\n+            elif hasattr(val, \"prepare_database_save\"):\n                 if field.remote_field:\n                     val = field.get_db_prep_save(\n                         val.prepare_database_save(field),\n@@ -1488,29 +1702,29 @@ class SQLUpdateCompiler(SQLCompiler):\n                 val = field.get_db_prep_save(val, connection=self.connection)\n \n             # Getting the placeholder for the field.\n-            if hasattr(field, 'get_placeholder'):\n+            if hasattr(field, \"get_placeholder\"):\n                 placeholder = field.get_placeholder(val, self, self.connection)\n             else:\n-                placeholder = '%s'\n+                placeholder = \"%s\"\n             name = field.column\n-            if hasattr(val, 'as_sql'):\n+            if hasattr(val, \"as_sql\"):\n                 sql, params = self.compile(val)\n-                values.append('%s = %s' % (qn(name), placeholder % sql))\n+                values.append(\"%s = %s\" % (qn(name), placeholder % sql))\n                 update_params.extend(params)\n             elif val is not None:\n-                values.append('%s = %s' % (qn(name), placeholder))\n+                values.append(\"%s = %s\" % (qn(name), placeholder))\n                 update_params.append(val)\n             else:\n-                values.append('%s = NULL' % qn(name))\n+                values.append(\"%s = NULL\" % qn(name))\n         table = self.query.base_table\n         result = [\n-            'UPDATE %s SET' % qn(table),\n-            ', '.join(values),\n+            \"UPDATE %s SET\" % qn(table),\n+            \", \".join(values),\n         ]\n         where, params = self.compile(self.query.where)\n         if where:\n-            result.append('WHERE %s' % where)\n-        return ' '.join(result), tuple(update_params + params)\n+            result.append(\"WHERE %s\" % where)\n+        return \" \".join(result), tuple(update_params + params)\n \n     def execute_sql(self, result_type):\n         \"\"\"\n@@ -1556,7 +1770,9 @@ class SQLUpdateCompiler(SQLCompiler):\n         query.add_fields([query.get_meta().pk.name])\n         super().pre_sql_setup()\n \n-        must_pre_select = count > 1 and not self.connection.features.update_can_self_select\n+        must_pre_select = (\n+            count > 1 and not self.connection.features.update_can_self_select\n+        )\n \n         # Now we adjust the current query: reset the where clause and get rid\n         # of all the tables we don't need (since they're in the sub-select).\n@@ -1568,11 +1784,11 @@ class SQLUpdateCompiler(SQLCompiler):\n             idents = []\n             for rows in query.get_compiler(self.using).execute_sql(MULTI):\n                 idents.extend(r[0] for r in rows)\n-            self.query.add_filter(('pk__in', idents))\n+            self.query.add_filter((\"pk__in\", idents))\n             self.query.related_ids = idents\n         else:\n             # The fast path. Filters and updates in one query.\n-            self.query.add_filter(('pk__in', query))\n+            self.query.add_filter((\"pk__in\", query))\n         self.query.reset_refcounts(refcounts_before)\n \n \n@@ -1589,10 +1805,10 @@ class SQLAggregateCompiler(SQLCompiler):\n             sql.append(ann_sql)\n             params.extend(ann_params)\n         self.col_count = len(self.query.annotation_select)\n-        sql = ', '.join(sql)\n+        sql = \", \".join(sql)\n         params = tuple(params)\n \n-        sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)\n+        sql = \"SELECT %s FROM (%s) subquery\" % (sql, self.query.subquery)\n         params = params + self.query.sub_params\n         return sql, params\n \n"}
{"instance_id": "django__django-13220", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex dc084b8692..79c2cc6fd0 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -5,21 +5,25 @@ Global Django exception and warning classes.\n \n class FieldDoesNotExist(Exception):\n     \"\"\"The requested model field does not exist\"\"\"\n+\n     pass\n \n \n class AppRegistryNotReady(Exception):\n     \"\"\"The django.apps registry is not populated yet\"\"\"\n+\n     pass\n \n \n class ObjectDoesNotExist(Exception):\n     \"\"\"The requested object does not exist\"\"\"\n+\n     silent_variable_failure = True\n \n \n class MultipleObjectsReturned(Exception):\n     \"\"\"The query returned multiple objects when only one was expected.\"\"\"\n+\n     pass\n \n \n@@ -29,21 +33,25 @@ class SuspiciousOperation(Exception):\n \n class SuspiciousMultipartForm(SuspiciousOperation):\n     \"\"\"Suspect MIME request in multipart form data\"\"\"\n+\n     pass\n \n \n class SuspiciousFileOperation(SuspiciousOperation):\n     \"\"\"A Suspicious filesystem operation was attempted\"\"\"\n+\n     pass\n \n \n class DisallowedHost(SuspiciousOperation):\n     \"\"\"HTTP_HOST header contains invalid value\"\"\"\n+\n     pass\n \n \n class DisallowedRedirect(SuspiciousOperation):\n     \"\"\"Redirect to scheme not in allowed list\"\"\"\n+\n     pass\n \n \n@@ -52,6 +60,7 @@ class TooManyFieldsSent(SuspiciousOperation):\n     The number of fields in a GET or POST request exceeded\n     settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.\n     \"\"\"\n+\n     pass\n \n \n@@ -60,44 +69,52 @@ class RequestDataTooBig(SuspiciousOperation):\n     The size of the request (excluding any file uploads) exceeded\n     settings.DATA_UPLOAD_MAX_MEMORY_SIZE.\n     \"\"\"\n+\n     pass\n \n \n class RequestAborted(Exception):\n     \"\"\"The request was closed before it was completed, or timed out.\"\"\"\n+\n     pass\n \n \n class PermissionDenied(Exception):\n     \"\"\"The user did not have permission to do that\"\"\"\n+\n     pass\n \n \n class ViewDoesNotExist(Exception):\n     \"\"\"The requested view does not exist\"\"\"\n+\n     pass\n \n \n class MiddlewareNotUsed(Exception):\n     \"\"\"This middleware is not used in this server configuration\"\"\"\n+\n     pass\n \n \n class ImproperlyConfigured(Exception):\n     \"\"\"Django is somehow improperly configured\"\"\"\n+\n     pass\n \n \n class FieldError(Exception):\n     \"\"\"Some kind of problem with a model field.\"\"\"\n+\n     pass\n \n \n-NON_FIELD_ERRORS = '__all__'\n+NON_FIELD_ERRORS = \"__all__\"\n \n \n class ValidationError(Exception):\n     \"\"\"An error while validating data.\"\"\"\n+\n     def __init__(self, message, code=None, params=None):\n         \"\"\"\n         The `message` argument can be a single error, a list of errors, or a\n@@ -110,9 +127,9 @@ class ValidationError(Exception):\n         super().__init__(message, code, params)\n \n         if isinstance(message, ValidationError):\n-            if hasattr(message, 'error_dict'):\n+            if hasattr(message, \"error_dict\"):\n                 message = message.error_dict\n-            elif not hasattr(message, 'message'):\n+            elif not hasattr(message, \"message\"):\n                 message = message.error_list\n             else:\n                 message, code, params = message.message, message.code, message.params\n@@ -130,7 +147,7 @@ class ValidationError(Exception):\n                 # Normalize plain strings to instances of ValidationError.\n                 if not isinstance(message, ValidationError):\n                     message = ValidationError(message)\n-                if hasattr(message, 'error_dict'):\n+                if hasattr(message, \"error_dict\"):\n                     self.error_list.extend(sum(message.error_dict.values(), []))\n                 else:\n                     self.error_list.extend(message.error_list)\n@@ -145,18 +162,18 @@ class ValidationError(Exception):\n     def message_dict(self):\n         # Trigger an AttributeError if this ValidationError\n         # doesn't have an error_dict.\n-        getattr(self, 'error_dict')\n+        getattr(self, \"error_dict\")\n \n         return dict(self)\n \n     @property\n     def messages(self):\n-        if hasattr(self, 'error_dict'):\n+        if hasattr(self, \"error_dict\"):\n             return sum(dict(self).values(), [])\n         return list(self)\n \n     def update_error_dict(self, error_dict):\n-        if hasattr(self, 'error_dict'):\n+        if hasattr(self, \"error_dict\"):\n             for field, error_list in self.error_dict.items():\n                 error_dict.setdefault(field, []).extend(error_list)\n         else:\n@@ -164,7 +181,7 @@ class ValidationError(Exception):\n         return error_dict\n \n     def __iter__(self):\n-        if hasattr(self, 'error_dict'):\n+        if hasattr(self, \"error_dict\"):\n             for field, errors in self.error_dict.items():\n                 yield field, list(ValidationError(errors))\n         else:\n@@ -174,20 +191,54 @@ class ValidationError(Exception):\n                     message %= error.params\n                 yield str(message)\n \n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return NotImplemented\n+        if hasattr(self, \"error_dict\") and hasattr(other, \"error_dict\"):\n+            if set(self.error_dict.keys()) != set(other.error_dict.keys()):\n+                return False\n+            for field in self.error_dict:\n+                self_msgs = sorted(\n+                    ((e.message, e.code, e.params) for e in self.error_dict[field]),\n+                    key=lambda x: (x[0] or \"\", x[1] or \"\", str(x[2] or \"\")),\n+                )\n+                other_msgs = sorted(\n+                    ((e.message, e.code, e.params) for e in other.error_dict[field]),\n+                    key=lambda x: (x[0] or \"\", x[1] or \"\", str(x[2] or \"\")),\n+                )\n+                if self_msgs != other_msgs:\n+                    return False\n+            return True\n+        if hasattr(self, \"error_dict\") or hasattr(other, \"error_dict\"):\n+            return False\n+        if hasattr(self, \"message\") != hasattr(other, \"message\"):\n+            return False\n+        self_msgs = sorted(\n+            ((e.message, e.code, e.params) for e in self.error_list),\n+            key=lambda x: (x[0] or \"\", x[1] or \"\", str(x[2] or \"\")),\n+        )\n+        other_msgs = sorted(\n+            ((e.message, e.code, e.params) for e in other.error_list),\n+            key=lambda x: (x[0] or \"\", x[1] or \"\", str(x[2] or \"\")),\n+        )\n+        return self_msgs == other_msgs\n+\n     def __str__(self):\n-        if hasattr(self, 'error_dict'):\n+        if hasattr(self, \"error_dict\"):\n             return repr(dict(self))\n         return repr(list(self))\n \n     def __repr__(self):\n-        return 'ValidationError(%s)' % self\n+        return \"ValidationError(%s)\" % self\n \n \n class EmptyResultSet(Exception):\n     \"\"\"A database query predicate is impossible.\"\"\"\n+\n     pass\n \n \n class SynchronousOnlyOperation(Exception):\n     \"\"\"The user tried to call a sync-only function from an async context.\"\"\"\n+\n     pass\n"}
{"instance_id": "django__django-13230", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 68ffb0bfe0..2e411edbf9 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -13,12 +13,12 @@ from django.utils.translation import get_language\n \n \n def add_domain(domain, url, secure=False):\n-    protocol = 'https' if secure else 'http'\n-    if url.startswith('//'):\n+    protocol = \"https\" if secure else \"http\"\n+    if url.startswith(\"//\"):\n         # Support network-path reference (see #16753) - RSS requires a protocol\n-        url = '%s:%s' % (protocol, url)\n-    elif not url.startswith(('http://', 'https://', 'mailto:')):\n-        url = iri_to_uri('%s://%s%s' % (protocol, domain, url))\n+        url = \"%s:%s\" % (protocol, url)\n+    elif not url.startswith((\"http://\", \"https://\", \"mailto:\")):\n+        url = iri_to_uri(\"%s://%s%s\" % (protocol, domain, url))\n     return url\n \n \n@@ -36,15 +36,16 @@ class Feed:\n         try:\n             obj = self.get_object(request, *args, **kwargs)\n         except ObjectDoesNotExist:\n-            raise Http404('Feed object does not exist.')\n+            raise Http404(\"Feed object does not exist.\")\n         feedgen = self.get_feed(obj, request)\n         response = HttpResponse(content_type=feedgen.content_type)\n-        if hasattr(self, 'item_pubdate') or hasattr(self, 'item_updateddate'):\n+        if hasattr(self, \"item_pubdate\") or hasattr(self, \"item_updateddate\"):\n             # if item_pubdate or item_updateddate is defined for the feed, set\n             # header so as ConditionalGetMiddleware is able to send 304 NOT MODIFIED\n-            response['Last-Modified'] = http_date(\n-                timegm(feedgen.latest_post_date().utctimetuple()))\n-        feedgen.write(response, 'utf-8')\n+            response[\"Last-Modified\"] = http_date(\n+                timegm(feedgen.latest_post_date().utctimetuple())\n+            )\n+        feedgen.write(response, \"utf-8\")\n         return response\n \n     def item_title(self, item):\n@@ -59,17 +60,17 @@ class Feed:\n             return item.get_absolute_url()\n         except AttributeError:\n             raise ImproperlyConfigured(\n-                'Give your %s class a get_absolute_url() method, or define an '\n-                'item_link() method in your Feed class.' % item.__class__.__name__\n+                \"Give your %s class a get_absolute_url() method, or define an \"\n+                \"item_link() method in your Feed class.\" % item.__class__.__name__\n             )\n \n     def item_enclosures(self, item):\n-        enc_url = self._get_dynamic_attr('item_enclosure_url', item)\n+        enc_url = self._get_dynamic_attr(\"item_enclosure_url\", item)\n         if enc_url:\n             enc = feedgenerator.Enclosure(\n                 url=str(enc_url),\n-                length=str(self._get_dynamic_attr('item_enclosure_length', item)),\n-                mime_type=str(self._get_dynamic_attr('item_enclosure_mime_type', item)),\n+                length=str(self._get_dynamic_attr(\"item_enclosure_length\", item)),\n+                mime_type=str(self._get_dynamic_attr(\"item_enclosure_mime_type\", item)),\n             )\n             return [enc]\n         return []\n@@ -87,7 +88,7 @@ class Feed:\n                 code = attr.__code__\n             except AttributeError:\n                 code = attr.__call__.__code__\n-            if code.co_argcount == 2:       # one argument is 'self'\n+            if code.co_argcount == 2:  # one argument is 'self'\n                 return attr(obj)\n             else:\n                 return attr()\n@@ -118,7 +119,7 @@ class Feed:\n         Default implementation preserves the old behavior\n         of using {'obj': item, 'site': current_site} as the context.\n         \"\"\"\n-        return {'obj': kwargs.get('item'), 'site': kwargs.get('site')}\n+        return {\"obj\": kwargs.get(\"item\"), \"site\": kwargs.get(\"site\")}\n \n     def get_feed(self, obj, request):\n         \"\"\"\n@@ -127,28 +128,28 @@ class Feed:\n         \"\"\"\n         current_site = get_current_site(request)\n \n-        link = self._get_dynamic_attr('link', obj)\n+        link = self._get_dynamic_attr(\"link\", obj)\n         link = add_domain(current_site.domain, link, request.is_secure())\n \n         feed = self.feed_type(\n-            title=self._get_dynamic_attr('title', obj),\n-            subtitle=self._get_dynamic_attr('subtitle', obj),\n+            title=self._get_dynamic_attr(\"title\", obj),\n+            subtitle=self._get_dynamic_attr(\"subtitle\", obj),\n             link=link,\n-            description=self._get_dynamic_attr('description', obj),\n+            description=self._get_dynamic_attr(\"description\", obj),\n             language=self.language or get_language(),\n             feed_url=add_domain(\n                 current_site.domain,\n-                self._get_dynamic_attr('feed_url', obj) or request.path,\n+                self._get_dynamic_attr(\"feed_url\", obj) or request.path,\n                 request.is_secure(),\n             ),\n-            author_name=self._get_dynamic_attr('author_name', obj),\n-            author_link=self._get_dynamic_attr('author_link', obj),\n-            author_email=self._get_dynamic_attr('author_email', obj),\n-            categories=self._get_dynamic_attr('categories', obj),\n-            feed_copyright=self._get_dynamic_attr('feed_copyright', obj),\n-            feed_guid=self._get_dynamic_attr('feed_guid', obj),\n-            ttl=self._get_dynamic_attr('ttl', obj),\n-            **self.feed_extra_kwargs(obj)\n+            author_name=self._get_dynamic_attr(\"author_name\", obj),\n+            author_link=self._get_dynamic_attr(\"author_link\", obj),\n+            author_email=self._get_dynamic_attr(\"author_email\", obj),\n+            categories=self._get_dynamic_attr(\"categories\", obj),\n+            feed_copyright=self._get_dynamic_attr(\"feed_copyright\", obj),\n+            feed_guid=self._get_dynamic_attr(\"feed_guid\", obj),\n+            ttl=self._get_dynamic_attr(\"ttl\", obj),\n+            **self.feed_extra_kwargs(obj),\n         )\n \n         title_tmp = None\n@@ -165,37 +166,38 @@ class Feed:\n             except TemplateDoesNotExist:\n                 pass\n \n-        for item in self._get_dynamic_attr('items', obj):\n-            context = self.get_context_data(item=item, site=current_site,\n-                                            obj=obj, request=request)\n+        for item in self._get_dynamic_attr(\"items\", obj):\n+            context = self.get_context_data(\n+                item=item, site=current_site, obj=obj, request=request\n+            )\n             if title_tmp is not None:\n                 title = title_tmp.render(context, request)\n             else:\n-                title = self._get_dynamic_attr('item_title', item)\n+                title = self._get_dynamic_attr(\"item_title\", item)\n             if description_tmp is not None:\n                 description = description_tmp.render(context, request)\n             else:\n-                description = self._get_dynamic_attr('item_description', item)\n+                description = self._get_dynamic_attr(\"item_description\", item)\n             link = add_domain(\n                 current_site.domain,\n-                self._get_dynamic_attr('item_link', item),\n+                self._get_dynamic_attr(\"item_link\", item),\n                 request.is_secure(),\n             )\n-            enclosures = self._get_dynamic_attr('item_enclosures', item)\n-            author_name = self._get_dynamic_attr('item_author_name', item)\n+            enclosures = self._get_dynamic_attr(\"item_enclosures\", item)\n+            author_name = self._get_dynamic_attr(\"item_author_name\", item)\n             if author_name is not None:\n-                author_email = self._get_dynamic_attr('item_author_email', item)\n-                author_link = self._get_dynamic_attr('item_author_link', item)\n+                author_email = self._get_dynamic_attr(\"item_author_email\", item)\n+                author_link = self._get_dynamic_attr(\"item_author_link\", item)\n             else:\n                 author_email = author_link = None\n \n             tz = get_default_timezone()\n \n-            pubdate = self._get_dynamic_attr('item_pubdate', item)\n+            pubdate = self._get_dynamic_attr(\"item_pubdate\", item)\n             if pubdate and is_naive(pubdate):\n                 pubdate = make_aware(pubdate, tz)\n \n-            updateddate = self._get_dynamic_attr('item_updateddate', item)\n+            updateddate = self._get_dynamic_attr(\"item_updateddate\", item)\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n@@ -203,17 +205,19 @@ class Feed:\n                 title=title,\n                 link=link,\n                 description=description,\n-                unique_id=self._get_dynamic_attr('item_guid', item, link),\n+                unique_id=self._get_dynamic_attr(\"item_guid\", item, link),\n                 unique_id_is_permalink=self._get_dynamic_attr(\n-                    'item_guid_is_permalink', item),\n+                    \"item_guid_is_permalink\", item\n+                ),\n                 enclosures=enclosures,\n                 pubdate=pubdate,\n                 updateddate=updateddate,\n                 author_name=author_name,\n                 author_email=author_email,\n                 author_link=author_link,\n-                categories=self._get_dynamic_attr('item_categories', item),\n-                item_copyright=self._get_dynamic_attr('item_copyright', item),\n-                **self.item_extra_kwargs(item)\n+                categories=self._get_dynamic_attr(\"item_categories\", item),\n+                item_copyright=self._get_dynamic_attr(\"item_copyright\", item),\n+                comments=self._get_dynamic_attr(\"item_comments\", item),\n+                **self.item_extra_kwargs(item),\n             )\n         return feed\n"}
{"instance_id": "django__django-13265", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": ""}
{"instance_id": "django__django-13315", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 2bce85beef..55ca1e28c5 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -18,7 +18,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -28,14 +31,38 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FilePathField', 'FloatField',\n-    'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED',\n-    'NullBooleanField', 'PositiveBigIntegerField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallAutoField',\n-    'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveBigIntegerField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -71,6 +98,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -97,15 +125,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -123,18 +151,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -170,7 +217,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -180,19 +227,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -210,12 +257,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -223,15 +270,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % LOOKUP_SEP,\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -250,7 +297,7 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -269,14 +316,22 @@ class Field(RegisterLookupMixin):\n                 ):\n                     break\n                 if self.max_length is not None and group_choices:\n-                    choice_max_length = max([\n-                        choice_max_length,\n-                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n-                    ])\n+                    choice_max_length = max(\n+                        [\n+                            choice_max_length,\n+                            *(\n+                                len(value)\n+                                for value, _ in group_choices\n+                                if isinstance(value, str)\n+                            ),\n+                        ]\n+                    )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n                 value, human_name = group_name, group_choices\n-                if not self._choices_is_value(value) or not self._choices_is_value(human_name):\n+                if not self._choices_is_value(value) or not self._choices_is_value(\n+                    human_name\n+                ):\n                     break\n                 if self.max_length is not None and isinstance(value, str):\n                     choice_max_length = max(choice_max_length, len(value))\n@@ -291,7 +346,7 @@ class Field(RegisterLookupMixin):\n                         \"'max_length' is too small to fit the longest value \"\n                         \"in 'choices' (%d characters).\" % choice_max_length,\n                         obj=self,\n-                        id='fields.E009',\n+                        id=\"fields.E009\",\n                     ),\n                 ]\n             return []\n@@ -301,7 +356,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -311,25 +366,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -341,7 +401,9 @@ class Field(RegisterLookupMixin):\n         app_label = self.model._meta.app_label\n         errors = []\n         for alias in databases:\n-            if router.allow_migrate(alias, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                alias, app_label, model_name=self.model._meta.model_name\n+            ):\n                 errors.extend(connections[alias].validation.check_field(self, **kwargs))\n         return errors\n \n@@ -355,11 +417,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -369,25 +432,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -397,6 +459,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -404,6 +467,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -463,7 +527,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -496,8 +560,8 @@ class Field(RegisterLookupMixin):\n             path = path.replace(\"django.db.models.fields.related\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.files\"):\n             path = path.replace(\"django.db.models.fields.files\", \"django.db.models\")\n-        elif path.startswith('django.db.models.fields.json'):\n-            path = path.replace('django.db.models.fields.json', 'django.db.models')\n+        elif path.startswith(\"django.db.models.fields.json\"):\n+            path = path.replace(\"django.db.models.fields.json\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.proxy\"):\n             path = path.replace(\"django.db.models.fields.proxy\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields\"):\n@@ -516,10 +580,9 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return (\n-                self.creation_counter == other.creation_counter and\n-                getattr(self, 'model', None) == getattr(other, 'model', None)\n-            )\n+            return self.creation_counter == other.creation_counter and getattr(\n+                self, \"model\", None\n+            ) == getattr(other, \"model\", None)\n         return NotImplemented\n \n     def __lt__(self, other):\n@@ -527,26 +590,29 @@ class Field(RegisterLookupMixin):\n         # Order by creation_counter first for backward compatibility.\n         if isinstance(other, Field):\n             if (\n-                self.creation_counter != other.creation_counter or\n-                not hasattr(self, 'model') and not hasattr(other, 'model')\n+                self.creation_counter != other.creation_counter\n+                or not hasattr(self, \"model\")\n+                and not hasattr(other, \"model\")\n             ):\n                 return self.creation_counter < other.creation_counter\n-            elif hasattr(self, 'model') != hasattr(other, 'model'):\n-                return not hasattr(self, 'model')  # Order no-model fields first\n+            elif hasattr(self, \"model\") != hasattr(other, \"model\"):\n+                return not hasattr(self, \"model\")  # Order no-model fields first\n             else:\n                 # creation_counter's are equal, compare only models.\n-                return (\n-                    (self.model._meta.app_label, self.model._meta.model_name) <\n-                    (other.model._meta.app_label, other.model._meta.model_name)\n+                return (self.model._meta.app_label, self.model._meta.model_name) < (\n+                    other.model._meta.app_label,\n+                    other.model._meta.model_name,\n                 )\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash((\n-            self.creation_counter,\n-            self.model._meta.app_label if hasattr(self, 'model') else None,\n-            self.model._meta.model_name if hasattr(self, 'model') else None,\n-        ))\n+        return hash(\n+            (\n+                self.creation_counter,\n+                self.model._meta.app_label if hasattr(self, \"model\") else None,\n+                self.model._meta.model_name if hasattr(self, \"model\") else None,\n+            )\n+        )\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n@@ -554,7 +620,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -573,7 +639,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -582,10 +648,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -623,7 +692,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -650,16 +719,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -673,7 +742,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -683,7 +752,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -745,7 +816,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -770,7 +841,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -793,10 +864,10 @@ class Field(RegisterLookupMixin):\n             # this class, but don't check methods derived from inheritance, to\n             # allow overriding inherited choices. For more complex inheritance\n             # structures users should override contribute_to_class().\n-            if 'get_%s_display' % self.name not in cls.__dict__:\n+            if \"get_%s_display\" % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n-                    'get_%s_display' % self.name,\n+                    \"get_%s_display\" % self.name,\n                     partialmethod(cls._get_FIELD_display, field=self),\n                 )\n \n@@ -857,11 +928,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -869,7 +950,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -877,10 +960,10 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n-        qs = rel_model._default_manager.complex_filter(limit_choices_to)\n+        qs = rel_model._default_manager.complex_filter(limit_choices_to).distinct()\n         if ordering:\n             qs = qs.order_by(*ordering)\n         return (blank_choice if include_blank else []) + [\n@@ -905,6 +988,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -913,24 +997,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -939,9 +1024,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -956,8 +1051,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -970,14 +1065,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -988,14 +1083,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -1008,7 +1103,7 @@ class CharField(Field):\n         self.validators.append(validators.MaxLengthValidator(self.max_length))\n \n     def check(self, **kwargs):\n-        databases = kwargs.get('databases') or []\n+        databases = kwargs.get(\"databases\") or []\n         return [\n             *super().check(**kwargs),\n             *self._check_db_collation(databases),\n@@ -1021,16 +1116,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1043,16 +1141,17 @@ class CharField(Field):\n                 continue\n             connection = connections[db]\n             if not (\n-                self.db_collation is None or\n-                'supports_collation_on_charfield' in self.model._meta.required_db_features or\n-                connection.features.supports_collation_on_charfield\n+                self.db_collation is None\n+                or \"supports_collation_on_charfield\"\n+                in self.model._meta.required_db_features\n+                or connection.features.supports_collation_on_charfield\n             ):\n                 errors.append(\n                     checks.Error(\n-                        '%s does not support a database collation on '\n-                        'CharFields.' % connection.display_name,\n+                        \"%s does not support a database collation on \"\n+                        \"CharFields.\" % connection.display_name,\n                         obj=self,\n-                        id='fields.E190',\n+                        id=\"fields.E190\",\n                     ),\n                 )\n         return errors\n@@ -1078,17 +1177,17 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.db_collation:\n-            kwargs['db_collation'] = self.db_collation\n+            kwargs[\"db_collation\"] = self.db_collation\n         return name, path, args, kwargs\n \n \n@@ -1096,20 +1195,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1121,8 +1218,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1130,7 +1233,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1143,19 +1246,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1186,13 +1294,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1201,12 +1309,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1231,15 +1339,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1254,12 +1362,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1274,25 +1388,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1329,13 +1451,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1356,10 +1478,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1370,9 +1494,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1381,15 +1505,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1411,13 +1535,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1430,24 +1555,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1474,7 +1607,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1482,7 +1615,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1498,7 +1631,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1506,7 +1639,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1518,7 +1651,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1536,9 +1669,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1553,25 +1686,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except (decimal.InvalidOperation, TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1581,10 +1718,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1605,9 +1745,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1625,13 +1765,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1640,7 +1782,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1652,20 +1794,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1680,23 +1833,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1708,15 +1861,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1725,7 +1880,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1750,22 +1905,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1779,10 +1936,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1796,22 +1954,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1837,16 +2001,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1857,32 +2023,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1900,14 +2068,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1917,13 +2093,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1931,11 +2107,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1947,8 +2123,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1960,7 +2138,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1968,37 +2146,39 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n     system_check_deprecated_details = {\n-        'msg': (\n-            'NullBooleanField is deprecated. Support for it (except in '\n-            'historical migrations) will be removed in Django 4.0.'\n+        \"msg\": (\n+            \"NullBooleanField is deprecated. Support for it (except in \"\n+            \"historical migrations) will be removed in Django 4.0.\"\n         ),\n-        'hint': 'Use BooleanField(null=True) instead.',\n-        'id': 'fields.W903',\n+        \"hint\": \"Use BooleanField(null=True) instead.\",\n+        \"id\": \"fields.W903\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2006,7 +2186,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -2023,16 +2202,18 @@ class PositiveIntegerRelDbTypeMixin:\n \n \n class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n-    description = _('Positive big integer')\n+    description = _(\"Positive big integer\")\n \n     def get_internal_type(self):\n-        return 'PositiveBigIntegerField'\n+        return \"PositiveBigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2042,10 +2223,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2055,17 +2238,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -2074,24 +2261,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2109,7 +2298,7 @@ class TextField(Field):\n         self.db_collation = db_collation\n \n     def check(self, **kwargs):\n-        databases = kwargs.get('databases') or []\n+        databases = kwargs.get(\"databases\") or []\n         return [\n             *super().check(**kwargs),\n             *self._check_db_collation(databases),\n@@ -2122,16 +2311,17 @@ class TextField(Field):\n                 continue\n             connection = connections[db]\n             if not (\n-                self.db_collation is None or\n-                'supports_collation_on_textfield' in self.model._meta.required_db_features or\n-                connection.features.supports_collation_on_textfield\n+                self.db_collation is None\n+                or \"supports_collation_on_textfield\"\n+                in self.model._meta.required_db_features\n+                or connection.features.supports_collation_on_textfield\n             ):\n                 errors.append(\n                     checks.Error(\n-                        '%s does not support a database collation on '\n-                        'TextFields.' % connection.display_name,\n+                        \"%s does not support a database collation on \"\n+                        \"TextFields.\" % connection.display_name,\n                         obj=self,\n-                        id='fields.E190',\n+                        id=\"fields.E190\",\n                     ),\n                 )\n         return errors\n@@ -2152,35 +2342,42 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.db_collation:\n-            kwargs['db_collation'] = self.db_collation\n+            kwargs[\"db_collation\"] = self.db_collation\n         return name, path, args, kwargs\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2214,13 +2411,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2233,8 +2430,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2257,15 +2454,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2288,13 +2485,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2302,30 +2501,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2340,7 +2541,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2348,9 +2549,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2363,8 +2564,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2375,29 +2576,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2419,29 +2620,31 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n     db_returning = True\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2454,9 +2657,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2464,8 +2667,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2479,8 +2682,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2511,34 +2713,33 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n         return subclass in self._subclasses or super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..b27cee1fe8 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -2,31 +2,46 @@\n Helper functions for creating Form classes from Django models\n and database field objects.\n \"\"\"\n+\n import warnings\n from itertools import chain\n \n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldError, ImproperlyConfigured, ValidationError,\n+    NON_FIELD_ERRORS,\n+    FieldError,\n+    ImproperlyConfigured,\n+    ValidationError,\n )\n from django.forms.fields import ChoiceField, Field\n from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, RadioSelect, SelectMultiple,\n+    HiddenInput,\n+    MultipleHiddenInput,\n+    RadioSelect,\n+    SelectMultiple,\n )\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n __all__ = (\n-    'ModelForm', 'BaseModelForm', 'model_to_dict', 'fields_for_model',\n-    'ModelChoiceField', 'ModelMultipleChoiceField', 'ALL_FIELDS',\n-    'BaseModelFormSet', 'modelformset_factory', 'BaseInlineFormSet',\n-    'inlineformset_factory', 'modelform_factory',\n+    \"ModelForm\",\n+    \"BaseModelForm\",\n+    \"model_to_dict\",\n+    \"fields_for_model\",\n+    \"ModelChoiceField\",\n+    \"ModelMultipleChoiceField\",\n+    \"ALL_FIELDS\",\n+    \"BaseModelFormSet\",\n+    \"modelformset_factory\",\n+    \"BaseInlineFormSet\",\n+    \"inlineformset_factory\",\n+    \"modelform_factory\",\n )\n \n-ALL_FIELDS = '__all__'\n+ALL_FIELDS = \"__all__\"\n \n \n def construct_instance(form, instance, fields=None, exclude=None):\n@@ -35,13 +50,17 @@ def construct_instance(form, instance, fields=None, exclude=None):\n     ``cleaned_data``, but do not save the returned instance to the database.\n     \"\"\"\n     from django.db import models\n+\n     opts = instance._meta\n \n     cleaned_data = form.cleaned_data\n     file_field_list = []\n     for f in opts.fields:\n-        if not f.editable or isinstance(f, models.AutoField) \\\n-                or f.name not in cleaned_data:\n+        if (\n+            not f.editable\n+            or isinstance(f, models.AutoField)\n+            or f.name not in cleaned_data\n+        ):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -50,9 +69,11 @@ def construct_instance(form, instance, fields=None, exclude=None):\n         # Leave defaults for fields that aren't in POST data, except for\n         # checkbox inputs because they don't appear in POST data if not checked.\n         if (\n-            f.has_default() and\n-            form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name)) and\n-            cleaned_data.get(f.name) in form[f.name].field.empty_values\n+            f.has_default()\n+            and form[f.name].field.widget.value_omitted_from_data(\n+                form.data, form.files, form.add_prefix(f.name)\n+            )\n+            and cleaned_data.get(f.name) in form[f.name].field.empty_values\n         ):\n             continue\n         # Defer saving file-type fields until after the other fields, so a\n@@ -70,6 +91,7 @@ def construct_instance(form, instance, fields=None, exclude=None):\n \n # ModelForms #################################################################\n \n+\n def model_to_dict(instance, fields=None, exclude=None):\n     \"\"\"\n     Return a dict containing the data in ``instance`` suitable for passing as\n@@ -85,7 +107,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     opts = instance._meta\n     data = {}\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n-        if not getattr(f, 'editable', False):\n+        if not getattr(f, \"editable\", False):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -97,16 +119,28 @@ def model_to_dict(instance, fields=None, exclude=None):\n \n def apply_limit_choices_to_to_formfield(formfield):\n     \"\"\"Apply limit_choices_to to the formfield's queryset if needed.\"\"\"\n-    if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n+    if hasattr(formfield, \"queryset\") and hasattr(formfield, \"get_limit_choices_to\"):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n-\n-\n-def fields_for_model(model, fields=None, exclude=None, widgets=None,\n-                     formfield_callback=None, localized_fields=None,\n-                     labels=None, help_texts=None, error_messages=None,\n-                     field_classes=None, *, apply_limit_choices_to=True):\n+            formfield.queryset = formfield.queryset.complex_filter(\n+                limit_choices_to\n+            ).distinct()\n+\n+\n+def fields_for_model(\n+    model,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    formfield_callback=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+    *,\n+    apply_limit_choices_to=True,\n+):\n     \"\"\"\n     Return a dictionary containing form fields for the given model.\n \n@@ -142,14 +176,22 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n     opts = model._meta\n     # Avoid circular import\n     from django.db.models import Field as ModelField\n-    sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)]\n-    for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)):\n-        if not getattr(f, 'editable', False):\n-            if (fields is not None and f.name in fields and\n-                    (exclude is None or f.name not in exclude)):\n+\n+    sortable_private_fields = [\n+        f for f in opts.private_fields if isinstance(f, ModelField)\n+    ]\n+    for f in sorted(\n+        chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)\n+    ):\n+        if not getattr(f, \"editable\", False):\n+            if (\n+                fields is not None\n+                and f.name in fields\n+                and (exclude is None or f.name not in exclude)\n+            ):\n                 raise FieldError(\n-                    \"'%s' cannot be specified for %s model form as it is a non-editable field\" % (\n-                        f.name, model.__name__)\n+                    \"'%s' cannot be specified for %s model form as it is a non-editable field\"\n+                    % (f.name, model.__name__)\n                 )\n             continue\n         if fields is not None and f.name not in fields:\n@@ -159,22 +201,24 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n         kwargs = {}\n         if widgets and f.name in widgets:\n-            kwargs['widget'] = widgets[f.name]\n-        if localized_fields == ALL_FIELDS or (localized_fields and f.name in localized_fields):\n-            kwargs['localize'] = True\n+            kwargs[\"widget\"] = widgets[f.name]\n+        if localized_fields == ALL_FIELDS or (\n+            localized_fields and f.name in localized_fields\n+        ):\n+            kwargs[\"localize\"] = True\n         if labels and f.name in labels:\n-            kwargs['label'] = labels[f.name]\n+            kwargs[\"label\"] = labels[f.name]\n         if help_texts and f.name in help_texts:\n-            kwargs['help_text'] = help_texts[f.name]\n+            kwargs[\"help_text\"] = help_texts[f.name]\n         if error_messages and f.name in error_messages:\n-            kwargs['error_messages'] = error_messages[f.name]\n+            kwargs[\"error_messages\"] = error_messages[f.name]\n         if field_classes and f.name in field_classes:\n-            kwargs['form_class'] = field_classes[f.name]\n+            kwargs[\"form_class\"] = field_classes[f.name]\n \n         if formfield_callback is None:\n             formfield = f.formfield(**kwargs)\n         elif not callable(formfield_callback):\n-            raise TypeError('formfield_callback must be a function or callable')\n+            raise TypeError(\"formfield_callback must be a function or callable\")\n         else:\n             formfield = formfield_callback(f, **kwargs)\n \n@@ -186,7 +230,8 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n             ignored.append(f.name)\n     if fields:\n         field_dict = {\n-            f: field_dict.get(f) for f in fields\n+            f: field_dict.get(f)\n+            for f in fields\n             if (not exclude or f not in exclude) and f not in ignored\n         }\n     return field_dict\n@@ -194,46 +239,49 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n class ModelFormOptions:\n     def __init__(self, options=None):\n-        self.model = getattr(options, 'model', None)\n-        self.fields = getattr(options, 'fields', None)\n-        self.exclude = getattr(options, 'exclude', None)\n-        self.widgets = getattr(options, 'widgets', None)\n-        self.localized_fields = getattr(options, 'localized_fields', None)\n-        self.labels = getattr(options, 'labels', None)\n-        self.help_texts = getattr(options, 'help_texts', None)\n-        self.error_messages = getattr(options, 'error_messages', None)\n-        self.field_classes = getattr(options, 'field_classes', None)\n+        self.model = getattr(options, \"model\", None)\n+        self.fields = getattr(options, \"fields\", None)\n+        self.exclude = getattr(options, \"exclude\", None)\n+        self.widgets = getattr(options, \"widgets\", None)\n+        self.localized_fields = getattr(options, \"localized_fields\", None)\n+        self.labels = getattr(options, \"labels\", None)\n+        self.help_texts = getattr(options, \"help_texts\", None)\n+        self.error_messages = getattr(options, \"error_messages\", None)\n+        self.field_classes = getattr(options, \"field_classes\", None)\n \n \n class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n     def __new__(mcs, name, bases, attrs):\n         base_formfield_callback = None\n         for b in bases:\n-            if hasattr(b, 'Meta') and hasattr(b.Meta, 'formfield_callback'):\n+            if hasattr(b, \"Meta\") and hasattr(b.Meta, \"formfield_callback\"):\n                 base_formfield_callback = b.Meta.formfield_callback\n                 break\n \n-        formfield_callback = attrs.pop('formfield_callback', base_formfield_callback)\n+        formfield_callback = attrs.pop(\"formfield_callback\", base_formfield_callback)\n \n         new_class = super().__new__(mcs, name, bases, attrs)\n \n         if bases == (BaseModelForm,):\n             return new_class\n \n-        opts = new_class._meta = ModelFormOptions(getattr(new_class, 'Meta', None))\n+        opts = new_class._meta = ModelFormOptions(getattr(new_class, \"Meta\", None))\n \n         # We check if a string was passed to `fields` or `exclude`,\n         # which is likely to be a mistake where the user typed ('foo') instead\n         # of ('foo',)\n-        for opt in ['fields', 'exclude', 'localized_fields']:\n+        for opt in [\"fields\", \"exclude\", \"localized_fields\"]:\n             value = getattr(opts, opt)\n             if isinstance(value, str) and value != ALL_FIELDS:\n-                msg = (\"%(model)s.Meta.%(opt)s cannot be a string. \"\n-                       \"Did you mean to type: ('%(value)s',)?\" % {\n-                           'model': new_class.__name__,\n-                           'opt': opt,\n-                           'value': value,\n-                       })\n+                msg = (\n+                    \"%(model)s.Meta.%(opt)s cannot be a string. \"\n+                    \"Did you mean to type: ('%(value)s',)?\"\n+                    % {\n+                        \"model\": new_class.__name__,\n+                        \"opt\": opt,\n+                        \"value\": value,\n+                    }\n+                )\n                 raise TypeError(msg)\n \n         if opts.model:\n@@ -251,9 +299,16 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n                 opts.fields = None\n \n             fields = fields_for_model(\n-                opts.model, opts.fields, opts.exclude, opts.widgets,\n-                formfield_callback, opts.localized_fields, opts.labels,\n-                opts.help_texts, opts.error_messages, opts.field_classes,\n+                opts.model,\n+                opts.fields,\n+                opts.exclude,\n+                opts.widgets,\n+                formfield_callback,\n+                opts.localized_fields,\n+                opts.labels,\n+                opts.help_texts,\n+                opts.error_messages,\n+                opts.field_classes,\n                 # limit_choices_to will be applied during ModelForm.__init__().\n                 apply_limit_choices_to=False,\n             )\n@@ -262,9 +317,8 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n             none_model_fields = {k for k, v in fields.items() if not v}\n             missing_fields = none_model_fields.difference(new_class.declared_fields)\n             if missing_fields:\n-                message = 'Unknown field(s) (%s) specified for %s'\n-                message = message % (', '.join(missing_fields),\n-                                     opts.model.__name__)\n+                message = \"Unknown field(s) (%s) specified for %s\"\n+                message = message % (\", \".join(missing_fields), opts.model.__name__)\n                 raise FieldError(message)\n             # Override default model fields with any custom declared ones\n             # (plus, include all the other declared fields).\n@@ -278,13 +332,23 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n \n \n class BaseModelForm(BaseForm):\n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 initial=None, error_class=ErrorList, label_suffix=None,\n-                 empty_permitted=False, instance=None, use_required_attribute=None,\n-                 renderer=None):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        initial=None,\n+        error_class=ErrorList,\n+        label_suffix=None,\n+        empty_permitted=False,\n+        instance=None,\n+        use_required_attribute=None,\n+        renderer=None,\n+    ):\n         opts = self._meta\n         if opts.model is None:\n-            raise ValueError('ModelForm has no model class specified.')\n+            raise ValueError(\"ModelForm has no model class specified.\")\n         if instance is None:\n             # if we didn't get an instance, instantiate a new one\n             self.instance = opts.model()\n@@ -300,8 +364,15 @@ class BaseModelForm(BaseForm):\n         # super will stop validate_unique from being called.\n         self._validate_unique = False\n         super().__init__(\n-            data, files, auto_id, prefix, object_data, error_class,\n-            label_suffix, empty_permitted, use_required_attribute=use_required_attribute,\n+            data,\n+            files,\n+            auto_id,\n+            prefix,\n+            object_data,\n+            error_class,\n+            label_suffix,\n+            empty_permitted,\n+            use_required_attribute=use_required_attribute,\n             renderer=renderer,\n         )\n         for formfield in self.fields.values():\n@@ -344,7 +415,11 @@ class BaseModelForm(BaseForm):\n             else:\n                 form_field = self.fields[field]\n                 field_value = self.cleaned_data.get(field)\n-                if not f.blank and not form_field.required and field_value in form_field.empty_values:\n+                if (\n+                    not f.blank\n+                    and not form_field.required\n+                    and field_value in form_field.empty_values\n+                ):\n                     exclude.append(f.name)\n         return exclude\n \n@@ -359,14 +434,17 @@ class BaseModelForm(BaseForm):\n \n         # Allow the model generated by construct_instance() to raise\n         # ValidationError and have them handled in the same way as others.\n-        if hasattr(errors, 'error_dict'):\n+        if hasattr(errors, \"error_dict\"):\n             error_dict = errors.error_dict\n         else:\n             error_dict = {NON_FIELD_ERRORS: errors}\n \n         for field, messages in error_dict.items():\n-            if (field == NON_FIELD_ERRORS and opts.error_messages and\n-                    NON_FIELD_ERRORS in opts.error_messages):\n+            if (\n+                field == NON_FIELD_ERRORS\n+                and opts.error_messages\n+                and NON_FIELD_ERRORS in opts.error_messages\n+            ):\n                 error_messages = opts.error_messages[NON_FIELD_ERRORS]\n             elif field in self.fields:\n                 error_messages = self.fields[field].error_messages\n@@ -374,8 +452,10 @@ class BaseModelForm(BaseForm):\n                 continue\n \n             for message in messages:\n-                if (isinstance(message, ValidationError) and\n-                        message.code in error_messages):\n+                if (\n+                    isinstance(message, ValidationError)\n+                    and message.code in error_messages\n+                ):\n                     message.message = error_messages[message.code]\n \n         self.add_error(None, errors)\n@@ -397,7 +477,9 @@ class BaseModelForm(BaseForm):\n                 exclude.append(name)\n \n         try:\n-            self.instance = construct_instance(self, self.instance, opts.fields, opts.exclude)\n+            self.instance = construct_instance(\n+                self, self.instance, opts.fields, opts.exclude\n+            )\n         except ValidationError as e:\n             self._update_errors(e)\n \n@@ -433,7 +515,7 @@ class BaseModelForm(BaseForm):\n         # private_fields here. (GenericRelation was previously a fake\n         # m2m field).\n         for f in chain(opts.many_to_many, opts.private_fields):\n-            if not hasattr(f, 'save_form_data'):\n+            if not hasattr(f, \"save_form_data\"):\n                 continue\n             if fields and f.name not in fields:\n                 continue\n@@ -450,9 +532,10 @@ class BaseModelForm(BaseForm):\n         \"\"\"\n         if self.errors:\n             raise ValueError(\n-                \"The %s could not be %s because the data didn't validate.\" % (\n+                \"The %s could not be %s because the data didn't validate.\"\n+                % (\n                     self.instance._meta.object_name,\n-                    'created' if self.instance._state.adding else 'changed',\n+                    \"created\" if self.instance._state.adding else \"changed\",\n                 )\n             )\n         if commit:\n@@ -472,10 +555,19 @@ class ModelForm(BaseModelForm, metaclass=ModelFormMetaclass):\n     pass\n \n \n-def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n-                      formfield_callback=None, widgets=None, localized_fields=None,\n-                      labels=None, help_texts=None, error_messages=None,\n-                      field_classes=None):\n+def modelform_factory(\n+    model,\n+    form=ModelForm,\n+    fields=None,\n+    exclude=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+):\n     \"\"\"\n     Return a ModelForm containing form fields for the given model. You can\n     optionally pass a `form` argument to use as a starting point for\n@@ -511,41 +603,37 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n     # inner class.\n \n     # Build up a list of attributes that the Meta object will have.\n-    attrs = {'model': model}\n+    attrs = {\"model\": model}\n     if fields is not None:\n-        attrs['fields'] = fields\n+        attrs[\"fields\"] = fields\n     if exclude is not None:\n-        attrs['exclude'] = exclude\n+        attrs[\"exclude\"] = exclude\n     if widgets is not None:\n-        attrs['widgets'] = widgets\n+        attrs[\"widgets\"] = widgets\n     if localized_fields is not None:\n-        attrs['localized_fields'] = localized_fields\n+        attrs[\"localized_fields\"] = localized_fields\n     if labels is not None:\n-        attrs['labels'] = labels\n+        attrs[\"labels\"] = labels\n     if help_texts is not None:\n-        attrs['help_texts'] = help_texts\n+        attrs[\"help_texts\"] = help_texts\n     if error_messages is not None:\n-        attrs['error_messages'] = error_messages\n+        attrs[\"error_messages\"] = error_messages\n     if field_classes is not None:\n-        attrs['field_classes'] = field_classes\n+        attrs[\"field_classes\"] = field_classes\n \n     # If parent form class already has an inner Meta, the Meta we're\n     # creating needs to inherit from the parent's inner meta.\n-    bases = (form.Meta,) if hasattr(form, 'Meta') else ()\n-    Meta = type('Meta', bases, attrs)\n+    bases = (form.Meta,) if hasattr(form, \"Meta\") else ()\n+    Meta = type(\"Meta\", bases, attrs)\n     if formfield_callback:\n         Meta.formfield_callback = staticmethod(formfield_callback)\n     # Give this new form class a reasonable name.\n-    class_name = model.__name__ + 'Form'\n+    class_name = model.__name__ + \"Form\"\n \n     # Class attributes for the new form class.\n-    form_class_attrs = {\n-        'Meta': Meta,\n-        'formfield_callback': formfield_callback\n-    }\n+    form_class_attrs = {\"Meta\": Meta, \"formfield_callback\": formfield_callback}\n \n-    if (getattr(Meta, 'fields', None) is None and\n-            getattr(Meta, 'exclude', None) is None):\n+    if getattr(Meta, \"fields\", None) is None and getattr(Meta, \"exclude\", None) is None:\n         raise ImproperlyConfigured(\n             \"Calling modelform_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n@@ -557,20 +645,39 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n \n # ModelFormSets ##############################################################\n \n+\n class BaseModelFormSet(BaseFormSet):\n     \"\"\"\n     A ``FormSet`` for editing a queryset and/or adding new objects to it.\n     \"\"\"\n+\n     model = None\n \n     # Set of fields that must be unique among forms of this set.\n     unique_fields = set()\n \n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 queryset=None, *, initial=None, **kwargs):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        queryset=None,\n+        *,\n+        initial=None,\n+        **kwargs,\n+    ):\n         self.queryset = queryset\n         self.initial_extra = initial\n-        super().__init__(**{'data': data, 'files': files, 'auto_id': auto_id, 'prefix': prefix, **kwargs})\n+        super().__init__(\n+            **{\n+                \"data\": data,\n+                \"files\": files,\n+                \"auto_id\": auto_id,\n+                \"prefix\": prefix,\n+                **kwargs,\n+            }\n+        )\n \n     def initial_form_count(self):\n         \"\"\"Return the number of forms that are required in this FormSet.\"\"\"\n@@ -579,7 +686,7 @@ class BaseModelFormSet(BaseFormSet):\n         return super().initial_form_count()\n \n     def _existing_object(self, pk):\n-        if not hasattr(self, '_object_dict'):\n+        if not hasattr(self, \"_object_dict\"):\n             self._object_dict = {o.pk: o for o in self.get_queryset()}\n         return self._object_dict.get(pk)\n \n@@ -596,7 +703,7 @@ class BaseModelFormSet(BaseFormSet):\n         pk_required = i < self.initial_form_count()\n         if pk_required:\n             if self.is_bound:\n-                pk_key = '%s-%s' % (self.add_prefix(i), self.model._meta.pk.name)\n+                pk_key = \"%s-%s\" % (self.add_prefix(i), self.model._meta.pk.name)\n                 try:\n                     pk = self.data[pk_key]\n                 except KeyError:\n@@ -612,13 +719,13 @@ class BaseModelFormSet(BaseFormSet):\n                         # user may have tampered with POST data.\n                         pass\n                     else:\n-                        kwargs['instance'] = self._existing_object(pk)\n+                        kwargs[\"instance\"] = self._existing_object(pk)\n             else:\n-                kwargs['instance'] = self.get_queryset()[i]\n+                kwargs[\"instance\"] = self.get_queryset()[i]\n         elif self.initial_extra:\n             # Set initial values for extra forms\n             try:\n-                kwargs['initial'] = self.initial_extra[i - self.initial_form_count()]\n+                kwargs[\"initial\"] = self.initial_extra[i - self.initial_form_count()]\n             except IndexError:\n                 pass\n         form = super()._construct_form(i, **kwargs)\n@@ -627,7 +734,7 @@ class BaseModelFormSet(BaseFormSet):\n         return form\n \n     def get_queryset(self):\n-        if not hasattr(self, '_queryset'):\n+        if not hasattr(self, \"_queryset\"):\n             if self.queryset is not None:\n                 qs = self.queryset\n             else:\n@@ -669,6 +776,7 @@ class BaseModelFormSet(BaseFormSet):\n             def save_m2m():\n                 for form in self.saved_forms:\n                     form.save_m2m()\n+\n             self.save_m2m = save_m2m\n         return self.save_existing_objects(commit) + self.save_new_objects(commit)\n \n@@ -682,10 +790,16 @@ class BaseModelFormSet(BaseFormSet):\n         all_unique_checks = set()\n         all_date_checks = set()\n         forms_to_delete = self.deleted_forms\n-        valid_forms = [form for form in self.forms if form.is_valid() and form not in forms_to_delete]\n+        valid_forms = [\n+            form\n+            for form in self.forms\n+            if form.is_valid() and form not in forms_to_delete\n+        ]\n         for form in valid_forms:\n             exclude = form._get_validation_exclusions()\n-            unique_checks, date_checks = form.instance._get_unique_checks(exclude=exclude)\n+            unique_checks, date_checks = form.instance._get_unique_checks(\n+                exclude=exclude\n+            )\n             all_unique_checks.update(unique_checks)\n             all_date_checks.update(date_checks)\n \n@@ -697,14 +811,18 @@ class BaseModelFormSet(BaseFormSet):\n                 # Get the data for the set of fields that must be unique among the forms.\n                 row_data = (\n                     field if field in self.unique_fields else form.cleaned_data[field]\n-                    for field in unique_check if field in form.cleaned_data\n+                    for field in unique_check\n+                    if field in form.cleaned_data\n                 )\n                 # Reduce Model instances to their primary key values\n                 row_data = tuple(\n-                    d._get_pk_val() if hasattr(d, '_get_pk_val')\n+                    d._get_pk_val()\n+                    if hasattr(d, \"_get_pk_val\")\n                     # Prevent \"unhashable type: list\" errors later on.\n-                    else tuple(d) if isinstance(d, list)\n-                    else d for d in row_data\n+                    else tuple(d)\n+                    if isinstance(d, list)\n+                    else d\n+                    for d in row_data\n                 )\n                 if row_data and None not in row_data:\n                     # if we've already seen it then we have a uniqueness failure\n@@ -712,7 +830,9 @@ class BaseModelFormSet(BaseFormSet):\n                         # poke error messages into the right places and mark\n                         # the form as invalid\n                         errors.append(self.get_unique_error_message(unique_check))\n-                        form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()])\n+                        form._errors[NON_FIELD_ERRORS] = self.error_class(\n+                            [self.get_form_error()]\n+                        )\n                         # remove the data from the cleaned_data dict since it was invalid\n                         for field in unique_check:\n                             if field in form.cleaned_data:\n@@ -725,10 +845,13 @@ class BaseModelFormSet(BaseFormSet):\n             uclass, lookup, field, unique_for = date_check\n             for form in valid_forms:\n                 # see if we have data for both fields\n-                if (form.cleaned_data and form.cleaned_data[field] is not None and\n-                        form.cleaned_data[unique_for] is not None):\n+                if (\n+                    form.cleaned_data\n+                    and form.cleaned_data[field] is not None\n+                    and form.cleaned_data[unique_for] is not None\n+                ):\n                     # if it's a date lookup we need to get the data for all the fields\n-                    if lookup == 'date':\n+                    if lookup == \"date\":\n                         date = form.cleaned_data[unique_for]\n                         date_data = (date.year, date.month, date.day)\n                     # otherwise it's just the attribute on the date/datetime\n@@ -741,7 +864,9 @@ class BaseModelFormSet(BaseFormSet):\n                         # poke error messages into the right places and mark\n                         # the form as invalid\n                         errors.append(self.get_date_error_message(date_check))\n-                        form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()])\n+                        form._errors[NON_FIELD_ERRORS] = self.error_class(\n+                            [self.get_form_error()]\n+                        )\n                         # remove the data from the cleaned_data dict since it was invalid\n                         del form.cleaned_data[field]\n                     # mark the data as seen\n@@ -756,7 +881,9 @@ class BaseModelFormSet(BaseFormSet):\n                 \"field\": unique_check[0],\n             }\n         else:\n-            return gettext(\"Please correct the duplicate data for %(field)s, which must be unique.\") % {\n+            return gettext(\n+                \"Please correct the duplicate data for %(field)s, which must be unique.\"\n+            ) % {\n                 \"field\": get_text_list(unique_check, _(\"and\")),\n             }\n \n@@ -765,9 +892,9 @@ class BaseModelFormSet(BaseFormSet):\n             \"Please correct the duplicate data for %(field_name)s \"\n             \"which must be unique for the %(lookup)s in %(date_field)s.\"\n         ) % {\n-            'field_name': date_check[2],\n-            'date_field': date_check[3],\n-            'lookup': str(date_check[1]),\n+            \"field_name\": date_check[2],\n+            \"date_field\": date_check[3],\n+            \"lookup\": str(date_check[1]),\n         }\n \n     def get_form_error(self):\n@@ -816,6 +943,7 @@ class BaseModelFormSet(BaseFormSet):\n     def add_fields(self, form, index):\n         \"\"\"Add a hidden field for the object's primary key.\"\"\"\n         from django.db.models import AutoField, ForeignKey, OneToOneField\n+\n         self._pk_field = pk = self.model._meta.pk\n         # If a pk isn't editable, then it won't be on the form, so we need to\n         # add it here so we can tell which object is which when we get the\n@@ -825,11 +953,15 @@ class BaseModelFormSet(BaseFormSet):\n \n         def pk_is_not_editable(pk):\n             return (\n-                (not pk.editable) or (pk.auto_created or isinstance(pk, AutoField)) or (\n-                    pk.remote_field and pk.remote_field.parent_link and\n-                    pk_is_not_editable(pk.remote_field.model._meta.pk)\n+                (not pk.editable)\n+                or (pk.auto_created or isinstance(pk, AutoField))\n+                or (\n+                    pk.remote_field\n+                    and pk.remote_field.parent_link\n+                    and pk_is_not_editable(pk.remote_field.model._meta.pk)\n                 )\n             )\n+\n         if pk_is_not_editable(pk) or pk.name not in form.fields:\n             if form.is_bound:\n                 # If we're adding the related instance, ignore its primary key\n@@ -853,45 +985,92 @@ class BaseModelFormSet(BaseFormSet):\n                 widget = form._meta.widgets.get(self._pk_field.name, HiddenInput)\n             else:\n                 widget = HiddenInput\n-            form.fields[self._pk_field.name] = ModelChoiceField(qs, initial=pk_value, required=False, widget=widget)\n+            form.fields[self._pk_field.name] = ModelChoiceField(\n+                qs, initial=pk_value, required=False, widget=widget\n+            )\n         super().add_fields(form, index)\n \n \n-def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n-                         formset=BaseModelFormSet, extra=1, can_delete=False,\n-                         can_order=False, max_num=None, fields=None, exclude=None,\n-                         widgets=None, validate_max=False, localized_fields=None,\n-                         labels=None, help_texts=None, error_messages=None,\n-                         min_num=None, validate_min=False, field_classes=None,\n-                         absolute_max=None, can_delete_extra=True):\n+def modelformset_factory(\n+    model,\n+    form=ModelForm,\n+    formfield_callback=None,\n+    formset=BaseModelFormSet,\n+    extra=1,\n+    can_delete=False,\n+    can_order=False,\n+    max_num=None,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+):\n     \"\"\"Return a FormSet class for the given Django model class.\"\"\"\n-    meta = getattr(form, 'Meta', None)\n-    if (getattr(meta, 'fields', fields) is None and\n-            getattr(meta, 'exclude', exclude) is None):\n+    meta = getattr(form, \"Meta\", None)\n+    if (\n+        getattr(meta, \"fields\", fields) is None\n+        and getattr(meta, \"exclude\", exclude) is None\n+    ):\n         raise ImproperlyConfigured(\n             \"Calling modelformset_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n         )\n \n-    form = modelform_factory(model, form=form, fields=fields, exclude=exclude,\n-                             formfield_callback=formfield_callback,\n-                             widgets=widgets, localized_fields=localized_fields,\n-                             labels=labels, help_texts=help_texts,\n-                             error_messages=error_messages, field_classes=field_classes)\n-    FormSet = formset_factory(form, formset, extra=extra, min_num=min_num, max_num=max_num,\n-                              can_order=can_order, can_delete=can_delete,\n-                              validate_min=validate_min, validate_max=validate_max,\n-                              absolute_max=absolute_max, can_delete_extra=can_delete_extra)\n+    form = modelform_factory(\n+        model,\n+        form=form,\n+        fields=fields,\n+        exclude=exclude,\n+        formfield_callback=formfield_callback,\n+        widgets=widgets,\n+        localized_fields=localized_fields,\n+        labels=labels,\n+        help_texts=help_texts,\n+        error_messages=error_messages,\n+        field_classes=field_classes,\n+    )\n+    FormSet = formset_factory(\n+        form,\n+        formset,\n+        extra=extra,\n+        min_num=min_num,\n+        max_num=max_num,\n+        can_order=can_order,\n+        can_delete=can_delete,\n+        validate_min=validate_min,\n+        validate_max=validate_max,\n+        absolute_max=absolute_max,\n+        can_delete_extra=can_delete_extra,\n+    )\n     FormSet.model = model\n     return FormSet\n \n \n # InlineFormSets #############################################################\n \n+\n class BaseInlineFormSet(BaseModelFormSet):\n     \"\"\"A formset for child objects related to a parent.\"\"\"\n-    def __init__(self, data=None, files=None, instance=None,\n-                 save_as_new=False, prefix=None, queryset=None, **kwargs):\n+\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        instance=None,\n+        save_as_new=False,\n+        prefix=None,\n+        queryset=None,\n+        **kwargs,\n+    ):\n         if instance is None:\n             self.instance = self.fk.remote_field.model()\n         else:\n@@ -921,7 +1100,7 @@ class BaseInlineFormSet(BaseModelFormSet):\n     def _construct_form(self, i, **kwargs):\n         form = super()._construct_form(i, **kwargs)\n         if self.save_as_new:\n-            mutable = getattr(form.data, '_mutable', None)\n+            mutable = getattr(form.data, \"_mutable\", None)\n             # Allow modifying an immutable QueryDict.\n             if mutable is not None:\n                 form.data._mutable = True\n@@ -937,13 +1116,13 @@ class BaseInlineFormSet(BaseModelFormSet):\n         fk_value = self.instance.pk\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n             fk_value = getattr(self.instance, self.fk.remote_field.field_name)\n-            fk_value = getattr(fk_value, 'pk', fk_value)\n+            fk_value = getattr(fk_value, \"pk\", fk_value)\n         setattr(form.instance, self.fk.get_attname(), fk_value)\n         return form\n \n     @classmethod\n     def get_default_prefix(cls):\n-        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace('+', '')\n+        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace(\"+\", \"\")\n \n     def save_new(self, form, commit=True):\n         # Ensure the latest copy of the related instance is present on each\n@@ -956,26 +1135,28 @@ class BaseInlineFormSet(BaseModelFormSet):\n         super().add_fields(form, index)\n         if self._pk_field == self.fk:\n             name = self._pk_field.name\n-            kwargs = {'pk_field': True}\n+            kwargs = {\"pk_field\": True}\n         else:\n             # The foreign key field might not be on the form, so we poke at the\n             # Model field to get the label, since we need that for error messages.\n             name = self.fk.name\n             kwargs = {\n-                'label': getattr(form.fields.get(name), 'label', capfirst(self.fk.verbose_name))\n+                \"label\": getattr(\n+                    form.fields.get(name), \"label\", capfirst(self.fk.verbose_name)\n+                )\n             }\n \n         # The InlineForeignKeyField assumes that the foreign key relation is\n         # based on the parent model's pk. If this isn't the case, set to_field\n         # to correctly resolve the initial form value.\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n-            kwargs['to_field'] = self.fk.remote_field.field_name\n+            kwargs[\"to_field\"] = self.fk.remote_field.field_name\n \n         # If we're adding a new object, ignore a parent's auto-generated key\n         # as it will be regenerated on the save request.\n         if self.instance._state.adding:\n-            if kwargs.get('to_field') is not None:\n-                to_field = self.instance._meta.get_field(kwargs['to_field'])\n+            if kwargs.get(\"to_field\") is not None:\n+                to_field = self.instance._meta.get_field(kwargs[\"to_field\"])\n             else:\n                 to_field = self.instance._meta.pk\n             if to_field.has_default():\n@@ -998,16 +1179,19 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     \"\"\"\n     # avoid circular import\n     from django.db.models import ForeignKey\n+\n     opts = model._meta\n     if fk_name:\n         fks_to_parent = [f for f in opts.fields if f.name == fk_name]\n         if len(fks_to_parent) == 1:\n             fk = fks_to_parent[0]\n-            if not isinstance(fk, ForeignKey) or \\\n-                    (fk.remote_field.model != parent_model and\n-                     fk.remote_field.model not in parent_model._meta.get_parent_list()):\n+            if not isinstance(fk, ForeignKey) or (\n+                fk.remote_field.model != parent_model\n+                and fk.remote_field.model not in parent_model._meta.get_parent_list()\n+            ):\n                 raise ValueError(\n-                    \"fk_name '%s' is not a ForeignKey to '%s'.\" % (fk_name, parent_model._meta.label)\n+                    \"fk_name '%s' is not a ForeignKey to '%s'.\"\n+                    % (fk_name, parent_model._meta.label)\n                 )\n         elif not fks_to_parent:\n             raise ValueError(\n@@ -1016,10 +1200,12 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     else:\n         # Try to discover what the ForeignKey from model to parent_model is\n         fks_to_parent = [\n-            f for f in opts.fields\n-            if isinstance(f, ForeignKey) and (\n-                f.remote_field.model == parent_model or\n-                f.remote_field.model in parent_model._meta.get_parent_list()\n+            f\n+            for f in opts.fields\n+            if isinstance(f, ForeignKey)\n+            and (\n+                f.remote_field.model == parent_model\n+                or f.remote_field.model in parent_model._meta.get_parent_list()\n             )\n         ]\n         if len(fks_to_parent) == 1:\n@@ -1028,7 +1214,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n             if can_fail:\n                 return\n             raise ValueError(\n-                \"'%s' has no ForeignKey to '%s'.\" % (\n+                \"'%s' has no ForeignKey to '%s'.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1036,7 +1223,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n         else:\n             raise ValueError(\n                 \"'%s' has more than one ForeignKey to '%s'. You must specify \"\n-                \"a 'fk_name' attribute.\" % (\n+                \"a 'fk_name' attribute.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1044,14 +1232,31 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     return fk\n \n \n-def inlineformset_factory(parent_model, model, form=ModelForm,\n-                          formset=BaseInlineFormSet, fk_name=None,\n-                          fields=None, exclude=None, extra=3, can_order=False,\n-                          can_delete=True, max_num=None, formfield_callback=None,\n-                          widgets=None, validate_max=False, localized_fields=None,\n-                          labels=None, help_texts=None, error_messages=None,\n-                          min_num=None, validate_min=False, field_classes=None,\n-                          absolute_max=None, can_delete_extra=True):\n+def inlineformset_factory(\n+    parent_model,\n+    model,\n+    form=ModelForm,\n+    formset=BaseInlineFormSet,\n+    fk_name=None,\n+    fields=None,\n+    exclude=None,\n+    extra=3,\n+    can_order=False,\n+    can_delete=True,\n+    max_num=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+):\n     \"\"\"\n     Return an ``InlineFormSet`` for the given kwargs.\n \n@@ -1063,26 +1268,26 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n     if fk.unique:\n         max_num = 1\n     kwargs = {\n-        'form': form,\n-        'formfield_callback': formfield_callback,\n-        'formset': formset,\n-        'extra': extra,\n-        'can_delete': can_delete,\n-        'can_order': can_order,\n-        'fields': fields,\n-        'exclude': exclude,\n-        'min_num': min_num,\n-        'max_num': max_num,\n-        'widgets': widgets,\n-        'validate_min': validate_min,\n-        'validate_max': validate_max,\n-        'localized_fields': localized_fields,\n-        'labels': labels,\n-        'help_texts': help_texts,\n-        'error_messages': error_messages,\n-        'field_classes': field_classes,\n-        'absolute_max': absolute_max,\n-        'can_delete_extra': can_delete_extra,\n+        \"form\": form,\n+        \"formfield_callback\": formfield_callback,\n+        \"formset\": formset,\n+        \"extra\": extra,\n+        \"can_delete\": can_delete,\n+        \"can_order\": can_order,\n+        \"fields\": fields,\n+        \"exclude\": exclude,\n+        \"min_num\": min_num,\n+        \"max_num\": max_num,\n+        \"widgets\": widgets,\n+        \"validate_min\": validate_min,\n+        \"validate_max\": validate_max,\n+        \"localized_fields\": localized_fields,\n+        \"labels\": labels,\n+        \"help_texts\": help_texts,\n+        \"error_messages\": error_messages,\n+        \"field_classes\": field_classes,\n+        \"absolute_max\": absolute_max,\n+        \"can_delete_extra\": can_delete_extra,\n     }\n     FormSet = modelformset_factory(model, **kwargs)\n     FormSet.fk = fk\n@@ -1091,14 +1296,16 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n \n # Fields #####################################################################\n \n+\n class InlineForeignKeyField(Field):\n     \"\"\"\n     A basic integer field that deals with validating the given value to a\n     given parent instance in an inline.\n     \"\"\"\n+\n     widget = HiddenInput\n     default_error_messages = {\n-        'invalid_choice': _('The inline value did not match the parent instance.'),\n+        \"invalid_choice\": _(\"The inline value did not match the parent instance.\"),\n     }\n \n     def __init__(self, parent_instance, *args, pk_field=False, to_field=None, **kwargs):\n@@ -1125,7 +1332,9 @@ class InlineForeignKeyField(Field):\n         else:\n             orig = self.parent_instance.pk\n         if str(value) != str(orig):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_choice\"], code=\"invalid_choice\"\n+            )\n         return self.parent_instance\n \n     def has_changed(self, initial, data):\n@@ -1179,33 +1388,50 @@ class ModelChoiceIterator:\n \n class ModelChoiceField(ChoiceField):\n     \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n-                            ' the available choices.'),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. That choice is not one of the available choices.\"\n+        ),\n     }\n     iterator = ModelChoiceIterator\n \n-    def __init__(self, queryset, *, empty_label=\"---------\",\n-                 required=True, widget=None, label=None, initial=None,\n-                 help_text='', to_field_name=None, limit_choices_to=None,\n-                 blank=False, **kwargs):\n+    def __init__(\n+        self,\n+        queryset,\n+        *,\n+        empty_label=\"---------\",\n+        required=True,\n+        widget=None,\n+        label=None,\n+        initial=None,\n+        help_text=\"\",\n+        to_field_name=None,\n+        limit_choices_to=None,\n+        blank=False,\n+        **kwargs,\n+    ):\n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n         Field.__init__(\n-            self, required=required, widget=widget, label=label,\n-            initial=initial, help_text=help_text, **kwargs\n+            self,\n+            required=required,\n+            widget=widget,\n+            label=label,\n+            initial=initial,\n+            help_text=help_text,\n+            **kwargs,\n         )\n-        if (\n-            (required and initial is not None) or\n-            (isinstance(self.widget, RadioSelect) and not blank)\n+        if (required and initial is not None) or (\n+            isinstance(self.widget, RadioSelect) and not blank\n         ):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n         self.queryset = queryset\n-        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.limit_choices_to = limit_choices_to  # limit the queryset later.\n         self.to_field_name = to_field_name\n \n     def get_limit_choices_to(self):\n@@ -1247,7 +1473,7 @@ class ModelChoiceField(ChoiceField):\n     def _get_choices(self):\n         # If self._choices is set, then somebody must have manually set\n         # the property self.choices. In this case, just return self._choices.\n-        if hasattr(self, '_choices'):\n+        if hasattr(self, \"_choices\"):\n             return self._choices\n \n         # Otherwise, execute the QuerySet in self.queryset to determine the\n@@ -1262,7 +1488,7 @@ class ModelChoiceField(ChoiceField):\n     choices = property(_get_choices, ChoiceField._set_choices)\n \n     def prepare_value(self, value):\n-        if hasattr(value, '_meta'):\n+        if hasattr(value, \"_meta\"):\n             if self.to_field_name:\n                 return value.serializable_value(self.to_field_name)\n             else:\n@@ -1273,12 +1499,14 @@ class ModelChoiceField(ChoiceField):\n         if value in self.empty_values:\n             return None\n         try:\n-            key = self.to_field_name or 'pk'\n+            key = self.to_field_name or \"pk\"\n             if isinstance(value, self.queryset.model):\n                 value = getattr(value, key)\n             value = self.queryset.get(**{key: value})\n         except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_choice\"], code=\"invalid_choice\"\n+            )\n         return value\n \n     def validate(self, value):\n@@ -1287,31 +1515,34 @@ class ModelChoiceField(ChoiceField):\n     def has_changed(self, initial, data):\n         if self.disabled:\n             return False\n-        initial_value = initial if initial is not None else ''\n-        data_value = data if data is not None else ''\n+        initial_value = initial if initial is not None else \"\"\n+        data_value = data if data is not None else \"\"\n         return str(self.prepare_value(initial_value)) != str(data_value)\n \n \n class ModelMultipleChoiceField(ModelChoiceField):\n     \"\"\"A MultipleChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     widget = SelectMultiple\n     hidden_widget = MultipleHiddenInput\n     default_error_messages = {\n-        'invalid_list': _('Enter a list of values.'),\n-        'invalid_choice': _('Select a valid choice. %(value)s is not one of the'\n-                            ' available choices.'),\n-        'invalid_pk_value': _('\u201c%(pk)s\u201d is not a valid value.')\n+        \"invalid_list\": _(\"Enter a list of values.\"),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n+        \"invalid_pk_value\": _(\"\u201c%(pk)s\u201d is not a valid value.\"),\n     }\n \n     def __init__(self, queryset, **kwargs):\n         super().__init__(queryset, empty_label=None, **kwargs)\n-        if self.error_messages.get('list') is not None:\n+        if self.error_messages.get(\"list\") is not None:\n             warnings.warn(\n                 \"The 'list' error message key is deprecated in favor of \"\n                 \"'invalid_list'.\",\n-                RemovedInDjango40Warning, stacklevel=2,\n+                RemovedInDjango40Warning,\n+                stacklevel=2,\n             )\n-            self.error_messages['invalid_list'] = self.error_messages['list']\n+            self.error_messages[\"invalid_list\"] = self.error_messages[\"list\"]\n \n     def to_python(self, value):\n         if not value:\n@@ -1321,13 +1552,13 @@ class ModelMultipleChoiceField(ModelChoiceField):\n     def clean(self, value):\n         value = self.prepare_value(value)\n         if self.required and not value:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n         elif not self.required and not value:\n             return self.queryset.none()\n         if not isinstance(value, (list, tuple)):\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         qs = self._check_values(value)\n         # Since this overrides the inherited ModelChoiceField.clean\n@@ -1341,7 +1572,7 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         corresponding objects. Raise a ValidationError if a given value is\n         invalid (not a valid PK, not in the queryset, etc.)\n         \"\"\"\n-        key = self.to_field_name or 'pk'\n+        key = self.to_field_name or \"pk\"\n         # deduplicate given values to avoid creating many querysets or\n         # requiring the database backend deduplicate efficiently.\n         try:\n@@ -1349,33 +1580,35 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         except TypeError:\n             # list of lists isn't hashable, for example\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         for pk in value:\n             try:\n                 self.queryset.filter(**{key: pk})\n             except (ValueError, TypeError):\n                 raise ValidationError(\n-                    self.error_messages['invalid_pk_value'],\n-                    code='invalid_pk_value',\n-                    params={'pk': pk},\n+                    self.error_messages[\"invalid_pk_value\"],\n+                    code=\"invalid_pk_value\",\n+                    params={\"pk\": pk},\n                 )\n-        qs = self.queryset.filter(**{'%s__in' % key: value})\n+        qs = self.queryset.filter(**{\"%s__in\" % key: value})\n         pks = {str(getattr(o, key)) for o in qs}\n         for val in value:\n             if str(val) not in pks:\n                 raise ValidationError(\n-                    self.error_messages['invalid_choice'],\n-                    code='invalid_choice',\n-                    params={'value': val},\n+                    self.error_messages[\"invalid_choice\"],\n+                    code=\"invalid_choice\",\n+                    params={\"value\": val},\n                 )\n         return qs\n \n     def prepare_value(self, value):\n-        if (hasattr(value, '__iter__') and\n-                not isinstance(value, str) and\n-                not hasattr(value, '_meta')):\n+        if (\n+            hasattr(value, \"__iter__\")\n+            and not isinstance(value, str)\n+            and not hasattr(value, \"_meta\")\n+        ):\n             prepare_value = super().prepare_value\n             return [prepare_value(v) for v in value]\n         return super().prepare_value(value)\n@@ -1395,7 +1628,6 @@ class ModelMultipleChoiceField(ModelChoiceField):\n \n \n def modelform_defines_fields(form_class):\n-    return hasattr(form_class, '_meta') and (\n-        form_class._meta.fields is not None or\n-        form_class._meta.exclude is not None\n+    return hasattr(form_class, \"_meta\") and (\n+        form_class._meta.fields is not None or form_class._meta.exclude is not None\n     )\n"}
{"instance_id": "django__django-13321", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 187e14b1b7..b1f8b5945f 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -10,7 +10,9 @@ from django.core import signing\n from django.core.exceptions import SuspiciousOperation\n from django.utils import timezone\n from django.utils.crypto import (\n-    constant_time_compare, get_random_string, salted_hmac,\n+    constant_time_compare,\n+    get_random_string,\n+    salted_hmac,\n )\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.module_loading import import_string\n@@ -26,6 +28,7 @@ class CreateError(Exception):\n     Used internally as a consistent exception type to catch from save (see the\n     docstring for SessionBase.save() for details).\n     \"\"\"\n+\n     pass\n \n \n@@ -33,6 +36,7 @@ class UpdateError(Exception):\n     \"\"\"\n     Occurs if Django tries to update a session that was deleted.\n     \"\"\"\n+\n     pass\n \n \n@@ -40,8 +44,9 @@ class SessionBase:\n     \"\"\"\n     Base class for all Session classes.\n     \"\"\"\n-    TEST_COOKIE_NAME = 'testcookie'\n-    TEST_COOKIE_VALUE = 'worked'\n+\n+    TEST_COOKIE_NAME = \"testcookie\"\n+    TEST_COOKIE_VALUE = \"worked\"\n \n     __not_given = object()\n \n@@ -57,10 +62,11 @@ class SessionBase:\n     def __getitem__(self, key):\n         if key == LANGUAGE_SESSION_KEY:\n             warnings.warn(\n-                'The user language will no longer be stored in '\n-                'request.session in Django 4.0. Read it from '\n-                'request.COOKIES[settings.LANGUAGE_COOKIE_NAME] instead.',\n-                RemovedInDjango40Warning, stacklevel=2,\n+                \"The user language will no longer be stored in \"\n+                \"request.session in Django 4.0. Read it from \"\n+                \"request.COOKIES[settings.LANGUAGE_COOKIE_NAME] instead.\",\n+                RemovedInDjango40Warning,\n+                stacklevel=2,\n             )\n         return self._session[key]\n \n@@ -74,7 +80,7 @@ class SessionBase:\n \n     @property\n     def key_salt(self):\n-        return 'django.contrib.sessions.' + self.__class__.__qualname__\n+        return \"django.contrib.sessions.\" + self.__class__.__qualname__\n \n     def get(self, key, default=None):\n         return self._session.get(key, default)\n@@ -109,16 +115,20 @@ class SessionBase:\n     def encode(self, session_dict):\n         \"Return the given session dictionary serialized and encoded as a string.\"\n         # RemovedInDjango40Warning: DEFAULT_HASHING_ALGORITHM will be removed.\n-        if settings.DEFAULT_HASHING_ALGORITHM == 'sha1':\n+        if settings.DEFAULT_HASHING_ALGORITHM == \"sha1\":\n             return self._legacy_encode(session_dict)\n         return signing.dumps(\n-            session_dict, salt=self.key_salt, serializer=self.serializer,\n+            session_dict,\n+            salt=self.key_salt,\n+            serializer=self.serializer,\n             compress=True,\n         )\n \n     def decode(self, session_data):\n         try:\n-            return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n+            return signing.loads(\n+                session_data, salt=self.key_salt, serializer=self.serializer\n+            )\n         # RemovedInDjango40Warning: when the deprecation ends, handle here\n         # exceptions similar to what _legacy_decode() does now.\n         except Exception:\n@@ -128,14 +138,17 @@ class SessionBase:\n         # RemovedInDjango40Warning.\n         serialized = self.serializer().dumps(session_dict)\n         hash = self._hash(serialized)\n-        return base64.b64encode(hash.encode() + b':' + serialized).decode('ascii')\n+        return base64.b64encode(hash.encode() + b\":\" + serialized).decode(\"ascii\")\n \n     def _legacy_decode(self, session_data):\n         # RemovedInDjango40Warning: pre-Django 3.1 format will be invalid.\n-        encoded_data = base64.b64decode(session_data.encode('ascii'))\n+        try:\n+            encoded_data = base64.b64decode(session_data.encode(\"ascii\"))\n+        except Exception:\n+            return {}\n         try:\n             # could produce ValueError if there is no ':'\n-            hash, serialized = encoded_data.split(b':', 1)\n+            hash, serialized = encoded_data.split(b\":\", 1)\n             expected_hash = self._hash(serialized)\n             if not constant_time_compare(hash.decode(), expected_hash):\n                 raise SuspiciousSession(\"Session data corrupted\")\n@@ -145,7 +158,7 @@ class SessionBase:\n             # ValueError, SuspiciousOperation, unpickling exceptions. If any of\n             # these happen, just return an empty dictionary (an empty session).\n             if isinstance(e, SuspiciousOperation):\n-                logger = logging.getLogger('django.security.%s' % e.__class__.__name__)\n+                logger = logging.getLogger(\"django.security.%s\" % e.__class__.__name__)\n                 logger.warning(str(e))\n             return {}\n \n@@ -241,18 +254,18 @@ class SessionBase:\n         arguments specifying the modification and expiry of the session.\n         \"\"\"\n         try:\n-            modification = kwargs['modification']\n+            modification = kwargs[\"modification\"]\n         except KeyError:\n             modification = timezone.now()\n         # Make the difference between \"expiry=None passed in kwargs\" and\n         # \"expiry not passed in kwargs\", in order to guarantee not to trigger\n         # self.load() when expiry is provided.\n         try:\n-            expiry = kwargs['expiry']\n+            expiry = kwargs[\"expiry\"]\n         except KeyError:\n-            expiry = self.get('_session_expiry')\n+            expiry = self.get(\"_session_expiry\")\n \n-        if not expiry:   # Checks both None and 0 cases\n+        if not expiry:  # Checks both None and 0 cases\n             return self.get_session_cookie_age()\n         if not isinstance(expiry, datetime):\n             return expiry\n@@ -266,14 +279,14 @@ class SessionBase:\n         arguments specifying the modification and expiry of the session.\n         \"\"\"\n         try:\n-            modification = kwargs['modification']\n+            modification = kwargs[\"modification\"]\n         except KeyError:\n             modification = timezone.now()\n         # Same comment as in get_expiry_age\n         try:\n-            expiry = kwargs['expiry']\n+            expiry = kwargs[\"expiry\"]\n         except KeyError:\n-            expiry = self.get('_session_expiry')\n+            expiry = self.get(\"_session_expiry\")\n \n         if isinstance(expiry, datetime):\n             return expiry\n@@ -298,13 +311,13 @@ class SessionBase:\n         if value is None:\n             # Remove any custom expiration for this session.\n             try:\n-                del self['_session_expiry']\n+                del self[\"_session_expiry\"]\n             except KeyError:\n                 pass\n             return\n         if isinstance(value, timedelta):\n             value = timezone.now() + value\n-        self['_session_expiry'] = value\n+        self[\"_session_expiry\"] = value\n \n     def get_expire_at_browser_close(self):\n         \"\"\"\n@@ -313,9 +326,9 @@ class SessionBase:\n         ``get_expiry_date()`` or ``get_expiry_age()`` to find the actual expiry\n         date/age, if there is one.\n         \"\"\"\n-        if self.get('_session_expiry') is None:\n+        if self.get(\"_session_expiry\") is None:\n             return settings.SESSION_EXPIRE_AT_BROWSER_CLOSE\n-        return self.get('_session_expiry') == 0\n+        return self.get(\"_session_expiry\") == 0\n \n     def flush(self):\n         \"\"\"\n@@ -343,7 +356,9 @@ class SessionBase:\n         \"\"\"\n         Return True if the given session_key already exists.\n         \"\"\"\n-        raise NotImplementedError('subclasses of SessionBase must provide an exists() method')\n+        raise NotImplementedError(\n+            \"subclasses of SessionBase must provide an exists() method\"\n+        )\n \n     def create(self):\n         \"\"\"\n@@ -351,7 +366,9 @@ class SessionBase:\n         a unique key and will have saved the result once (with empty data)\n         before the method returns.\n         \"\"\"\n-        raise NotImplementedError('subclasses of SessionBase must provide a create() method')\n+        raise NotImplementedError(\n+            \"subclasses of SessionBase must provide a create() method\"\n+        )\n \n     def save(self, must_create=False):\n         \"\"\"\n@@ -359,20 +376,26 @@ class SessionBase:\n         object (or raise CreateError). Otherwise, only update an existing\n         object and don't create one (raise UpdateError if needed).\n         \"\"\"\n-        raise NotImplementedError('subclasses of SessionBase must provide a save() method')\n+        raise NotImplementedError(\n+            \"subclasses of SessionBase must provide a save() method\"\n+        )\n \n     def delete(self, session_key=None):\n         \"\"\"\n         Delete the session data under this key. If the key is None, use the\n         current session key value.\n         \"\"\"\n-        raise NotImplementedError('subclasses of SessionBase must provide a delete() method')\n+        raise NotImplementedError(\n+            \"subclasses of SessionBase must provide a delete() method\"\n+        )\n \n     def load(self):\n         \"\"\"\n         Load the session data and return a dictionary.\n         \"\"\"\n-        raise NotImplementedError('subclasses of SessionBase must provide a load() method')\n+        raise NotImplementedError(\n+            \"subclasses of SessionBase must provide a load() method\"\n+        )\n \n     @classmethod\n     def clear_expired(cls):\n@@ -383,4 +406,4 @@ class SessionBase:\n         NotImplementedError. If it isn't necessary, because the backend has\n         a built-in expiration mechanism, it should be a no-op.\n         \"\"\"\n-        raise NotImplementedError('This backend does not support clear_expired().')\n+        raise NotImplementedError(\"This backend does not support clear_expired().\")\n"}
{"instance_id": "django__django-13401", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..da1f570c7f 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -18,7 +18,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -28,14 +31,38 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FilePathField', 'FloatField',\n-    'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED',\n-    'NullBooleanField', 'PositiveBigIntegerField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallAutoField',\n-    'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveBigIntegerField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -71,6 +98,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -97,15 +125,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -123,18 +151,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -170,7 +217,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -180,19 +227,19 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n         app = model._meta.app_label\n-        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+        return \"%s.%s.%s\" % (app, model._meta.object_name, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -210,12 +257,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -223,15 +270,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % LOOKUP_SEP,\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -250,7 +297,7 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -269,14 +316,22 @@ class Field(RegisterLookupMixin):\n                 ):\n                     break\n                 if self.max_length is not None and group_choices:\n-                    choice_max_length = max([\n-                        choice_max_length,\n-                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n-                    ])\n+                    choice_max_length = max(\n+                        [\n+                            choice_max_length,\n+                            *(\n+                                len(value)\n+                                for value, _ in group_choices\n+                                if isinstance(value, str)\n+                            ),\n+                        ]\n+                    )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n                 value, human_name = group_name, group_choices\n-                if not self._choices_is_value(value) or not self._choices_is_value(human_name):\n+                if not self._choices_is_value(value) or not self._choices_is_value(\n+                    human_name\n+                ):\n                     break\n                 if self.max_length is not None and isinstance(value, str):\n                     choice_max_length = max(choice_max_length, len(value))\n@@ -291,7 +346,7 @@ class Field(RegisterLookupMixin):\n                         \"'max_length' is too small to fit the longest value \"\n                         \"in 'choices' (%d characters).\" % choice_max_length,\n                         obj=self,\n-                        id='fields.E009',\n+                        id=\"fields.E009\",\n                     ),\n                 ]\n             return []\n@@ -301,7 +356,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -311,25 +366,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -341,7 +401,9 @@ class Field(RegisterLookupMixin):\n         app_label = self.model._meta.app_label\n         errors = []\n         for alias in databases:\n-            if router.allow_migrate(alias, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                alias, app_label, model_name=self.model._meta.model_name\n+            ):\n                 errors.extend(connections[alias].validation.check_field(self, **kwargs))\n         return errors\n \n@@ -355,11 +417,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -369,25 +432,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -397,6 +459,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -404,6 +467,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -463,7 +527,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -496,8 +560,8 @@ class Field(RegisterLookupMixin):\n             path = path.replace(\"django.db.models.fields.related\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.files\"):\n             path = path.replace(\"django.db.models.fields.files\", \"django.db.models\")\n-        elif path.startswith('django.db.models.fields.json'):\n-            path = path.replace('django.db.models.fields.json', 'django.db.models')\n+        elif path.startswith(\"django.db.models.fields.json\"):\n+            path = path.replace(\"django.db.models.fields.json\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.proxy\"):\n             path = path.replace(\"django.db.models.fields.proxy\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields\"):\n@@ -516,17 +580,38 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return self.creation_counter == other.creation_counter and getattr(\n+                self, \"model\", None\n+            ) == getattr(other, \"model\", None)\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n+        # Order by creation_counter first for backwards compatibility.\n         if isinstance(other, Field):\n-            return self.creation_counter < other.creation_counter\n+            if self.creation_counter != other.creation_counter:\n+                return self.creation_counter < other.creation_counter\n+            # creation_counters are equal, compare models\n+            self_model = getattr(self, \"model\", None)\n+            other_model = getattr(other, \"model\", None)\n+            if self_model is None and other_model is None:\n+                return False\n+            if self_model is None:\n+                return True\n+            if other_model is None:\n+                return False\n+            # compare model._meta.label rather than model to ensure\n+            # consistent ordering regardless of model reference\n+            return self_model._meta.label < other_model._meta.label\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash(\n+            (\n+                self.creation_counter,\n+                getattr(self, \"model\", None),\n+            )\n+        )\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n@@ -534,7 +619,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -553,7 +638,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -562,10 +647,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -603,7 +691,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -630,16 +718,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -653,7 +741,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -663,7 +751,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -725,7 +815,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -750,7 +840,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -773,10 +863,10 @@ class Field(RegisterLookupMixin):\n             # this class, but don't check methods derived from inheritance, to\n             # allow overriding inherited choices. For more complex inheritance\n             # structures users should override contribute_to_class().\n-            if 'get_%s_display' % self.name not in cls.__dict__:\n+            if \"get_%s_display\" % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n-                    'get_%s_display' % self.name,\n+                    \"get_%s_display\" % self.name,\n                     partialmethod(cls._get_FIELD_display, field=self),\n                 )\n \n@@ -837,11 +927,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -849,7 +949,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -857,8 +959,8 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n@@ -885,6 +987,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -893,24 +996,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -919,9 +1023,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -936,8 +1050,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -950,14 +1064,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -968,14 +1082,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -998,16 +1112,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1034,10 +1151,10 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -1046,20 +1163,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1071,8 +1186,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1080,7 +1201,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1093,19 +1214,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1136,13 +1262,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1151,12 +1277,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1181,15 +1307,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1204,12 +1330,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1224,25 +1356,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1279,13 +1419,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1306,10 +1446,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1320,9 +1462,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1331,15 +1473,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1361,13 +1503,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1380,24 +1523,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1424,7 +1575,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1432,7 +1583,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1448,7 +1599,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1456,7 +1607,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1468,7 +1619,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1486,9 +1637,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1503,25 +1654,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except (decimal.InvalidOperation, TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1531,10 +1686,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1555,9 +1713,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1575,13 +1733,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1590,7 +1750,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1602,20 +1762,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1630,23 +1801,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1658,15 +1829,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1675,7 +1848,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1700,22 +1873,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1729,10 +1904,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1746,22 +1922,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1787,16 +1969,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1807,32 +1991,34 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1850,14 +2036,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1867,13 +2061,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1881,11 +2075,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1897,8 +2091,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1910,7 +2106,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1918,37 +2114,39 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n     system_check_deprecated_details = {\n-        'msg': (\n-            'NullBooleanField is deprecated. Support for it (except in '\n-            'historical migrations) will be removed in Django 4.0.'\n+        \"msg\": (\n+            \"NullBooleanField is deprecated. Support for it (except in \"\n+            \"historical migrations) will be removed in Django 4.0.\"\n         ),\n-        'hint': 'Use BooleanField(null=True) instead.',\n-        'id': 'fields.W903',\n+        \"hint\": \"Use BooleanField(null=True) instead.\",\n+        \"id\": \"fields.W903\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1956,7 +2154,6 @@ class NullBooleanField(BooleanField):\n \n \n class PositiveIntegerRelDbTypeMixin:\n-\n     def rel_db_type(self, connection):\n         \"\"\"\n         Return the data type that a related field pointing to this field should\n@@ -1973,16 +2170,18 @@ class PositiveIntegerRelDbTypeMixin:\n \n \n class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n-    description = _('Positive big integer')\n+    description = _(\"Positive big integer\")\n \n     def get_internal_type(self):\n-        return 'PositiveBigIntegerField'\n+        return \"PositiveBigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -1992,10 +2191,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2005,17 +2206,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -2024,24 +2229,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n@@ -2070,29 +2277,36 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2126,13 +2340,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2145,8 +2359,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2169,15 +2383,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2200,13 +2414,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2214,30 +2430,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2252,7 +2470,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2260,9 +2478,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2275,8 +2493,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2287,29 +2505,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2331,29 +2549,31 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n     db_returning = True\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2366,9 +2586,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2376,8 +2596,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2391,8 +2611,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2423,34 +2642,33 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n         return subclass in self._subclasses or super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\n"}
{"instance_id": "django__django-13447", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 837dabfea8..2d8d49726c 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -10,7 +10,9 @@ from django.contrib.auth import REDIRECT_FIELD_NAME\n from django.core.exceptions import ImproperlyConfigured\n from django.db.models.base import ModelBase\n from django.http import (\n-    Http404, HttpResponsePermanentRedirect, HttpResponseRedirect,\n+    Http404,\n+    HttpResponsePermanentRedirect,\n+    HttpResponseRedirect,\n )\n from django.template.response import TemplateResponse\n from django.urls import NoReverseMatch, Resolver404, resolve, reverse\n@@ -45,20 +47,20 @@ class AdminSite:\n     \"\"\"\n \n     # Text to put at the end of each page's <title>.\n-    site_title = gettext_lazy('Django site admin')\n+    site_title = gettext_lazy(\"Django site admin\")\n \n     # Text to put in each page's <h1>.\n-    site_header = gettext_lazy('Django administration')\n+    site_header = gettext_lazy(\"Django administration\")\n \n     # Text to put at the top of the admin index page.\n-    index_title = gettext_lazy('Site administration')\n+    index_title = gettext_lazy(\"Site administration\")\n \n     # URL for the \"View site\" link at the top of each admin page.\n-    site_url = '/'\n+    site_url = \"/\"\n \n     enable_nav_sidebar = True\n \n-    empty_value_display = '-'\n+    empty_value_display = \"-\"\n \n     login_form = None\n     index_template = None\n@@ -70,10 +72,10 @@ class AdminSite:\n \n     final_catch_all_view = True\n \n-    def __init__(self, name='admin'):\n+    def __init__(self, name=\"admin\"):\n         self._registry = {}  # model_class class -> admin_class instance\n         self.name = name\n-        self._actions = {'delete_selected': actions.delete_selected}\n+        self._actions = {\"delete_selected\": actions.delete_selected}\n         self._global_actions = self._actions.copy()\n         all_sites.add(self)\n \n@@ -87,7 +89,9 @@ class AdminSite:\n         app_configs = set(app_configs)  # Speed up lookups below\n \n         errors = []\n-        modeladmins = (o for o in self._registry.values() if o.__class__ is not ModelAdmin)\n+        modeladmins = (\n+            o for o in self._registry.values() if o.__class__ is not ModelAdmin\n+        )\n         for modeladmin in modeladmins:\n             if modeladmin.model._meta.app_config in app_configs:\n                 errors.extend(modeladmin.check())\n@@ -113,17 +117,18 @@ class AdminSite:\n         for model in model_or_iterable:\n             if model._meta.abstract:\n                 raise ImproperlyConfigured(\n-                    'The model %s is abstract, so it cannot be registered with admin.' % model.__name__\n+                    \"The model %s is abstract, so it cannot be registered with admin.\"\n+                    % model.__name__\n                 )\n \n             if model in self._registry:\n                 registered_admin = str(self._registry[model])\n-                msg = 'The model %s is already registered ' % model.__name__\n-                if registered_admin.endswith('.ModelAdmin'):\n+                msg = \"The model %s is already registered \" % model.__name__\n+                if registered_admin.endswith(\".ModelAdmin\"):\n                     # Most likely registered without a ModelAdmin subclass.\n-                    msg += 'in app %r.' % re.sub(r'\\.ModelAdmin$', '', registered_admin)\n+                    msg += \"in app %r.\" % re.sub(r\"\\.ModelAdmin$\", \"\", registered_admin)\n                 else:\n-                    msg += 'with %r.' % registered_admin\n+                    msg += \"with %r.\" % registered_admin\n                 raise AlreadyRegistered(msg)\n \n             # Ignore the registration if the model has been\n@@ -135,8 +140,10 @@ class AdminSite:\n                     # For reasons I don't quite understand, without a __module__\n                     # the created class appears to \"live\" in the wrong place,\n                     # which causes issues later on.\n-                    options['__module__'] = __name__\n-                    admin_class = type(\"%sAdmin\" % model.__name__, (admin_class,), options)\n+                    options[\"__module__\"] = __name__\n+                    admin_class = type(\n+                        \"%sAdmin\" % model.__name__, (admin_class,), options\n+                    )\n \n                 # Instantiate the admin class to save in the registry\n                 self._registry[model] = admin_class(model, self)\n@@ -151,7 +158,7 @@ class AdminSite:\n             model_or_iterable = [model_or_iterable]\n         for model in model_or_iterable:\n             if model not in self._registry:\n-                raise NotRegistered('The model %s is not registered' % model.__name__)\n+                raise NotRegistered(\"The model %s is not registered\" % model.__name__)\n             del self._registry[model]\n \n     def is_registered(self, model):\n@@ -218,24 +225,27 @@ class AdminSite:\n         ``never_cache`` decorator. If the view can be safely cached, set\n         cacheable=True.\n         \"\"\"\n+\n         def inner(request, *args, **kwargs):\n             if not self.has_permission(request):\n-                if request.path == reverse('admin:logout', current_app=self.name):\n-                    index_path = reverse('admin:index', current_app=self.name)\n+                if request.path == reverse(\"admin:logout\", current_app=self.name):\n+                    index_path = reverse(\"admin:index\", current_app=self.name)\n                     return HttpResponseRedirect(index_path)\n                 # Inner import to prevent django.contrib.admin (app) from\n                 # importing django.contrib.auth.models.User (unrelated model).\n                 from django.contrib.auth.views import redirect_to_login\n+\n                 return redirect_to_login(\n                     request.get_full_path(),\n-                    reverse('admin:login', current_app=self.name)\n+                    reverse(\"admin:login\", current_app=self.name),\n                 )\n             return view(request, *args, **kwargs)\n+\n         if not cacheable:\n             inner = never_cache(inner)\n         # We add csrf_protect here so this function can be used as a utility\n         # function for any view, without having to repeat 'csrf_protect'.\n-        if not getattr(view, 'csrf_exempt', False):\n+        if not getattr(view, \"csrf_exempt\", False):\n             inner = csrf_protect(inner)\n         return update_wrapper(inner, view)\n \n@@ -249,26 +259,31 @@ class AdminSite:\n         def wrap(view, cacheable=False):\n             def wrapper(*args, **kwargs):\n                 return self.admin_view(view, cacheable)(*args, **kwargs)\n+\n             wrapper.admin_site = self\n             return update_wrapper(wrapper, view)\n \n         # Admin-site-wide views.\n         urlpatterns = [\n-            path('', wrap(self.index), name='index'),\n-            path('login/', self.login, name='login'),\n-            path('logout/', wrap(self.logout), name='logout'),\n-            path('password_change/', wrap(self.password_change, cacheable=True), name='password_change'),\n+            path(\"\", wrap(self.index), name=\"index\"),\n+            path(\"login/\", self.login, name=\"login\"),\n+            path(\"logout/\", wrap(self.logout), name=\"logout\"),\n+            path(\n+                \"password_change/\",\n+                wrap(self.password_change, cacheable=True),\n+                name=\"password_change\",\n+            ),\n             path(\n-                'password_change/done/',\n+                \"password_change/done/\",\n                 wrap(self.password_change_done, cacheable=True),\n-                name='password_change_done',\n+                name=\"password_change_done\",\n             ),\n-            path('autocomplete/', wrap(self.autocomplete_view), name='autocomplete'),\n-            path('jsi18n/', wrap(self.i18n_javascript, cacheable=True), name='jsi18n'),\n+            path(\"autocomplete/\", wrap(self.autocomplete_view), name=\"autocomplete\"),\n+            path(\"jsi18n/\", wrap(self.i18n_javascript, cacheable=True), name=\"jsi18n\"),\n             path(\n-                'r/<int:content_type_id>/<path:object_id>/',\n+                \"r/<int:content_type_id>/<path:object_id>/\",\n                 wrap(contenttype_views.shortcut),\n-                name='view_on_site',\n+                name=\"view_on_site\",\n             ),\n         ]\n \n@@ -277,7 +292,10 @@ class AdminSite:\n         valid_app_labels = []\n         for model, model_admin in self._registry.items():\n             urlpatterns += [\n-                path('%s/%s/' % (model._meta.app_label, model._meta.model_name), include(model_admin.urls)),\n+                path(\n+                    \"%s/%s/\" % (model._meta.app_label, model._meta.model_name),\n+                    include(model_admin.urls),\n+                ),\n             ]\n             if model._meta.app_label not in valid_app_labels:\n                 valid_app_labels.append(model._meta.app_label)\n@@ -285,19 +303,19 @@ class AdminSite:\n         # If there were ModelAdmins registered, we should have a list of app\n         # labels for which we need to allow access to the app_index view,\n         if valid_app_labels:\n-            regex = r'^(?P<app_label>' + '|'.join(valid_app_labels) + ')/$'\n+            regex = r\"^(?P<app_label>\" + \"|\".join(valid_app_labels) + \")/$\"\n             urlpatterns += [\n-                re_path(regex, wrap(self.app_index), name='app_list'),\n+                re_path(regex, wrap(self.app_index), name=\"app_list\"),\n             ]\n \n         if self.final_catch_all_view:\n-            urlpatterns.append(re_path(r'(?P<url>.*)$', wrap(self.catch_all_view)))\n+            urlpatterns.append(re_path(r\"(?P<url>.*)$\", wrap(self.catch_all_view)))\n \n         return urlpatterns\n \n     @property\n     def urls(self):\n-        return self.get_urls(), 'admin', self.name\n+        return self.get_urls(), \"admin\", self.name\n \n     def each_context(self, request):\n         \"\"\"\n@@ -307,16 +325,18 @@ class AdminSite:\n         For sites running on a subpath, use the SCRIPT_NAME value if site_url\n         hasn't been customized.\n         \"\"\"\n-        script_name = request.META['SCRIPT_NAME']\n-        site_url = script_name if self.site_url == '/' and script_name else self.site_url\n+        script_name = request.META[\"SCRIPT_NAME\"]\n+        site_url = (\n+            script_name if self.site_url == \"/\" and script_name else self.site_url\n+        )\n         return {\n-            'site_title': self.site_title,\n-            'site_header': self.site_header,\n-            'site_url': site_url,\n-            'has_permission': self.has_permission(request),\n-            'available_apps': self.get_app_list(request),\n-            'is_popup': False,\n-            'is_nav_sidebar_enabled': self.enable_nav_sidebar,\n+            \"site_title\": self.site_title,\n+            \"site_header\": self.site_header,\n+            \"site_url\": site_url,\n+            \"has_permission\": self.has_permission(request),\n+            \"available_apps\": self.get_app_list(request),\n+            \"is_popup\": False,\n+            \"is_nav_sidebar_enabled\": self.enable_nav_sidebar,\n         }\n \n     def password_change(self, request, extra_context=None):\n@@ -325,14 +345,15 @@ class AdminSite:\n         \"\"\"\n         from django.contrib.admin.forms import AdminPasswordChangeForm\n         from django.contrib.auth.views import PasswordChangeView\n-        url = reverse('admin:password_change_done', current_app=self.name)\n+\n+        url = reverse(\"admin:password_change_done\", current_app=self.name)\n         defaults = {\n-            'form_class': AdminPasswordChangeForm,\n-            'success_url': url,\n-            'extra_context': {**self.each_context(request), **(extra_context or {})},\n+            \"form_class\": AdminPasswordChangeForm,\n+            \"success_url\": url,\n+            \"extra_context\": {**self.each_context(request), **(extra_context or {})},\n         }\n         if self.password_change_template is not None:\n-            defaults['template_name'] = self.password_change_template\n+            defaults[\"template_name\"] = self.password_change_template\n         request.current_app = self.name\n         return PasswordChangeView.as_view(**defaults)(request)\n \n@@ -341,11 +362,12 @@ class AdminSite:\n         Display the \"success\" page after a password change.\n         \"\"\"\n         from django.contrib.auth.views import PasswordChangeDoneView\n+\n         defaults = {\n-            'extra_context': {**self.each_context(request), **(extra_context or {})},\n+            \"extra_context\": {**self.each_context(request), **(extra_context or {})},\n         }\n         if self.password_change_done_template is not None:\n-            defaults['template_name'] = self.password_change_done_template\n+            defaults[\"template_name\"] = self.password_change_done_template\n         request.current_app = self.name\n         return PasswordChangeDoneView.as_view(**defaults)(request)\n \n@@ -356,7 +378,7 @@ class AdminSite:\n         `extra_context` is unused but present for consistency with the other\n         admin views.\n         \"\"\"\n-        return JavaScriptCatalog.as_view(packages=['django.contrib.admin'])(request)\n+        return JavaScriptCatalog.as_view(packages=[\"django.contrib.admin\"])(request)\n \n     def logout(self, request, extra_context=None):\n         \"\"\"\n@@ -365,17 +387,18 @@ class AdminSite:\n         This should *not* assume the user is already logged in.\n         \"\"\"\n         from django.contrib.auth.views import LogoutView\n+\n         defaults = {\n-            'extra_context': {\n+            \"extra_context\": {\n                 **self.each_context(request),\n                 # Since the user isn't logged out at this point, the value of\n                 # has_permission must be overridden.\n-                'has_permission': False,\n-                **(extra_context or {})\n+                \"has_permission\": False,\n+                **(extra_context or {}),\n             },\n         }\n         if self.logout_template is not None:\n-            defaults['template_name'] = self.logout_template\n+            defaults[\"template_name\"] = self.logout_template\n         request.current_app = self.name\n         return LogoutView.as_view(**defaults)(request)\n \n@@ -384,9 +407,9 @@ class AdminSite:\n         \"\"\"\n         Display the login form for the given HttpRequest.\n         \"\"\"\n-        if request.method == 'GET' and self.has_permission(request):\n+        if request.method == \"GET\" and self.has_permission(request):\n             # Already logged-in, redirect to admin index\n-            index_path = reverse('admin:index', current_app=self.name)\n+            index_path = reverse(\"admin:index\", current_app=self.name)\n             return HttpResponseRedirect(index_path)\n \n         # Since this module gets imported in the application's root package,\n@@ -394,21 +417,24 @@ class AdminSite:\n         # and django.contrib.admin.forms eventually imports User.\n         from django.contrib.admin.forms import AdminAuthenticationForm\n         from django.contrib.auth.views import LoginView\n+\n         context = {\n             **self.each_context(request),\n-            'title': _('Log in'),\n-            'app_path': request.get_full_path(),\n-            'username': request.user.get_username(),\n+            \"title\": _(\"Log in\"),\n+            \"app_path\": request.get_full_path(),\n+            \"username\": request.user.get_username(),\n         }\n-        if (REDIRECT_FIELD_NAME not in request.GET and\n-                REDIRECT_FIELD_NAME not in request.POST):\n-            context[REDIRECT_FIELD_NAME] = reverse('admin:index', current_app=self.name)\n+        if (\n+            REDIRECT_FIELD_NAME not in request.GET\n+            and REDIRECT_FIELD_NAME not in request.POST\n+        ):\n+            context[REDIRECT_FIELD_NAME] = reverse(\"admin:index\", current_app=self.name)\n         context.update(extra_context or {})\n \n         defaults = {\n-            'extra_context': context,\n-            'authentication_form': self.login_form or AdminAuthenticationForm,\n-            'template_name': self.login_template or 'admin/login.html',\n+            \"extra_context\": context,\n+            \"authentication_form\": self.login_form or AdminAuthenticationForm,\n+            \"template_name\": self.login_template or \"admin/login.html\",\n         }\n         request.current_app = self.name\n         return LoginView.as_view(**defaults)(request)\n@@ -418,19 +444,19 @@ class AdminSite:\n \n     @no_append_slash\n     def catch_all_view(self, request, url):\n-        if settings.APPEND_SLASH and not url.endswith('/'):\n-            urlconf = getattr(request, 'urlconf', None)\n-            path = '%s/' % request.path_info\n+        if settings.APPEND_SLASH and not url.endswith(\"/\"):\n+            urlconf = getattr(request, \"urlconf\", None)\n+            path = \"%s/\" % request.path_info\n             try:\n                 match = resolve(path, urlconf)\n             except Resolver404:\n                 pass\n             else:\n-                if getattr(match.func, 'should_append_slash', True):\n+                if getattr(match.func, \"should_append_slash\", True):\n                     return HttpResponsePermanentRedirect(path)\n         raise Http404\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -439,7 +465,8 @@ class AdminSite:\n \n         if label:\n             models = {\n-                m: m_a for m, m_a in self._registry.items()\n+                m: m_a\n+                for m, m_a in self._registry.items()\n                 if m._meta.app_label == label\n             }\n         else:\n@@ -461,37 +488,42 @@ class AdminSite:\n \n             info = (app_label, model._meta.model_name)\n             model_dict = {\n-                'name': capfirst(model._meta.verbose_name_plural),\n-                'object_name': model._meta.object_name,\n-                'perms': perms,\n-                'admin_url': None,\n-                'add_url': None,\n+                \"name\": capfirst(model._meta.verbose_name_plural),\n+                \"object_name\": model._meta.object_name,\n+                \"perms\": perms,\n+                \"admin_url\": None,\n+                \"add_url\": None,\n+                \"model\": model,\n             }\n-            if perms.get('change') or perms.get('view'):\n-                model_dict['view_only'] = not perms.get('change')\n+            if perms.get(\"change\") or perms.get(\"view\"):\n+                model_dict[\"view_only\"] = not perms.get(\"change\")\n                 try:\n-                    model_dict['admin_url'] = reverse('admin:%s_%s_changelist' % info, current_app=self.name)\n+                    model_dict[\"admin_url\"] = reverse(\n+                        \"admin:%s_%s_changelist\" % info, current_app=self.name\n+                    )\n                 except NoReverseMatch:\n                     pass\n-            if perms.get('add'):\n+            if perms.get(\"add\"):\n                 try:\n-                    model_dict['add_url'] = reverse('admin:%s_%s_add' % info, current_app=self.name)\n+                    model_dict[\"add_url\"] = reverse(\n+                        \"admin:%s_%s_add\" % info, current_app=self.name\n+                    )\n                 except NoReverseMatch:\n                     pass\n \n             if app_label in app_dict:\n-                app_dict[app_label]['models'].append(model_dict)\n+                app_dict[app_label][\"models\"].append(model_dict)\n             else:\n                 app_dict[app_label] = {\n-                    'name': apps.get_app_config(app_label).verbose_name,\n-                    'app_label': app_label,\n-                    'app_url': reverse(\n-                        'admin:app_list',\n-                        kwargs={'app_label': app_label},\n+                    \"name\": apps.get_app_config(app_label).verbose_name,\n+                    \"app_label\": app_label,\n+                    \"app_url\": reverse(\n+                        \"admin:app_list\",\n+                        kwargs={\"app_label\": app_label},\n                         current_app=self.name,\n                     ),\n-                    'has_module_perms': has_module_perms,\n-                    'models': [model_dict],\n+                    \"has_module_perms\": has_module_perms,\n+                    \"models\": [model_dict],\n                 }\n \n         if label:\n@@ -503,14 +535,14 @@ class AdminSite:\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n \n         # Sort the apps alphabetically.\n-        app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n+        app_list = sorted(app_dict.values(), key=lambda x: x[\"name\"].lower())\n \n         # Sort the models alphabetically within each app.\n         for app in app_list:\n-            app['models'].sort(key=lambda x: x['name'])\n+            app[\"models\"].sort(key=lambda x: x[\"name\"])\n \n         return app_list\n \n@@ -523,42 +555,46 @@ class AdminSite:\n \n         context = {\n             **self.each_context(request),\n-            'title': self.index_title,\n-            'subtitle': None,\n-            'app_list': app_list,\n+            \"title\": self.index_title,\n+            \"subtitle\": None,\n+            \"app_list\": app_list,\n             **(extra_context or {}),\n         }\n \n         request.current_app = self.name\n \n-        return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n+        return TemplateResponse(\n+            request, self.index_template or \"admin/index.html\", context\n+        )\n \n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n-            raise Http404('The requested admin page does not exist.')\n+            raise Http404(\"The requested admin page does not exist.\")\n         # Sort the models alphabetically within each app.\n-        app_dict['models'].sort(key=lambda x: x['name'])\n+        app_dict[\"models\"].sort(key=lambda x: x[\"name\"])\n         context = {\n             **self.each_context(request),\n-            'title': _('%(app)s administration') % {'app': app_dict['name']},\n-            'subtitle': None,\n-            'app_list': [app_dict],\n-            'app_label': app_label,\n+            \"title\": _(\"%(app)s administration\") % {\"app\": app_dict[\"name\"]},\n+            \"subtitle\": None,\n+            \"app_list\": [app_dict],\n+            \"app_label\": app_label,\n             **(extra_context or {}),\n         }\n \n         request.current_app = self.name\n \n-        return TemplateResponse(request, self.app_index_template or [\n-            'admin/%s/app_index.html' % app_label,\n-            'admin/app_index.html'\n-        ], context)\n+        return TemplateResponse(\n+            request,\n+            self.app_index_template\n+            or [\"admin/%s/app_index.html\" % app_label, \"admin/app_index.html\"],\n+            context,\n+        )\n \n \n class DefaultAdminSite(LazyObject):\n     def _setup(self):\n-        AdminSiteClass = import_string(apps.get_app_config('admin').default_site)\n+        AdminSiteClass = import_string(apps.get_app_config(\"admin\").default_site)\n         self._wrapped = AdminSiteClass()\n \n \n"}
{"instance_id": "django__django-13448", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..7b1fda0468 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -10,7 +10,7 @@ from django.db.transaction import atomic\n \n # The prefix to put on the default database name when creating\n # the test database.\n-TEST_DATABASE_PREFIX = 'test_'\n+TEST_DATABASE_PREFIX = \"test_\"\n \n \n class BaseDatabaseCreation:\n@@ -18,6 +18,7 @@ class BaseDatabaseCreation:\n     Encapsulate backend-specific differences pertaining to creation and\n     destruction of the test database.\n     \"\"\"\n+\n     def __init__(self, connection):\n         self.connection = connection\n \n@@ -27,7 +28,9 @@ class BaseDatabaseCreation:\n     def log(self, msg):\n         sys.stderr.write(msg + os.linesep)\n \n-    def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=False):\n+    def create_test_db(\n+        self, verbosity=1, autoclobber=False, serialize=True, keepdb=False, migrate=True\n+    ):\n         \"\"\"\n         Create a test database, prompting the user for confirmation if the\n         database already exists. Return the name of the test database created.\n@@ -38,14 +41,17 @@ class BaseDatabaseCreation:\n         test_database_name = self._get_test_db_name()\n \n         if verbosity >= 1:\n-            action = 'Creating'\n+            action = \"Creating\"\n             if keepdb:\n                 action = \"Using existing\"\n \n-            self.log('%s test database for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, test_database_name),\n-            ))\n+            self.log(\n+                \"%s test database for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, test_database_name),\n+                )\n+            )\n \n         # We could skip this call if keepdb is True, but we instead\n         # give it the keepdb param. This is to handle the case\n@@ -58,12 +64,12 @@ class BaseDatabaseCreation:\n         settings.DATABASES[self.connection.alias][\"NAME\"] = test_database_name\n         self.connection.settings_dict[\"NAME\"] = test_database_name\n \n-        if self.connection.settings_dict['TEST']['MIGRATE']:\n+        if migrate:\n             # We report migrate messages at one level lower than that\n             # requested. This ensures we don't get flooded with messages during\n             # testing (unless you really ask to be flooded).\n             call_command(\n-                'migrate',\n+                \"migrate\",\n                 verbosity=max(verbosity - 1, 0),\n                 interactive=False,\n                 database=self.connection.alias,\n@@ -74,10 +80,10 @@ class BaseDatabaseCreation:\n         # and store it on the connection. This slightly horrific process is so people\n         # who are testing on databases without transactions or who are using\n         # a TransactionTestCase still get a clean database on every test run.\n-        if serialize:\n+        if serialize and migrate:\n             self.connection._test_serialized_contents = self.serialize_db_to_string()\n \n-        call_command('createcachetable', database=self.connection.alias)\n+        call_command(\"createcachetable\", database=self.connection.alias)\n \n         # Ensure a connection for the side effect of initializing the test database.\n         self.connection.ensure_connection()\n@@ -89,7 +95,7 @@ class BaseDatabaseCreation:\n         Set this database up to be used in testing as a mirror of a primary\n         database whose settings are given.\n         \"\"\"\n-        self.connection.settings_dict['NAME'] = primary_settings_dict['NAME']\n+        self.connection.settings_dict[\"NAME\"] = primary_settings_dict[\"NAME\"]\n \n     def serialize_db_to_string(self):\n         \"\"\"\n@@ -97,25 +103,27 @@ class BaseDatabaseCreation:\n         Designed only for test runner usage; will not handle large\n         amounts of data.\n         \"\"\"\n+\n         # Iteratively return every object for all models to serialize.\n         def get_objects():\n             from django.db.migrations.loader import MigrationLoader\n+\n             loader = MigrationLoader(self.connection)\n             for app_config in apps.get_app_configs():\n                 if (\n-                    app_config.models_module is not None and\n-                    app_config.label in loader.migrated_apps and\n-                    app_config.name not in settings.TEST_NON_SERIALIZED_APPS\n+                    app_config.models_module is not None\n+                    and app_config.label in loader.migrated_apps\n+                    and app_config.name not in settings.TEST_NON_SERIALIZED_APPS\n                 ):\n                     for model in app_config.get_models():\n-                        if (\n-                            model._meta.can_migrate(self.connection) and\n-                            router.allow_migrate_model(self.connection.alias, model)\n-                        ):\n+                        if model._meta.can_migrate(\n+                            self.connection\n+                        ) and router.allow_migrate_model(self.connection.alias, model):\n                             queryset = model._default_manager.using(\n                                 self.connection.alias,\n                             ).order_by(model._meta.pk.name)\n                             yield from queryset.iterator()\n+\n         # Serialize to a string\n         out = StringIO()\n         serializers.serialize(\"json\", get_objects(), indent=None, stream=out)\n@@ -133,7 +141,9 @@ class BaseDatabaseCreation:\n             # Disable constraint checks, because some databases (MySQL) doesn't\n             # support deferred checks.\n             with self.connection.constraint_checks_disabled():\n-                for obj in serializers.deserialize('json', data, using=self.connection.alias):\n+                for obj in serializers.deserialize(\n+                    \"json\", data, using=self.connection.alias\n+                ):\n                     obj.save()\n                     table_names.add(obj.object.__class__._meta.db_table)\n             # Manually check for any invalid keys that might have been added,\n@@ -146,7 +156,7 @@ class BaseDatabaseCreation:\n         \"\"\"\n         return \"'%s'%s\" % (\n             self.connection.alias,\n-            (\" ('%s')\" % database_name) if verbosity >= 2 else '',\n+            (\" ('%s')\" % database_name) if verbosity >= 2 else \"\",\n         )\n \n     def _get_test_db_name(self):\n@@ -156,12 +166,12 @@ class BaseDatabaseCreation:\n         _create_test_db() and when no external munging is done with the 'NAME'\n         settings.\n         \"\"\"\n-        if self.connection.settings_dict['TEST']['NAME']:\n-            return self.connection.settings_dict['TEST']['NAME']\n-        return TEST_DATABASE_PREFIX + self.connection.settings_dict['NAME']\n+        if self.connection.settings_dict[\"TEST\"][\"NAME\"]:\n+            return self.connection.settings_dict[\"TEST\"][\"NAME\"]\n+        return TEST_DATABASE_PREFIX + self.connection.settings_dict[\"NAME\"]\n \n     def _execute_create_test_db(self, cursor, parameters, keepdb=False):\n-        cursor.execute('CREATE DATABASE %(dbname)s %(suffix)s' % parameters)\n+        cursor.execute(\"CREATE DATABASE %(dbname)s %(suffix)s\" % parameters)\n \n     def _create_test_db(self, verbosity, autoclobber, keepdb=False):\n         \"\"\"\n@@ -169,8 +179,8 @@ class BaseDatabaseCreation:\n         \"\"\"\n         test_database_name = self._get_test_db_name()\n         test_db_params = {\n-            'dbname': self.connection.ops.quote_name(test_database_name),\n-            'suffix': self.sql_table_creation_suffix(),\n+            \"dbname\": self.connection.ops.quote_name(test_database_name),\n+            \"suffix\": self.sql_table_creation_suffix(),\n         }\n         # Create the test database and connect to it.\n         with self._nodb_cursor() as cursor:\n@@ -182,24 +192,30 @@ class BaseDatabaseCreation:\n                 if keepdb:\n                     return test_database_name\n \n-                self.log('Got an error creating the test database: %s' % e)\n+                self.log(\"Got an error creating the test database: %s\" % e)\n                 if not autoclobber:\n                     confirm = input(\n                         \"Type 'yes' if you would like to try deleting the test \"\n-                        \"database '%s', or 'no' to cancel: \" % test_database_name)\n-                if autoclobber or confirm == 'yes':\n+                        \"database '%s', or 'no' to cancel: \" % test_database_name\n+                    )\n+                if autoclobber or confirm == \"yes\":\n                     try:\n                         if verbosity >= 1:\n-                            self.log('Destroying old test database for alias %s...' % (\n-                                self._get_database_display_str(verbosity, test_database_name),\n-                            ))\n-                        cursor.execute('DROP DATABASE %(dbname)s' % test_db_params)\n+                            self.log(\n+                                \"Destroying old test database for alias %s...\"\n+                                % (\n+                                    self._get_database_display_str(\n+                                        verbosity, test_database_name\n+                                    ),\n+                                )\n+                            )\n+                        cursor.execute(\"DROP DATABASE %(dbname)s\" % test_db_params)\n                         self._execute_create_test_db(cursor, test_db_params, keepdb)\n                     except Exception as e:\n-                        self.log('Got an error recreating the test database: %s' % e)\n+                        self.log(\"Got an error recreating the test database: %s\" % e)\n                         sys.exit(2)\n                 else:\n-                    self.log('Tests cancelled.')\n+                    self.log(\"Tests cancelled.\")\n                     sys.exit(1)\n \n         return test_database_name\n@@ -208,16 +224,19 @@ class BaseDatabaseCreation:\n         \"\"\"\n         Clone a test database.\n         \"\"\"\n-        source_database_name = self.connection.settings_dict['NAME']\n+        source_database_name = self.connection.settings_dict[\"NAME\"]\n \n         if verbosity >= 1:\n-            action = 'Cloning test database'\n+            action = \"Cloning test database\"\n             if keepdb:\n-                action = 'Using existing clone'\n-            self.log('%s for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, source_database_name),\n-            ))\n+                action = \"Using existing clone\"\n+            self.log(\n+                \"%s for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, source_database_name),\n+                )\n+            )\n \n         # We could skip this call if keepdb is True, but we instead\n         # give it the keepdb param. See create_test_db for details.\n@@ -231,7 +250,10 @@ class BaseDatabaseCreation:\n         # already and its name has been copied to settings_dict['NAME'] so\n         # we don't need to call _get_test_db_name.\n         orig_settings_dict = self.connection.settings_dict\n-        return {**orig_settings_dict, 'NAME': '{}_{}'.format(orig_settings_dict['NAME'], suffix)}\n+        return {\n+            **orig_settings_dict,\n+            \"NAME\": \"{}_{}\".format(orig_settings_dict[\"NAME\"], suffix),\n+        }\n \n     def _clone_test_db(self, suffix, verbosity, keepdb=False):\n         \"\"\"\n@@ -239,27 +261,33 @@ class BaseDatabaseCreation:\n         \"\"\"\n         raise NotImplementedError(\n             \"The database backend doesn't support cloning databases. \"\n-            \"Disable the option to run tests in parallel processes.\")\n+            \"Disable the option to run tests in parallel processes.\"\n+        )\n \n-    def destroy_test_db(self, old_database_name=None, verbosity=1, keepdb=False, suffix=None):\n+    def destroy_test_db(\n+        self, old_database_name=None, verbosity=1, keepdb=False, suffix=None\n+    ):\n         \"\"\"\n         Destroy a test database, prompting the user for confirmation if the\n         database already exists.\n         \"\"\"\n         self.connection.close()\n         if suffix is None:\n-            test_database_name = self.connection.settings_dict['NAME']\n+            test_database_name = self.connection.settings_dict[\"NAME\"]\n         else:\n-            test_database_name = self.get_test_db_clone_settings(suffix)['NAME']\n+            test_database_name = self.get_test_db_clone_settings(suffix)[\"NAME\"]\n \n         if verbosity >= 1:\n-            action = 'Destroying'\n+            action = \"Destroying\"\n             if keepdb:\n-                action = 'Preserving'\n-            self.log('%s test database for alias %s...' % (\n-                action,\n-                self._get_database_display_str(verbosity, test_database_name),\n-            ))\n+                action = \"Preserving\"\n+            self.log(\n+                \"%s test database for alias %s...\"\n+                % (\n+                    action,\n+                    self._get_database_display_str(verbosity, test_database_name),\n+                )\n+            )\n \n         # if we want to preserve the database\n         # skip the actual destroying piece.\n@@ -280,14 +308,15 @@ class BaseDatabaseCreation:\n         # to do so, because it's not allowed to delete a database while being\n         # connected to it.\n         with self._nodb_cursor() as cursor:\n-            cursor.execute(\"DROP DATABASE %s\"\n-                           % self.connection.ops.quote_name(test_database_name))\n+            cursor.execute(\n+                \"DROP DATABASE %s\" % self.connection.ops.quote_name(test_database_name)\n+            )\n \n     def sql_table_creation_suffix(self):\n         \"\"\"\n         SQL to append to the end of the test table creation statements.\n         \"\"\"\n-        return ''\n+        return \"\"\n \n     def test_db_signature(self):\n         \"\"\"\n@@ -297,8 +326,8 @@ class BaseDatabaseCreation:\n         \"\"\"\n         settings_dict = self.connection.settings_dict\n         return (\n-            settings_dict['HOST'],\n-            settings_dict['PORT'],\n-            settings_dict['ENGINE'],\n+            settings_dict[\"HOST\"],\n+            settings_dict[\"PORT\"],\n+            settings_dict[\"ENGINE\"],\n             self._get_test_db_name(),\n         )\ndiff --git a/django/test/utils.py b/django/test/utils.py\nindex 4f4ce99967..1291d71543 100644\n--- a/django/test/utils.py\n+++ b/django/test/utils.py\n@@ -34,15 +34,24 @@ except ImportError:\n \n \n __all__ = (\n-    'Approximate', 'ContextList', 'isolate_lru_cache', 'get_runner',\n-    'CaptureQueriesContext',\n-    'ignore_warnings', 'isolate_apps', 'modify_settings', 'override_settings',\n-    'override_system_checks', 'tag',\n-    'requires_tz_support',\n-    'setup_databases', 'setup_test_environment', 'teardown_test_environment',\n+    \"Approximate\",\n+    \"ContextList\",\n+    \"isolate_lru_cache\",\n+    \"get_runner\",\n+    \"CaptureQueriesContext\",\n+    \"ignore_warnings\",\n+    \"isolate_apps\",\n+    \"modify_settings\",\n+    \"override_settings\",\n+    \"override_system_checks\",\n+    \"tag\",\n+    \"requires_tz_support\",\n+    \"setup_databases\",\n+    \"setup_test_environment\",\n+    \"teardown_test_environment\",\n )\n \n-TZ_SUPPORT = hasattr(time, 'tzset')\n+TZ_SUPPORT = hasattr(time, \"tzset\")\n \n \n class Approximate:\n@@ -62,6 +71,7 @@ class ContextList(list):\n     A wrapper that provides direct key access to context items contained\n     in a list of context objects.\n     \"\"\"\n+\n     def __getitem__(self, key):\n         if isinstance(key, str):\n             for subcontext in self:\n@@ -109,7 +119,7 @@ def setup_test_environment(debug=None):\n     Perform global pre-test setup, such as installing the instrumented template\n     renderer and setting the email backend to the locmem email backend.\n     \"\"\"\n-    if hasattr(_TestState, 'saved_data'):\n+    if hasattr(_TestState, \"saved_data\"):\n         # Executing this function twice would overwrite the saved values.\n         raise RuntimeError(\n             \"setup_test_environment() was already called and can't be called \"\n@@ -124,13 +134,13 @@ def setup_test_environment(debug=None):\n \n     saved_data.allowed_hosts = settings.ALLOWED_HOSTS\n     # Add the default host of the test client.\n-    settings.ALLOWED_HOSTS = [*settings.ALLOWED_HOSTS, 'testserver']\n+    settings.ALLOWED_HOSTS = [*settings.ALLOWED_HOSTS, \"testserver\"]\n \n     saved_data.debug = settings.DEBUG\n     settings.DEBUG = debug\n \n     saved_data.email_backend = settings.EMAIL_BACKEND\n-    settings.EMAIL_BACKEND = 'django.core.mail.backends.locmem.EmailBackend'\n+    settings.EMAIL_BACKEND = \"django.core.mail.backends.locmem.EmailBackend\"\n \n     saved_data.template_render = Template._render\n     Template._render = instrumented_test_render\n@@ -156,8 +166,16 @@ def teardown_test_environment():\n     del mail.outbox\n \n \n-def setup_databases(verbosity, interactive, *, time_keeper=None, keepdb=False, debug_sql=False, parallel=0,\n-                    aliases=None):\n+def setup_databases(\n+    verbosity,\n+    interactive,\n+    *,\n+    time_keeper=None,\n+    keepdb=False,\n+    debug_sql=False,\n+    parallel=0,\n+    aliases=None,\n+):\n     \"\"\"Create the test databases.\"\"\"\n     if time_keeper is None:\n         time_keeper = NullTimeKeeper()\n@@ -180,7 +198,10 @@ def setup_databases(verbosity, interactive, *, time_keeper=None, keepdb=False, d\n                         verbosity=verbosity,\n                         autoclobber=not interactive,\n                         keepdb=keepdb,\n-                        serialize=connection.settings_dict['TEST'].get('SERIALIZE', True),\n+                        serialize=connection.settings_dict[\"TEST\"].get(\n+                            \"SERIALIZE\", True\n+                        ),\n+                        migrate=connection.settings_dict[\"TEST\"].get(\"MIGRATE\", True),\n                     )\n                 if parallel > 1:\n                     for index in range(parallel):\n@@ -192,12 +213,15 @@ def setup_databases(verbosity, interactive, *, time_keeper=None, keepdb=False, d\n                             )\n             # Configure all other connections as mirrors of the first one\n             else:\n-                connections[alias].creation.set_as_test_mirror(connections[first_alias].settings_dict)\n+                connections[alias].creation.set_as_test_mirror(\n+                    connections[first_alias].settings_dict\n+                )\n \n     # Configure the test mirrors.\n     for alias, mirror_alias in mirrored_aliases.items():\n         connections[alias].creation.set_as_test_mirror(\n-            connections[mirror_alias].settings_dict)\n+            connections[mirror_alias].settings_dict\n+        )\n \n     if debug_sql:\n         for alias in connections:\n@@ -269,26 +293,31 @@ def get_unique_databases_and_mirrors(aliases=None):\n \n     for alias in connections:\n         connection = connections[alias]\n-        test_settings = connection.settings_dict['TEST']\n+        test_settings = connection.settings_dict[\"TEST\"]\n \n-        if test_settings['MIRROR']:\n+        if test_settings[\"MIRROR\"]:\n             # If the database is marked as a test mirror, save the alias.\n-            mirrored_aliases[alias] = test_settings['MIRROR']\n+            mirrored_aliases[alias] = test_settings[\"MIRROR\"]\n         elif alias in aliases:\n             # Store a tuple with DB parameters that uniquely identify it.\n             # If we have two aliases with the same values for that tuple,\n             # we only need to create the test database once.\n             item = test_databases.setdefault(\n                 connection.creation.test_db_signature(),\n-                (connection.settings_dict['NAME'], set())\n+                (connection.settings_dict[\"NAME\"], set()),\n             )\n             item[1].add(alias)\n \n-            if 'DEPENDENCIES' in test_settings:\n-                dependencies[alias] = test_settings['DEPENDENCIES']\n+            if \"DEPENDENCIES\" in test_settings:\n+                dependencies[alias] = test_settings[\"DEPENDENCIES\"]\n             else:\n-                if alias != DEFAULT_DB_ALIAS and connection.creation.test_db_signature() != default_sig:\n-                    dependencies[alias] = test_settings.get('DEPENDENCIES', [DEFAULT_DB_ALIAS])\n+                if (\n+                    alias != DEFAULT_DB_ALIAS\n+                    and connection.creation.test_db_signature() != default_sig\n+                ):\n+                    dependencies[alias] = test_settings.get(\n+                        \"DEPENDENCIES\", [DEFAULT_DB_ALIAS]\n+                    )\n \n     test_databases = dict(dependency_ordered(test_databases.items(), dependencies))\n     return test_databases, mirrored_aliases\n@@ -310,12 +339,12 @@ def teardown_databases(old_config, verbosity, parallel=0, keepdb=False):\n \n def get_runner(settings, test_runner_class=None):\n     test_runner_class = test_runner_class or settings.TEST_RUNNER\n-    test_path = test_runner_class.split('.')\n+    test_path = test_runner_class.split(\".\")\n     # Allow for relative paths\n     if len(test_path) > 1:\n-        test_module_name = '.'.join(test_path[:-1])\n+        test_module_name = \".\".join(test_path[:-1])\n     else:\n-        test_module_name = '.'\n+        test_module_name = \".\"\n     test_module = __import__(test_module_name, {}, {}, test_path[-1])\n     return getattr(test_module, test_path[-1])\n \n@@ -332,6 +361,7 @@ class TestContextDecorator:\n     `kwarg_name`: keyword argument passing the return value of enable() if\n                   used as a function decorator.\n     \"\"\"\n+\n     def __init__(self, attr_name=None, kwarg_name=None):\n         self.attr_name = attr_name\n         self.kwarg_name = kwarg_name\n@@ -361,7 +391,7 @@ class TestContextDecorator:\n \n             cls.setUp = setUp\n             return cls\n-        raise TypeError('Can only decorate subclasses of unittest.TestCase')\n+        raise TypeError(\"Can only decorate subclasses of unittest.TestCase\")\n \n     def decorate_callable(self, func):\n         if asyncio.iscoroutinefunction(func):\n@@ -374,12 +404,14 @@ class TestContextDecorator:\n                         kwargs[self.kwarg_name] = context\n                     return await func(*args, **kwargs)\n         else:\n+\n             @wraps(func)\n             def inner(*args, **kwargs):\n                 with self as context:\n                     if self.kwarg_name:\n                         kwargs[self.kwarg_name] = context\n                     return func(*args, **kwargs)\n+\n         return inner\n \n     def __call__(self, decorated):\n@@ -387,7 +419,7 @@ class TestContextDecorator:\n             return self.decorate_class(decorated)\n         elif callable(decorated):\n             return self.decorate_callable(decorated)\n-        raise TypeError('Cannot decorate object of type %s' % type(decorated))\n+        raise TypeError(\"Cannot decorate object of type %s\" % type(decorated))\n \n \n class override_settings(TestContextDecorator):\n@@ -397,6 +429,7 @@ class override_settings(TestContextDecorator):\n     with the ``with`` statement. In either event, entering/exiting are called\n     before and after, respectively, the function/block is executed.\n     \"\"\"\n+\n     enable_exception = None\n \n     def __init__(self, **kwargs):\n@@ -406,9 +439,9 @@ class override_settings(TestContextDecorator):\n     def enable(self):\n         # Keep this code at the beginning to leave the settings unchanged\n         # in case it raises an exception because INSTALLED_APPS is invalid.\n-        if 'INSTALLED_APPS' in self.options:\n+        if \"INSTALLED_APPS\" in self.options:\n             try:\n-                apps.set_installed_apps(self.options['INSTALLED_APPS'])\n+                apps.set_installed_apps(self.options[\"INSTALLED_APPS\"])\n             except Exception:\n                 apps.unset_installed_apps()\n                 raise\n@@ -421,14 +454,16 @@ class override_settings(TestContextDecorator):\n             try:\n                 setting_changed.send(\n                     sender=settings._wrapped.__class__,\n-                    setting=key, value=new_value, enter=True,\n+                    setting=key,\n+                    value=new_value,\n+                    enter=True,\n                 )\n             except Exception as exc:\n                 self.enable_exception = exc\n                 self.disable()\n \n     def disable(self):\n-        if 'INSTALLED_APPS' in self.options:\n+        if \"INSTALLED_APPS\" in self.options:\n             apps.unset_installed_apps()\n         settings._wrapped = self.wrapped\n         del self.wrapped\n@@ -437,7 +472,9 @@ class override_settings(TestContextDecorator):\n             new_value = getattr(settings, key, None)\n             responses_for_setting = setting_changed.send_robust(\n                 sender=settings._wrapped.__class__,\n-                setting=key, value=new_value, enter=False,\n+                setting=key,\n+                value=new_value,\n+                enter=False,\n             )\n             responses.extend(responses_for_setting)\n         if self.enable_exception is not None:\n@@ -460,10 +497,12 @@ class override_settings(TestContextDecorator):\n \n     def decorate_class(self, cls):\n         from django.test import SimpleTestCase\n+\n         if not issubclass(cls, SimpleTestCase):\n             raise ValueError(\n                 \"Only subclasses of Django SimpleTestCase can be decorated \"\n-                \"with override_settings\")\n+                \"with override_settings\"\n+            )\n         self.save_options(cls)\n         return cls\n \n@@ -473,6 +512,7 @@ class modify_settings(override_settings):\n     Like override_settings, but makes it possible to append, prepend, or remove\n     items instead of redefining the entire list.\n     \"\"\"\n+\n     def __init__(self, *args, **kwargs):\n         if args:\n             # Hack used when instantiating from SimpleTestCase.setUpClass.\n@@ -488,8 +528,9 @@ class modify_settings(override_settings):\n             test_func._modified_settings = self.operations\n         else:\n             # Duplicate list to prevent subclasses from altering their parent.\n-            test_func._modified_settings = list(\n-                test_func._modified_settings) + self.operations\n+            test_func._modified_settings = (\n+                list(test_func._modified_settings) + self.operations\n+            )\n \n     def enable(self):\n         self.options = {}\n@@ -504,11 +545,11 @@ class modify_settings(override_settings):\n                 # items my be a single value or an iterable.\n                 if isinstance(items, str):\n                     items = [items]\n-                if action == 'append':\n+                if action == \"append\":\n                     value = value + [item for item in items if item not in value]\n-                elif action == 'prepend':\n+                elif action == \"prepend\":\n                     value = [item for item in items if item not in value] + value\n-                elif action == 'remove':\n+                elif action == \"remove\":\n                     value = [item for item in value if item not in items]\n                 else:\n                     raise ValueError(\"Unsupported action: %s\" % action)\n@@ -522,8 +563,10 @@ class override_system_checks(TestContextDecorator):\n     Useful when you override `INSTALLED_APPS`, e.g. if you exclude `auth` app,\n     you also need to exclude its system checks.\n     \"\"\"\n+\n     def __init__(self, new_checks, deployment_checks=None):\n         from django.core.checks.registry import registry\n+\n         self.registry = registry\n         self.new_checks = new_checks\n         self.deployment_checks = deployment_checks\n@@ -533,12 +576,12 @@ class override_system_checks(TestContextDecorator):\n         self.old_checks = self.registry.registered_checks\n         self.registry.registered_checks = set()\n         for check in self.new_checks:\n-            self.registry.register(check, *getattr(check, 'tags', ()))\n+            self.registry.register(check, *getattr(check, \"tags\", ()))\n         self.old_deployment_checks = self.registry.deployment_checks\n         if self.deployment_checks is not None:\n             self.registry.deployment_checks = set()\n             for check in self.deployment_checks:\n-                self.registry.register(check, *getattr(check, 'tags', ()), deploy=True)\n+                self.registry.register(check, *getattr(check, \"tags\", ()), deploy=True)\n \n     def disable(self):\n         self.registry.registered_checks = self.old_checks\n@@ -554,18 +597,18 @@ def compare_xml(want, got):\n \n     Based on https://github.com/lxml/lxml/blob/master/src/lxml/doctestcompare.py\n     \"\"\"\n-    _norm_whitespace_re = re.compile(r'[ \\t\\n][ \\t\\n]+')\n+    _norm_whitespace_re = re.compile(r\"[ \\t\\n][ \\t\\n]+\")\n \n     def norm_whitespace(v):\n-        return _norm_whitespace_re.sub(' ', v)\n+        return _norm_whitespace_re.sub(\" \", v)\n \n     def child_text(element):\n-        return ''.join(c.data for c in element.childNodes\n-                       if c.nodeType == Node.TEXT_NODE)\n+        return \"\".join(\n+            c.data for c in element.childNodes if c.nodeType == Node.TEXT_NODE\n+        )\n \n     def children(element):\n-        return [c for c in element.childNodes\n-                if c.nodeType == Node.ELEMENT_NODE]\n+        return [c for c in element.childNodes if c.nodeType == Node.ELEMENT_NODE]\n \n     def norm_child_text(element):\n         return norm_whitespace(child_text(element))\n@@ -584,7 +627,9 @@ def compare_xml(want, got):\n         got_children = children(got_element)\n         if len(want_children) != len(got_children):\n             return False\n-        return all(check_element(want, got) for want, got in zip(want_children, got_children))\n+        return all(\n+            check_element(want, got) for want, got in zip(want_children, got_children)\n+        )\n \n     def first_node(document):\n         for node in document.childNodes:\n@@ -595,13 +640,13 @@ def compare_xml(want, got):\n             ):\n                 return node\n \n-    want = want.strip().replace('\\\\n', '\\n')\n-    got = got.strip().replace('\\\\n', '\\n')\n+    want = want.strip().replace(\"\\\\n\", \"\\n\")\n+    got = got.strip().replace(\"\\\\n\", \"\\n\")\n \n     # If the string is not a complete xml document, we may need to add a\n     # root element. This allow us to compare fragments, like \"<foo/><bar/>\"\n-    if not want.startswith('<?xml'):\n-        wrapper = '<root>%s</root>'\n+    if not want.startswith(\"<?xml\"):\n+        wrapper = \"<root>%s</root>\"\n         want = wrapper % want\n         got = wrapper % got\n \n@@ -616,6 +661,7 @@ class CaptureQueriesContext:\n     \"\"\"\n     Context manager that captures queries executed by the specified connection.\n     \"\"\"\n+\n     def __init__(self, connection):\n         self.connection = connection\n \n@@ -630,7 +676,7 @@ class CaptureQueriesContext:\n \n     @property\n     def captured_queries(self):\n-        return self.connection.queries[self.initial_queries:self.final_queries]\n+        return self.connection.queries[self.initial_queries : self.final_queries]\n \n     def __enter__(self):\n         self.force_debug_cursor = self.connection.force_debug_cursor\n@@ -654,7 +700,7 @@ class CaptureQueriesContext:\n class ignore_warnings(TestContextDecorator):\n     def __init__(self, **kwargs):\n         self.ignore_kwargs = kwargs\n-        if 'message' in self.ignore_kwargs or 'module' in self.ignore_kwargs:\n+        if \"message\" in self.ignore_kwargs or \"module\" in self.ignore_kwargs:\n             self.filter_func = warnings.filterwarnings\n         else:\n             self.filter_func = warnings.simplefilter\n@@ -663,7 +709,7 @@ class ignore_warnings(TestContextDecorator):\n     def enable(self):\n         self.catch_warnings = warnings.catch_warnings()\n         self.catch_warnings.__enter__()\n-        self.filter_func('ignore', **self.ignore_kwargs)\n+        self.filter_func(\"ignore\", **self.ignore_kwargs)\n \n     def disable(self):\n         self.catch_warnings.__exit__(*sys.exc_info())\n@@ -677,7 +723,7 @@ class ignore_warnings(TestContextDecorator):\n requires_tz_support = skipUnless(\n     TZ_SUPPORT,\n     \"This test relies on the ability to run a program in an arbitrary \"\n-    \"time zone, but your operating system isn't able to do that.\"\n+    \"time zone, but your operating system isn't able to do that.\",\n )\n \n \n@@ -720,9 +766,9 @@ def captured_output(stream_name):\n def captured_stdout():\n     \"\"\"Capture the output of sys.stdout:\n \n-       with captured_stdout() as stdout:\n-           print(\"hello\")\n-       self.assertEqual(stdout.getvalue(), \"hello\\n\")\n+    with captured_stdout() as stdout:\n+        print(\"hello\")\n+    self.assertEqual(stdout.getvalue(), \"hello\\n\")\n     \"\"\"\n     return captured_output(\"stdout\")\n \n@@ -730,9 +776,9 @@ def captured_stdout():\n def captured_stderr():\n     \"\"\"Capture the output of sys.stderr:\n \n-       with captured_stderr() as stderr:\n-           print(\"hello\", file=sys.stderr)\n-       self.assertEqual(stderr.getvalue(), \"hello\\n\")\n+    with captured_stderr() as stderr:\n+        print(\"hello\", file=sys.stderr)\n+    self.assertEqual(stderr.getvalue(), \"hello\\n\")\n     \"\"\"\n     return captured_output(\"stderr\")\n \n@@ -740,12 +786,12 @@ def captured_stderr():\n def captured_stdin():\n     \"\"\"Capture the input to sys.stdin:\n \n-       with captured_stdin() as stdin:\n-           stdin.write('hello\\n')\n-           stdin.seek(0)\n-           # call test code that consumes from sys.stdin\n-           captured = input()\n-       self.assertEqual(captured, \"hello\")\n+    with captured_stdin() as stdin:\n+        stdin.write('hello\\n')\n+        stdin.seek(0)\n+        # call test code that consumes from sys.stdin\n+        captured = input()\n+    self.assertEqual(captured, \"hello\")\n     \"\"\"\n     return captured_output(\"stdin\")\n \n@@ -773,18 +819,24 @@ def require_jinja2(test_func):\n     Django template engine for a test or skip it if Jinja2 isn't available.\n     \"\"\"\n     test_func = skipIf(jinja2 is None, \"this test requires jinja2\")(test_func)\n-    return override_settings(TEMPLATES=[{\n-        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n-        'APP_DIRS': True,\n-    }, {\n-        'BACKEND': 'django.template.backends.jinja2.Jinja2',\n-        'APP_DIRS': True,\n-        'OPTIONS': {'keep_trailing_newline': True},\n-    }])(test_func)\n+    return override_settings(\n+        TEMPLATES=[\n+            {\n+                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n+                \"APP_DIRS\": True,\n+            },\n+            {\n+                \"BACKEND\": \"django.template.backends.jinja2.Jinja2\",\n+                \"APP_DIRS\": True,\n+                \"OPTIONS\": {\"keep_trailing_newline\": True},\n+            },\n+        ]\n+    )(test_func)\n \n \n class override_script_prefix(TestContextDecorator):\n     \"\"\"Decorator or context manager to temporary override the script prefix.\"\"\"\n+\n     def __init__(self, prefix):\n         self.prefix = prefix\n         super().__init__()\n@@ -802,8 +854,9 @@ class LoggingCaptureMixin:\n     Capture the output from the 'django' logger and store it on the class's\n     logger_output attribute.\n     \"\"\"\n+\n     def setUp(self):\n-        self.logger = logging.getLogger('django')\n+        self.logger = logging.getLogger(\"django\")\n         self.old_stream = self.logger.handlers[0].stream\n         self.logger_output = StringIO()\n         self.logger.handlers[0].stream = self.logger_output\n@@ -828,6 +881,7 @@ class isolate_apps(TestContextDecorator):\n     `kwarg_name`: keyword argument passing the isolated registry if used as a\n                   function decorator.\n     \"\"\"\n+\n     def __init__(self, *installed_apps, **kwargs):\n         self.installed_apps = installed_apps\n         super().__init__(**kwargs)\n@@ -835,11 +889,11 @@ class isolate_apps(TestContextDecorator):\n     def enable(self):\n         self.old_apps = Options.default_apps\n         apps = Apps(self.installed_apps)\n-        setattr(Options, 'default_apps', apps)\n+        setattr(Options, \"default_apps\", apps)\n         return apps\n \n     def disable(self):\n-        setattr(Options, 'default_apps', self.old_apps)\n+        setattr(Options, \"default_apps\", self.old_apps)\n \n \n class TimeKeeper:\n@@ -859,7 +913,7 @@ class TimeKeeper:\n     def print_results(self):\n         for name, end_times in self.records.items():\n             for record_time in end_times:\n-                record = '%s took %.3fs' % (name, record_time)\n+                record = \"%s took %.3fs\" % (name, record_time)\n                 sys.stderr.write(record + os.linesep)\n \n \n@@ -874,12 +928,14 @@ class NullTimeKeeper:\n \n def tag(*tags):\n     \"\"\"Decorator to add tags to a test class or method.\"\"\"\n+\n     def decorator(obj):\n-        if hasattr(obj, 'tags'):\n+        if hasattr(obj, \"tags\"):\n             obj.tags = obj.tags.union(tags)\n         else:\n-            setattr(obj, 'tags', set(tags))\n+            setattr(obj, \"tags\", set(tags))\n         return obj\n+\n     return decorator\n \n \n"}
{"instance_id": "django__django-13551", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..cb7a75f9f7 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -10,6 +10,7 @@ class PasswordResetTokenGenerator:\n     Strategy object used to generate and check tokens for the password\n     reset mechanism.\n     \"\"\"\n+\n     key_salt = \"django.contrib.auth.tokens.PasswordResetTokenGenerator\"\n     algorithm = None\n     secret = None\n@@ -72,15 +73,15 @@ class PasswordResetTokenGenerator:\n             # RemovedInDjango40Warning: when the deprecation ends, remove the\n             # legacy argument and replace with:\n             #   algorithm=self.algorithm,\n-            algorithm='sha1' if legacy else self.algorithm,\n+            algorithm=\"sha1\" if legacy else self.algorithm,\n         ).hexdigest()[::2]  # Limit to shorten the URL.\n         return \"%s-%s\" % (ts_b36, hash_string)\n \n     def _make_hash_value(self, user, timestamp):\n         \"\"\"\n-        Hash the user's primary key and some user state that's sure to change\n-        after a password reset to produce a token that invalidated when it's\n-        used:\n+        Hash the user's primary key, email (if available), and some user state\n+        that's sure to change after a password reset to produce a token that is\n+        invalidated when it's used:\n         1. The password field will change upon a password reset (even if the\n            same password is chosen, due to password salting).\n         2. The last_login field will usually be updated very shortly after\n@@ -93,8 +94,16 @@ class PasswordResetTokenGenerator:\n         \"\"\"\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n-        login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        login_timestamp = (\n+            \"\"\n+            if user.last_login is None\n+            else user.last_login.replace(microsecond=0, tzinfo=None)\n+        )\n+        email_field = user.get_email_field_name()\n+        email = getattr(user, email_field, \"\") or \"\"\n+        return (\n+            str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n+        )\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n"}
{"instance_id": "django__django-13590", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..cc7e9cabe9 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -6,6 +6,7 @@ themselves do not have to (and could be backed by things other than SQL\n databases). The abstraction barrier only works one way: this module has to know\n all about the internals of models in order to get the information it needs.\n \"\"\"\n+\n import copy\n import difflib\n import functools\n@@ -18,7 +19,9 @@ from itertools import chain, count, product\n from string import ascii_uppercase\n \n from django.core.exceptions import (\n-    EmptyResultSet, FieldDoesNotExist, FieldError,\n+    EmptyResultSet,\n+    FieldDoesNotExist,\n+    FieldError,\n )\n from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n from django.db.models.aggregates import Count\n@@ -28,27 +31,37 @@ from django.db.models.fields import Field\n from django.db.models.fields.related_lookups import MultiColSource\n from django.db.models.lookups import Lookup\n from django.db.models.query_utils import (\n-    Q, check_rel_lookup_compatibility, refs_expression,\n+    Q,\n+    check_rel_lookup_compatibility,\n+    refs_expression,\n )\n from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\n from django.db.models.sql.datastructures import (\n-    BaseTable, Empty, Join, MultiJoin,\n+    BaseTable,\n+    Empty,\n+    Join,\n+    MultiJoin,\n )\n from django.db.models.sql.where import (\n-    AND, OR, ExtraWhere, NothingNode, WhereNode,\n+    AND,\n+    OR,\n+    ExtraWhere,\n+    NothingNode,\n+    WhereNode,\n )\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import cached_property\n from django.utils.tree import Node\n \n-__all__ = ['Query', 'RawQuery']\n+__all__ = [\"Query\", \"RawQuery\"]\n \n \n def get_field_names_from_opts(opts):\n-    return set(chain.from_iterable(\n-        (f.name, f.attname) if f.concrete else (f.name,)\n-        for f in opts.get_fields()\n-    ))\n+    return set(\n+        chain.from_iterable(\n+            (f.name, f.attname) if f.concrete else (f.name,) for f in opts.get_fields()\n+        )\n+    )\n \n \n def get_children_from_q(q):\n@@ -60,8 +73,8 @@ def get_children_from_q(q):\n \n \n JoinInfo = namedtuple(\n-    'JoinInfo',\n-    ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')\n+    \"JoinInfo\",\n+    (\"final_field\", \"targets\", \"opts\", \"joins\", \"path\", \"transform_function\"),\n )\n \n \n@@ -90,8 +103,7 @@ class RawQuery:\n         if self.cursor is None:\n             self._execute_query()\n         converter = connections[self.using].introspection.identifier_converter\n-        return [converter(column_meta[0])\n-                for column_meta in self.cursor.description]\n+        return [converter(column_meta[0]) for column_meta in self.cursor.description]\n \n     def __iter__(self):\n         # Always execute a new query for a new iterator.\n@@ -136,10 +148,10 @@ class RawQuery:\n class Query(BaseExpression):\n     \"\"\"A single SQL query.\"\"\"\n \n-    alias_prefix = 'T'\n+    alias_prefix = \"T\"\n     subq_aliases = frozenset([alias_prefix])\n \n-    compiler = 'SQLCompiler'\n+    compiler = \"SQLCompiler\"\n \n     def __init__(self, model, where=WhereNode, alias_cols=True):\n         self.model = model\n@@ -157,7 +169,7 @@ class Query(BaseExpression):\n         # aliases too.\n         # Map external tables to whether they are aliased.\n         self.external_aliases = {}\n-        self.table_map = {}     # Maps table names to list of aliases.\n+        self.table_map = {}  # Maps table names to list of aliases.\n         self.default_cols = True\n         self.default_ordering = True\n         self.standard_ordering = True\n@@ -233,13 +245,15 @@ class Query(BaseExpression):\n     def output_field(self):\n         if len(self.select) == 1:\n             select = self.select[0]\n-            return getattr(select, 'target', None) or select.field\n+            return getattr(select, \"target\", None) or select.field\n         elif len(self.annotation_select) == 1:\n             return next(iter(self.annotation_select.values())).output_field\n \n     @property\n     def has_select_fields(self):\n-        return bool(self.select or self.annotation_select_mask or self.extra_select_mask)\n+        return bool(\n+            self.select or self.annotation_select_mask or self.extra_select_mask\n+        )\n \n     @cached_property\n     def base_table(self):\n@@ -325,7 +339,7 @@ class Query(BaseExpression):\n             # Use deepcopy because select_related stores fields in nested\n             # dicts.\n             obj.select_related = copy.deepcopy(obj.select_related)\n-        if 'subq_aliases' in self.__dict__:\n+        if \"subq_aliases\" in self.__dict__:\n             obj.subq_aliases = self.subq_aliases.copy()\n         obj.used_aliases = self.used_aliases.copy()\n         obj._filtered_relations = self._filtered_relations.copy()\n@@ -347,7 +361,7 @@ class Query(BaseExpression):\n         if not obj.filter_is_sticky:\n             obj.used_aliases = set()\n         obj.filter_is_sticky = False\n-        if hasattr(obj, '_setup_query'):\n+        if hasattr(obj, \"_setup_query\"):\n             obj._setup_query()\n         return obj\n \n@@ -397,11 +411,13 @@ class Query(BaseExpression):\n                         break\n                 else:\n                     # An expression that is not selected the subquery.\n-                    if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):\n+                    if isinstance(expr, Col) or (\n+                        expr.contains_aggregate and not expr.is_summary\n+                    ):\n                         # Reference column or another aggregate. Select it\n                         # under a non-conflicting alias.\n                         col_cnt += 1\n-                        col_alias = '__col%d' % col_cnt\n+                        col_alias = \"__col%d\" % col_cnt\n                         self.annotations[col_alias] = expr\n                         self.append_annotation_mask([col_alias])\n                         new_expr = Ref(col_alias, expr)\n@@ -420,8 +436,8 @@ class Query(BaseExpression):\n         if not self.annotation_select:\n             return {}\n         existing_annotations = [\n-            annotation for alias, annotation\n-            in self.annotations.items()\n+            annotation\n+            for alias, annotation in self.annotations.items()\n             if alias not in added_aggregate_names\n         ]\n         # Decide if we need to use a subquery.\n@@ -435,9 +451,15 @@ class Query(BaseExpression):\n         # those operations must be done in a subquery so that the query\n         # aggregates on the limit and/or distinct results instead of applying\n         # the distinct and limit after the aggregation.\n-        if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or\n-                self.distinct or self.combinator):\n+        if (\n+            isinstance(self.group_by, tuple)\n+            or self.is_sliced\n+            or existing_annotations\n+            or self.distinct\n+            or self.combinator\n+        ):\n             from django.db.models.sql.subqueries import AggregateQuery\n+\n             outer_query = AggregateQuery(self.model)\n             inner_query = self.clone()\n             inner_query.select_for_update = False\n@@ -455,15 +477,18 @@ class Query(BaseExpression):\n                 # clearing the select clause can alter results if distinct is\n                 # used.\n                 has_existing_aggregate_annotations = any(\n-                    annotation for annotation in existing_annotations\n-                    if getattr(annotation, 'contains_aggregate', True)\n+                    annotation\n+                    for annotation in existing_annotations\n+                    if getattr(annotation, \"contains_aggregate\", True)\n                 )\n                 if inner_query.default_cols and has_existing_aggregate_annotations:\n-                    inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                    inner_query.group_by = (\n+                        self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n+                    )\n                 inner_query.default_cols = False\n \n-            relabels = {t: 'subquery' for t in inner_query.alias_map}\n-            relabels[None] = 'subquery'\n+            relabels = {t: \"subquery\" for t in inner_query.alias_map}\n+            relabels[None] = \"subquery\"\n             # Remove any aggregates marked for reduction from the subquery\n             # and move them to the outer AggregateQuery.\n             col_cnt = 0\n@@ -471,23 +496,28 @@ class Query(BaseExpression):\n                 annotation_select_mask = inner_query.annotation_select_mask\n                 if expression.is_summary:\n                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)\n-                    outer_query.annotations[alias] = expression.relabeled_clone(relabels)\n+                    outer_query.annotations[alias] = expression.relabeled_clone(\n+                        relabels\n+                    )\n                     del inner_query.annotations[alias]\n                     annotation_select_mask.remove(alias)\n                 # Make sure the annotation_select wont use cached results.\n                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)\n-            if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:\n+            if (\n+                inner_query.select == ()\n+                and not inner_query.default_cols\n+                and not inner_query.annotation_select_mask\n+            ):\n                 # In case of Model.objects[0:3].count(), there would be no\n                 # field selected in the inner query, yet we must use a subquery.\n                 # So, make sure at least one field is selected.\n-                inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                inner_query.select = (\n+                    self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n+                )\n             try:\n                 outer_query.add_subquery(inner_query, using)\n             except EmptyResultSet:\n-                return {\n-                    alias: None\n-                    for alias in outer_query.annotation_select\n-                }\n+                return {alias: None for alias in outer_query.annotation_select}\n         else:\n             outer_query = self\n             self.select = ()\n@@ -513,8 +543,8 @@ class Query(BaseExpression):\n         Perform a COUNT() query using the current filter constraints.\n         \"\"\"\n         obj = self.clone()\n-        obj.add_annotation(Count('*'), alias='__count', is_summary=True)\n-        number = obj.get_aggregation(using, ['__count'])['__count']\n+        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n+        number = obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n         if number is None:\n             number = 0\n         return number\n@@ -526,15 +556,17 @@ class Query(BaseExpression):\n         q = self.clone()\n         if not q.distinct:\n             if q.group_by is True:\n-                q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)\n+                q.add_fields(\n+                    (f.attname for f in self.model._meta.concrete_fields), False\n+                )\n                 # Disable GROUP BY aliases to avoid orphaning references to the\n                 # SELECT clause which is about to be cleared.\n                 q.set_group_by(allow_aliases=False)\n             q.clear_select_clause()\n         q.clear_ordering(True)\n         q.set_limits(high=1)\n-        q.add_extra({'a': 1}, None, None, None, None, None)\n-        q.set_extra_mask(['a'])\n+        q.add_extra({\"a\": 1}, None, None, None, None, None)\n+        q.set_extra_mask([\"a\"])\n         return q\n \n     def has_results(self, using):\n@@ -548,7 +580,7 @@ class Query(BaseExpression):\n         q.explain_format = format\n         q.explain_options = options\n         compiler = q.get_compiler(using=using)\n-        return '\\n'.join(compiler.explain_query())\n+        return \"\\n\".join(compiler.explain_query())\n \n     def combine(self, rhs, connector):\n         \"\"\"\n@@ -559,18 +591,20 @@ class Query(BaseExpression):\n         The 'connector' parameter describes how to connect filters from the\n         'rhs' query.\n         \"\"\"\n-        assert self.model == rhs.model, \\\n+        assert self.model == rhs.model, (\n             \"Cannot combine queries on two different base models.\"\n-        assert not self.is_sliced, \\\n-            \"Cannot combine queries once a slice has been taken.\"\n-        assert self.distinct == rhs.distinct, \\\n+        )\n+        assert not self.is_sliced, \"Cannot combine queries once a slice has been taken.\"\n+        assert self.distinct == rhs.distinct, (\n             \"Cannot combine a unique query with a non-unique query.\"\n-        assert self.distinct_fields == rhs.distinct_fields, \\\n+        )\n+        assert self.distinct_fields == rhs.distinct_fields, (\n             \"Cannot combine queries with different distinct fields.\"\n+        )\n \n         # Work out how to relabel the rhs aliases, if necessary.\n         change_map = {}\n-        conjunction = (connector == AND)\n+        conjunction = connector == AND\n \n         # Determine which existing joins can be reused. When combining the\n         # query with AND we must recreate all joins for m2m filters. When\n@@ -590,7 +624,8 @@ class Query(BaseExpression):\n         self.get_initial_alias()\n         joinpromoter = JoinPromoter(connector, 2, False)\n         joinpromoter.add_votes(\n-            j for j in self.alias_map if self.alias_map[j].join_type == INNER)\n+            j for j in self.alias_map if self.alias_map[j].join_type == INNER\n+        )\n         rhs_votes = set()\n         # Now, add the joins from rhs query into the new query (skipping base\n         # table).\n@@ -635,7 +670,9 @@ class Query(BaseExpression):\n             # really make sense (or return consistent value sets). Not worth\n             # the extra complexity when you can write a real query instead.\n             if self.extra and rhs.extra:\n-                raise ValueError(\"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\")\n+                raise ValueError(\n+                    \"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\"\n+                )\n         self.extra.update(rhs.extra)\n         extra_select_mask = set()\n         if self.extra_select_mask is not None:\n@@ -753,11 +790,13 @@ class Query(BaseExpression):\n \n         # Create a new alias for this table.\n         if alias_list:\n-            alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)\n+            alias = \"%s%d\" % (self.alias_prefix, len(self.alias_map) + 1)\n             alias_list.append(alias)\n         else:\n             # The first occurrence of a table uses the table name directly.\n-            alias = filtered_relation.alias if filtered_relation is not None else table_name\n+            alias = (\n+                filtered_relation.alias if filtered_relation is not None else table_name\n+            )\n             self.table_map[table_name] = [alias]\n         self.alias_refcount[alias] = 1\n         return alias, True\n@@ -792,16 +831,19 @@ class Query(BaseExpression):\n             # Only the first alias (skipped above) should have None join_type\n             assert self.alias_map[alias].join_type is not None\n             parent_alias = self.alias_map[alias].parent_alias\n-            parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n+            parent_louter = (\n+                parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n+            )\n             already_louter = self.alias_map[alias].join_type == LOUTER\n-            if ((self.alias_map[alias].nullable or parent_louter) and\n-                    not already_louter):\n+            if (self.alias_map[alias].nullable or parent_louter) and not already_louter:\n                 self.alias_map[alias] = self.alias_map[alias].promote()\n                 # Join type of 'alias' changed, so re-examine all aliases that\n                 # refer to this one.\n                 aliases.extend(\n-                    join for join in self.alias_map\n-                    if self.alias_map[join].parent_alias == alias and join not in aliases\n+                    join\n+                    for join in self.alias_map\n+                    if self.alias_map[join].parent_alias == alias\n+                    and join not in aliases\n                 )\n \n     def demote_joins(self, aliases):\n@@ -844,10 +886,13 @@ class Query(BaseExpression):\n         # \"group by\" and \"where\".\n         self.where.relabel_aliases(change_map)\n         if isinstance(self.group_by, tuple):\n-            self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])\n+            self.group_by = tuple(\n+                [col.relabeled_clone(change_map) for col in self.group_by]\n+            )\n         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n         self.annotations = self.annotations and {\n-            key: col.relabeled_clone(change_map) for key, col in self.annotations.items()\n+            key: col.relabeled_clone(change_map)\n+            for key, col in self.annotations.items()\n         }\n \n         # 2. Rename the alias in the internal table/alias datastructures.\n@@ -878,6 +923,7 @@ class Query(BaseExpression):\n         conflict. Even tables that previously had no alias will get an alias\n         after this call.\n         \"\"\"\n+\n         def prefix_gen():\n             \"\"\"\n             Generate a sequence of characters in alphabetical order:\n@@ -891,9 +937,9 @@ class Query(BaseExpression):\n             prefix = chr(ord(self.alias_prefix) + 1)\n             yield prefix\n             for n in count(1):\n-                seq = alphabet[alphabet.index(prefix):] if prefix else alphabet\n+                seq = alphabet[alphabet.index(prefix) :] if prefix else alphabet\n                 for s in product(seq, repeat=n):\n-                    yield ''.join(s)\n+                    yield \"\".join(s)\n                 prefix = None\n \n         if self.alias_prefix != outer_query.alias_prefix:\n@@ -911,14 +957,16 @@ class Query(BaseExpression):\n                 break\n             if pos > local_recursion_limit:\n                 raise RecursionError(\n-                    'Maximum recursion depth exceeded: too many subqueries.'\n+                    \"Maximum recursion depth exceeded: too many subqueries.\"\n                 )\n         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])\n         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)\n-        self.change_aliases({\n-            alias: '%s%d' % (self.alias_prefix, pos)\n-            for pos, alias in enumerate(self.alias_map)\n-        })\n+        self.change_aliases(\n+            {\n+                alias: \"%s%d\" % (self.alias_prefix, pos)\n+                for pos, alias in enumerate(self.alias_map)\n+            }\n+        )\n \n     def get_initial_alias(self):\n         \"\"\"\n@@ -958,12 +1006,14 @@ class Query(BaseExpression):\n         \"\"\"\n         if reuse_with_filtered_relation and reuse:\n             reuse_aliases = [\n-                a for a, j in self.alias_map.items()\n+                a\n+                for a, j in self.alias_map.items()\n                 if a in reuse and j.equals(join, with_filtered_relation=False)\n             ]\n         else:\n             reuse_aliases = [\n-                a for a, j in self.alias_map.items()\n+                a\n+                for a, j in self.alias_map.items()\n                 if (reuse is None or a in reuse) and j == join\n             ]\n         if reuse_aliases:\n@@ -977,7 +1027,9 @@ class Query(BaseExpression):\n             return reuse_alias\n \n         # No reuse is possible, so we need a new alias.\n-        alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)\n+        alias, _ = self.table_alias(\n+            join.table_name, create=True, filtered_relation=join.filtered_relation\n+        )\n         if join.join_type:\n             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n                 join_type = LOUTER\n@@ -1023,8 +1075,9 @@ class Query(BaseExpression):\n \n     def add_annotation(self, annotation, alias, is_summary=False, select=True):\n         \"\"\"Add a single annotation expression to the Query.\"\"\"\n-        annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,\n-                                                   summarize=is_summary)\n+        annotation = annotation.resolve_expression(\n+            self, allow_joins=True, reuse=None, summarize=is_summary\n+        )\n         if select:\n             self.append_annotation_mask([alias])\n         else:\n@@ -1038,48 +1091,56 @@ class Query(BaseExpression):\n         clone.subquery = True\n         # It's safe to drop ordering if the queryset isn't using slicing,\n         # distinct(*fields) or select_for_update().\n-        if (self.low_mark == 0 and self.high_mark is None and\n-                not self.distinct_fields and\n-                not self.select_for_update):\n+        if (\n+            self.low_mark == 0\n+            and self.high_mark is None\n+            and not self.distinct_fields\n+            and not self.select_for_update\n+        ):\n             clone.clear_ordering(True)\n         clone.where.resolve_expression(query, *args, **kwargs)\n         for key, value in clone.annotations.items():\n             resolved = value.resolve_expression(query, *args, **kwargs)\n-            if hasattr(resolved, 'external_aliases'):\n+            if hasattr(resolved, \"external_aliases\"):\n                 resolved.external_aliases.update(clone.external_aliases)\n             clone.annotations[key] = resolved\n         # Outer query's aliases are considered external.\n         for alias, table in query.alias_map.items():\n             clone.external_aliases[alias] = (\n-                (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or\n-                (isinstance(table, BaseTable) and table.table_name != table.table_alias)\n+                isinstance(table, Join)\n+                and table.join_field.related_model._meta.db_table != alias\n+            ) or (\n+                isinstance(table, BaseTable) and table.table_name != table.table_alias\n             )\n         return clone\n \n     def get_external_cols(self):\n         exprs = chain(self.annotations.values(), self.where.children)\n         return [\n-            col for col in self._gen_cols(exprs)\n-            if col.alias in self.external_aliases\n+            col for col in self._gen_cols(exprs) if col.alias in self.external_aliases\n         ]\n \n     def as_sql(self, compiler, connection):\n         sql, params = self.get_compiler(connection=connection).as_sql()\n         if self.subquery:\n-            sql = '(%s)' % sql\n+            sql = \"(%s)\" % sql\n         return sql, params\n \n     def resolve_lookup_value(self, value, can_reuse, allow_joins):\n-        if hasattr(value, 'resolve_expression'):\n+        if hasattr(value, \"resolve_expression\"):\n             value = value.resolve_expression(\n-                self, reuse=can_reuse, allow_joins=allow_joins,\n+                self,\n+                reuse=can_reuse,\n+                allow_joins=allow_joins,\n             )\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n             return type(value)(\n-                self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n-                for sub_value in value\n+                *(\n+                    self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n+                    for sub_value in value\n+                )\n             )\n         return value\n \n@@ -1089,15 +1150,17 @@ class Query(BaseExpression):\n         \"\"\"\n         lookup_splitted = lookup.split(LOOKUP_SEP)\n         if self.annotations:\n-            expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)\n+            expression, expression_lookups = refs_expression(\n+                lookup_splitted, self.annotations\n+            )\n             if expression:\n                 return expression_lookups, (), expression\n         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n-        field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]\n+        field_parts = lookup_splitted[0 : len(lookup_splitted) - len(lookup_parts)]\n         if len(lookup_parts) > 1 and not field_parts:\n             raise FieldError(\n-                'Invalid lookup \"%s\" for model %s\".' %\n-                (lookup, self.get_meta().model.__name__)\n+                'Invalid lookup \"%s\" for model %s\".'\n+                % (lookup, self.get_meta().model.__name__)\n             )\n         return lookup_parts, field_parts, False\n \n@@ -1106,11 +1169,12 @@ class Query(BaseExpression):\n         Check whether the object passed while querying is of the correct type.\n         If not, raise a ValueError specifying the wrong object.\n         \"\"\"\n-        if hasattr(value, '_meta'):\n+        if hasattr(value, \"_meta\"):\n             if not check_rel_lookup_compatibility(value._meta.model, opts, field):\n                 raise ValueError(\n-                    'Cannot query \"%s\": Must be \"%s\" instance.' %\n-                    (value, opts.object_name))\n+                    'Cannot query \"%s\": Must be \"%s\" instance.'\n+                    % (value, opts.object_name)\n+                )\n \n     def check_related_objects(self, field, value, opts):\n         \"\"\"Check the type of object passed to query relations.\"\"\"\n@@ -1120,29 +1184,30 @@ class Query(BaseExpression):\n             # opts would be Author's (from the author field) and value.model\n             # would be Author.objects.all() queryset's .model (Author also).\n             # The field is the related field on the lhs side.\n-            if (isinstance(value, Query) and not value.has_select_fields and\n-                    not check_rel_lookup_compatibility(value.model, opts, field)):\n+            if (\n+                isinstance(value, Query)\n+                and not value.has_select_fields\n+                and not check_rel_lookup_compatibility(value.model, opts, field)\n+            ):\n                 raise ValueError(\n-                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".' %\n-                    (value.model._meta.object_name, opts.object_name)\n+                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".'\n+                    % (value.model._meta.object_name, opts.object_name)\n                 )\n-            elif hasattr(value, '_meta'):\n+            elif hasattr(value, \"_meta\"):\n                 self.check_query_object_type(value, opts, field)\n-            elif hasattr(value, '__iter__'):\n+            elif hasattr(value, \"__iter__\"):\n                 for v in value:\n                     self.check_query_object_type(v, opts, field)\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if (\n-            hasattr(expression, 'resolve_expression') and\n-            not getattr(expression, 'filterable', True)\n+        if hasattr(expression, \"resolve_expression\") and not getattr(\n+            expression, \"filterable\", True\n         ):\n             raise NotSupportedError(\n-                expression.__class__.__name__ + ' is disallowed in the filter '\n-                'clause.'\n+                expression.__class__.__name__ + \" is disallowed in the filter clause.\"\n             )\n-        if hasattr(expression, 'get_source_expressions'):\n+        if hasattr(expression, \"get_source_expressions\"):\n             for expr in expression.get_source_expressions():\n                 self.check_filterable(expr)\n \n@@ -1156,7 +1221,7 @@ class Query(BaseExpression):\n         and get_transform().\n         \"\"\"\n         # __exact is the default lookup if one isn't given.\n-        *transforms, lookup_name = lookups or ['exact']\n+        *transforms, lookup_name = lookups or [\"exact\"]\n         for name in transforms:\n             lhs = self.try_transform(lhs, name)\n         # First try get_lookup() so that the lookup takes precedence if the lhs\n@@ -1164,11 +1229,13 @@ class Query(BaseExpression):\n         lookup_class = lhs.get_lookup(lookup_name)\n         if not lookup_class:\n             if lhs.field.is_relation:\n-                raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))\n+                raise FieldError(\n+                    \"Related Field got invalid lookup: {}\".format(lookup_name)\n+                )\n             # A lookup wasn't found. Try to interpret the name as a transform\n             # and do an Exact lookup against it.\n             lhs = self.try_transform(lhs, lookup_name)\n-            lookup_name = 'exact'\n+            lookup_name = \"exact\"\n             lookup_class = lhs.get_lookup(lookup_name)\n             if not lookup_class:\n                 return\n@@ -1177,17 +1244,20 @@ class Query(BaseExpression):\n         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n         # uses of None as a query value unless the lookup supports it.\n         if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n-            if lookup_name not in ('exact', 'iexact'):\n+            if lookup_name not in (\"exact\", \"iexact\"):\n                 raise ValueError(\"Cannot use None as a query value\")\n-            return lhs.get_lookup('isnull')(lhs, True)\n+            return lhs.get_lookup(\"isnull\")(lhs, True)\n \n         # For Oracle '' is equivalent to null. The check must be done at this\n         # stage because join promotion can't be done in the compiler. Using\n         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n         # A similar thing is done in is_nullable(), too.\n-        if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and\n-                lookup_name == 'exact' and lookup.rhs == ''):\n-            return lhs.get_lookup('isnull')(lhs, True)\n+        if (\n+            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n+            and lookup_name == \"exact\"\n+            and lookup.rhs == \"\"\n+        ):\n+            return lhs.get_lookup(\"isnull\")(lhs, True)\n \n         return lookup\n \n@@ -1201,19 +1271,29 @@ class Query(BaseExpression):\n             return transform_class(lhs)\n         else:\n             output_field = lhs.output_field.__class__\n-            suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())\n+            suggested_lookups = difflib.get_close_matches(\n+                name, output_field.get_lookups()\n+            )\n             if suggested_lookups:\n-                suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)\n+                suggestion = \", perhaps you meant %s?\" % \" or \".join(suggested_lookups)\n             else:\n-                suggestion = '.'\n+                suggestion = \".\"\n             raise FieldError(\n                 \"Unsupported lookup '%s' for %s or join on the field not \"\n                 \"permitted%s\" % (name, output_field.__name__, suggestion)\n             )\n \n-    def build_filter(self, filter_expr, branch_negated=False, current_negated=False,\n-                     can_reuse=None, allow_joins=True, split_subq=True,\n-                     reuse_with_filtered_relation=False, check_filterable=True):\n+    def build_filter(\n+        self,\n+        filter_expr,\n+        branch_negated=False,\n+        current_negated=False,\n+        can_reuse=None,\n+        allow_joins=True,\n+        split_subq=True,\n+        reuse_with_filtered_relation=False,\n+        check_filterable=True,\n+    ):\n         \"\"\"\n         Build a WhereNode for a single filter clause but don't add it\n         to this Query. Query.add_q() will then add this filter to the where\n@@ -1254,11 +1334,13 @@ class Query(BaseExpression):\n                 split_subq=split_subq,\n                 check_filterable=check_filterable,\n             )\n-        if hasattr(filter_expr, 'resolve_expression'):\n-            if not getattr(filter_expr, 'conditional', False):\n-                raise TypeError('Cannot filter against a non-conditional expression.')\n+        if hasattr(filter_expr, \"resolve_expression\"):\n+            if not getattr(filter_expr, \"conditional\", False):\n+                raise TypeError(\"Cannot filter against a non-conditional expression.\")\n             condition = self.build_lookup(\n-                ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True\n+                [\"exact\"],\n+                filter_expr.resolve_expression(self, allow_joins=allow_joins),\n+                True,\n             )\n             clause = self.where_class()\n             clause.add(condition, AND)\n@@ -1276,7 +1358,9 @@ class Query(BaseExpression):\n \n         pre_joins = self.alias_refcount.copy()\n         value = self.resolve_lookup_value(value, can_reuse, allow_joins)\n-        used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}\n+        used_joins = {\n+            k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)\n+        }\n \n         if check_filterable:\n             self.check_filterable(value)\n@@ -1293,7 +1377,11 @@ class Query(BaseExpression):\n \n         try:\n             join_info = self.setup_joins(\n-                parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,\n+                parts,\n+                opts,\n+                alias,\n+                can_reuse=can_reuse,\n+                allow_many=allow_many,\n                 reuse_with_filtered_relation=reuse_with_filtered_relation,\n             )\n \n@@ -1311,7 +1399,9 @@ class Query(BaseExpression):\n         # Update used_joins before trimming since they are reused to determine\n         # which joins could be later promoted to INNER.\n         used_joins.update(join_info.joins)\n-        targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)\n+        targets, alias, join_list = self.trim_joins(\n+            join_info.targets, join_info.joins, join_info.path\n+        )\n         if can_reuse is not None:\n             can_reuse.update(join_list)\n \n@@ -1319,11 +1409,15 @@ class Query(BaseExpression):\n             # No support for transforms for relational fields\n             num_lookups = len(lookups)\n             if num_lookups > 1:\n-                raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))\n+                raise FieldError(\n+                    \"Related Field got invalid lookup: {}\".format(lookups[0])\n+                )\n             if len(targets) == 1:\n                 col = self._get_col(targets[0], join_info.final_field, alias)\n             else:\n-                col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)\n+                col = MultiColSource(\n+                    alias, targets, join_info.targets, join_info.final_field\n+                )\n         else:\n             col = self._get_col(targets[0], join_info.final_field, alias)\n \n@@ -1331,10 +1425,16 @@ class Query(BaseExpression):\n         lookup_type = condition.lookup_name\n         clause.add(condition, AND)\n \n-        require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated\n-        if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:\n+        require_outer = (\n+            lookup_type == \"isnull\" and condition.rhs is True and not current_negated\n+        )\n+        if (\n+            current_negated\n+            and (lookup_type != \"isnull\" or condition.rhs is False)\n+            and condition.rhs is not None\n+        ):\n             require_outer = True\n-            if lookup_type != 'isnull':\n+            if lookup_type != \"isnull\":\n                 # The condition added here will be SQL like this:\n                 # NOT (col IS NOT NULL), where the first NOT is added in\n                 # upper layers of code. The reason for addition is that if col\n@@ -1345,16 +1445,16 @@ class Query(BaseExpression):\n                 #   <=>\n                 # NOT (col IS NOT NULL AND col = someval).\n                 if (\n-                    self.is_nullable(targets[0]) or\n-                    self.alias_map[join_list[-1]].join_type == LOUTER\n+                    self.is_nullable(targets[0])\n+                    or self.alias_map[join_list[-1]].join_type == LOUTER\n                 ):\n-                    lookup_class = targets[0].get_lookup('isnull')\n+                    lookup_class = targets[0].get_lookup(\"isnull\")\n                     col = self._get_col(targets[0], join_info.targets[0], alias)\n                     clause.add(lookup_class(col, False), AND)\n                 # If someval is a nullable column, someval IS NOT NULL is\n                 # added.\n                 if isinstance(value, Col) and self.is_nullable(value.target):\n-                    lookup_class = value.target.get_lookup('isnull')\n+                    lookup_class = value.target.get_lookup(\"isnull\")\n                     clause.add(lookup_class(value, False), AND)\n         return clause, used_joins if not require_outer else ()\n \n@@ -1372,7 +1472,9 @@ class Query(BaseExpression):\n         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if\n         # rel_a doesn't produce any rows, then the whole condition must fail.\n         # So, demotion is OK.\n-        existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}\n+        existing_inner = {\n+            a for a in self.alias_map if self.alias_map[a].join_type == INNER\n+        }\n         clause, _ = self._add_q(q_object, self.used_aliases)\n         if clause:\n             self.where.add(clause, AND)\n@@ -1381,21 +1483,33 @@ class Query(BaseExpression):\n     def build_where(self, filter_expr):\n         return self.build_filter(filter_expr, allow_joins=False)[0]\n \n-    def _add_q(self, q_object, used_aliases, branch_negated=False,\n-               current_negated=False, allow_joins=True, split_subq=True,\n-               check_filterable=True):\n+    def _add_q(\n+        self,\n+        q_object,\n+        used_aliases,\n+        branch_negated=False,\n+        current_negated=False,\n+        allow_joins=True,\n+        split_subq=True,\n+        check_filterable=True,\n+    ):\n         \"\"\"Add a Q-object to the current filter.\"\"\"\n         connector = q_object.connector\n         current_negated = current_negated ^ q_object.negated\n         branch_negated = branch_negated or q_object.negated\n-        target_clause = self.where_class(connector=connector,\n-                                         negated=q_object.negated)\n-        joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)\n+        target_clause = self.where_class(connector=connector, negated=q_object.negated)\n+        joinpromoter = JoinPromoter(\n+            q_object.connector, len(q_object.children), current_negated\n+        )\n         for child in q_object.children:\n             child_clause, needed_inner = self.build_filter(\n-                child, can_reuse=used_aliases, branch_negated=branch_negated,\n-                current_negated=current_negated, allow_joins=allow_joins,\n-                split_subq=split_subq, check_filterable=check_filterable,\n+                child,\n+                can_reuse=used_aliases,\n+                branch_negated=branch_negated,\n+                current_negated=current_negated,\n+                allow_joins=allow_joins,\n+                split_subq=split_subq,\n+                check_filterable=check_filterable,\n             )\n             joinpromoter.add_votes(needed_inner)\n             if child_clause:\n@@ -1403,7 +1517,9 @@ class Query(BaseExpression):\n         needed_inner = joinpromoter.update_join_types(self)\n         return target_clause, needed_inner\n \n-    def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):\n+    def build_filtered_relation_q(\n+        self, q_object, reuse, branch_negated=False, current_negated=False\n+    ):\n         \"\"\"Add a FilteredRelation object to the current filter.\"\"\"\n         connector = q_object.connector\n         current_negated ^= q_object.negated\n@@ -1412,14 +1528,19 @@ class Query(BaseExpression):\n         for child in q_object.children:\n             if isinstance(child, Node):\n                 child_clause = self.build_filtered_relation_q(\n-                    child, reuse=reuse, branch_negated=branch_negated,\n+                    child,\n+                    reuse=reuse,\n+                    branch_negated=branch_negated,\n                     current_negated=current_negated,\n                 )\n             else:\n                 child_clause, _ = self.build_filter(\n-                    child, can_reuse=reuse, branch_negated=branch_negated,\n+                    child,\n+                    can_reuse=reuse,\n+                    branch_negated=branch_negated,\n                     current_negated=current_negated,\n-                    allow_joins=True, split_subq=False,\n+                    allow_joins=True,\n+                    split_subq=False,\n                     reuse_with_filtered_relation=True,\n                 )\n             target_clause.add(child_clause, connector)\n@@ -1428,7 +1549,9 @@ class Query(BaseExpression):\n     def add_filtered_relation(self, filtered_relation, alias):\n         filtered_relation.alias = alias\n         lookups = dict(get_children_from_q(filtered_relation.condition))\n-        relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(filtered_relation.relation_name)\n+        relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(\n+            filtered_relation.relation_name\n+        )\n         if relation_lookup_parts:\n             raise ValueError(\n                 \"FilteredRelation's relation_name cannot contain lookups \"\n@@ -1472,7 +1595,7 @@ class Query(BaseExpression):\n         path, names_with_path = [], []\n         for pos, name in enumerate(names):\n             cur_names_with_path = (name, [])\n-            if name == 'pk':\n+            if name == \"pk\":\n                 name = opts.pk.name\n \n             field = None\n@@ -1487,7 +1610,10 @@ class Query(BaseExpression):\n                     if LOOKUP_SEP in filtered_relation.relation_name:\n                         parts = filtered_relation.relation_name.split(LOOKUP_SEP)\n                         filtered_relation_path, field, _, _ = self.names_to_path(\n-                            parts, opts, allow_many, fail_on_missing,\n+                            parts,\n+                            opts,\n+                            allow_many,\n+                            fail_on_missing,\n                         )\n                         path.extend(filtered_relation_path[:-1])\n                     else:\n@@ -1514,13 +1640,17 @@ class Query(BaseExpression):\n                 # one step.\n                 pos -= 1\n                 if pos == -1 or fail_on_missing:\n-                    available = sorted([\n-                        *get_field_names_from_opts(opts),\n-                        *self.annotation_select,\n-                        *self._filtered_relations,\n-                    ])\n-                    raise FieldError(\"Cannot resolve keyword '%s' into field. \"\n-                                     \"Choices are: %s\" % (name, \", \".join(available)))\n+                    available = sorted(\n+                        [\n+                            *get_field_names_from_opts(opts),\n+                            *self.annotation_select,\n+                            *self._filtered_relations,\n+                        ]\n+                    )\n+                    raise FieldError(\n+                        \"Cannot resolve keyword '%s' into field. \"\n+                        \"Choices are: %s\" % (name, \", \".join(available))\n+                    )\n                 break\n             # Check if we need any joins for concrete inheritance cases (the\n             # field lives in parent, but we are currently in one of its\n@@ -1531,12 +1661,12 @@ class Query(BaseExpression):\n                     path.extend(path_to_parent)\n                     cur_names_with_path[1].extend(path_to_parent)\n                     opts = path_to_parent[-1].to_opts\n-            if hasattr(field, 'get_path_info'):\n+            if hasattr(field, \"get_path_info\"):\n                 pathinfos = field.get_path_info(filtered_relation)\n                 if not allow_many:\n                     for inner_pos, p in enumerate(pathinfos):\n                         if p.m2m:\n-                            cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])\n+                            cur_names_with_path[1].extend(pathinfos[0 : inner_pos + 1])\n                             names_with_path.append(cur_names_with_path)\n                             raise MultiJoin(pos + 1, names_with_path)\n                 last = pathinfos[-1]\n@@ -1553,12 +1683,20 @@ class Query(BaseExpression):\n                 if fail_on_missing and pos + 1 != len(names):\n                     raise FieldError(\n                         \"Cannot resolve keyword %r into field. Join on '%s'\"\n-                        \" not permitted.\" % (names[pos + 1], name))\n+                        \" not permitted.\" % (names[pos + 1], name)\n+                    )\n                 break\n-        return path, final_field, targets, names[pos + 1:]\n-\n-    def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,\n-                    reuse_with_filtered_relation=False):\n+        return path, final_field, targets, names[pos + 1 :]\n+\n+    def setup_joins(\n+        self,\n+        names,\n+        opts,\n+        alias,\n+        can_reuse=None,\n+        allow_many=True,\n+        reuse_with_filtered_relation=False,\n+    ):\n         \"\"\"\n         Compute the necessary table joins for the passage through the fields\n         given in 'names'. 'opts' is the Options class for the current model\n@@ -1604,7 +1742,10 @@ class Query(BaseExpression):\n         for pivot in range(len(names), 0, -1):\n             try:\n                 path, final_field, targets, rest = self.names_to_path(\n-                    names[:pivot], opts, allow_many, fail_on_missing=True,\n+                    names[:pivot],\n+                    opts,\n+                    allow_many,\n+                    fail_on_missing=True,\n                 )\n             except FieldError as exc:\n                 if pivot == 1:\n@@ -1619,6 +1760,7 @@ class Query(BaseExpression):\n                 transforms = names[pivot:]\n                 break\n         for name in transforms:\n+\n             def transform(field, alias, *, name, previous):\n                 try:\n                     wrapped = previous(field, alias)\n@@ -1629,7 +1771,10 @@ class Query(BaseExpression):\n                         raise last_field_exception\n                     else:\n                         raise\n-            final_transformer = functools.partial(transform, name=name, previous=final_transformer)\n+\n+            final_transformer = functools.partial(\n+                transform, name=name, previous=final_transformer\n+            )\n         # Then, add the path to the query's joins. Note that we can't trim\n         # joins at this stage - we will need the information about join type\n         # of the trimmed joins.\n@@ -1646,12 +1791,18 @@ class Query(BaseExpression):\n             else:\n                 nullable = True\n             connection = Join(\n-                opts.db_table, alias, table_alias, INNER, join.join_field,\n-                nullable, filtered_relation=filtered_relation,\n+                opts.db_table,\n+                alias,\n+                table_alias,\n+                INNER,\n+                join.join_field,\n+                nullable,\n+                filtered_relation=filtered_relation,\n             )\n             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None\n             alias = self.join(\n-                connection, reuse=reuse,\n+                connection,\n+                reuse=reuse,\n                 reuse_with_filtered_relation=reuse_with_filtered_relation,\n             )\n             joins.append(alias)\n@@ -1682,7 +1833,11 @@ class Query(BaseExpression):\n             cur_targets = {t.column for t in targets}\n             if not cur_targets.issubset(join_targets):\n                 break\n-            targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}\n+            targets_dict = {\n+                r[1].column: r[0]\n+                for r in info.join_field.related_fields\n+                if r[1].column in cur_targets\n+            }\n             targets = tuple(targets_dict[t.column] for t in targets)\n             self.unref_alias(joins.pop())\n         return targets, joins[-1], joins\n@@ -1708,8 +1863,7 @@ class Query(BaseExpression):\n                 for alias in self._gen_col_aliases([annotation]):\n                     if isinstance(self.alias_map[alias], Join):\n                         raise FieldError(\n-                            'Joined field references are not permitted in '\n-                            'this query'\n+                            \"Joined field references are not permitted in this query\"\n                         )\n             if summarize:\n                 # Summarize currently means we are doing an aggregate() query\n@@ -1726,13 +1880,20 @@ class Query(BaseExpression):\n                 return annotation\n         else:\n             field_list = name.split(LOOKUP_SEP)\n-            join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)\n-            targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)\n+            join_info = self.setup_joins(\n+                field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse\n+            )\n+            targets, final_alias, join_list = self.trim_joins(\n+                join_info.targets, join_info.joins, join_info.path\n+            )\n             if not allow_joins and len(join_list) > 1:\n-                raise FieldError('Joined field references are not permitted in this query')\n+                raise FieldError(\n+                    \"Joined field references are not permitted in this query\"\n+                )\n             if len(targets) > 1:\n-                raise FieldError(\"Referencing multicolumn fields with F() objects \"\n-                                 \"isn't supported\")\n+                raise FieldError(\n+                    \"Referencing multicolumn fields with F() objects isn't supported\"\n+                )\n             # Verify that the last lookup in name is a field or a transform:\n             # transform_function() raises FieldError if not.\n             join_info.transform_function(targets[0], final_alias)\n@@ -1781,7 +1942,7 @@ class Query(BaseExpression):\n         select_field = col.target\n         alias = col.alias\n         if self.is_nullable(select_field):\n-            lookup_class = select_field.get_lookup('isnull')\n+            lookup_class = select_field.get_lookup(\"isnull\")\n             lookup = lookup_class(select_field.get_col(alias), False)\n             query.where.add(lookup, AND)\n         if alias in can_reuse:\n@@ -1789,21 +1950,26 @@ class Query(BaseExpression):\n             # Need to add a restriction so that outer query's filters are in effect for\n             # the subquery, too.\n             query.bump_prefix(self)\n-            lookup_class = select_field.get_lookup('exact')\n+            lookup_class = select_field.get_lookup(\"exact\")\n             # Note that the query.select[0].alias is different from alias\n             # due to bump_prefix above.\n-            lookup = lookup_class(pk.get_col(query.select[0].alias),\n-                                  pk.get_col(alias))\n+            lookup = lookup_class(pk.get_col(query.select[0].alias), pk.get_col(alias))\n             query.where.add(lookup, AND)\n             query.external_aliases[alias] = True\n \n         condition, needed_inner = self.build_filter(\n-            ('%s__in' % trimmed_prefix, query),\n-            current_negated=True, branch_negated=True, can_reuse=can_reuse)\n+            (\"%s__in\" % trimmed_prefix, query),\n+            current_negated=True,\n+            branch_negated=True,\n+            can_reuse=can_reuse,\n+        )\n         if contains_louter:\n             or_null_condition, _ = self.build_filter(\n-                ('%s__isnull' % trimmed_prefix, True),\n-                current_negated=True, branch_negated=True, can_reuse=can_reuse)\n+                (\"%s__isnull\" % trimmed_prefix, True),\n+                current_negated=True,\n+                branch_negated=True,\n+                can_reuse=can_reuse,\n+            )\n             condition.add(or_null_condition, OR)\n             # Note that the end result will be:\n             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.\n@@ -1881,8 +2047,8 @@ class Query(BaseExpression):\n         self.values_select = ()\n \n     def add_select_col(self, col):\n-        self.select += col,\n-        self.values_select += col.output_field.name,\n+        self.select += (col,)\n+        self.values_select += (col.output_field.name,)\n \n     def set_select(self, cols):\n         self.default_cols = False\n@@ -1908,7 +2074,9 @@ class Query(BaseExpression):\n             for name in field_names:\n                 # Join promotion note - we must not remove any rows here, so\n                 # if there is no existing joins, use outer join.\n-                join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)\n+                join_info = self.setup_joins(\n+                    name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m\n+                )\n                 targets, final_alias, joins = self.trim_joins(\n                     join_info.targets,\n                     join_info.joins,\n@@ -1927,16 +2095,21 @@ class Query(BaseExpression):\n                 raise\n             elif name in self.annotations:\n                 raise FieldError(\n-                    \"Cannot select the '%s' alias. Use annotate() to promote \"\n-                    \"it.\" % name\n+                    \"Cannot select the '%s' alias. Use annotate() to promote it.\" % name\n                 )\n             else:\n-                names = sorted([\n-                    *get_field_names_from_opts(opts), *self.extra,\n-                    *self.annotation_select, *self._filtered_relations\n-                ])\n-                raise FieldError(\"Cannot resolve keyword %r into field. \"\n-                                 \"Choices are: %s\" % (name, \", \".join(names)))\n+                names = sorted(\n+                    [\n+                        *get_field_names_from_opts(opts),\n+                        *self.extra,\n+                        *self.annotation_select,\n+                        *self._filtered_relations,\n+                    ]\n+                )\n+                raise FieldError(\n+                    \"Cannot resolve keyword %r into field. \"\n+                    \"Choices are: %s\" % (name, \", \".join(names))\n+                )\n \n     def add_ordering(self, *ordering):\n         \"\"\"\n@@ -1950,18 +2123,18 @@ class Query(BaseExpression):\n         errors = []\n         for item in ordering:\n             if isinstance(item, str):\n-                if '.' in item:\n+                if \".\" in item:\n                     warnings.warn(\n-                        'Passing column raw column aliases to order_by() is '\n-                        'deprecated. Wrap %r in a RawSQL expression before '\n-                        'passing it to order_by().' % item,\n+                        \"Passing column raw column aliases to order_by() is \"\n+                        \"deprecated. Wrap %r in a RawSQL expression before \"\n+                        \"passing it to order_by().\" % item,\n                         category=RemovedInDjango40Warning,\n                         stacklevel=3,\n                     )\n                     continue\n-                if item == '?':\n+                if item == \"?\":\n                     continue\n-                if item.startswith('-'):\n+                if item.startswith(\"-\"):\n                     item = item[1:]\n                 if item in self.annotations:\n                     continue\n@@ -1970,15 +2143,15 @@ class Query(BaseExpression):\n                 # names_to_path() validates the lookup. A descriptive\n                 # FieldError will be raise if it's not.\n                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n-            elif not hasattr(item, 'resolve_expression'):\n+            elif not hasattr(item, \"resolve_expression\"):\n                 errors.append(item)\n-            if getattr(item, 'contains_aggregate', False):\n+            if getattr(item, \"contains_aggregate\", False):\n                 raise FieldError(\n-                    'Using an aggregate in order_by() without also including '\n-                    'it in annotate() is not allowed: %s' % item\n+                    \"Using an aggregate in order_by() without also including \"\n+                    \"it in annotate() is not allowed: %s\" % item\n                 )\n         if errors:\n-            raise FieldError('Invalid order_by arguments: %s' % errors)\n+            raise FieldError(\"Invalid order_by arguments: %s\" % errors)\n         if ordering:\n             self.order_by += ordering\n         else:\n@@ -2010,21 +2183,20 @@ class Query(BaseExpression):\n             for join in list(self.alias_map.values())[1:]:  # Skip base table.\n                 model = join.join_field.related_model\n                 if model not in seen_models:\n-                    column_names.update({\n-                        field.column\n-                        for field in model._meta.local_concrete_fields\n-                    })\n+                    column_names.update(\n+                        {field.column for field in model._meta.local_concrete_fields}\n+                    )\n                     seen_models.add(model)\n \n         group_by = list(self.select)\n         if self.annotation_select:\n             for alias, annotation in self.annotation_select.items():\n                 signature = inspect.signature(annotation.get_group_by_cols)\n-                if 'alias' not in signature.parameters:\n+                if \"alias\" not in signature.parameters:\n                     annotation_class = annotation.__class__\n                     msg = (\n-                        '`alias=None` must be added to the signature of '\n-                        '%s.%s.get_group_by_cols().'\n+                        \"`alias=None` must be added to the signature of \"\n+                        \"%s.%s.get_group_by_cols().\"\n                     ) % (annotation_class.__module__, annotation_class.__qualname__)\n                     warnings.warn(msg, category=RemovedInDjango40Warning)\n                     group_by_cols = annotation.get_group_by_cols()\n@@ -2071,7 +2243,7 @@ class Query(BaseExpression):\n                 entry_params = []\n                 pos = entry.find(\"%s\")\n                 while pos != -1:\n-                    if pos == 0 or entry[pos - 1] != '%':\n+                    if pos == 0 or entry[pos - 1] != \"%\":\n                         entry_params.append(next(param_iter))\n                     pos = entry.find(\"%s\", pos + 2)\n                 select_pairs[name] = (entry, entry_params)\n@@ -2119,8 +2291,8 @@ class Query(BaseExpression):\n         \"\"\"\n         existing, defer = self.deferred_loading\n         field_names = set(field_names)\n-        if 'pk' in field_names:\n-            field_names.remove('pk')\n+        if \"pk\" in field_names:\n+            field_names.remove(\"pk\")\n             field_names.add(self.get_meta().pk.name)\n \n         if defer:\n@@ -2206,7 +2378,9 @@ class Query(BaseExpression):\n         # Selected annotations must be known before setting the GROUP BY\n         # clause.\n         if self.group_by is True:\n-            self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)\n+            self.add_fields(\n+                (f.attname for f in self.model._meta.concrete_fields), False\n+            )\n             # Disable GROUP BY aliases to avoid orphaning references to the\n             # SELECT clause which is about to be cleared.\n             self.set_group_by(allow_aliases=False)\n@@ -2236,7 +2410,8 @@ class Query(BaseExpression):\n             return {}\n         elif self.annotation_select_mask is not None:\n             self._annotation_select_cache = {\n-                k: v for k, v in self.annotations.items()\n+                k: v\n+                for k, v in self.annotations.items()\n                 if k in self.annotation_select_mask\n             }\n             return self._annotation_select_cache\n@@ -2251,8 +2426,7 @@ class Query(BaseExpression):\n             return {}\n         elif self.extra_select_mask is not None:\n             self._extra_select_cache = {\n-                k: v for k, v in self.extra.items()\n-                if k in self.extra_select_mask\n+                k: v for k, v in self.extra.items() if k in self.extra_select_mask\n             }\n             return self._extra_select_cache\n         else:\n@@ -2279,8 +2453,7 @@ class Query(BaseExpression):\n         # the lookup part of the query. That is, avoid trimming\n         # joins generated for F() expressions.\n         lookup_tables = [\n-            t for t in self.alias_map\n-            if t in self._lookup_joins or t == self.base_table\n+            t for t in self.alias_map if t in self._lookup_joins or t == self.base_table\n         ]\n         for trimmed_paths, path in enumerate(all_paths):\n             if path.m2m:\n@@ -2299,8 +2472,7 @@ class Query(BaseExpression):\n                 break\n             trimmed_prefix.append(name)\n             paths_in_prefix -= len(path)\n-        trimmed_prefix.append(\n-            join_field.foreign_related_fields[0].name)\n+        trimmed_prefix.append(join_field.foreign_related_fields[0].name)\n         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)\n         # Lets still see if we can trim the first join from the inner query\n         # (that is, self). We can't do this for:\n@@ -2314,7 +2486,8 @@ class Query(BaseExpression):\n             select_alias = lookup_tables[trimmed_paths + 1]\n             self.unref_alias(lookup_tables[trimmed_paths])\n             extra_restriction = join_field.get_extra_restriction(\n-                self.where_class, None, lookup_tables[trimmed_paths + 1])\n+                self.where_class, None, lookup_tables[trimmed_paths + 1]\n+            )\n             if extra_restriction:\n                 self.where.add(extra_restriction, AND)\n         else:\n@@ -2327,7 +2500,9 @@ class Query(BaseExpression):\n         # But the first entry in the query's FROM clause must not be a JOIN.\n         for table in self.alias_map:\n             if self.alias_refcount[table] > 0:\n-                self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)\n+                self.alias_map[table] = BaseTable(\n+                    self.alias_map[table].table_name, table\n+                )\n                 break\n         self.set_select([f.get_col(select_alias) for f in select_fields])\n         return trimmed_prefix, contains_louter\n@@ -2346,12 +2521,12 @@ class Query(BaseExpression):\n         # is_nullable() is needed to the compiler stage, but that is not easy\n         # to do currently.\n         return (\n-            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and\n-            field.empty_strings_allowed\n+            connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n+            and field.empty_strings_allowed\n         ) or field.null\n \n \n-def get_order_dir(field, default='ASC'):\n+def get_order_dir(field, default=\"ASC\"):\n     \"\"\"\n     Return the field name and direction for an order specification. For\n     example, '-foo' is returned as ('foo', 'DESC').\n@@ -2360,7 +2535,7 @@ def get_order_dir(field, default='ASC'):\n     prefix) should sort. The '-' prefix always sorts the opposite way.\n     \"\"\"\n     dirn = ORDER_DIR[default]\n-    if field[0] == '-':\n+    if field[0] == \"-\":\n         return field[1:], dirn[1]\n     return field, dirn[0]\n \n@@ -2434,7 +2609,7 @@ class JoinPromoter:\n             # to rel_a would remove a valid match from the query. So, we need\n             # to promote any existing INNER to LOUTER (it is possible this\n             # promotion in turn will be demoted later on).\n-            if self.effective_connector == 'OR' and votes < self.num_children:\n+            if self.effective_connector == \"OR\" and votes < self.num_children:\n                 to_promote.add(table)\n             # If connector is AND and there is a filter that can match only\n             # when there is a joinable row, then use INNER. For example, in\n@@ -2446,8 +2621,9 @@ class JoinPromoter:\n             #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)\n             # then if rel_a doesn't produce any rows, the whole condition\n             # can't match. Hence we can safely use INNER join.\n-            if self.effective_connector == 'AND' or (\n-                    self.effective_connector == 'OR' and votes == self.num_children):\n+            if self.effective_connector == \"AND\" or (\n+                self.effective_connector == \"OR\" and votes == self.num_children\n+            ):\n                 to_demote.add(table)\n             # Finally, what happens in cases where we have:\n             #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0\n"}
{"instance_id": "django__django-13658", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..e411e86348 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,7 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(prog=self.prog_name, usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n"}
{"instance_id": "django__django-13660", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 2b306a579e..8ed9013481 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -15,28 +15,34 @@ class Command(BaseCommand):\n     )\n \n     requires_system_checks = []\n-    shells = ['ipython', 'bpython', 'python']\n+    shells = [\"ipython\", \"bpython\", \"python\"]\n \n     def add_arguments(self, parser):\n         parser.add_argument(\n-            '--no-startup', action='store_true',\n-            help='When using plain Python, ignore the PYTHONSTARTUP environment variable and ~/.pythonrc.py script.',\n+            \"--no-startup\",\n+            action=\"store_true\",\n+            help=\"When using plain Python, ignore the PYTHONSTARTUP environment variable and ~/.pythonrc.py script.\",\n         )\n         parser.add_argument(\n-            '-i', '--interface', choices=self.shells,\n+            \"-i\",\n+            \"--interface\",\n+            choices=self.shells,\n             help='Specify an interactive interpreter interface. Available options: \"ipython\", \"bpython\", and \"python\"',\n         )\n         parser.add_argument(\n-            '-c', '--command',\n-            help='Instead of opening an interactive shell, run a command as Django and exit.',\n+            \"-c\",\n+            \"--command\",\n+            help=\"Instead of opening an interactive shell, run a command as Django and exit.\",\n         )\n \n     def ipython(self, options):\n         from IPython import start_ipython\n+\n         start_ipython(argv=[])\n \n     def bpython(self, options):\n         import bpython\n+\n         bpython.embed()\n \n     def python(self, options):\n@@ -53,19 +59,22 @@ class Command(BaseCommand):\n             # We don't have to wrap the following import in a 'try', because\n             # we already know 'readline' was imported successfully.\n             import rlcompleter\n+\n             readline.set_completer(rlcompleter.Completer(imported_objects).complete)\n             # Enable tab completion on systems using libedit (e.g. macOS).\n             # These lines are copied from Python's Lib/site.py.\n-            readline_doc = getattr(readline, '__doc__', '')\n-            if readline_doc is not None and 'libedit' in readline_doc:\n+            readline_doc = getattr(readline, \"__doc__\", \"\")\n+            if readline_doc is not None and \"libedit\" in readline_doc:\n                 readline.parse_and_bind(\"bind ^I rl_complete\")\n             else:\n                 readline.parse_and_bind(\"tab:complete\")\n \n         # We want to honor both $PYTHONSTARTUP and .pythonrc.py, so follow system\n         # conventions and get $PYTHONSTARTUP first then .pythonrc.py.\n-        if not options['no_startup']:\n-            for pythonrc in OrderedSet([os.environ.get(\"PYTHONSTARTUP\"), os.path.expanduser('~/.pythonrc.py')]):\n+        if not options[\"no_startup\"]:\n+            for pythonrc in OrderedSet(\n+                [os.environ.get(\"PYTHONSTARTUP\"), os.path.expanduser(\"~/.pythonrc.py\")]\n+            ):\n                 if not pythonrc:\n                     continue\n                 if not os.path.isfile(pythonrc):\n@@ -75,7 +84,7 @@ class Command(BaseCommand):\n                 # Match the behavior of the cpython shell where an error in\n                 # PYTHONSTARTUP prints an exception and continues.\n                 try:\n-                    exec(compile(pythonrc_code, pythonrc, 'exec'), imported_objects)\n+                    exec(compile(pythonrc_code, pythonrc, \"exec\"), imported_objects)\n                 except Exception:\n                     traceback.print_exc()\n \n@@ -83,17 +92,23 @@ class Command(BaseCommand):\n \n     def handle(self, **options):\n         # Execute the command and exit.\n-        if options['command']:\n-            exec(options['command'])\n+        if options[\"command\"]:\n+            exec(options[\"command\"], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n-        if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+        if (\n+            sys.platform != \"win32\"\n+            and not sys.stdin.isatty()\n+            and select.select([sys.stdin], [], [], 0)[0]\n+        ):\n+            exec(sys.stdin.read(), {})\n             return\n \n-        available_shells = [options['interface']] if options['interface'] else self.shells\n+        available_shells = (\n+            [options[\"interface\"]] if options[\"interface\"] else self.shells\n+        )\n \n         for shell in available_shells:\n             try:\n"}
{"instance_id": "django__django-13710", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex dadd4acfa1..bcde2a83b4 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2040,7 +2040,7 @@ class InlineModelAdmin(BaseModelAdmin):\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            self.verbose_name_plural = format_lazy('{}s', self.verbose_name)\n \n     @property\n     def media(self):\n"}
{"instance_id": "django__django-13757", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex 29c6ff0926..4b441ef35d 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -10,32 +10,36 @@ from django.utils.translation import gettext_lazy as _\n from . import Field\n from .mixins import CheckFieldDefaultMixin\n \n-__all__ = ['JSONField']\n+__all__ = [\"JSONField\"]\n \n \n class JSONField(CheckFieldDefaultMixin, Field):\n     empty_strings_allowed = False\n-    description = _('A JSON object')\n+    description = _(\"A JSON object\")\n     default_error_messages = {\n-        'invalid': _('Value must be valid JSON.'),\n+        \"invalid\": _(\"Value must be valid JSON.\"),\n     }\n-    _default_hint = ('dict', '{}')\n+    _default_hint = (\"dict\", \"{}\")\n \n     def __init__(\n-        self, verbose_name=None, name=None, encoder=None, decoder=None,\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        encoder=None,\n+        decoder=None,\n         **kwargs,\n     ):\n         if encoder and not callable(encoder):\n-            raise ValueError('The encoder parameter must be a callable object.')\n+            raise ValueError(\"The encoder parameter must be a callable object.\")\n         if decoder and not callable(decoder):\n-            raise ValueError('The decoder parameter must be a callable object.')\n+            raise ValueError(\"The decoder parameter must be a callable object.\")\n         self.encoder = encoder\n         self.decoder = decoder\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n         errors = super().check(**kwargs)\n-        databases = kwargs.get('databases') or []\n+        databases = kwargs.get(\"databases\") or []\n         errors.extend(self._check_supported(databases))\n         return errors\n \n@@ -46,20 +50,19 @@ class JSONField(CheckFieldDefaultMixin, Field):\n                 continue\n             connection = connections[db]\n             if (\n-                self.model._meta.required_db_vendor and\n-                self.model._meta.required_db_vendor != connection.vendor\n+                self.model._meta.required_db_vendor\n+                and self.model._meta.required_db_vendor != connection.vendor\n             ):\n                 continue\n             if not (\n-                'supports_json_field' in self.model._meta.required_db_features or\n-                connection.features.supports_json_field\n+                \"supports_json_field\" in self.model._meta.required_db_features\n+                or connection.features.supports_json_field\n             ):\n                 errors.append(\n                     checks.Error(\n-                        '%s does not support JSONFields.'\n-                        % connection.display_name,\n+                        \"%s does not support JSONFields.\" % connection.display_name,\n                         obj=self.model,\n-                        id='fields.E180',\n+                        id=\"fields.E180\",\n                     )\n                 )\n         return errors\n@@ -67,9 +70,9 @@ class JSONField(CheckFieldDefaultMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.encoder is not None:\n-            kwargs['encoder'] = self.encoder\n+            kwargs[\"encoder\"] = self.encoder\n         if self.decoder is not None:\n-            kwargs['decoder'] = self.decoder\n+            kwargs[\"decoder\"] = self.decoder\n         return name, path, args, kwargs\n \n     def from_db_value(self, value, expression, connection):\n@@ -85,7 +88,7 @@ class JSONField(CheckFieldDefaultMixin, Field):\n             return value\n \n     def get_internal_type(self):\n-        return 'JSONField'\n+        return \"JSONField\"\n \n     def get_prep_value(self, value):\n         if value is None:\n@@ -104,64 +107,66 @@ class JSONField(CheckFieldDefaultMixin, Field):\n             json.dumps(value, cls=self.encoder)\n         except TypeError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def value_to_string(self, obj):\n         return self.value_from_object(obj)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.JSONField,\n-            'encoder': self.encoder,\n-            'decoder': self.decoder,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.JSONField,\n+                \"encoder\": self.encoder,\n+                \"decoder\": self.decoder,\n+                **kwargs,\n+            }\n+        )\n \n \n def compile_json_path(key_transforms, include_root=True):\n-    path = ['$'] if include_root else []\n+    path = [\"$\"] if include_root else []\n     for key_transform in key_transforms:\n         try:\n             num = int(key_transform)\n         except ValueError:  # non-integer\n-            path.append('.')\n+            path.append(\".\")\n             path.append(json.dumps(key_transform))\n         else:\n-            path.append('[%s]' % num)\n-    return ''.join(path)\n+            path.append(\"[%s]\" % num)\n+    return \"\".join(path)\n \n \n class DataContains(PostgresOperatorLookup):\n-    lookup_name = 'contains'\n-    postgres_operator = '@>'\n+    lookup_name = \"contains\"\n+    postgres_operator = \"@>\"\n \n     def as_sql(self, compiler, connection):\n         if not connection.features.supports_json_field_contains:\n             raise NotSupportedError(\n-                'contains lookup is not supported on this database backend.'\n+                \"contains lookup is not supported on this database backend.\"\n             )\n         lhs, lhs_params = self.process_lhs(compiler, connection)\n         rhs, rhs_params = self.process_rhs(compiler, connection)\n         params = tuple(lhs_params) + tuple(rhs_params)\n-        return 'JSON_CONTAINS(%s, %s)' % (lhs, rhs), params\n+        return \"JSON_CONTAINS(%s, %s)\" % (lhs, rhs), params\n \n \n class ContainedBy(PostgresOperatorLookup):\n-    lookup_name = 'contained_by'\n-    postgres_operator = '<@'\n+    lookup_name = \"contained_by\"\n+    postgres_operator = \"<@\"\n \n     def as_sql(self, compiler, connection):\n         if not connection.features.supports_json_field_contains:\n             raise NotSupportedError(\n-                'contained_by lookup is not supported on this database backend.'\n+                \"contained_by lookup is not supported on this database backend.\"\n             )\n         lhs, lhs_params = self.process_lhs(compiler, connection)\n         rhs, rhs_params = self.process_rhs(compiler, connection)\n         params = tuple(rhs_params) + tuple(lhs_params)\n-        return 'JSON_CONTAINS(%s, %s)' % (rhs, lhs), params\n+        return \"JSON_CONTAINS(%s, %s)\" % (rhs, lhs), params\n \n \n class HasKeyLookup(PostgresOperatorLookup):\n@@ -170,11 +175,13 @@ class HasKeyLookup(PostgresOperatorLookup):\n     def as_sql(self, compiler, connection, template=None):\n         # Process JSON path from the left-hand side.\n         if isinstance(self.lhs, KeyTransform):\n-            lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+            lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(\n+                compiler, connection\n+            )\n             lhs_json_path = compile_json_path(lhs_key_transforms)\n         else:\n             lhs, lhs_params = self.process_lhs(compiler, connection)\n-            lhs_json_path = '$'\n+            lhs_json_path = \"$\"\n         sql = template % lhs\n         # Process JSON path from the right-hand side.\n         rhs = self.rhs\n@@ -186,20 +193,27 @@ class HasKeyLookup(PostgresOperatorLookup):\n                 *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)\n             else:\n                 rhs_key_transforms = [key]\n-            rhs_params.append('%s%s' % (\n-                lhs_json_path,\n-                compile_json_path(rhs_key_transforms, include_root=False),\n-            ))\n+            rhs_params.append(\n+                \"%s%s\"\n+                % (\n+                    lhs_json_path,\n+                    compile_json_path(rhs_key_transforms, include_root=False),\n+                )\n+            )\n         # Add condition for each key.\n         if self.logical_operator:\n-            sql = '(%s)' % self.logical_operator.join([sql] * len(rhs_params))\n+            sql = \"(%s)\" % self.logical_operator.join([sql] * len(rhs_params))\n         return sql, tuple(lhs_params) + tuple(rhs_params)\n \n     def as_mysql(self, compiler, connection):\n-        return self.as_sql(compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\")\n+        return self.as_sql(\n+            compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\"\n+        )\n \n     def as_oracle(self, compiler, connection):\n-        sql, params = self.as_sql(compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\")\n+        sql, params = self.as_sql(\n+            compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\"\n+        )\n         # Add paths directly into SQL because path expressions cannot be passed\n         # as bind variables on Oracle.\n         return sql % tuple(params), []\n@@ -213,28 +227,30 @@ class HasKeyLookup(PostgresOperatorLookup):\n         return super().as_postgresql(compiler, connection)\n \n     def as_sqlite(self, compiler, connection):\n-        return self.as_sql(compiler, connection, template='JSON_TYPE(%s, %%s) IS NOT NULL')\n+        return self.as_sql(\n+            compiler, connection, template=\"JSON_TYPE(%s, %%s) IS NOT NULL\"\n+        )\n \n \n class HasKey(HasKeyLookup):\n-    lookup_name = 'has_key'\n-    postgres_operator = '?'\n+    lookup_name = \"has_key\"\n+    postgres_operator = \"?\"\n     prepare_rhs = False\n \n \n class HasKeys(HasKeyLookup):\n-    lookup_name = 'has_keys'\n-    postgres_operator = '?&'\n-    logical_operator = ' AND '\n+    lookup_name = \"has_keys\"\n+    postgres_operator = \"?&\"\n+    logical_operator = \" AND \"\n \n     def get_prep_lookup(self):\n         return [str(item) for item in self.rhs]\n \n \n class HasAnyKeys(HasKeys):\n-    lookup_name = 'has_any_keys'\n-    postgres_operator = '?|'\n-    logical_operator = ' OR '\n+    lookup_name = \"has_any_keys\"\n+    postgres_operator = \"?|\"\n+    logical_operator = \" OR \"\n \n \n class JSONExact(lookups.Exact):\n@@ -242,9 +258,9 @@ class JSONExact(lookups.Exact):\n \n     def process_lhs(self, compiler, connection):\n         lhs, lhs_params = super().process_lhs(compiler, connection)\n-        if connection.vendor == 'sqlite':\n+        if connection.vendor == \"sqlite\":\n             rhs, rhs_params = super().process_rhs(compiler, connection)\n-            if rhs == '%s' and rhs_params == [None]:\n+            if rhs == \"%s\" and rhs_params == [None]:\n                 # Use JSON_TYPE instead of JSON_EXTRACT for NULLs.\n                 lhs = \"JSON_TYPE(%s, '$')\" % lhs\n         return lhs, lhs_params\n@@ -252,9 +268,9 @@ class JSONExact(lookups.Exact):\n     def process_rhs(self, compiler, connection):\n         rhs, rhs_params = super().process_rhs(compiler, connection)\n         # Treat None lookup values as null.\n-        if rhs == '%s' and rhs_params == [None]:\n-            rhs_params = ['null']\n-        if connection.vendor == 'mysql':\n+        if rhs == \"%s\" and rhs_params == [None]:\n+            rhs_params = [\"null\"]\n+        if connection.vendor == \"mysql\":\n             func = [\"JSON_EXTRACT(%s, '$')\"] * len(rhs_params)\n             rhs = rhs % tuple(func)\n         return rhs, rhs_params\n@@ -269,8 +285,8 @@ JSONField.register_lookup(JSONExact)\n \n \n class KeyTransform(Transform):\n-    postgres_operator = '->'\n-    postgres_nested_operator = '#>'\n+    postgres_operator = \"->\"\n+    postgres_nested_operator = \"#>\"\n \n     def __init__(self, key_name, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n@@ -283,44 +299,44 @@ class KeyTransform(Transform):\n             key_transforms.insert(0, previous.key_name)\n             previous = previous.lhs\n         lhs, params = compiler.compile(previous)\n-        if connection.vendor == 'oracle':\n+        if connection.vendor == \"oracle\":\n             # Escape string-formatting.\n-            key_transforms = [key.replace('%', '%%') for key in key_transforms]\n+            key_transforms = [key.replace(\"%\", \"%%\") for key in key_transforms]\n         return lhs, params, key_transforms\n \n     def as_mysql(self, compiler, connection):\n         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n         json_path = compile_json_path(key_transforms)\n-        return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n+        return \"JSON_EXTRACT(%s, %%s)\" % lhs, tuple(params) + (json_path,)\n \n     def as_oracle(self, compiler, connection):\n         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n         json_path = compile_json_path(key_transforms)\n         return (\n-            \"COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))\" %\n-            ((lhs, json_path) * 2)\n+            \"COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))\"\n+            % ((lhs, json_path) * 2)\n         ), tuple(params) * 2\n \n     def as_postgresql(self, compiler, connection):\n         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n         if len(key_transforms) > 1:\n-            sql = '(%s %s %%s)' % (lhs, self.postgres_nested_operator)\n+            sql = \"(%s %s %%s)\" % (lhs, self.postgres_nested_operator)\n             return sql, tuple(params) + (key_transforms,)\n         try:\n             lookup = int(self.key_name)\n         except ValueError:\n             lookup = self.key_name\n-        return '(%s %s %%s)' % (lhs, self.postgres_operator), tuple(params) + (lookup,)\n+        return \"(%s %s %%s)\" % (lhs, self.postgres_operator), tuple(params) + (lookup,)\n \n     def as_sqlite(self, compiler, connection):\n         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n         json_path = compile_json_path(key_transforms)\n-        return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n+        return \"JSON_EXTRACT(%s, %%s)\" % lhs, tuple(params) + (json_path,)\n \n \n class KeyTextTransform(KeyTransform):\n-    postgres_operator = '->>'\n-    postgres_nested_operator = '#>>'\n+    postgres_operator = \"->>\"\n+    postgres_nested_operator = \"#>>\"\n \n \n class KeyTransformTextLookupMixin:\n@@ -330,14 +346,16 @@ class KeyTransformTextLookupMixin:\n     key values to text and performing the lookup on the resulting\n     representation.\n     \"\"\"\n+\n     def __init__(self, key_transform, *args, **kwargs):\n         if not isinstance(key_transform, KeyTransform):\n             raise TypeError(\n-                'Transform should be an instance of KeyTransform in order to '\n-                'use this lookup.'\n+                \"Transform should be an instance of KeyTransform in order to \"\n+                \"use this lookup.\"\n             )\n         key_text_transform = KeyTextTransform(\n-            key_transform.key_name, *key_transform.source_expressions,\n+            key_transform.key_name,\n+            *key_transform.source_expressions,\n             **key_transform.extra,\n         )\n         super().__init__(key_text_transform, *args, **kwargs)\n@@ -350,16 +368,17 @@ class CaseInsensitiveMixin:\n     Because utf8mb4_bin is a binary collation, comparison of JSON values is\n     case-sensitive.\n     \"\"\"\n+\n     def process_lhs(self, compiler, connection):\n         lhs, lhs_params = super().process_lhs(compiler, connection)\n-        if connection.vendor == 'mysql':\n-            return 'LOWER(%s)' % lhs, lhs_params\n+        if connection.vendor == \"mysql\":\n+            return \"LOWER(%s)\" % lhs, lhs_params\n         return lhs, lhs_params\n \n     def process_rhs(self, compiler, connection):\n         rhs, rhs_params = super().process_rhs(compiler, connection)\n-        if connection.vendor == 'mysql':\n-            return 'LOWER(%s)' % rhs, rhs_params\n+        if connection.vendor == \"mysql\":\n+            return \"LOWER(%s)\" % rhs, rhs_params\n         return rhs, rhs_params\n \n \n@@ -367,87 +386,105 @@ class KeyTransformIsNull(lookups.IsNull):\n     # key__isnull=False is the same as has_key='key'\n     def as_oracle(self, compiler, connection):\n         if not self.rhs:\n-            return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)\n-        return super().as_sql(compiler, connection)\n+            return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(\n+                compiler, connection\n+            )\n+        lhs, params, key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+        json_path = compile_json_path(key_transforms)\n+        return \"JSON_EXISTS(%s, '%s') = 0\" % (lhs, json_path), params\n \n     def as_sqlite(self, compiler, connection):\n         if not self.rhs:\n-            return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(compiler, connection)\n-        return super().as_sql(compiler, connection)\n+            return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(\n+                compiler, connection\n+            )\n+        lhs, params, key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+        json_path = compile_json_path(key_transforms)\n+        return \"JSON_TYPE(%s, '%s') IS NULL\" % (lhs, json_path), params\n \n \n class KeyTransformIn(lookups.In):\n     def resolve_expression_parameter(self, compiler, connection, sql, param):\n         sql, params = super().resolve_expression_parameter(\n-            compiler, connection, sql, param,\n+            compiler,\n+            connection,\n+            sql,\n+            param,\n         )\n         if (\n-            not hasattr(param, 'as_sql') and\n-            not connection.features.has_native_json_field\n+            not hasattr(param, \"as_sql\")\n+            and not connection.features.has_native_json_field\n         ):\n-            if connection.vendor == 'oracle':\n+            if connection.vendor == \"oracle\":\n                 value = json.loads(param)\n                 sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"\n                 if isinstance(value, (list, dict)):\n-                    sql = sql % 'JSON_QUERY'\n+                    sql = sql % \"JSON_QUERY\"\n                 else:\n-                    sql = sql % 'JSON_VALUE'\n-            elif connection.vendor in {'sqlite', 'mysql'}:\n+                    sql = sql % \"JSON_VALUE\"\n+            elif connection.vendor in {\"sqlite\", \"mysql\"}:\n                 sql = \"JSON_EXTRACT(%s, '$')\"\n-        if connection.vendor == 'mysql' and connection.mysql_is_mariadb:\n-            sql = 'JSON_UNQUOTE(%s)' % sql\n+        if connection.vendor == \"mysql\" and connection.mysql_is_mariadb:\n+            sql = \"JSON_UNQUOTE(%s)\" % sql\n         return sql, params\n \n \n class KeyTransformExact(JSONExact):\n     def process_lhs(self, compiler, connection):\n         lhs, lhs_params = super().process_lhs(compiler, connection)\n-        if connection.vendor == 'sqlite':\n+        if connection.vendor == \"sqlite\":\n             rhs, rhs_params = super().process_rhs(compiler, connection)\n-            if rhs == '%s' and rhs_params == ['null']:\n+            if rhs == \"%s\" and rhs_params == [\"null\"]:\n                 lhs, *_ = self.lhs.preprocess_lhs(compiler, connection)\n-                lhs = 'JSON_TYPE(%s, %%s)' % lhs\n+                lhs = \"JSON_TYPE(%s, %%s)\" % lhs\n         return lhs, lhs_params\n \n     def process_rhs(self, compiler, connection):\n         if isinstance(self.rhs, KeyTransform):\n             return super(lookups.Exact, self).process_rhs(compiler, connection)\n         rhs, rhs_params = super().process_rhs(compiler, connection)\n-        if connection.vendor == 'oracle':\n+        if connection.vendor == \"oracle\":\n             func = []\n             sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"\n             for value in rhs_params:\n                 value = json.loads(value)\n                 if isinstance(value, (list, dict)):\n-                    func.append(sql % 'JSON_QUERY')\n+                    func.append(sql % \"JSON_QUERY\")\n                 else:\n-                    func.append(sql % 'JSON_VALUE')\n+                    func.append(sql % \"JSON_VALUE\")\n             rhs = rhs % tuple(func)\n-        elif connection.vendor == 'sqlite':\n-            func = [\"JSON_EXTRACT(%s, '$')\" if value != 'null' else '%s' for value in rhs_params]\n+        elif connection.vendor == \"sqlite\":\n+            func = [\n+                \"JSON_EXTRACT(%s, '$')\" if value != \"null\" else \"%s\"\n+                for value in rhs_params\n+            ]\n             rhs = rhs % tuple(func)\n         return rhs, rhs_params\n \n     def as_oracle(self, compiler, connection):\n         rhs, rhs_params = super().process_rhs(compiler, connection)\n-        if rhs_params == ['null']:\n+        if rhs_params == [\"null\"]:\n             # Field has key and it's NULL.\n             has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)\n             has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)\n-            is_null_expr = self.lhs.get_lookup('isnull')(self.lhs, True)\n+            is_null_expr = self.lhs.get_lookup(\"isnull\")(self.lhs, True)\n             is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)\n             return (\n-                '%s AND %s' % (has_key_sql, is_null_sql),\n+                \"%s AND %s\" % (has_key_sql, is_null_sql),\n                 tuple(has_key_params) + tuple(is_null_params),\n             )\n         return super().as_sql(compiler, connection)\n \n \n-class KeyTransformIExact(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact):\n+class KeyTransformIExact(\n+    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact\n+):\n     pass\n \n \n-class KeyTransformIContains(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains):\n+class KeyTransformIContains(\n+    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains\n+):\n     pass\n \n \n@@ -455,7 +492,9 @@ class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):\n     pass\n \n \n-class KeyTransformIStartsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith):\n+class KeyTransformIStartsWith(\n+    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith\n+):\n     pass\n \n \n@@ -463,7 +502,9 @@ class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):\n     pass\n \n \n-class KeyTransformIEndsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith):\n+class KeyTransformIEndsWith(\n+    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith\n+):\n     pass\n \n \n@@ -471,7 +512,9 @@ class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):\n     pass\n \n \n-class KeyTransformIRegex(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex):\n+class KeyTransformIRegex(\n+    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex\n+):\n     pass\n \n \n@@ -518,7 +561,6 @@ KeyTransform.register_lookup(KeyTransformGte)\n \n \n class KeyTransformFactory:\n-\n     def __init__(self, key_name):\n         self.key_name = key_name\n \n"}
{"instance_id": "django__django-13768", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/dispatch/dispatcher.py b/django/dispatch/dispatcher.py\nindex b7d9d26389..1051aafc77 100644\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,3 +1,4 @@\n+import logging\n import threading\n import warnings\n import weakref\n@@ -6,8 +7,11 @@ from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.inspect import func_accepts_kwargs\n \n \n+logger = logging.getLogger(\"django.dispatch\")\n+\n+\n def _make_id(target):\n-    if hasattr(target, '__func__'):\n+    if hasattr(target, \"__func__\"):\n         return (id(target.__self__), id(target.__func__))\n     return id(target)\n \n@@ -27,6 +31,7 @@ class Signal:\n         receivers\n             { receiverkey (id) : weakref(receiver) }\n     \"\"\"\n+\n     def __init__(self, providing_args=None, use_caching=False):\n         \"\"\"\n         Create a new signal.\n@@ -34,11 +39,12 @@ class Signal:\n         self.receivers = []\n         if providing_args is not None:\n             warnings.warn(\n-                'The providing_args argument is deprecated. As it is purely '\n-                'documentational, it has no replacement. If you rely on this '\n-                'argument as documentation, you can move the text to a code '\n-                'comment or docstring.',\n-                RemovedInDjango40Warning, stacklevel=2,\n+                \"The providing_args argument is deprecated. As it is purely \"\n+                \"documentational, it has no replacement. If you rely on this \"\n+                \"argument as documentation, you can move the text to a code \"\n+                \"comment or docstring.\",\n+                RemovedInDjango40Warning,\n+                stacklevel=2,\n             )\n         self.lock = threading.Lock()\n         self.use_caching = use_caching\n@@ -91,7 +97,9 @@ class Signal:\n \n             # Check for **kwargs\n             if not func_accepts_kwargs(receiver):\n-                raise ValueError(\"Signal receivers must accept keyword arguments (**kwargs).\")\n+                raise ValueError(\n+                    \"Signal receivers must accept keyword arguments (**kwargs).\"\n+                )\n \n         if dispatch_uid:\n             lookup_key = (dispatch_uid, _make_id(sender))\n@@ -102,7 +110,7 @@ class Signal:\n             ref = weakref.ref\n             receiver_object = receiver\n             # Check for bound methods\n-            if hasattr(receiver, '__self__') and hasattr(receiver, '__func__'):\n+            if hasattr(receiver, \"__self__\") and hasattr(receiver, \"__func__\"):\n                 ref = weakref.WeakMethod\n                 receiver_object = receiver.__self__\n             receiver = ref(receiver)\n@@ -171,7 +179,10 @@ class Signal:\n \n         Return a list of tuple pairs [(receiver, response), ... ].\n         \"\"\"\n-        if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n+        if (\n+            not self.receivers\n+            or self.sender_receivers_cache.get(sender) is NO_RECEIVERS\n+        ):\n             return []\n \n         return [\n@@ -198,7 +209,10 @@ class Signal:\n         If any receiver raises an error (specifically any subclass of\n         Exception), return the error instance as the result for that receiver.\n         \"\"\"\n-        if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n+        if (\n+            not self.receivers\n+            or self.sender_receivers_cache.get(sender) is NO_RECEIVERS\n+        ):\n             return []\n \n         # Call each receiver with whatever arguments it can accept.\n@@ -208,6 +222,12 @@ class Signal:\n             try:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n+                logger.exception(\n+                    \"Exception calling %s in signal %s raised %s.\",\n+                    receiver,\n+                    self,\n+                    err,\n+                )\n                 responses.append((receiver, err))\n             else:\n                 responses.append((receiver, response))\n@@ -218,8 +238,9 @@ class Signal:\n         if self._dead_receivers:\n             self._dead_receivers = False\n             self.receivers = [\n-                r for r in self.receivers\n-                if not(isinstance(r[1], weakref.ReferenceType) and r[1]() is None)\n+                r\n+                for r in self.receivers\n+                if not (isinstance(r[1], weakref.ReferenceType) and r[1]() is None)\n             ]\n \n     def _live_receivers(self, sender):\n@@ -284,6 +305,7 @@ def receiver(signal, **kwargs):\n         def signals_receiver(sender, **kwargs):\n             ...\n     \"\"\"\n+\n     def _decorator(func):\n         if isinstance(signal, (list, tuple)):\n             for s in signal:\n@@ -291,4 +313,5 @@ def receiver(signal, **kwargs):\n         else:\n             signal.connect(func, **kwargs)\n         return func\n+\n     return _decorator\n"}
{"instance_id": "django__django-13925", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 4038859cfa..bee1772782 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -9,28 +9,48 @@ from django.apps import apps\n from django.conf import settings\n from django.core import checks\n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldDoesNotExist, FieldError, MultipleObjectsReturned,\n-    ObjectDoesNotExist, ValidationError,\n+    NON_FIELD_ERRORS,\n+    FieldDoesNotExist,\n+    FieldError,\n+    MultipleObjectsReturned,\n+    ObjectDoesNotExist,\n+    ValidationError,\n )\n from django.db import (\n-    DEFAULT_DB_ALIAS, DJANGO_VERSION_PICKLE_KEY, DatabaseError, connection,\n-    connections, router, transaction,\n+    DEFAULT_DB_ALIAS,\n+    DJANGO_VERSION_PICKLE_KEY,\n+    DatabaseError,\n+    connection,\n+    connections,\n+    router,\n+    transaction,\n )\n from django.db.models import (\n-    NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value,\n+    NOT_PROVIDED,\n+    ExpressionWrapper,\n+    IntegerField,\n+    Max,\n+    Value,\n )\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.constraints import CheckConstraint, UniqueConstraint\n from django.db.models.deletion import CASCADE, Collector\n from django.db.models.fields.related import (\n-    ForeignObjectRel, OneToOneField, lazy_related_operation, resolve_relation,\n+    ForeignObjectRel,\n+    OneToOneField,\n+    lazy_related_operation,\n+    resolve_relation,\n )\n from django.db.models.functions import Coalesce\n from django.db.models.manager import Manager\n from django.db.models.options import Options\n from django.db.models.query import F, Q\n from django.db.models.signals import (\n-    class_prepared, post_init, post_save, pre_init, pre_save,\n+    class_prepared,\n+    post_init,\n+    post_save,\n+    pre_init,\n+    pre_save,\n )\n from django.db.models.utils import make_model_tuple\n from django.utils.encoding import force_str\n@@ -41,10 +61,10 @@ from django.utils.translation import gettext_lazy as _\n \n class Deferred:\n     def __repr__(self):\n-        return '<Deferred field>'\n+        return \"<Deferred field>\"\n \n     def __str__(self):\n-        return '<Deferred field>'\n+        return \"<Deferred field>\"\n \n \n DEFERRED = Deferred()\n@@ -58,19 +78,24 @@ def subclass_exception(name, bases, module, attached_to):\n     that the returned exception class will be added as an attribute to the\n     'attached_to' class.\n     \"\"\"\n-    return type(name, bases, {\n-        '__module__': module,\n-        '__qualname__': '%s.%s' % (attached_to.__qualname__, name),\n-    })\n+    return type(\n+        name,\n+        bases,\n+        {\n+            \"__module__\": module,\n+            \"__qualname__\": \"%s.%s\" % (attached_to.__qualname__, name),\n+        },\n+    )\n \n \n def _has_contribute_to_class(value):\n     # Only call contribute_to_class() if it's bound.\n-    return not inspect.isclass(value) and hasattr(value, 'contribute_to_class')\n+    return not inspect.isclass(value) and hasattr(value, \"contribute_to_class\")\n \n \n class ModelBase(type):\n     \"\"\"Metaclass for all models.\"\"\"\n+\n     def __new__(cls, name, bases, attrs, **kwargs):\n         super_new = super().__new__\n \n@@ -81,12 +106,12 @@ class ModelBase(type):\n             return super_new(cls, name, bases, attrs)\n \n         # Create the class.\n-        module = attrs.pop('__module__')\n-        new_attrs = {'__module__': module}\n-        classcell = attrs.pop('__classcell__', None)\n+        module = attrs.pop(\"__module__\")\n+        new_attrs = {\"__module__\": module}\n+        classcell = attrs.pop(\"__classcell__\", None)\n         if classcell is not None:\n-            new_attrs['__classcell__'] = classcell\n-        attr_meta = attrs.pop('Meta', None)\n+            new_attrs[\"__classcell__\"] = classcell\n+        attr_meta = attrs.pop(\"Meta\", None)\n         # Pass all attrs without a (Django-specific) contribute_to_class()\n         # method to type.__new__() so that they're properly initialized\n         # (i.e. __set_name__()).\n@@ -98,16 +123,16 @@ class ModelBase(type):\n                 new_attrs[obj_name] = obj\n         new_class = super_new(cls, name, bases, new_attrs, **kwargs)\n \n-        abstract = getattr(attr_meta, 'abstract', False)\n-        meta = attr_meta or getattr(new_class, 'Meta', None)\n-        base_meta = getattr(new_class, '_meta', None)\n+        abstract = getattr(attr_meta, \"abstract\", False)\n+        meta = attr_meta or getattr(new_class, \"Meta\", None)\n+        base_meta = getattr(new_class, \"_meta\", None)\n \n         app_label = None\n \n         # Look for an application configuration to attach the model to.\n         app_config = apps.get_containing_app_config(module)\n \n-        if getattr(meta, 'app_label', None) is None:\n+        if getattr(meta, \"app_label\", None) is None:\n             if app_config is None:\n                 if not abstract:\n                     raise RuntimeError(\n@@ -119,33 +144,43 @@ class ModelBase(type):\n             else:\n                 app_label = app_config.label\n \n-        new_class.add_to_class('_meta', Options(meta, app_label))\n+        new_class.add_to_class(\"_meta\", Options(meta, app_label))\n         if not abstract:\n             new_class.add_to_class(\n-                'DoesNotExist',\n+                \"DoesNotExist\",\n                 subclass_exception(\n-                    'DoesNotExist',\n+                    \"DoesNotExist\",\n                     tuple(\n-                        x.DoesNotExist for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n-                    ) or (ObjectDoesNotExist,),\n+                        x.DoesNotExist\n+                        for x in parents\n+                        if hasattr(x, \"_meta\") and not x._meta.abstract\n+                    )\n+                    or (ObjectDoesNotExist,),\n                     module,\n-                    attached_to=new_class))\n+                    attached_to=new_class,\n+                ),\n+            )\n             new_class.add_to_class(\n-                'MultipleObjectsReturned',\n+                \"MultipleObjectsReturned\",\n                 subclass_exception(\n-                    'MultipleObjectsReturned',\n+                    \"MultipleObjectsReturned\",\n                     tuple(\n-                        x.MultipleObjectsReturned for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n-                    ) or (MultipleObjectsReturned,),\n+                        x.MultipleObjectsReturned\n+                        for x in parents\n+                        if hasattr(x, \"_meta\") and not x._meta.abstract\n+                    )\n+                    or (MultipleObjectsReturned,),\n                     module,\n-                    attached_to=new_class))\n+                    attached_to=new_class,\n+                ),\n+            )\n             if base_meta and not base_meta.abstract:\n                 # Non-abstract child classes inherit some attributes from their\n                 # non-abstract parent (unless an ABC comes before it in the\n                 # method resolution order).\n-                if not hasattr(meta, 'ordering'):\n+                if not hasattr(meta, \"ordering\"):\n                     new_class._meta.ordering = base_meta.ordering\n-                if not hasattr(meta, 'get_latest_by'):\n+                if not hasattr(meta, \"get_latest_by\"):\n                     new_class._meta.get_latest_by = base_meta.get_latest_by\n \n         is_proxy = new_class._meta.proxy\n@@ -153,7 +188,9 @@ class ModelBase(type):\n         # If the model is a proxy, ensure that the base class\n         # hasn't been swapped out.\n         if is_proxy and base_meta and base_meta.swapped:\n-            raise TypeError(\"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped))\n+            raise TypeError(\n+                \"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped)\n+            )\n \n         # Add remaining attributes (those with a contribute_to_class() method)\n         # to the class.\n@@ -164,14 +201,14 @@ class ModelBase(type):\n         new_fields = chain(\n             new_class._meta.local_fields,\n             new_class._meta.local_many_to_many,\n-            new_class._meta.private_fields\n+            new_class._meta.private_fields,\n         )\n         field_names = {f.name for f in new_fields}\n \n         # Basic setup for proxy models.\n         if is_proxy:\n             base = None\n-            for parent in [kls for kls in parents if hasattr(kls, '_meta')]:\n+            for parent in [kls for kls in parents if hasattr(kls, \"_meta\")]:\n                 if parent._meta.abstract:\n                     if parent._meta.fields:\n                         raise TypeError(\n@@ -183,9 +220,14 @@ class ModelBase(type):\n                 if base is None:\n                     base = parent\n                 elif parent._meta.concrete_model is not base._meta.concrete_model:\n-                    raise TypeError(\"Proxy model '%s' has more than one non-abstract model base class.\" % name)\n+                    raise TypeError(\n+                        \"Proxy model '%s' has more than one non-abstract model base class.\"\n+                        % name\n+                    )\n             if base is None:\n-                raise TypeError(\"Proxy model '%s' has no non-abstract model base class.\" % name)\n+                raise TypeError(\n+                    \"Proxy model '%s' has no non-abstract model base class.\" % name\n+                )\n             new_class._meta.setup_proxy(base)\n             new_class._meta.concrete_model = base._meta.concrete_model\n         else:\n@@ -195,7 +237,7 @@ class ModelBase(type):\n         parent_links = {}\n         for base in reversed([new_class] + parents):\n             # Conceptually equivalent to `if base is Model`.\n-            if not hasattr(base, '_meta'):\n+            if not hasattr(base, \"_meta\"):\n                 continue\n             # Skip concrete parent classes.\n             if base != new_class and not base._meta.abstract:\n@@ -210,7 +252,7 @@ class ModelBase(type):\n         inherited_attributes = set()\n         # Do the appropriate setup for any model parents.\n         for base in new_class.mro():\n-            if base not in parents or not hasattr(base, '_meta'):\n+            if base not in parents or not hasattr(base, \"_meta\"):\n                 # Things without _meta aren't functional models, so they're\n                 # uninteresting parents.\n                 inherited_attributes.update(base.__dict__)\n@@ -223,8 +265,9 @@ class ModelBase(type):\n                 for field in parent_fields:\n                     if field.name in field_names:\n                         raise FieldError(\n-                            'Local field %r in class %r clashes with field of '\n-                            'the same name from base class %r.' % (\n+                            \"Local field %r in class %r clashes with field of \"\n+                            \"the same name from base class %r.\"\n+                            % (\n                                 field.name,\n                                 name,\n                                 base.__name__,\n@@ -239,7 +282,7 @@ class ModelBase(type):\n                 if base_key in parent_links:\n                     field = parent_links[base_key]\n                 elif not is_proxy:\n-                    attr_name = '%s_ptr' % base._meta.model_name\n+                    attr_name = \"%s_ptr\" % base._meta.model_name\n                     field = OneToOneField(\n                         base,\n                         on_delete=CASCADE,\n@@ -252,7 +295,8 @@ class ModelBase(type):\n                         raise FieldError(\n                             \"Auto-generated field '%s' in class %r for \"\n                             \"parent_link to base class %r clashes with \"\n-                            \"declared field of the same name.\" % (\n+                            \"declared field of the same name.\"\n+                            % (\n                                 attr_name,\n                                 name,\n                                 base.__name__,\n@@ -271,9 +315,11 @@ class ModelBase(type):\n \n                 # Add fields from abstract base class if it wasn't overridden.\n                 for field in parent_fields:\n-                    if (field.name not in field_names and\n-                            field.name not in new_class.__dict__ and\n-                            field.name not in inherited_attributes):\n+                    if (\n+                        field.name not in field_names\n+                        and field.name not in new_class.__dict__\n+                        and field.name not in inherited_attributes\n+                    ):\n                         new_field = copy.deepcopy(field)\n                         new_class.add_to_class(field.name, new_field)\n                         # Replace parent links defined on this base by the new\n@@ -292,8 +338,9 @@ class ModelBase(type):\n                 if field.name in field_names:\n                     if not base._meta.abstract:\n                         raise FieldError(\n-                            'Local field %r in class %r clashes with field of '\n-                            'the same name from base class %r.' % (\n+                            \"Local field %r in class %r clashes with field of \"\n+                            \"the same name from base class %r.\"\n+                            % (\n                                 field.name,\n                                 name,\n                                 base.__name__,\n@@ -307,7 +354,9 @@ class ModelBase(type):\n \n         # Copy indexes so that index names are unique when models extend an\n         # abstract model.\n-        new_class._meta.indexes = [copy.deepcopy(idx) for idx in new_class._meta.indexes]\n+        new_class._meta.indexes = [\n+            copy.deepcopy(idx) for idx in new_class._meta.indexes\n+        ]\n \n         if abstract:\n             # Abstract base models can't be instantiated and don't appear in\n@@ -333,8 +382,12 @@ class ModelBase(type):\n         opts._prepare(cls)\n \n         if opts.order_with_respect_to:\n-            cls.get_next_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=True)\n-            cls.get_previous_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=False)\n+            cls.get_next_in_order = partialmethod(\n+                cls._get_next_or_previous_in_order, is_next=True\n+            )\n+            cls.get_previous_in_order = partialmethod(\n+                cls._get_next_or_previous_in_order, is_next=False\n+            )\n \n             # Defer creating accessors on the foreign class until it has been\n             # created and registered. If remote_field is None, we're ordering\n@@ -348,21 +401,26 @@ class ModelBase(type):\n \n         # Give the class a docstring -- its definition.\n         if cls.__doc__ is None:\n-            cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n+            cls.__doc__ = \"%s(%s)\" % (\n+                cls.__name__,\n+                \", \".join(f.name for f in opts.fields),\n+            )\n \n-        get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(opts.label_lower)\n+        get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(\n+            opts.label_lower\n+        )\n         if get_absolute_url_override:\n-            setattr(cls, 'get_absolute_url', get_absolute_url_override)\n+            setattr(cls, \"get_absolute_url\", get_absolute_url_override)\n \n         if not opts.managers:\n-            if any(f.name == 'objects' for f in opts.fields):\n+            if any(f.name == \"objects\" for f in opts.fields):\n                 raise ValueError(\n                     \"Model %s must specify a custom Manager, because it has a \"\n                     \"field named 'objects'.\" % cls.__name__\n                 )\n             manager = Manager()\n             manager.auto_created = True\n-            cls.add_to_class('objects', manager)\n+            cls.add_to_class(\"objects\", manager)\n \n         # Set the name of _meta.indexes. This can't be done in\n         # Options.contribute_to_class() because fields haven't been added to\n@@ -392,6 +450,7 @@ class ModelStateFieldsCacheDescriptor:\n \n class ModelState:\n     \"\"\"Store model instance state.\"\"\"\n+\n     db = None\n     # If true, uniqueness validation checks will consider this a new, unsaved\n     # object. Necessary for correct validation of new instances of objects with\n@@ -402,7 +461,6 @@ class ModelState:\n \n \n class Model(metaclass=ModelBase):\n-\n     def __init__(self, *args, **kwargs):\n         # Alias some things as locals to avoid repeat global lookups\n         cls = self.__class__\n@@ -410,7 +468,7 @@ class Model(metaclass=ModelBase):\n         _setattr = setattr\n         _DEFERRED = DEFERRED\n         if opts.abstract:\n-            raise TypeError('Abstract models cannot be instantiated.')\n+            raise TypeError(\"Abstract models cannot be instantiated.\")\n \n         pre_init.send(sender=cls, args=args, kwargs=kwargs)\n \n@@ -500,7 +558,10 @@ class Model(metaclass=ModelBase):\n                 except (AttributeError, FieldDoesNotExist):\n                     pass\n             for kwarg in kwargs:\n-                raise TypeError(\"%s() got an unexpected keyword argument '%s'\" % (cls.__name__, kwarg))\n+                raise TypeError(\n+                    \"%s() got an unexpected keyword argument '%s'\"\n+                    % (cls.__name__, kwarg)\n+                )\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n \n@@ -518,10 +579,10 @@ class Model(metaclass=ModelBase):\n         return new\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def __str__(self):\n-        return '%s object (%s)' % (self.__class__.__name__, self.pk)\n+        return \"%s object (%s)\" % (self.__class__.__name__, self.pk)\n \n     def __eq__(self, other):\n         if not isinstance(other, Model):\n@@ -547,8 +608,8 @@ class Model(metaclass=ModelBase):\n     def __getstate__(self):\n         \"\"\"Hook to allow choosing the attributes to pickle.\"\"\"\n         state = self.__dict__.copy()\n-        state['_state'] = copy.copy(state['_state'])\n-        state['_state'].fields_cache = state['_state'].fields_cache.copy()\n+        state[\"_state\"] = copy.copy(state[\"_state\"])\n+        state[\"_state\"].fields_cache = state[\"_state\"].fields_cache.copy()\n         return state\n \n     def __setstate__(self, state):\n@@ -587,7 +648,8 @@ class Model(metaclass=ModelBase):\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n         return {\n-            f.attname for f in self._meta.concrete_fields\n+            f.attname\n+            for f in self._meta.concrete_fields\n             if f.attname not in self.__dict__\n         }\n \n@@ -609,7 +671,7 @@ class Model(metaclass=ModelBase):\n         if fields is None:\n             self._prefetched_objects_cache = {}\n         else:\n-            prefetched_objects_cache = getattr(self, '_prefetched_objects_cache', ())\n+            prefetched_objects_cache = getattr(self, \"_prefetched_objects_cache\", ())\n             for field in fields:\n                 if field in prefetched_objects_cache:\n                     del prefetched_objects_cache[field]\n@@ -619,10 +681,13 @@ class Model(metaclass=ModelBase):\n             if any(LOOKUP_SEP in f for f in fields):\n                 raise ValueError(\n                     'Found \"%s\" in fields argument. Relations and transforms '\n-                    'are not allowed in fields.' % LOOKUP_SEP)\n+                    \"are not allowed in fields.\" % LOOKUP_SEP\n+                )\n \n-        hints = {'instance': self}\n-        db_instance_qs = self.__class__._base_manager.db_manager(using, hints=hints).filter(pk=self.pk)\n+        hints = {\"instance\": self}\n+        db_instance_qs = self.__class__._base_manager.db_manager(\n+            using, hints=hints\n+        ).filter(pk=self.pk)\n \n         # Use provided fields, if not set then reload all non-deferred fields.\n         deferred_fields = self.get_deferred_fields()\n@@ -630,8 +695,11 @@ class Model(metaclass=ModelBase):\n             fields = list(fields)\n             db_instance_qs = db_instance_qs.only(*fields)\n         elif deferred_fields:\n-            fields = [f.attname for f in self._meta.concrete_fields\n-                      if f.attname not in deferred_fields]\n+            fields = [\n+                f.attname\n+                for f in self._meta.concrete_fields\n+                if f.attname not in deferred_fields\n+            ]\n             db_instance_qs = db_instance_qs.only(*fields)\n \n         db_instance = db_instance_qs.get()\n@@ -669,8 +737,9 @@ class Model(metaclass=ModelBase):\n             return getattr(self, field_name)\n         return getattr(self, field.attname)\n \n-    def save(self, force_insert=False, force_update=False, using=None,\n-             update_fields=None):\n+    def save(\n+        self, force_insert=False, force_update=False, using=None, update_fields=None\n+    ):\n         \"\"\"\n         Save the current instance. Override this in a subclass if you want to\n         control the saving process.\n@@ -679,7 +748,7 @@ class Model(metaclass=ModelBase):\n         that the \"save\" must be an SQL insert or update (or equivalent for\n         non-SQL backends), respectively. Normally, they should not be set.\n         \"\"\"\n-        self._prepare_related_fields_for_save(operation_name='save')\n+        self._prepare_related_fields_for_save(operation_name=\"save\")\n \n         using = using or router.db_for_write(self.__class__, instance=self)\n         if force_insert and (force_update or update_fields):\n@@ -707,9 +776,9 @@ class Model(metaclass=ModelBase):\n \n             if non_model_fields:\n                 raise ValueError(\n-                    'The following fields do not exist in this model, are m2m '\n-                    'fields, or are non-concrete fields: %s'\n-                    % ', '.join(non_model_fields)\n+                    \"The following fields do not exist in this model, are m2m \"\n+                    \"fields, or are non-concrete fields: %s\"\n+                    % \", \".join(non_model_fields)\n                 )\n \n         # If saving to the same database, and this model is deferred, then\n@@ -717,18 +786,29 @@ class Model(metaclass=ModelBase):\n         elif not force_insert and deferred_fields and using == self._state.db:\n             field_names = set()\n             for field in self._meta.concrete_fields:\n-                if not field.primary_key and not hasattr(field, 'through'):\n+                if not field.primary_key and not hasattr(field, \"through\"):\n                     field_names.add(field.attname)\n             loaded_fields = field_names.difference(deferred_fields)\n             if loaded_fields:\n                 update_fields = frozenset(loaded_fields)\n \n-        self.save_base(using=using, force_insert=force_insert,\n-                       force_update=force_update, update_fields=update_fields)\n+        self.save_base(\n+            using=using,\n+            force_insert=force_insert,\n+            force_update=force_update,\n+            update_fields=update_fields,\n+        )\n+\n     save.alters_data = True\n \n-    def save_base(self, raw=False, force_insert=False,\n-                  force_update=False, using=None, update_fields=None):\n+    def save_base(\n+        self,\n+        raw=False,\n+        force_insert=False,\n+        force_update=False,\n+        using=None,\n+        update_fields=None,\n+    ):\n         \"\"\"\n         Handle the parts of saving which should be done only once per save,\n         yet need to be done in raw saves, too. This includes some sanity\n@@ -748,7 +828,10 @@ class Model(metaclass=ModelBase):\n         meta = cls._meta\n         if not meta.auto_created:\n             pre_save.send(\n-                sender=origin, instance=self, raw=raw, using=using,\n+                sender=origin,\n+                instance=self,\n+                raw=raw,\n+                using=using,\n                 update_fields=update_fields,\n             )\n         # A transaction isn't needed if one query is issued.\n@@ -761,8 +844,12 @@ class Model(metaclass=ModelBase):\n             if not raw:\n                 parent_inserted = self._save_parents(cls, using, update_fields)\n             updated = self._save_table(\n-                raw, cls, force_insert or parent_inserted,\n-                force_update, using, update_fields,\n+                raw,\n+                cls,\n+                force_insert or parent_inserted,\n+                force_update,\n+                using,\n+                update_fields,\n             )\n         # Store the database on which the object was saved\n         self._state.db = using\n@@ -772,8 +859,12 @@ class Model(metaclass=ModelBase):\n         # Signal that the save is complete\n         if not meta.auto_created:\n             post_save.send(\n-                sender=origin, instance=self, created=(not updated),\n-                update_fields=update_fields, raw=raw, using=using,\n+                sender=origin,\n+                instance=self,\n+                created=(not updated),\n+                update_fields=update_fields,\n+                raw=raw,\n+                using=using,\n             )\n \n     save_base.alters_data = True\n@@ -784,12 +875,19 @@ class Model(metaclass=ModelBase):\n         inserted = False\n         for parent, field in meta.parents.items():\n             # Make sure the link fields are synced between parent and self.\n-            if (field and getattr(self, parent._meta.pk.attname) is None and\n-                    getattr(self, field.attname) is not None):\n+            if (\n+                field\n+                and getattr(self, parent._meta.pk.attname) is None\n+                and getattr(self, field.attname) is not None\n+            ):\n                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n-            parent_inserted = self._save_parents(cls=parent, using=using, update_fields=update_fields)\n+            parent_inserted = self._save_parents(\n+                cls=parent, using=using, update_fields=update_fields\n+            )\n             updated = self._save_table(\n-                cls=parent, using=using, update_fields=update_fields,\n+                cls=parent,\n+                using=using,\n+                update_fields=update_fields,\n                 force_insert=parent_inserted,\n             )\n             if not updated:\n@@ -806,8 +904,15 @@ class Model(metaclass=ModelBase):\n                     field.delete_cached_value(self)\n         return inserted\n \n-    def _save_table(self, raw=False, cls=None, force_insert=False,\n-                    force_update=False, using=None, update_fields=None):\n+    def _save_table(\n+        self,\n+        raw=False,\n+        cls=None,\n+        force_insert=False,\n+        force_update=False,\n+        using=None,\n+        update_fields=None,\n+    ):\n         \"\"\"\n         Do the heavy-lifting involved in saving. Update or insert the data\n         for a single table.\n@@ -816,8 +921,11 @@ class Model(metaclass=ModelBase):\n         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]\n \n         if update_fields:\n-            non_pks = [f for f in non_pks\n-                       if f.name in update_fields or f.attname in update_fields]\n+            non_pks = [\n+                f\n+                for f in non_pks\n+                if f.name in update_fields or f.attname in update_fields\n+            ]\n \n         pk_val = self._get_pk_val(meta)\n         if pk_val is None:\n@@ -829,21 +937,28 @@ class Model(metaclass=ModelBase):\n         updated = False\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n-            not raw and\n-            not force_insert and\n-            self._state.adding and\n-            meta.pk.default and\n-            meta.pk.default is not NOT_PROVIDED\n+            not raw\n+            and not force_insert\n+            and self._state.adding\n+            and meta.pk.default\n+            and meta.pk.default is not NOT_PROVIDED\n         ):\n             force_insert = True\n         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n         if pk_set and not force_insert:\n             base_qs = cls._base_manager.using(using)\n-            values = [(f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False)))\n-                      for f in non_pks]\n+            values = [\n+                (\n+                    f,\n+                    None,\n+                    (getattr(self, f.attname) if raw else f.pre_save(self, False)),\n+                )\n+                for f in non_pks\n+            ]\n             forced_update = update_fields or force_update\n-            updated = self._do_update(base_qs, using, pk_val, values, update_fields,\n-                                      forced_update)\n+            updated = self._do_update(\n+                base_qs, using, pk_val, values, update_fields, forced_update\n+            )\n             if force_update and not updated:\n                 raise DatabaseError(\"Forced update did not affect any rows.\")\n             if update_fields and not updated:\n@@ -854,18 +969,26 @@ class Model(metaclass=ModelBase):\n                 # autopopulate the _order field\n                 field = meta.order_with_respect_to\n                 filter_args = field.get_filter_kwargs_for_object(self)\n-                self._order = cls._base_manager.using(using).filter(**filter_args).aggregate(\n-                    _order__max=Coalesce(\n-                        ExpressionWrapper(Max('_order') + Value(1), output_field=IntegerField()),\n-                        Value(0),\n-                    ),\n-                )['_order__max']\n+                self._order = (\n+                    cls._base_manager.using(using)\n+                    .filter(**filter_args)\n+                    .aggregate(\n+                        _order__max=Coalesce(\n+                            ExpressionWrapper(\n+                                Max(\"_order\") + Value(1), output_field=IntegerField()\n+                            ),\n+                            Value(0),\n+                        ),\n+                    )[\"_order__max\"]\n+                )\n             fields = meta.local_concrete_fields\n             if not pk_set:\n                 fields = [f for f in fields if f is not meta.auto_field]\n \n             returning_fields = meta.db_returning_fields\n-            results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)\n+            results = self._do_insert(\n+                cls._base_manager, using, fields, returning_fields, raw\n+            )\n             if results:\n                 for value, field in zip(results[0], returning_fields):\n                     setattr(self, field.attname, value)\n@@ -886,7 +1009,8 @@ class Model(metaclass=ModelBase):\n             return update_fields is not None or filtered.exists()\n         if self._meta.select_on_save and not forced_update:\n             return (\n-                filtered.exists() and\n+                filtered.exists()\n+                and\n                 # It may happen that the object is deleted from the DB right after\n                 # this check, causing the subsequent UPDATE to return zero matching\n                 # rows. The same result can occur in some rare cases when the\n@@ -904,8 +1028,11 @@ class Model(metaclass=ModelBase):\n         return the newly created data for the model.\n         \"\"\"\n         return manager._insert(\n-            [self], fields=fields, returning_fields=returning_fields,\n-            using=using, raw=raw,\n+            [self],\n+            fields=fields,\n+            returning_fields=returning_fields,\n+            using=using,\n+            raw=raw,\n         )\n \n     def _prepare_related_fields_for_save(self, operation_name):\n@@ -939,14 +1066,16 @@ class Model(metaclass=ModelBase):\n                     setattr(self, field.attname, obj.pk)\n                 # If the relationship's pk/to_field was changed, clear the\n                 # cached relationship.\n-                if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n+                if getattr(obj, field.target_field.attname) != getattr(\n+                    self, field.attname\n+                ):\n                     field.delete_cached_value(self)\n \n     def delete(self, using=None, keep_parents=False):\n         using = using or router.db_for_write(self.__class__, instance=self)\n         assert self.pk is not None, (\n-            \"%s object can't be deleted because its %s attribute is set to None.\" %\n-            (self._meta.object_name, self._meta.pk.attname)\n+            \"%s object can't be deleted because its %s attribute is set to None.\"\n+            % (self._meta.object_name, self._meta.pk.attname)\n         )\n \n         collector = Collector(using=using)\n@@ -959,42 +1088,58 @@ class Model(metaclass=ModelBase):\n         value = getattr(self, field.attname)\n         choices_dict = dict(make_hashable(field.flatchoices))\n         # force_str() to coerce lazy strings.\n-        return force_str(choices_dict.get(make_hashable(value), value), strings_only=True)\n+        return force_str(\n+            choices_dict.get(make_hashable(value), value), strings_only=True\n+        )\n \n     def _get_next_or_previous_by_FIELD(self, field, is_next, **kwargs):\n         if not self.pk:\n             raise ValueError(\"get_next/get_previous cannot be used on unsaved objects.\")\n-        op = 'gt' if is_next else 'lt'\n-        order = '' if is_next else '-'\n+        op = \"gt\" if is_next else \"lt\"\n+        order = \"\" if is_next else \"-\"\n         param = getattr(self, field.attname)\n-        q = Q(**{'%s__%s' % (field.name, op): param})\n-        q = q | Q(**{field.name: param, 'pk__%s' % op: self.pk})\n-        qs = self.__class__._default_manager.using(self._state.db).filter(**kwargs).filter(q).order_by(\n-            '%s%s' % (order, field.name), '%spk' % order\n+        q = Q(**{\"%s__%s\" % (field.name, op): param})\n+        q = q | Q(**{field.name: param, \"pk__%s\" % op: self.pk})\n+        qs = (\n+            self.__class__._default_manager.using(self._state.db)\n+            .filter(**kwargs)\n+            .filter(q)\n+            .order_by(\"%s%s\" % (order, field.name), \"%spk\" % order)\n         )\n         try:\n             return qs[0]\n         except IndexError:\n-            raise self.DoesNotExist(\"%s matching query does not exist.\" % self.__class__._meta.object_name)\n+            raise self.DoesNotExist(\n+                \"%s matching query does not exist.\" % self.__class__._meta.object_name\n+            )\n \n     def _get_next_or_previous_in_order(self, is_next):\n         cachename = \"__%s_order_cache\" % is_next\n         if not hasattr(self, cachename):\n-            op = 'gt' if is_next else 'lt'\n-            order = '_order' if is_next else '-_order'\n+            op = \"gt\" if is_next else \"lt\"\n+            order = \"_order\" if is_next else \"-_order\"\n             order_field = self._meta.order_with_respect_to\n             filter_args = order_field.get_filter_kwargs_for_object(self)\n-            obj = self.__class__._default_manager.filter(**filter_args).filter(**{\n-                '_order__%s' % op: self.__class__._default_manager.values('_order').filter(**{\n-                    self._meta.pk.name: self.pk\n-                })\n-            }).order_by(order)[:1].get()\n+            obj = (\n+                self.__class__._default_manager.filter(**filter_args)\n+                .filter(\n+                    **{\n+                        \"_order__%s\" % op: self.__class__._default_manager.values(\n+                            \"_order\"\n+                        ).filter(**{self._meta.pk.name: self.pk})\n+                    }\n+                )\n+                .order_by(order)[:1]\n+                .get()\n+            )\n             setattr(self, cachename, obj)\n         return getattr(self, cachename)\n \n     def prepare_database_save(self, field):\n         if self.pk is None:\n-            raise ValueError(\"Unsaved model instance %r cannot be used in an ORM query.\" % self)\n+            raise ValueError(\n+                \"Unsaved model instance %r cannot be used in an ORM query.\" % self\n+            )\n         return getattr(self, field.remote_field.get_related_field().attname)\n \n     def clean(self):\n@@ -1038,7 +1183,9 @@ class Model(metaclass=ModelBase):\n         constraints = [(self.__class__, self._meta.total_unique_constraints)]\n         for parent_class in self._meta.get_parent_list():\n             if parent_class._meta.unique_together:\n-                unique_togethers.append((parent_class, parent_class._meta.unique_together))\n+                unique_togethers.append(\n+                    (parent_class, parent_class._meta.unique_together)\n+                )\n             if parent_class._meta.total_unique_constraints:\n                 constraints.append(\n                     (parent_class, parent_class._meta.total_unique_constraints)\n@@ -1073,11 +1220,11 @@ class Model(metaclass=ModelBase):\n                 if f.unique:\n                     unique_checks.append((model_class, (name,)))\n                 if f.unique_for_date and f.unique_for_date not in exclude:\n-                    date_checks.append((model_class, 'date', name, f.unique_for_date))\n+                    date_checks.append((model_class, \"date\", name, f.unique_for_date))\n                 if f.unique_for_year and f.unique_for_year not in exclude:\n-                    date_checks.append((model_class, 'year', name, f.unique_for_year))\n+                    date_checks.append((model_class, \"year\", name, f.unique_for_year))\n                 if f.unique_for_month and f.unique_for_month not in exclude:\n-                    date_checks.append((model_class, 'month', name, f.unique_for_month))\n+                    date_checks.append((model_class, \"month\", name, f.unique_for_month))\n         return unique_checks, date_checks\n \n     def _perform_unique_checks(self, unique_checks):\n@@ -1092,8 +1239,10 @@ class Model(metaclass=ModelBase):\n                 f = self._meta.get_field(field_name)\n                 lookup_value = getattr(self, f.attname)\n                 # TODO: Handle multiple backends with different feature flags.\n-                if (lookup_value is None or\n-                        (lookup_value == '' and connection.features.interprets_empty_strings_as_nulls)):\n+                if lookup_value is None or (\n+                    lookup_value == \"\"\n+                    and connection.features.interprets_empty_strings_as_nulls\n+                ):\n                     # no value, skip the lookup\n                     continue\n                 if f.primary_key and not self._state.adding:\n@@ -1121,7 +1270,9 @@ class Model(metaclass=ModelBase):\n                     key = unique_check[0]\n                 else:\n                     key = NON_FIELD_ERRORS\n-                errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))\n+                errors.setdefault(key, []).append(\n+                    self.unique_error_message(model_class, unique_check)\n+                )\n \n         return errors\n \n@@ -1134,12 +1285,14 @@ class Model(metaclass=ModelBase):\n             date = getattr(self, unique_for)\n             if date is None:\n                 continue\n-            if lookup_type == 'date':\n-                lookup_kwargs['%s__day' % unique_for] = date.day\n-                lookup_kwargs['%s__month' % unique_for] = date.month\n-                lookup_kwargs['%s__year' % unique_for] = date.year\n+            if lookup_type == \"date\":\n+                lookup_kwargs[\"%s__day\" % unique_for] = date.day\n+                lookup_kwargs[\"%s__month\" % unique_for] = date.month\n+                lookup_kwargs[\"%s__year\" % unique_for] = date.year\n             else:\n-                lookup_kwargs['%s__%s' % (unique_for, lookup_type)] = getattr(date, lookup_type)\n+                lookup_kwargs[\"%s__%s\" % (unique_for, lookup_type)] = getattr(\n+                    date, lookup_type\n+                )\n             lookup_kwargs[field] = getattr(self, field)\n \n             qs = model_class._default_manager.filter(**lookup_kwargs)\n@@ -1158,46 +1311,48 @@ class Model(metaclass=ModelBase):\n         opts = self._meta\n         field = opts.get_field(field_name)\n         return ValidationError(\n-            message=field.error_messages['unique_for_date'],\n-            code='unique_for_date',\n+            message=field.error_messages[\"unique_for_date\"],\n+            code=\"unique_for_date\",\n             params={\n-                'model': self,\n-                'model_name': capfirst(opts.verbose_name),\n-                'lookup_type': lookup_type,\n-                'field': field_name,\n-                'field_label': capfirst(field.verbose_name),\n-                'date_field': unique_for,\n-                'date_field_label': capfirst(opts.get_field(unique_for).verbose_name),\n-            }\n+                \"model\": self,\n+                \"model_name\": capfirst(opts.verbose_name),\n+                \"lookup_type\": lookup_type,\n+                \"field\": field_name,\n+                \"field_label\": capfirst(field.verbose_name),\n+                \"date_field\": unique_for,\n+                \"date_field_label\": capfirst(opts.get_field(unique_for).verbose_name),\n+            },\n         )\n \n     def unique_error_message(self, model_class, unique_check):\n         opts = model_class._meta\n \n         params = {\n-            'model': self,\n-            'model_class': model_class,\n-            'model_name': capfirst(opts.verbose_name),\n-            'unique_check': unique_check,\n+            \"model\": self,\n+            \"model_class\": model_class,\n+            \"model_name\": capfirst(opts.verbose_name),\n+            \"unique_check\": unique_check,\n         }\n \n         # A unique field\n         if len(unique_check) == 1:\n             field = opts.get_field(unique_check[0])\n-            params['field_label'] = capfirst(field.verbose_name)\n+            params[\"field_label\"] = capfirst(field.verbose_name)\n             return ValidationError(\n-                message=field.error_messages['unique'],\n-                code='unique',\n+                message=field.error_messages[\"unique\"],\n+                code=\"unique\",\n                 params=params,\n             )\n \n         # unique_together\n         else:\n-            field_labels = [capfirst(opts.get_field(f).verbose_name) for f in unique_check]\n-            params['field_labels'] = get_text_list(field_labels, _('and'))\n+            field_labels = [\n+                capfirst(opts.get_field(f).verbose_name) for f in unique_check\n+            ]\n+            params[\"field_labels\"] = get_text_list(field_labels, _(\"and\"))\n             return ValidationError(\n                 message=_(\"%(model_name)s with this %(field_labels)s already exists.\"),\n-                code='unique_together',\n+                code=\"unique_together\",\n                 params=params,\n             )\n \n@@ -1264,9 +1419,13 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def check(cls, **kwargs):\n-        errors = [*cls._check_swappable(), *cls._check_model(), *cls._check_managers(**kwargs)]\n+        errors = [\n+            *cls._check_swappable(),\n+            *cls._check_model(),\n+            *cls._check_managers(**kwargs),\n+        ]\n         if not cls._meta.swapped:\n-            databases = kwargs.get('databases') or []\n+            databases = kwargs.get(\"databases\") or []\n             errors += [\n                 *cls._check_fields(**kwargs),\n                 *cls._check_m2m_through_same_relationship(),\n@@ -1298,9 +1457,10 @@ class Model(metaclass=ModelBase):\n     @classmethod\n     def _check_default_pk(cls):\n         if (\n-            cls._meta.pk.auto_created and\n-            not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n-            not cls._meta.app_config._is_default_auto_field_overridden\n+            cls._meta.pk.auto_created\n+            and not cls._meta.pk.remote_field\n+            and not settings.is_overridden(\"DEFAULT_AUTO_FIELD\")\n+            and not cls._meta.app_config._is_default_auto_field_overridden\n         ):\n             return [\n                 checks.Warning(\n@@ -1314,7 +1474,7 @@ class Model(metaclass=ModelBase):\n                         f\"of AutoField, e.g. 'django.db.models.BigAutoField'.\"\n                     ),\n                     obj=cls,\n-                    id='models.W042',\n+                    id=\"models.W042\",\n                 ),\n             ]\n         return []\n@@ -1329,19 +1489,19 @@ class Model(metaclass=ModelBase):\n             except ValueError:\n                 errors.append(\n                     checks.Error(\n-                        \"'%s' is not of the form 'app_label.app_name'.\" % cls._meta.swappable,\n-                        id='models.E001',\n+                        \"'%s' is not of the form 'app_label.app_name'.\"\n+                        % cls._meta.swappable,\n+                        id=\"models.E001\",\n                     )\n                 )\n             except LookupError:\n-                app_label, model_name = cls._meta.swapped.split('.')\n+                app_label, model_name = cls._meta.swapped.split(\".\")\n                 errors.append(\n                     checks.Error(\n                         \"'%s' references '%s.%s', which has not been \"\n-                        \"installed, or is abstract.\" % (\n-                            cls._meta.swappable, app_label, model_name\n-                        ),\n-                        id='models.E002',\n+                        \"installed, or is abstract.\"\n+                        % (cls._meta.swappable, app_label, model_name),\n+                        id=\"models.E002\",\n                     )\n                 )\n         return errors\n@@ -1354,7 +1514,7 @@ class Model(metaclass=ModelBase):\n                 errors.append(\n                     checks.Error(\n                         \"Proxy model '%s' contains model fields.\" % cls.__name__,\n-                        id='models.E017',\n+                        id=\"models.E017\",\n                     )\n                 )\n         return errors\n@@ -1379,8 +1539,7 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def _check_m2m_through_same_relationship(cls):\n-        \"\"\" Check if no relationship model is used by more than one m2m field.\n-        \"\"\"\n+        \"\"\"Check if no relationship model is used by more than one m2m field.\"\"\"\n \n         errors = []\n         seen_intermediary_signatures = []\n@@ -1394,15 +1553,20 @@ class Model(metaclass=ModelBase):\n         fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))\n \n         for f in fields:\n-            signature = (f.remote_field.model, cls, f.remote_field.through, f.remote_field.through_fields)\n+            signature = (\n+                f.remote_field.model,\n+                cls,\n+                f.remote_field.through,\n+                f.remote_field.through_fields,\n+            )\n             if signature in seen_intermediary_signatures:\n                 errors.append(\n                     checks.Error(\n                         \"The model has two identical many-to-many relations \"\n-                        \"through the intermediate model '%s'.\" %\n-                        f.remote_field.through._meta.label,\n+                        \"through the intermediate model '%s'.\"\n+                        % f.remote_field.through._meta.label,\n                         obj=cls,\n-                        id='models.E003',\n+                        id=\"models.E003\",\n                     )\n                 )\n             else:\n@@ -1412,15 +1576,17 @@ class Model(metaclass=ModelBase):\n     @classmethod\n     def _check_id_field(cls):\n         \"\"\"Check if `id` field is a primary key.\"\"\"\n-        fields = [f for f in cls._meta.local_fields if f.name == 'id' and f != cls._meta.pk]\n+        fields = [\n+            f for f in cls._meta.local_fields if f.name == \"id\" and f != cls._meta.pk\n+        ]\n         # fields is empty or consists of the invalid \"id\" field\n-        if fields and not fields[0].primary_key and cls._meta.pk.name == 'id':\n+        if fields and not fields[0].primary_key and cls._meta.pk.name == \"id\":\n             return [\n                 checks.Error(\n                     \"'id' can only be used as a field name if the field also \"\n                     \"sets 'primary_key=True'.\",\n                     obj=cls,\n-                    id='models.E004',\n+                    id=\"models.E004\",\n                 )\n             ]\n         else:\n@@ -1441,12 +1607,10 @@ class Model(metaclass=ModelBase):\n                         checks.Error(\n                             \"The field '%s' from parent model \"\n                             \"'%s' clashes with the field '%s' \"\n-                            \"from parent model '%s'.\" % (\n-                                clash.name, clash.model._meta,\n-                                f.name, f.model._meta\n-                            ),\n+                            \"from parent model '%s'.\"\n+                            % (clash.name, clash.model._meta, f.name, f.model._meta),\n                             obj=cls,\n-                            id='models.E005',\n+                            id=\"models.E005\",\n                         )\n                     )\n                 used_fields[f.name] = f\n@@ -1466,16 +1630,16 @@ class Model(metaclass=ModelBase):\n             # field \"id\" and automatically added unique field \"id\", both\n             # defined at the same model. This special case is considered in\n             # _check_id_field and here we ignore it.\n-            id_conflict = f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n+            id_conflict = (\n+                f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n+            )\n             if clash and not id_conflict:\n                 errors.append(\n                     checks.Error(\n                         \"The field '%s' clashes with the field '%s' \"\n-                        \"from model '%s'.\" % (\n-                            f.name, clash.name, clash.model._meta\n-                        ),\n+                        \"from model '%s'.\" % (f.name, clash.name, clash.model._meta),\n                         obj=f,\n-                        id='models.E006',\n+                        id=\"models.E006\",\n                     )\n                 )\n             used_fields[f.name] = f\n@@ -1500,7 +1664,7 @@ class Model(metaclass=ModelBase):\n                         \"another field.\" % (f.name, column_name),\n                         hint=\"Specify a 'db_column' for the field.\",\n                         obj=cls,\n-                        id='models.E007'\n+                        id=\"models.E007\",\n                     )\n                 )\n             else:\n@@ -1512,13 +1676,13 @@ class Model(metaclass=ModelBase):\n     def _check_model_name_db_lookup_clashes(cls):\n         errors = []\n         model_name = cls.__name__\n-        if model_name.startswith('_') or model_name.endswith('_'):\n+        if model_name.startswith(\"_\") or model_name.endswith(\"_\"):\n             errors.append(\n                 checks.Error(\n                     \"The model name '%s' cannot start or end with an underscore \"\n                     \"as it collides with the query lookup syntax.\" % model_name,\n                     obj=cls,\n-                    id='models.E023'\n+                    id=\"models.E023\",\n                 )\n             )\n         elif LOOKUP_SEP in model_name:\n@@ -1527,7 +1691,7 @@ class Model(metaclass=ModelBase):\n                     \"The model name '%s' cannot contain double underscores as \"\n                     \"it collides with the query lookup syntax.\" % model_name,\n                     obj=cls,\n-                    id='models.E024'\n+                    id=\"models.E024\",\n                 )\n             )\n         return errors\n@@ -1537,7 +1701,8 @@ class Model(metaclass=ModelBase):\n         errors = []\n         property_names = cls._meta._property_names\n         related_field_accessors = (\n-            f.get_attname() for f in cls._meta._get_fields(reverse=False)\n+            f.get_attname()\n+            for f in cls._meta._get_fields(reverse=False)\n             if f.is_relation and f.related_model is not None\n         )\n         for accessor in related_field_accessors:\n@@ -1547,7 +1712,7 @@ class Model(metaclass=ModelBase):\n                         \"The property '%s' clashes with a related field \"\n                         \"accessor.\" % accessor,\n                         obj=cls,\n-                        id='models.E025',\n+                        id=\"models.E025\",\n                     )\n                 )\n         return errors\n@@ -1561,7 +1726,7 @@ class Model(metaclass=ModelBase):\n                     \"The model cannot have more than one field with \"\n                     \"'primary_key=True'.\",\n                     obj=cls,\n-                    id='models.E026',\n+                    id=\"models.E026\",\n                 )\n             )\n         return errors\n@@ -1574,16 +1739,18 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'index_together' must be a list or tuple.\",\n                     obj=cls,\n-                    id='models.E008',\n+                    id=\"models.E008\",\n                 )\n             ]\n \n-        elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together):\n+        elif any(\n+            not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together\n+        ):\n             return [\n                 checks.Error(\n                     \"All 'index_together' elements must be lists or tuples.\",\n                     obj=cls,\n-                    id='models.E009',\n+                    id=\"models.E009\",\n                 )\n             ]\n \n@@ -1601,16 +1768,19 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'unique_together' must be a list or tuple.\",\n                     obj=cls,\n-                    id='models.E010',\n+                    id=\"models.E010\",\n                 )\n             ]\n \n-        elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.unique_together):\n+        elif any(\n+            not isinstance(fields, (tuple, list))\n+            for fields in cls._meta.unique_together\n+        ):\n             return [\n                 checks.Error(\n                     \"All 'unique_together' elements must be lists or tuples.\",\n                     obj=cls,\n-                    id='models.E011',\n+                    id=\"models.E011\",\n                 )\n             ]\n \n@@ -1628,13 +1798,13 @@ class Model(metaclass=ModelBase):\n         for index in cls._meta.indexes:\n             # Index name can't start with an underscore or a number, restricted\n             # for cross-database compatibility with Oracle.\n-            if index.name[0] == '_' or index.name[0].isdigit():\n+            if index.name[0] == \"_\" or index.name[0].isdigit():\n                 errors.append(\n                     checks.Error(\n                         \"The index name '%s' cannot start with an underscore \"\n                         \"or a number.\" % index.name,\n                         obj=cls,\n-                        id='models.E033',\n+                        id=\"models.E033\",\n                     ),\n                 )\n             if len(index.name) > index.max_name_length:\n@@ -1643,7 +1813,7 @@ class Model(metaclass=ModelBase):\n                         \"The index name '%s' cannot be longer than %d \"\n                         \"characters.\" % (index.name, index.max_name_length),\n                         obj=cls,\n-                        id='models.E034',\n+                        id=\"models.E034\",\n                     ),\n                 )\n             if index.contains_expressions:\n@@ -1656,57 +1826,59 @@ class Model(metaclass=ModelBase):\n                 continue\n             connection = connections[db]\n             if not (\n-                connection.features.supports_partial_indexes or\n-                'supports_partial_indexes' in cls._meta.required_db_features\n+                connection.features.supports_partial_indexes\n+                or \"supports_partial_indexes\" in cls._meta.required_db_features\n             ) and any(index.condition is not None for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes with conditions.'\n+                        \"%s does not support indexes with conditions.\"\n                         % connection.display_name,\n                         hint=(\n                             \"Conditions will be ignored. Silence this warning \"\n                             \"if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W037',\n+                        id=\"models.W037\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_covering_indexes or\n-                'supports_covering_indexes' in cls._meta.required_db_features\n+                connection.features.supports_covering_indexes\n+                or \"supports_covering_indexes\" in cls._meta.required_db_features\n             ) and any(index.include for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes with non-key columns.'\n+                        \"%s does not support indexes with non-key columns.\"\n                         % connection.display_name,\n                         hint=(\n                             \"Non-key columns will be ignored. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W040',\n+                        id=\"models.W040\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_expression_indexes or\n-                'supports_expression_indexes' in cls._meta.required_db_features\n+                connection.features.supports_expression_indexes\n+                or \"supports_expression_indexes\" in cls._meta.required_db_features\n             ) and any(index.contains_expressions for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes on expressions.'\n+                        \"%s does not support indexes on expressions.\"\n                         % connection.display_name,\n                         hint=(\n                             \"An index won't be created. Silence this warning \"\n                             \"if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W043',\n+                        id=\"models.W043\",\n                     )\n                 )\n-        fields = [field for index in cls._meta.indexes for field, _ in index.fields_orders]\n+        fields = [\n+            field for index in cls._meta.indexes for field, _ in index.fields_orders\n+        ]\n         fields += [include for index in cls._meta.indexes for include in index.include]\n         fields += references\n-        errors.extend(cls._check_local_fields(fields, 'indexes'))\n+        errors.extend(cls._check_local_fields(fields, \"indexes\"))\n         return errors\n \n     @classmethod\n@@ -1718,7 +1890,7 @@ class Model(metaclass=ModelBase):\n         forward_fields_map = {}\n         for field in cls._meta._get_fields(reverse=False):\n             forward_fields_map[field.name] = field\n-            if hasattr(field, 'attname'):\n+            if hasattr(field, \"attname\"):\n                 forward_fields_map[field.attname] = field\n \n         errors = []\n@@ -1728,11 +1900,13 @@ class Model(metaclass=ModelBase):\n             except KeyError:\n                 errors.append(\n                     checks.Error(\n-                        \"'%s' refers to the nonexistent field '%s'.\" % (\n-                            option, field_name,\n+                        \"'%s' refers to the nonexistent field '%s'.\"\n+                        % (\n+                            option,\n+                            field_name,\n                         ),\n                         obj=cls,\n-                        id='models.E012',\n+                        id=\"models.E012\",\n                     )\n                 )\n             else:\n@@ -1740,11 +1914,14 @@ class Model(metaclass=ModelBase):\n                     errors.append(\n                         checks.Error(\n                             \"'%s' refers to a ManyToManyField '%s', but \"\n-                            \"ManyToManyFields are not permitted in '%s'.\" % (\n-                                option, field_name, option,\n+                            \"ManyToManyFields are not permitted in '%s'.\"\n+                            % (\n+                                option,\n+                                field_name,\n+                                option,\n                             ),\n                             obj=cls,\n-                            id='models.E013',\n+                            id=\"models.E013\",\n                         )\n                     )\n                 elif field not in cls._meta.local_fields:\n@@ -1754,7 +1931,7 @@ class Model(metaclass=ModelBase):\n                             % (option, field_name, cls._meta.object_name),\n                             hint=\"This issue may be caused by multi-table inheritance.\",\n                             obj=cls,\n-                            id='models.E016',\n+                            id=\"models.E016\",\n                         )\n                     )\n         return errors\n@@ -1770,7 +1947,7 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n                     obj=cls,\n-                    id='models.E021',\n+                    id=\"models.E021\",\n                 ),\n             ]\n \n@@ -1782,7 +1959,7 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'ordering' must be a tuple or list (even if you want to order by only one field).\",\n                     obj=cls,\n-                    id='models.E014',\n+                    id=\"models.E014\",\n                 )\n             ]\n \n@@ -1790,10 +1967,10 @@ class Model(metaclass=ModelBase):\n         fields = cls._meta.ordering\n \n         # Skip expressions and '?' fields.\n-        fields = (f for f in fields if isinstance(f, str) and f != '?')\n+        fields = (f for f in fields if isinstance(f, str) and f != \"?\")\n \n         # Convert \"-field\" to \"field\".\n-        fields = ((f[1:] if f.startswith('-') else f) for f in fields)\n+        fields = ((f[1:] if f.startswith(\"-\") else f) for f in fields)\n \n         # Separate related fields and non-related fields.\n         _fields = []\n@@ -1812,7 +1989,7 @@ class Model(metaclass=ModelBase):\n             for part in field.split(LOOKUP_SEP):\n                 try:\n                     # pk is an alias that won't be found by opts.get_field.\n-                    if part == 'pk':\n+                    if part == \"pk\":\n                         fld = _cls._meta.pk\n                     else:\n                         fld = _cls._meta.get_field(part)\n@@ -1829,13 +2006,13 @@ class Model(metaclass=ModelBase):\n                                 \"'ordering' refers to the nonexistent field, \"\n                                 \"related field, or lookup '%s'.\" % field,\n                                 obj=cls,\n-                                id='models.E015',\n+                                id=\"models.E015\",\n                             )\n                         )\n \n         # Skip ordering on pk. This is always a valid order_by field\n         # but is an alias and therefore won't be found by opts.get_field.\n-        fields = {f for f in fields if f != 'pk'}\n+        fields = {f for f in fields if f != \"pk\"}\n \n         # Check for invalid or nonexistent fields in ordering.\n         invalid_fields = []\n@@ -1843,10 +2020,14 @@ class Model(metaclass=ModelBase):\n         # Any field name that is not present in field_names does not exist.\n         # Also, ordering by m2m fields is not allowed.\n         opts = cls._meta\n-        valid_fields = set(chain.from_iterable(\n-            (f.name, f.attname) if not (f.auto_created and not f.concrete) else (f.field.related_query_name(),)\n-            for f in chain(opts.fields, opts.related_objects)\n-        ))\n+        valid_fields = set(\n+            chain.from_iterable(\n+                (f.name, f.attname)\n+                if not (f.auto_created and not f.concrete)\n+                else (f.field.related_query_name(),)\n+                for f in chain(opts.fields, opts.related_objects)\n+            )\n+        )\n \n         invalid_fields.extend(fields - valid_fields)\n \n@@ -1856,7 +2037,7 @@ class Model(metaclass=ModelBase):\n                     \"'ordering' refers to the nonexistent field, related \"\n                     \"field, or lookup '%s'.\" % invalid_field,\n                     obj=cls,\n-                    id='models.E015',\n+                    id=\"models.E015\",\n                 )\n             )\n         return errors\n@@ -1898,7 +2079,11 @@ class Model(metaclass=ModelBase):\n \n             # Check if auto-generated name for the field is too long\n             # for the database.\n-            if f.db_column is None and column_name is not None and len(column_name) > allowed_len:\n+            if (\n+                f.db_column is None\n+                and column_name is not None\n+                and len(column_name) > allowed_len\n+            ):\n                 errors.append(\n                     checks.Error(\n                         'Autogenerated column name too long for field \"%s\". '\n@@ -1906,7 +2091,7 @@ class Model(metaclass=ModelBase):\n                         % (column_name, allowed_len, db_alias),\n                         hint=\"Set the column name manually using 'db_column'.\",\n                         obj=cls,\n-                        id='models.E018',\n+                        id=\"models.E018\",\n                     )\n                 )\n \n@@ -1919,10 +2104,14 @@ class Model(metaclass=ModelBase):\n             # for the database.\n             for m2m in f.remote_field.through._meta.local_fields:\n                 _, rel_name = m2m.get_attname_column()\n-                if m2m.db_column is None and rel_name is not None and len(rel_name) > allowed_len:\n+                if (\n+                    m2m.db_column is None\n+                    and rel_name is not None\n+                    and len(rel_name) > allowed_len\n+                ):\n                     errors.append(\n                         checks.Error(\n-                            'Autogenerated column name too long for M2M field '\n+                            \"Autogenerated column name too long for M2M field \"\n                             '\"%s\". Maximum length is \"%s\" for database \"%s\".'\n                             % (rel_name, allowed_len, db_alias),\n                             hint=(\n@@ -1930,7 +2119,7 @@ class Model(metaclass=ModelBase):\n                                 \"M2M and then set column_name using 'db_column'.\"\n                             ),\n                             obj=cls,\n-                            id='models.E019',\n+                            id=\"models.E019\",\n                         )\n                     )\n \n@@ -1948,7 +2137,7 @@ class Model(metaclass=ModelBase):\n                     yield from cls._get_expr_references(child)\n         elif isinstance(expr, F):\n             yield tuple(expr.name.split(LOOKUP_SEP))\n-        elif hasattr(expr, 'get_source_expressions'):\n+        elif hasattr(expr, \"get_source_expressions\"):\n             for src_expr in expr.get_source_expressions():\n                 yield from cls._get_expr_references(src_expr)\n \n@@ -1960,107 +2149,118 @@ class Model(metaclass=ModelBase):\n                 continue\n             connection = connections[db]\n             if not (\n-                connection.features.supports_table_check_constraints or\n-                'supports_table_check_constraints' in cls._meta.required_db_features\n+                connection.features.supports_table_check_constraints\n+                or \"supports_table_check_constraints\" in cls._meta.required_db_features\n             ) and any(\n                 isinstance(constraint, CheckConstraint)\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support check constraints.' % connection.display_name,\n+                        \"%s does not support check constraints.\"\n+                        % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W027',\n+                        id=\"models.W027\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_partial_indexes or\n-                'supports_partial_indexes' in cls._meta.required_db_features\n+                connection.features.supports_partial_indexes\n+                or \"supports_partial_indexes\" in cls._meta.required_db_features\n             ) and any(\n-                isinstance(constraint, UniqueConstraint) and constraint.condition is not None\n+                isinstance(constraint, UniqueConstraint)\n+                and constraint.condition is not None\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support unique constraints with '\n-                        'conditions.' % connection.display_name,\n+                        \"%s does not support unique constraints with \"\n+                        \"conditions.\" % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W036',\n+                        id=\"models.W036\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_deferrable_unique_constraints or\n-                'supports_deferrable_unique_constraints' in cls._meta.required_db_features\n+                connection.features.supports_deferrable_unique_constraints\n+                or \"supports_deferrable_unique_constraints\"\n+                in cls._meta.required_db_features\n             ) and any(\n-                isinstance(constraint, UniqueConstraint) and constraint.deferrable is not None\n+                isinstance(constraint, UniqueConstraint)\n+                and constraint.deferrable is not None\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support deferrable unique constraints.'\n+                        \"%s does not support deferrable unique constraints.\"\n                         % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W038',\n+                        id=\"models.W038\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_covering_indexes or\n-                'supports_covering_indexes' in cls._meta.required_db_features\n+                connection.features.supports_covering_indexes\n+                or \"supports_covering_indexes\" in cls._meta.required_db_features\n             ) and any(\n                 isinstance(constraint, UniqueConstraint) and constraint.include\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support unique constraints with non-key '\n-                        'columns.' % connection.display_name,\n+                        \"%s does not support unique constraints with non-key \"\n+                        \"columns.\" % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W039',\n+                        id=\"models.W039\",\n                     )\n                 )\n-            fields = set(chain.from_iterable(\n-                (*constraint.fields, *constraint.include)\n-                for constraint in cls._meta.constraints if isinstance(constraint, UniqueConstraint)\n-            ))\n+            fields = set(\n+                chain.from_iterable(\n+                    (*constraint.fields, *constraint.include)\n+                    for constraint in cls._meta.constraints\n+                    if isinstance(constraint, UniqueConstraint)\n+                )\n+            )\n             references = set()\n             for constraint in cls._meta.constraints:\n                 if isinstance(constraint, UniqueConstraint):\n                     if (\n-                        connection.features.supports_partial_indexes or\n-                        'supports_partial_indexes' not in cls._meta.required_db_features\n+                        connection.features.supports_partial_indexes\n+                        or \"supports_partial_indexes\"\n+                        not in cls._meta.required_db_features\n                     ) and isinstance(constraint.condition, Q):\n-                        references.update(cls._get_expr_references(constraint.condition))\n+                        references.update(\n+                            cls._get_expr_references(constraint.condition)\n+                        )\n                 elif isinstance(constraint, CheckConstraint):\n                     if (\n-                        connection.features.supports_table_check_constraints or\n-                        'supports_table_check_constraints' not in cls._meta.required_db_features\n+                        connection.features.supports_table_check_constraints\n+                        or \"supports_table_check_constraints\"\n+                        not in cls._meta.required_db_features\n                     ) and isinstance(constraint.check, Q):\n                         references.update(cls._get_expr_references(constraint.check))\n             for field_name, *lookups in references:\n                 # pk is an alias that won't be found by opts.get_field.\n-                if field_name != 'pk':\n+                if field_name != \"pk\":\n                     fields.add(field_name)\n                 if not lookups:\n                     # If it has no lookups it cannot result in a JOIN.\n                     continue\n                 try:\n-                    if field_name == 'pk':\n+                    if field_name == \"pk\":\n                         field = cls._meta.pk\n                     else:\n                         field = cls._meta.get_field(field_name)\n@@ -2071,18 +2271,18 @@ class Model(metaclass=ModelBase):\n                 # JOIN must happen at the first lookup.\n                 first_lookup = lookups[0]\n                 if (\n-                    field.get_transform(first_lookup) is None and\n-                    field.get_lookup(first_lookup) is None\n+                    field.get_transform(first_lookup) is None\n+                    and field.get_lookup(first_lookup) is None\n                 ):\n                     errors.append(\n                         checks.Error(\n                             \"'constraints' refers to the joined field '%s'.\"\n                             % LOOKUP_SEP.join([field_name] + lookups),\n                             obj=cls,\n-                            id='models.E041',\n+                            id=\"models.E041\",\n                         )\n                     )\n-            errors.extend(cls._check_local_fields(fields, 'constraints'))\n+            errors.extend(cls._check_local_fields(fields, \"constraints\"))\n         return errors\n \n \n@@ -2092,14 +2292,16 @@ class Model(metaclass=ModelBase):\n \n # ORDERING METHODS #########################\n \n+\n def method_set_order(self, ordered_obj, id_list, using=None):\n     if using is None:\n         using = DEFAULT_DB_ALIAS\n     order_wrt = ordered_obj._meta.order_with_respect_to\n     filter_args = order_wrt.get_forward_related_filter(self)\n-    ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update([\n-        ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)\n-    ], ['_order'])\n+    ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update(\n+        [ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)],\n+        [\"_order\"],\n+    )\n \n \n def method_get_order(self, ordered_obj):\n@@ -2112,15 +2314,16 @@ def method_get_order(self, ordered_obj):\n def make_foreign_order_accessors(model, related_model):\n     setattr(\n         related_model,\n-        'get_%s_order' % model.__name__.lower(),\n-        partialmethod(method_get_order, model)\n+        \"get_%s_order\" % model.__name__.lower(),\n+        partialmethod(method_get_order, model),\n     )\n     setattr(\n         related_model,\n-        'set_%s_order' % model.__name__.lower(),\n-        partialmethod(method_set_order, model)\n+        \"set_%s_order\" % model.__name__.lower(),\n+        partialmethod(method_set_order, model),\n     )\n \n+\n ########\n # MISC #\n ########\n"}
{"instance_id": "django__django-13933", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 422bc5d178..56ba6d2df7 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -2,29 +2,44 @@\n Helper functions for creating Form classes from Django models\n and database field objects.\n \"\"\"\n+\n from itertools import chain\n \n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldError, ImproperlyConfigured, ValidationError,\n+    NON_FIELD_ERRORS,\n+    FieldError,\n+    ImproperlyConfigured,\n+    ValidationError,\n )\n from django.forms.fields import ChoiceField, Field\n from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, RadioSelect, SelectMultiple,\n+    HiddenInput,\n+    MultipleHiddenInput,\n+    RadioSelect,\n+    SelectMultiple,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n __all__ = (\n-    'ModelForm', 'BaseModelForm', 'model_to_dict', 'fields_for_model',\n-    'ModelChoiceField', 'ModelMultipleChoiceField', 'ALL_FIELDS',\n-    'BaseModelFormSet', 'modelformset_factory', 'BaseInlineFormSet',\n-    'inlineformset_factory', 'modelform_factory',\n+    \"ModelForm\",\n+    \"BaseModelForm\",\n+    \"model_to_dict\",\n+    \"fields_for_model\",\n+    \"ModelChoiceField\",\n+    \"ModelMultipleChoiceField\",\n+    \"ALL_FIELDS\",\n+    \"BaseModelFormSet\",\n+    \"modelformset_factory\",\n+    \"BaseInlineFormSet\",\n+    \"inlineformset_factory\",\n+    \"modelform_factory\",\n )\n \n-ALL_FIELDS = '__all__'\n+ALL_FIELDS = \"__all__\"\n \n \n def construct_instance(form, instance, fields=None, exclude=None):\n@@ -33,13 +48,17 @@ def construct_instance(form, instance, fields=None, exclude=None):\n     ``cleaned_data``, but do not save the returned instance to the database.\n     \"\"\"\n     from django.db import models\n+\n     opts = instance._meta\n \n     cleaned_data = form.cleaned_data\n     file_field_list = []\n     for f in opts.fields:\n-        if not f.editable or isinstance(f, models.AutoField) \\\n-                or f.name not in cleaned_data:\n+        if (\n+            not f.editable\n+            or isinstance(f, models.AutoField)\n+            or f.name not in cleaned_data\n+        ):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -48,9 +67,11 @@ def construct_instance(form, instance, fields=None, exclude=None):\n         # Leave defaults for fields that aren't in POST data, except for\n         # checkbox inputs because they don't appear in POST data if not checked.\n         if (\n-            f.has_default() and\n-            form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name)) and\n-            cleaned_data.get(f.name) in form[f.name].field.empty_values\n+            f.has_default()\n+            and form[f.name].field.widget.value_omitted_from_data(\n+                form.data, form.files, form.add_prefix(f.name)\n+            )\n+            and cleaned_data.get(f.name) in form[f.name].field.empty_values\n         ):\n             continue\n         # Defer saving file-type fields until after the other fields, so a\n@@ -68,6 +89,7 @@ def construct_instance(form, instance, fields=None, exclude=None):\n \n # ModelForms #################################################################\n \n+\n def model_to_dict(instance, fields=None, exclude=None):\n     \"\"\"\n     Return a dict containing the data in ``instance`` suitable for passing as\n@@ -83,7 +105,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     opts = instance._meta\n     data = {}\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n-        if not getattr(f, 'editable', False):\n+        if not getattr(f, \"editable\", False):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -96,23 +118,34 @@ def model_to_dict(instance, fields=None, exclude=None):\n def apply_limit_choices_to_to_formfield(formfield):\n     \"\"\"Apply limit_choices_to to the formfield's queryset if needed.\"\"\"\n     from django.db.models import Exists, OuterRef, Q\n-    if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n+\n+    if hasattr(formfield, \"queryset\") and hasattr(formfield, \"get_limit_choices_to\"):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to:\n             complex_filter = limit_choices_to\n             if not isinstance(complex_filter, Q):\n                 complex_filter = Q(**limit_choices_to)\n-            complex_filter &= Q(pk=OuterRef('pk'))\n+            complex_filter &= Q(pk=OuterRef(\"pk\"))\n             # Use Exists() to avoid potential duplicates.\n             formfield.queryset = formfield.queryset.filter(\n                 Exists(formfield.queryset.model._base_manager.filter(complex_filter)),\n             )\n \n \n-def fields_for_model(model, fields=None, exclude=None, widgets=None,\n-                     formfield_callback=None, localized_fields=None,\n-                     labels=None, help_texts=None, error_messages=None,\n-                     field_classes=None, *, apply_limit_choices_to=True):\n+def fields_for_model(\n+    model,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    formfield_callback=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+    *,\n+    apply_limit_choices_to=True,\n+):\n     \"\"\"\n     Return a dictionary containing form fields for the given model.\n \n@@ -148,14 +181,22 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n     opts = model._meta\n     # Avoid circular import\n     from django.db.models import Field as ModelField\n-    sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)]\n-    for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)):\n-        if not getattr(f, 'editable', False):\n-            if (fields is not None and f.name in fields and\n-                    (exclude is None or f.name not in exclude)):\n+\n+    sortable_private_fields = [\n+        f for f in opts.private_fields if isinstance(f, ModelField)\n+    ]\n+    for f in sorted(\n+        chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)\n+    ):\n+        if not getattr(f, \"editable\", False):\n+            if (\n+                fields is not None\n+                and f.name in fields\n+                and (exclude is None or f.name not in exclude)\n+            ):\n                 raise FieldError(\n-                    \"'%s' cannot be specified for %s model form as it is a non-editable field\" % (\n-                        f.name, model.__name__)\n+                    \"'%s' cannot be specified for %s model form as it is a non-editable field\"\n+                    % (f.name, model.__name__)\n                 )\n             continue\n         if fields is not None and f.name not in fields:\n@@ -165,22 +206,24 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n         kwargs = {}\n         if widgets and f.name in widgets:\n-            kwargs['widget'] = widgets[f.name]\n-        if localized_fields == ALL_FIELDS or (localized_fields and f.name in localized_fields):\n-            kwargs['localize'] = True\n+            kwargs[\"widget\"] = widgets[f.name]\n+        if localized_fields == ALL_FIELDS or (\n+            localized_fields and f.name in localized_fields\n+        ):\n+            kwargs[\"localize\"] = True\n         if labels and f.name in labels:\n-            kwargs['label'] = labels[f.name]\n+            kwargs[\"label\"] = labels[f.name]\n         if help_texts and f.name in help_texts:\n-            kwargs['help_text'] = help_texts[f.name]\n+            kwargs[\"help_text\"] = help_texts[f.name]\n         if error_messages and f.name in error_messages:\n-            kwargs['error_messages'] = error_messages[f.name]\n+            kwargs[\"error_messages\"] = error_messages[f.name]\n         if field_classes and f.name in field_classes:\n-            kwargs['form_class'] = field_classes[f.name]\n+            kwargs[\"form_class\"] = field_classes[f.name]\n \n         if formfield_callback is None:\n             formfield = f.formfield(**kwargs)\n         elif not callable(formfield_callback):\n-            raise TypeError('formfield_callback must be a function or callable')\n+            raise TypeError(\"formfield_callback must be a function or callable\")\n         else:\n             formfield = formfield_callback(f, **kwargs)\n \n@@ -192,7 +235,8 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n             ignored.append(f.name)\n     if fields:\n         field_dict = {\n-            f: field_dict.get(f) for f in fields\n+            f: field_dict.get(f)\n+            for f in fields\n             if (not exclude or f not in exclude) and f not in ignored\n         }\n     return field_dict\n@@ -200,46 +244,49 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n class ModelFormOptions:\n     def __init__(self, options=None):\n-        self.model = getattr(options, 'model', None)\n-        self.fields = getattr(options, 'fields', None)\n-        self.exclude = getattr(options, 'exclude', None)\n-        self.widgets = getattr(options, 'widgets', None)\n-        self.localized_fields = getattr(options, 'localized_fields', None)\n-        self.labels = getattr(options, 'labels', None)\n-        self.help_texts = getattr(options, 'help_texts', None)\n-        self.error_messages = getattr(options, 'error_messages', None)\n-        self.field_classes = getattr(options, 'field_classes', None)\n+        self.model = getattr(options, \"model\", None)\n+        self.fields = getattr(options, \"fields\", None)\n+        self.exclude = getattr(options, \"exclude\", None)\n+        self.widgets = getattr(options, \"widgets\", None)\n+        self.localized_fields = getattr(options, \"localized_fields\", None)\n+        self.labels = getattr(options, \"labels\", None)\n+        self.help_texts = getattr(options, \"help_texts\", None)\n+        self.error_messages = getattr(options, \"error_messages\", None)\n+        self.field_classes = getattr(options, \"field_classes\", None)\n \n \n class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n     def __new__(mcs, name, bases, attrs):\n         base_formfield_callback = None\n         for b in bases:\n-            if hasattr(b, 'Meta') and hasattr(b.Meta, 'formfield_callback'):\n+            if hasattr(b, \"Meta\") and hasattr(b.Meta, \"formfield_callback\"):\n                 base_formfield_callback = b.Meta.formfield_callback\n                 break\n \n-        formfield_callback = attrs.pop('formfield_callback', base_formfield_callback)\n+        formfield_callback = attrs.pop(\"formfield_callback\", base_formfield_callback)\n \n         new_class = super().__new__(mcs, name, bases, attrs)\n \n         if bases == (BaseModelForm,):\n             return new_class\n \n-        opts = new_class._meta = ModelFormOptions(getattr(new_class, 'Meta', None))\n+        opts = new_class._meta = ModelFormOptions(getattr(new_class, \"Meta\", None))\n \n         # We check if a string was passed to `fields` or `exclude`,\n         # which is likely to be a mistake where the user typed ('foo') instead\n         # of ('foo',)\n-        for opt in ['fields', 'exclude', 'localized_fields']:\n+        for opt in [\"fields\", \"exclude\", \"localized_fields\"]:\n             value = getattr(opts, opt)\n             if isinstance(value, str) and value != ALL_FIELDS:\n-                msg = (\"%(model)s.Meta.%(opt)s cannot be a string. \"\n-                       \"Did you mean to type: ('%(value)s',)?\" % {\n-                           'model': new_class.__name__,\n-                           'opt': opt,\n-                           'value': value,\n-                       })\n+                msg = (\n+                    \"%(model)s.Meta.%(opt)s cannot be a string. \"\n+                    \"Did you mean to type: ('%(value)s',)?\"\n+                    % {\n+                        \"model\": new_class.__name__,\n+                        \"opt\": opt,\n+                        \"value\": value,\n+                    }\n+                )\n                 raise TypeError(msg)\n \n         if opts.model:\n@@ -257,9 +304,16 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n                 opts.fields = None\n \n             fields = fields_for_model(\n-                opts.model, opts.fields, opts.exclude, opts.widgets,\n-                formfield_callback, opts.localized_fields, opts.labels,\n-                opts.help_texts, opts.error_messages, opts.field_classes,\n+                opts.model,\n+                opts.fields,\n+                opts.exclude,\n+                opts.widgets,\n+                formfield_callback,\n+                opts.localized_fields,\n+                opts.labels,\n+                opts.help_texts,\n+                opts.error_messages,\n+                opts.field_classes,\n                 # limit_choices_to will be applied during ModelForm.__init__().\n                 apply_limit_choices_to=False,\n             )\n@@ -268,9 +322,8 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n             none_model_fields = {k for k, v in fields.items() if not v}\n             missing_fields = none_model_fields.difference(new_class.declared_fields)\n             if missing_fields:\n-                message = 'Unknown field(s) (%s) specified for %s'\n-                message = message % (', '.join(missing_fields),\n-                                     opts.model.__name__)\n+                message = \"Unknown field(s) (%s) specified for %s\"\n+                message = message % (\", \".join(missing_fields), opts.model.__name__)\n                 raise FieldError(message)\n             # Override default model fields with any custom declared ones\n             # (plus, include all the other declared fields).\n@@ -284,13 +337,23 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n \n \n class BaseModelForm(BaseForm):\n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 initial=None, error_class=ErrorList, label_suffix=None,\n-                 empty_permitted=False, instance=None, use_required_attribute=None,\n-                 renderer=None):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        initial=None,\n+        error_class=ErrorList,\n+        label_suffix=None,\n+        empty_permitted=False,\n+        instance=None,\n+        use_required_attribute=None,\n+        renderer=None,\n+    ):\n         opts = self._meta\n         if opts.model is None:\n-            raise ValueError('ModelForm has no model class specified.')\n+            raise ValueError(\"ModelForm has no model class specified.\")\n         if instance is None:\n             # if we didn't get an instance, instantiate a new one\n             self.instance = opts.model()\n@@ -306,8 +369,15 @@ class BaseModelForm(BaseForm):\n         # super will stop validate_unique from being called.\n         self._validate_unique = False\n         super().__init__(\n-            data, files, auto_id, prefix, object_data, error_class,\n-            label_suffix, empty_permitted, use_required_attribute=use_required_attribute,\n+            data,\n+            files,\n+            auto_id,\n+            prefix,\n+            object_data,\n+            error_class,\n+            label_suffix,\n+            empty_permitted,\n+            use_required_attribute=use_required_attribute,\n             renderer=renderer,\n         )\n         for formfield in self.fields.values():\n@@ -350,7 +420,11 @@ class BaseModelForm(BaseForm):\n             else:\n                 form_field = self.fields[field]\n                 field_value = self.cleaned_data.get(field)\n-                if not f.blank and not form_field.required and field_value in form_field.empty_values:\n+                if (\n+                    not f.blank\n+                    and not form_field.required\n+                    and field_value in form_field.empty_values\n+                ):\n                     exclude.append(f.name)\n         return exclude\n \n@@ -365,14 +439,17 @@ class BaseModelForm(BaseForm):\n \n         # Allow the model generated by construct_instance() to raise\n         # ValidationError and have them handled in the same way as others.\n-        if hasattr(errors, 'error_dict'):\n+        if hasattr(errors, \"error_dict\"):\n             error_dict = errors.error_dict\n         else:\n             error_dict = {NON_FIELD_ERRORS: errors}\n \n         for field, messages in error_dict.items():\n-            if (field == NON_FIELD_ERRORS and opts.error_messages and\n-                    NON_FIELD_ERRORS in opts.error_messages):\n+            if (\n+                field == NON_FIELD_ERRORS\n+                and opts.error_messages\n+                and NON_FIELD_ERRORS in opts.error_messages\n+            ):\n                 error_messages = opts.error_messages[NON_FIELD_ERRORS]\n             elif field in self.fields:\n                 error_messages = self.fields[field].error_messages\n@@ -380,8 +457,10 @@ class BaseModelForm(BaseForm):\n                 continue\n \n             for message in messages:\n-                if (isinstance(message, ValidationError) and\n-                        message.code in error_messages):\n+                if (\n+                    isinstance(message, ValidationError)\n+                    and message.code in error_messages\n+                ):\n                     message.message = error_messages[message.code]\n \n         self.add_error(None, errors)\n@@ -403,7 +482,9 @@ class BaseModelForm(BaseForm):\n                 exclude.append(name)\n \n         try:\n-            self.instance = construct_instance(self, self.instance, opts.fields, opts.exclude)\n+            self.instance = construct_instance(\n+                self, self.instance, opts.fields, opts.exclude\n+            )\n         except ValidationError as e:\n             self._update_errors(e)\n \n@@ -439,7 +520,7 @@ class BaseModelForm(BaseForm):\n         # private_fields here. (GenericRelation was previously a fake\n         # m2m field).\n         for f in chain(opts.many_to_many, opts.private_fields):\n-            if not hasattr(f, 'save_form_data'):\n+            if not hasattr(f, \"save_form_data\"):\n                 continue\n             if fields and f.name not in fields:\n                 continue\n@@ -456,9 +537,10 @@ class BaseModelForm(BaseForm):\n         \"\"\"\n         if self.errors:\n             raise ValueError(\n-                \"The %s could not be %s because the data didn't validate.\" % (\n+                \"The %s could not be %s because the data didn't validate.\"\n+                % (\n                     self.instance._meta.object_name,\n-                    'created' if self.instance._state.adding else 'changed',\n+                    \"created\" if self.instance._state.adding else \"changed\",\n                 )\n             )\n         if commit:\n@@ -478,10 +560,19 @@ class ModelForm(BaseModelForm, metaclass=ModelFormMetaclass):\n     pass\n \n \n-def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n-                      formfield_callback=None, widgets=None, localized_fields=None,\n-                      labels=None, help_texts=None, error_messages=None,\n-                      field_classes=None):\n+def modelform_factory(\n+    model,\n+    form=ModelForm,\n+    fields=None,\n+    exclude=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+):\n     \"\"\"\n     Return a ModelForm containing form fields for the given model. You can\n     optionally pass a `form` argument to use as a starting point for\n@@ -517,41 +608,37 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n     # inner class.\n \n     # Build up a list of attributes that the Meta object will have.\n-    attrs = {'model': model}\n+    attrs = {\"model\": model}\n     if fields is not None:\n-        attrs['fields'] = fields\n+        attrs[\"fields\"] = fields\n     if exclude is not None:\n-        attrs['exclude'] = exclude\n+        attrs[\"exclude\"] = exclude\n     if widgets is not None:\n-        attrs['widgets'] = widgets\n+        attrs[\"widgets\"] = widgets\n     if localized_fields is not None:\n-        attrs['localized_fields'] = localized_fields\n+        attrs[\"localized_fields\"] = localized_fields\n     if labels is not None:\n-        attrs['labels'] = labels\n+        attrs[\"labels\"] = labels\n     if help_texts is not None:\n-        attrs['help_texts'] = help_texts\n+        attrs[\"help_texts\"] = help_texts\n     if error_messages is not None:\n-        attrs['error_messages'] = error_messages\n+        attrs[\"error_messages\"] = error_messages\n     if field_classes is not None:\n-        attrs['field_classes'] = field_classes\n+        attrs[\"field_classes\"] = field_classes\n \n     # If parent form class already has an inner Meta, the Meta we're\n     # creating needs to inherit from the parent's inner meta.\n-    bases = (form.Meta,) if hasattr(form, 'Meta') else ()\n-    Meta = type('Meta', bases, attrs)\n+    bases = (form.Meta,) if hasattr(form, \"Meta\") else ()\n+    Meta = type(\"Meta\", bases, attrs)\n     if formfield_callback:\n         Meta.formfield_callback = staticmethod(formfield_callback)\n     # Give this new form class a reasonable name.\n-    class_name = model.__name__ + 'Form'\n+    class_name = model.__name__ + \"Form\"\n \n     # Class attributes for the new form class.\n-    form_class_attrs = {\n-        'Meta': Meta,\n-        'formfield_callback': formfield_callback\n-    }\n+    form_class_attrs = {\"Meta\": Meta, \"formfield_callback\": formfield_callback}\n \n-    if (getattr(Meta, 'fields', None) is None and\n-            getattr(Meta, 'exclude', None) is None):\n+    if getattr(Meta, \"fields\", None) is None and getattr(Meta, \"exclude\", None) is None:\n         raise ImproperlyConfigured(\n             \"Calling modelform_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n@@ -563,20 +650,39 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n \n # ModelFormSets ##############################################################\n \n+\n class BaseModelFormSet(BaseFormSet):\n     \"\"\"\n     A ``FormSet`` for editing a queryset and/or adding new objects to it.\n     \"\"\"\n+\n     model = None\n \n     # Set of fields that must be unique among forms of this set.\n     unique_fields = set()\n \n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 queryset=None, *, initial=None, **kwargs):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        queryset=None,\n+        *,\n+        initial=None,\n+        **kwargs,\n+    ):\n         self.queryset = queryset\n         self.initial_extra = initial\n-        super().__init__(**{'data': data, 'files': files, 'auto_id': auto_id, 'prefix': prefix, **kwargs})\n+        super().__init__(\n+            **{\n+                \"data\": data,\n+                \"files\": files,\n+                \"auto_id\": auto_id,\n+                \"prefix\": prefix,\n+                **kwargs,\n+            }\n+        )\n \n     def initial_form_count(self):\n         \"\"\"Return the number of forms that are required in this FormSet.\"\"\"\n@@ -585,7 +691,7 @@ class BaseModelFormSet(BaseFormSet):\n         return super().initial_form_count()\n \n     def _existing_object(self, pk):\n-        if not hasattr(self, '_object_dict'):\n+        if not hasattr(self, \"_object_dict\"):\n             self._object_dict = {o.pk: o for o in self.get_queryset()}\n         return self._object_dict.get(pk)\n \n@@ -602,7 +708,7 @@ class BaseModelFormSet(BaseFormSet):\n         pk_required = i < self.initial_form_count()\n         if pk_required:\n             if self.is_bound:\n-                pk_key = '%s-%s' % (self.add_prefix(i), self.model._meta.pk.name)\n+                pk_key = \"%s-%s\" % (self.add_prefix(i), self.model._meta.pk.name)\n                 try:\n                     pk = self.data[pk_key]\n                 except KeyError:\n@@ -618,13 +724,13 @@ class BaseModelFormSet(BaseFormSet):\n                         # user may have tampered with POST data.\n                         pass\n                     else:\n-                        kwargs['instance'] = self._existing_object(pk)\n+                        kwargs[\"instance\"] = self._existing_object(pk)\n             else:\n-                kwargs['instance'] = self.get_queryset()[i]\n+                kwargs[\"instance\"] = self.get_queryset()[i]\n         elif self.initial_extra:\n             # Set initial values for extra forms\n             try:\n-                kwargs['initial'] = self.initial_extra[i - self.initial_form_count()]\n+                kwargs[\"initial\"] = self.initial_extra[i - self.initial_form_count()]\n             except IndexError:\n                 pass\n         form = super()._construct_form(i, **kwargs)\n@@ -633,7 +739,7 @@ class BaseModelFormSet(BaseFormSet):\n         return form\n \n     def get_queryset(self):\n-        if not hasattr(self, '_queryset'):\n+        if not hasattr(self, \"_queryset\"):\n             if self.queryset is not None:\n                 qs = self.queryset\n             else:\n@@ -675,6 +781,7 @@ class BaseModelFormSet(BaseFormSet):\n             def save_m2m():\n                 for form in self.saved_forms:\n                     form.save_m2m()\n+\n             self.save_m2m = save_m2m\n         return self.save_existing_objects(commit) + self.save_new_objects(commit)\n \n@@ -688,10 +795,16 @@ class BaseModelFormSet(BaseFormSet):\n         all_unique_checks = set()\n         all_date_checks = set()\n         forms_to_delete = self.deleted_forms\n-        valid_forms = [form for form in self.forms if form.is_valid() and form not in forms_to_delete]\n+        valid_forms = [\n+            form\n+            for form in self.forms\n+            if form.is_valid() and form not in forms_to_delete\n+        ]\n         for form in valid_forms:\n             exclude = form._get_validation_exclusions()\n-            unique_checks, date_checks = form.instance._get_unique_checks(exclude=exclude)\n+            unique_checks, date_checks = form.instance._get_unique_checks(\n+                exclude=exclude\n+            )\n             all_unique_checks.update(unique_checks)\n             all_date_checks.update(date_checks)\n \n@@ -703,14 +816,18 @@ class BaseModelFormSet(BaseFormSet):\n                 # Get the data for the set of fields that must be unique among the forms.\n                 row_data = (\n                     field if field in self.unique_fields else form.cleaned_data[field]\n-                    for field in unique_check if field in form.cleaned_data\n+                    for field in unique_check\n+                    if field in form.cleaned_data\n                 )\n                 # Reduce Model instances to their primary key values\n                 row_data = tuple(\n-                    d._get_pk_val() if hasattr(d, '_get_pk_val')\n+                    d._get_pk_val()\n+                    if hasattr(d, \"_get_pk_val\")\n                     # Prevent \"unhashable type: list\" errors later on.\n-                    else tuple(d) if isinstance(d, list)\n-                    else d for d in row_data\n+                    else tuple(d)\n+                    if isinstance(d, list)\n+                    else d\n+                    for d in row_data\n                 )\n                 if row_data and None not in row_data:\n                     # if we've already seen it then we have a uniqueness failure\n@@ -718,7 +835,9 @@ class BaseModelFormSet(BaseFormSet):\n                         # poke error messages into the right places and mark\n                         # the form as invalid\n                         errors.append(self.get_unique_error_message(unique_check))\n-                        form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()])\n+                        form._errors[NON_FIELD_ERRORS] = self.error_class(\n+                            [self.get_form_error()]\n+                        )\n                         # remove the data from the cleaned_data dict since it was invalid\n                         for field in unique_check:\n                             if field in form.cleaned_data:\n@@ -731,10 +850,13 @@ class BaseModelFormSet(BaseFormSet):\n             uclass, lookup, field, unique_for = date_check\n             for form in valid_forms:\n                 # see if we have data for both fields\n-                if (form.cleaned_data and form.cleaned_data[field] is not None and\n-                        form.cleaned_data[unique_for] is not None):\n+                if (\n+                    form.cleaned_data\n+                    and form.cleaned_data[field] is not None\n+                    and form.cleaned_data[unique_for] is not None\n+                ):\n                     # if it's a date lookup we need to get the data for all the fields\n-                    if lookup == 'date':\n+                    if lookup == \"date\":\n                         date = form.cleaned_data[unique_for]\n                         date_data = (date.year, date.month, date.day)\n                     # otherwise it's just the attribute on the date/datetime\n@@ -747,7 +869,9 @@ class BaseModelFormSet(BaseFormSet):\n                         # poke error messages into the right places and mark\n                         # the form as invalid\n                         errors.append(self.get_date_error_message(date_check))\n-                        form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()])\n+                        form._errors[NON_FIELD_ERRORS] = self.error_class(\n+                            [self.get_form_error()]\n+                        )\n                         # remove the data from the cleaned_data dict since it was invalid\n                         del form.cleaned_data[field]\n                     # mark the data as seen\n@@ -762,7 +886,9 @@ class BaseModelFormSet(BaseFormSet):\n                 \"field\": unique_check[0],\n             }\n         else:\n-            return gettext(\"Please correct the duplicate data for %(field)s, which must be unique.\") % {\n+            return gettext(\n+                \"Please correct the duplicate data for %(field)s, which must be unique.\"\n+            ) % {\n                 \"field\": get_text_list(unique_check, _(\"and\")),\n             }\n \n@@ -771,9 +897,9 @@ class BaseModelFormSet(BaseFormSet):\n             \"Please correct the duplicate data for %(field_name)s \"\n             \"which must be unique for the %(lookup)s in %(date_field)s.\"\n         ) % {\n-            'field_name': date_check[2],\n-            'date_field': date_check[3],\n-            'lookup': str(date_check[1]),\n+            \"field_name\": date_check[2],\n+            \"date_field\": date_check[3],\n+            \"lookup\": str(date_check[1]),\n         }\n \n     def get_form_error(self):\n@@ -822,6 +948,7 @@ class BaseModelFormSet(BaseFormSet):\n     def add_fields(self, form, index):\n         \"\"\"Add a hidden field for the object's primary key.\"\"\"\n         from django.db.models import AutoField, ForeignKey, OneToOneField\n+\n         self._pk_field = pk = self.model._meta.pk\n         # If a pk isn't editable, then it won't be on the form, so we need to\n         # add it here so we can tell which object is which when we get the\n@@ -831,11 +958,15 @@ class BaseModelFormSet(BaseFormSet):\n \n         def pk_is_not_editable(pk):\n             return (\n-                (not pk.editable) or (pk.auto_created or isinstance(pk, AutoField)) or (\n-                    pk.remote_field and pk.remote_field.parent_link and\n-                    pk_is_not_editable(pk.remote_field.model._meta.pk)\n+                (not pk.editable)\n+                or (pk.auto_created or isinstance(pk, AutoField))\n+                or (\n+                    pk.remote_field\n+                    and pk.remote_field.parent_link\n+                    and pk_is_not_editable(pk.remote_field.model._meta.pk)\n                 )\n             )\n+\n         if pk_is_not_editable(pk) or pk.name not in form.fields:\n             if form.is_bound:\n                 # If we're adding the related instance, ignore its primary key\n@@ -859,45 +990,92 @@ class BaseModelFormSet(BaseFormSet):\n                 widget = form._meta.widgets.get(self._pk_field.name, HiddenInput)\n             else:\n                 widget = HiddenInput\n-            form.fields[self._pk_field.name] = ModelChoiceField(qs, initial=pk_value, required=False, widget=widget)\n+            form.fields[self._pk_field.name] = ModelChoiceField(\n+                qs, initial=pk_value, required=False, widget=widget\n+            )\n         super().add_fields(form, index)\n \n \n-def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n-                         formset=BaseModelFormSet, extra=1, can_delete=False,\n-                         can_order=False, max_num=None, fields=None, exclude=None,\n-                         widgets=None, validate_max=False, localized_fields=None,\n-                         labels=None, help_texts=None, error_messages=None,\n-                         min_num=None, validate_min=False, field_classes=None,\n-                         absolute_max=None, can_delete_extra=True):\n+def modelformset_factory(\n+    model,\n+    form=ModelForm,\n+    formfield_callback=None,\n+    formset=BaseModelFormSet,\n+    extra=1,\n+    can_delete=False,\n+    can_order=False,\n+    max_num=None,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+):\n     \"\"\"Return a FormSet class for the given Django model class.\"\"\"\n-    meta = getattr(form, 'Meta', None)\n-    if (getattr(meta, 'fields', fields) is None and\n-            getattr(meta, 'exclude', exclude) is None):\n+    meta = getattr(form, \"Meta\", None)\n+    if (\n+        getattr(meta, \"fields\", fields) is None\n+        and getattr(meta, \"exclude\", exclude) is None\n+    ):\n         raise ImproperlyConfigured(\n             \"Calling modelformset_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n         )\n \n-    form = modelform_factory(model, form=form, fields=fields, exclude=exclude,\n-                             formfield_callback=formfield_callback,\n-                             widgets=widgets, localized_fields=localized_fields,\n-                             labels=labels, help_texts=help_texts,\n-                             error_messages=error_messages, field_classes=field_classes)\n-    FormSet = formset_factory(form, formset, extra=extra, min_num=min_num, max_num=max_num,\n-                              can_order=can_order, can_delete=can_delete,\n-                              validate_min=validate_min, validate_max=validate_max,\n-                              absolute_max=absolute_max, can_delete_extra=can_delete_extra)\n+    form = modelform_factory(\n+        model,\n+        form=form,\n+        fields=fields,\n+        exclude=exclude,\n+        formfield_callback=formfield_callback,\n+        widgets=widgets,\n+        localized_fields=localized_fields,\n+        labels=labels,\n+        help_texts=help_texts,\n+        error_messages=error_messages,\n+        field_classes=field_classes,\n+    )\n+    FormSet = formset_factory(\n+        form,\n+        formset,\n+        extra=extra,\n+        min_num=min_num,\n+        max_num=max_num,\n+        can_order=can_order,\n+        can_delete=can_delete,\n+        validate_min=validate_min,\n+        validate_max=validate_max,\n+        absolute_max=absolute_max,\n+        can_delete_extra=can_delete_extra,\n+    )\n     FormSet.model = model\n     return FormSet\n \n \n # InlineFormSets #############################################################\n \n+\n class BaseInlineFormSet(BaseModelFormSet):\n     \"\"\"A formset for child objects related to a parent.\"\"\"\n-    def __init__(self, data=None, files=None, instance=None,\n-                 save_as_new=False, prefix=None, queryset=None, **kwargs):\n+\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        instance=None,\n+        save_as_new=False,\n+        prefix=None,\n+        queryset=None,\n+        **kwargs,\n+    ):\n         if instance is None:\n             self.instance = self.fk.remote_field.model()\n         else:\n@@ -927,7 +1105,7 @@ class BaseInlineFormSet(BaseModelFormSet):\n     def _construct_form(self, i, **kwargs):\n         form = super()._construct_form(i, **kwargs)\n         if self.save_as_new:\n-            mutable = getattr(form.data, '_mutable', None)\n+            mutable = getattr(form.data, \"_mutable\", None)\n             # Allow modifying an immutable QueryDict.\n             if mutable is not None:\n                 form.data._mutable = True\n@@ -943,13 +1121,13 @@ class BaseInlineFormSet(BaseModelFormSet):\n         fk_value = self.instance.pk\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n             fk_value = getattr(self.instance, self.fk.remote_field.field_name)\n-            fk_value = getattr(fk_value, 'pk', fk_value)\n+            fk_value = getattr(fk_value, \"pk\", fk_value)\n         setattr(form.instance, self.fk.get_attname(), fk_value)\n         return form\n \n     @classmethod\n     def get_default_prefix(cls):\n-        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace('+', '')\n+        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace(\"+\", \"\")\n \n     def save_new(self, form, commit=True):\n         # Ensure the latest copy of the related instance is present on each\n@@ -962,26 +1140,28 @@ class BaseInlineFormSet(BaseModelFormSet):\n         super().add_fields(form, index)\n         if self._pk_field == self.fk:\n             name = self._pk_field.name\n-            kwargs = {'pk_field': True}\n+            kwargs = {\"pk_field\": True}\n         else:\n             # The foreign key field might not be on the form, so we poke at the\n             # Model field to get the label, since we need that for error messages.\n             name = self.fk.name\n             kwargs = {\n-                'label': getattr(form.fields.get(name), 'label', capfirst(self.fk.verbose_name))\n+                \"label\": getattr(\n+                    form.fields.get(name), \"label\", capfirst(self.fk.verbose_name)\n+                )\n             }\n \n         # The InlineForeignKeyField assumes that the foreign key relation is\n         # based on the parent model's pk. If this isn't the case, set to_field\n         # to correctly resolve the initial form value.\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n-            kwargs['to_field'] = self.fk.remote_field.field_name\n+            kwargs[\"to_field\"] = self.fk.remote_field.field_name\n \n         # If we're adding a new object, ignore a parent's auto-generated key\n         # as it will be regenerated on the save request.\n         if self.instance._state.adding:\n-            if kwargs.get('to_field') is not None:\n-                to_field = self.instance._meta.get_field(kwargs['to_field'])\n+            if kwargs.get(\"to_field\") is not None:\n+                to_field = self.instance._meta.get_field(kwargs[\"to_field\"])\n             else:\n                 to_field = self.instance._meta.pk\n             if to_field.has_default():\n@@ -1004,16 +1184,19 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     \"\"\"\n     # avoid circular import\n     from django.db.models import ForeignKey\n+\n     opts = model._meta\n     if fk_name:\n         fks_to_parent = [f for f in opts.fields if f.name == fk_name]\n         if len(fks_to_parent) == 1:\n             fk = fks_to_parent[0]\n-            if not isinstance(fk, ForeignKey) or \\\n-                    (fk.remote_field.model != parent_model and\n-                     fk.remote_field.model not in parent_model._meta.get_parent_list()):\n+            if not isinstance(fk, ForeignKey) or (\n+                fk.remote_field.model != parent_model\n+                and fk.remote_field.model not in parent_model._meta.get_parent_list()\n+            ):\n                 raise ValueError(\n-                    \"fk_name '%s' is not a ForeignKey to '%s'.\" % (fk_name, parent_model._meta.label)\n+                    \"fk_name '%s' is not a ForeignKey to '%s'.\"\n+                    % (fk_name, parent_model._meta.label)\n                 )\n         elif not fks_to_parent:\n             raise ValueError(\n@@ -1022,10 +1205,12 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     else:\n         # Try to discover what the ForeignKey from model to parent_model is\n         fks_to_parent = [\n-            f for f in opts.fields\n-            if isinstance(f, ForeignKey) and (\n-                f.remote_field.model == parent_model or\n-                f.remote_field.model in parent_model._meta.get_parent_list()\n+            f\n+            for f in opts.fields\n+            if isinstance(f, ForeignKey)\n+            and (\n+                f.remote_field.model == parent_model\n+                or f.remote_field.model in parent_model._meta.get_parent_list()\n             )\n         ]\n         if len(fks_to_parent) == 1:\n@@ -1034,7 +1219,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n             if can_fail:\n                 return\n             raise ValueError(\n-                \"'%s' has no ForeignKey to '%s'.\" % (\n+                \"'%s' has no ForeignKey to '%s'.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1042,7 +1228,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n         else:\n             raise ValueError(\n                 \"'%s' has more than one ForeignKey to '%s'. You must specify \"\n-                \"a 'fk_name' attribute.\" % (\n+                \"a 'fk_name' attribute.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1050,14 +1237,31 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     return fk\n \n \n-def inlineformset_factory(parent_model, model, form=ModelForm,\n-                          formset=BaseInlineFormSet, fk_name=None,\n-                          fields=None, exclude=None, extra=3, can_order=False,\n-                          can_delete=True, max_num=None, formfield_callback=None,\n-                          widgets=None, validate_max=False, localized_fields=None,\n-                          labels=None, help_texts=None, error_messages=None,\n-                          min_num=None, validate_min=False, field_classes=None,\n-                          absolute_max=None, can_delete_extra=True):\n+def inlineformset_factory(\n+    parent_model,\n+    model,\n+    form=ModelForm,\n+    formset=BaseInlineFormSet,\n+    fk_name=None,\n+    fields=None,\n+    exclude=None,\n+    extra=3,\n+    can_order=False,\n+    can_delete=True,\n+    max_num=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+):\n     \"\"\"\n     Return an ``InlineFormSet`` for the given kwargs.\n \n@@ -1069,26 +1273,26 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n     if fk.unique:\n         max_num = 1\n     kwargs = {\n-        'form': form,\n-        'formfield_callback': formfield_callback,\n-        'formset': formset,\n-        'extra': extra,\n-        'can_delete': can_delete,\n-        'can_order': can_order,\n-        'fields': fields,\n-        'exclude': exclude,\n-        'min_num': min_num,\n-        'max_num': max_num,\n-        'widgets': widgets,\n-        'validate_min': validate_min,\n-        'validate_max': validate_max,\n-        'localized_fields': localized_fields,\n-        'labels': labels,\n-        'help_texts': help_texts,\n-        'error_messages': error_messages,\n-        'field_classes': field_classes,\n-        'absolute_max': absolute_max,\n-        'can_delete_extra': can_delete_extra,\n+        \"form\": form,\n+        \"formfield_callback\": formfield_callback,\n+        \"formset\": formset,\n+        \"extra\": extra,\n+        \"can_delete\": can_delete,\n+        \"can_order\": can_order,\n+        \"fields\": fields,\n+        \"exclude\": exclude,\n+        \"min_num\": min_num,\n+        \"max_num\": max_num,\n+        \"widgets\": widgets,\n+        \"validate_min\": validate_min,\n+        \"validate_max\": validate_max,\n+        \"localized_fields\": localized_fields,\n+        \"labels\": labels,\n+        \"help_texts\": help_texts,\n+        \"error_messages\": error_messages,\n+        \"field_classes\": field_classes,\n+        \"absolute_max\": absolute_max,\n+        \"can_delete_extra\": can_delete_extra,\n     }\n     FormSet = modelformset_factory(model, **kwargs)\n     FormSet.fk = fk\n@@ -1097,14 +1301,16 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n \n # Fields #####################################################################\n \n+\n class InlineForeignKeyField(Field):\n     \"\"\"\n     A basic integer field that deals with validating the given value to a\n     given parent instance in an inline.\n     \"\"\"\n+\n     widget = HiddenInput\n     default_error_messages = {\n-        'invalid_choice': _('The inline value did not match the parent instance.'),\n+        \"invalid_choice\": _(\"The inline value did not match the parent instance.\"),\n     }\n \n     def __init__(self, parent_instance, *args, pk_field=False, to_field=None, **kwargs):\n@@ -1131,7 +1337,9 @@ class InlineForeignKeyField(Field):\n         else:\n             orig = self.parent_instance.pk\n         if str(value) != str(orig):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_choice\"], code=\"invalid_choice\"\n+            )\n         return self.parent_instance\n \n     def has_changed(self, initial, data):\n@@ -1185,33 +1393,50 @@ class ModelChoiceIterator:\n \n class ModelChoiceField(ChoiceField):\n     \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n-                            ' the available choices.'),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n     }\n     iterator = ModelChoiceIterator\n \n-    def __init__(self, queryset, *, empty_label=\"---------\",\n-                 required=True, widget=None, label=None, initial=None,\n-                 help_text='', to_field_name=None, limit_choices_to=None,\n-                 blank=False, **kwargs):\n+    def __init__(\n+        self,\n+        queryset,\n+        *,\n+        empty_label=\"---------\",\n+        required=True,\n+        widget=None,\n+        label=None,\n+        initial=None,\n+        help_text=\"\",\n+        to_field_name=None,\n+        limit_choices_to=None,\n+        blank=False,\n+        **kwargs,\n+    ):\n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n         Field.__init__(\n-            self, required=required, widget=widget, label=label,\n-            initial=initial, help_text=help_text, **kwargs\n+            self,\n+            required=required,\n+            widget=widget,\n+            label=label,\n+            initial=initial,\n+            help_text=help_text,\n+            **kwargs,\n         )\n-        if (\n-            (required and initial is not None) or\n-            (isinstance(self.widget, RadioSelect) and not blank)\n+        if (required and initial is not None) or (\n+            isinstance(self.widget, RadioSelect) and not blank\n         ):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n         self.queryset = queryset\n-        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.limit_choices_to = limit_choices_to  # limit the queryset later.\n         self.to_field_name = to_field_name\n \n     def get_limit_choices_to(self):\n@@ -1253,7 +1478,7 @@ class ModelChoiceField(ChoiceField):\n     def _get_choices(self):\n         # If self._choices is set, then somebody must have manually set\n         # the property self.choices. In this case, just return self._choices.\n-        if hasattr(self, '_choices'):\n+        if hasattr(self, \"_choices\"):\n             return self._choices\n \n         # Otherwise, execute the QuerySet in self.queryset to determine the\n@@ -1268,7 +1493,7 @@ class ModelChoiceField(ChoiceField):\n     choices = property(_get_choices, ChoiceField._set_choices)\n \n     def prepare_value(self, value):\n-        if hasattr(value, '_meta'):\n+        if hasattr(value, \"_meta\"):\n             if self.to_field_name:\n                 return value.serializable_value(self.to_field_name)\n             else:\n@@ -1279,12 +1504,16 @@ class ModelChoiceField(ChoiceField):\n         if value in self.empty_values:\n             return None\n         try:\n-            key = self.to_field_name or 'pk'\n+            key = self.to_field_name or \"pk\"\n             if isinstance(value, self.queryset.model):\n                 value = getattr(value, key)\n             value = self.queryset.get(**{key: value})\n         except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n+            )\n         return value\n \n     def validate(self, value):\n@@ -1293,20 +1522,22 @@ class ModelChoiceField(ChoiceField):\n     def has_changed(self, initial, data):\n         if self.disabled:\n             return False\n-        initial_value = initial if initial is not None else ''\n-        data_value = data if data is not None else ''\n+        initial_value = initial if initial is not None else \"\"\n+        data_value = data if data is not None else \"\"\n         return str(self.prepare_value(initial_value)) != str(data_value)\n \n \n class ModelMultipleChoiceField(ModelChoiceField):\n     \"\"\"A MultipleChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     widget = SelectMultiple\n     hidden_widget = MultipleHiddenInput\n     default_error_messages = {\n-        'invalid_list': _('Enter a list of values.'),\n-        'invalid_choice': _('Select a valid choice. %(value)s is not one of the'\n-                            ' available choices.'),\n-        'invalid_pk_value': _('\u201c%(pk)s\u201d is not a valid value.')\n+        \"invalid_list\": _(\"Enter a list of values.\"),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n+        \"invalid_pk_value\": _(\"\u201c%(pk)s\u201d is not a valid value.\"),\n     }\n \n     def __init__(self, queryset, **kwargs):\n@@ -1320,13 +1551,13 @@ class ModelMultipleChoiceField(ModelChoiceField):\n     def clean(self, value):\n         value = self.prepare_value(value)\n         if self.required and not value:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n         elif not self.required and not value:\n             return self.queryset.none()\n         if not isinstance(value, (list, tuple)):\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         qs = self._check_values(value)\n         # Since this overrides the inherited ModelChoiceField.clean\n@@ -1340,7 +1571,7 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         corresponding objects. Raise a ValidationError if a given value is\n         invalid (not a valid PK, not in the queryset, etc.)\n         \"\"\"\n-        key = self.to_field_name or 'pk'\n+        key = self.to_field_name or \"pk\"\n         # deduplicate given values to avoid creating many querysets or\n         # requiring the database backend deduplicate efficiently.\n         try:\n@@ -1348,33 +1579,35 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         except TypeError:\n             # list of lists isn't hashable, for example\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         for pk in value:\n             try:\n                 self.queryset.filter(**{key: pk})\n             except (ValueError, TypeError):\n                 raise ValidationError(\n-                    self.error_messages['invalid_pk_value'],\n-                    code='invalid_pk_value',\n-                    params={'pk': pk},\n+                    self.error_messages[\"invalid_pk_value\"],\n+                    code=\"invalid_pk_value\",\n+                    params={\"pk\": pk},\n                 )\n-        qs = self.queryset.filter(**{'%s__in' % key: value})\n+        qs = self.queryset.filter(**{\"%s__in\" % key: value})\n         pks = {str(getattr(o, key)) for o in qs}\n         for val in value:\n             if str(val) not in pks:\n                 raise ValidationError(\n-                    self.error_messages['invalid_choice'],\n-                    code='invalid_choice',\n-                    params={'value': val},\n+                    self.error_messages[\"invalid_choice\"],\n+                    code=\"invalid_choice\",\n+                    params={\"value\": val},\n                 )\n         return qs\n \n     def prepare_value(self, value):\n-        if (hasattr(value, '__iter__') and\n-                not isinstance(value, str) and\n-                not hasattr(value, '_meta')):\n+        if (\n+            hasattr(value, \"__iter__\")\n+            and not isinstance(value, str)\n+            and not hasattr(value, \"_meta\")\n+        ):\n             prepare_value = super().prepare_value\n             return [prepare_value(v) for v in value]\n         return super().prepare_value(value)\n@@ -1394,7 +1627,6 @@ class ModelMultipleChoiceField(ModelChoiceField):\n \n \n def modelform_defines_fields(form_class):\n-    return hasattr(form_class, '_meta') and (\n-        form_class._meta.fields is not None or\n-        form_class._meta.exclude is not None\n+    return hasattr(form_class, \"_meta\") and (\n+        form_class._meta.fields is not None or form_class._meta.exclude is not None\n     )\n"}
{"instance_id": "django__django-13964", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 2428218696..06b1c32842 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -9,28 +9,48 @@ from django.apps import apps\n from django.conf import settings\n from django.core import checks\n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldDoesNotExist, FieldError, MultipleObjectsReturned,\n-    ObjectDoesNotExist, ValidationError,\n+    NON_FIELD_ERRORS,\n+    FieldDoesNotExist,\n+    FieldError,\n+    MultipleObjectsReturned,\n+    ObjectDoesNotExist,\n+    ValidationError,\n )\n from django.db import (\n-    DEFAULT_DB_ALIAS, DJANGO_VERSION_PICKLE_KEY, DatabaseError, connection,\n-    connections, router, transaction,\n+    DEFAULT_DB_ALIAS,\n+    DJANGO_VERSION_PICKLE_KEY,\n+    DatabaseError,\n+    connection,\n+    connections,\n+    router,\n+    transaction,\n )\n from django.db.models import (\n-    NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value,\n+    NOT_PROVIDED,\n+    ExpressionWrapper,\n+    IntegerField,\n+    Max,\n+    Value,\n )\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.constraints import CheckConstraint, UniqueConstraint\n from django.db.models.deletion import CASCADE, Collector\n from django.db.models.fields.related import (\n-    ForeignObjectRel, OneToOneField, lazy_related_operation, resolve_relation,\n+    ForeignObjectRel,\n+    OneToOneField,\n+    lazy_related_operation,\n+    resolve_relation,\n )\n from django.db.models.functions import Coalesce\n from django.db.models.manager import Manager\n from django.db.models.options import Options\n from django.db.models.query import F, Q\n from django.db.models.signals import (\n-    class_prepared, post_init, post_save, pre_init, pre_save,\n+    class_prepared,\n+    post_init,\n+    post_save,\n+    pre_init,\n+    pre_save,\n )\n from django.db.models.utils import make_model_tuple\n from django.utils.encoding import force_str\n@@ -41,10 +61,10 @@ from django.utils.translation import gettext_lazy as _\n \n class Deferred:\n     def __repr__(self):\n-        return '<Deferred field>'\n+        return \"<Deferred field>\"\n \n     def __str__(self):\n-        return '<Deferred field>'\n+        return \"<Deferred field>\"\n \n \n DEFERRED = Deferred()\n@@ -58,19 +78,24 @@ def subclass_exception(name, bases, module, attached_to):\n     that the returned exception class will be added as an attribute to the\n     'attached_to' class.\n     \"\"\"\n-    return type(name, bases, {\n-        '__module__': module,\n-        '__qualname__': '%s.%s' % (attached_to.__qualname__, name),\n-    })\n+    return type(\n+        name,\n+        bases,\n+        {\n+            \"__module__\": module,\n+            \"__qualname__\": \"%s.%s\" % (attached_to.__qualname__, name),\n+        },\n+    )\n \n \n def _has_contribute_to_class(value):\n     # Only call contribute_to_class() if it's bound.\n-    return not inspect.isclass(value) and hasattr(value, 'contribute_to_class')\n+    return not inspect.isclass(value) and hasattr(value, \"contribute_to_class\")\n \n \n class ModelBase(type):\n     \"\"\"Metaclass for all models.\"\"\"\n+\n     def __new__(cls, name, bases, attrs, **kwargs):\n         super_new = super().__new__\n \n@@ -81,12 +106,12 @@ class ModelBase(type):\n             return super_new(cls, name, bases, attrs)\n \n         # Create the class.\n-        module = attrs.pop('__module__')\n-        new_attrs = {'__module__': module}\n-        classcell = attrs.pop('__classcell__', None)\n+        module = attrs.pop(\"__module__\")\n+        new_attrs = {\"__module__\": module}\n+        classcell = attrs.pop(\"__classcell__\", None)\n         if classcell is not None:\n-            new_attrs['__classcell__'] = classcell\n-        attr_meta = attrs.pop('Meta', None)\n+            new_attrs[\"__classcell__\"] = classcell\n+        attr_meta = attrs.pop(\"Meta\", None)\n         # Pass all attrs without a (Django-specific) contribute_to_class()\n         # method to type.__new__() so that they're properly initialized\n         # (i.e. __set_name__()).\n@@ -98,16 +123,16 @@ class ModelBase(type):\n                 new_attrs[obj_name] = obj\n         new_class = super_new(cls, name, bases, new_attrs, **kwargs)\n \n-        abstract = getattr(attr_meta, 'abstract', False)\n-        meta = attr_meta or getattr(new_class, 'Meta', None)\n-        base_meta = getattr(new_class, '_meta', None)\n+        abstract = getattr(attr_meta, \"abstract\", False)\n+        meta = attr_meta or getattr(new_class, \"Meta\", None)\n+        base_meta = getattr(new_class, \"_meta\", None)\n \n         app_label = None\n \n         # Look for an application configuration to attach the model to.\n         app_config = apps.get_containing_app_config(module)\n \n-        if getattr(meta, 'app_label', None) is None:\n+        if getattr(meta, \"app_label\", None) is None:\n             if app_config is None:\n                 if not abstract:\n                     raise RuntimeError(\n@@ -119,33 +144,43 @@ class ModelBase(type):\n             else:\n                 app_label = app_config.label\n \n-        new_class.add_to_class('_meta', Options(meta, app_label))\n+        new_class.add_to_class(\"_meta\", Options(meta, app_label))\n         if not abstract:\n             new_class.add_to_class(\n-                'DoesNotExist',\n+                \"DoesNotExist\",\n                 subclass_exception(\n-                    'DoesNotExist',\n+                    \"DoesNotExist\",\n                     tuple(\n-                        x.DoesNotExist for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n-                    ) or (ObjectDoesNotExist,),\n+                        x.DoesNotExist\n+                        for x in parents\n+                        if hasattr(x, \"_meta\") and not x._meta.abstract\n+                    )\n+                    or (ObjectDoesNotExist,),\n                     module,\n-                    attached_to=new_class))\n+                    attached_to=new_class,\n+                ),\n+            )\n             new_class.add_to_class(\n-                'MultipleObjectsReturned',\n+                \"MultipleObjectsReturned\",\n                 subclass_exception(\n-                    'MultipleObjectsReturned',\n+                    \"MultipleObjectsReturned\",\n                     tuple(\n-                        x.MultipleObjectsReturned for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n-                    ) or (MultipleObjectsReturned,),\n+                        x.MultipleObjectsReturned\n+                        for x in parents\n+                        if hasattr(x, \"_meta\") and not x._meta.abstract\n+                    )\n+                    or (MultipleObjectsReturned,),\n                     module,\n-                    attached_to=new_class))\n+                    attached_to=new_class,\n+                ),\n+            )\n             if base_meta and not base_meta.abstract:\n                 # Non-abstract child classes inherit some attributes from their\n                 # non-abstract parent (unless an ABC comes before it in the\n                 # method resolution order).\n-                if not hasattr(meta, 'ordering'):\n+                if not hasattr(meta, \"ordering\"):\n                     new_class._meta.ordering = base_meta.ordering\n-                if not hasattr(meta, 'get_latest_by'):\n+                if not hasattr(meta, \"get_latest_by\"):\n                     new_class._meta.get_latest_by = base_meta.get_latest_by\n \n         is_proxy = new_class._meta.proxy\n@@ -153,7 +188,9 @@ class ModelBase(type):\n         # If the model is a proxy, ensure that the base class\n         # hasn't been swapped out.\n         if is_proxy and base_meta and base_meta.swapped:\n-            raise TypeError(\"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped))\n+            raise TypeError(\n+                \"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped)\n+            )\n \n         # Add remaining attributes (those with a contribute_to_class() method)\n         # to the class.\n@@ -164,14 +201,14 @@ class ModelBase(type):\n         new_fields = chain(\n             new_class._meta.local_fields,\n             new_class._meta.local_many_to_many,\n-            new_class._meta.private_fields\n+            new_class._meta.private_fields,\n         )\n         field_names = {f.name for f in new_fields}\n \n         # Basic setup for proxy models.\n         if is_proxy:\n             base = None\n-            for parent in [kls for kls in parents if hasattr(kls, '_meta')]:\n+            for parent in [kls for kls in parents if hasattr(kls, \"_meta\")]:\n                 if parent._meta.abstract:\n                     if parent._meta.fields:\n                         raise TypeError(\n@@ -183,9 +220,14 @@ class ModelBase(type):\n                 if base is None:\n                     base = parent\n                 elif parent._meta.concrete_model is not base._meta.concrete_model:\n-                    raise TypeError(\"Proxy model '%s' has more than one non-abstract model base class.\" % name)\n+                    raise TypeError(\n+                        \"Proxy model '%s' has more than one non-abstract model base class.\"\n+                        % name\n+                    )\n             if base is None:\n-                raise TypeError(\"Proxy model '%s' has no non-abstract model base class.\" % name)\n+                raise TypeError(\n+                    \"Proxy model '%s' has no non-abstract model base class.\" % name\n+                )\n             new_class._meta.setup_proxy(base)\n             new_class._meta.concrete_model = base._meta.concrete_model\n         else:\n@@ -195,7 +237,7 @@ class ModelBase(type):\n         parent_links = {}\n         for base in reversed([new_class] + parents):\n             # Conceptually equivalent to `if base is Model`.\n-            if not hasattr(base, '_meta'):\n+            if not hasattr(base, \"_meta\"):\n                 continue\n             # Skip concrete parent classes.\n             if base != new_class and not base._meta.abstract:\n@@ -210,7 +252,7 @@ class ModelBase(type):\n         inherited_attributes = set()\n         # Do the appropriate setup for any model parents.\n         for base in new_class.mro():\n-            if base not in parents or not hasattr(base, '_meta'):\n+            if base not in parents or not hasattr(base, \"_meta\"):\n                 # Things without _meta aren't functional models, so they're\n                 # uninteresting parents.\n                 inherited_attributes.update(base.__dict__)\n@@ -223,8 +265,9 @@ class ModelBase(type):\n                 for field in parent_fields:\n                     if field.name in field_names:\n                         raise FieldError(\n-                            'Local field %r in class %r clashes with field of '\n-                            'the same name from base class %r.' % (\n+                            \"Local field %r in class %r clashes with field of \"\n+                            \"the same name from base class %r.\"\n+                            % (\n                                 field.name,\n                                 name,\n                                 base.__name__,\n@@ -239,7 +282,7 @@ class ModelBase(type):\n                 if base_key in parent_links:\n                     field = parent_links[base_key]\n                 elif not is_proxy:\n-                    attr_name = '%s_ptr' % base._meta.model_name\n+                    attr_name = \"%s_ptr\" % base._meta.model_name\n                     field = OneToOneField(\n                         base,\n                         on_delete=CASCADE,\n@@ -252,7 +295,8 @@ class ModelBase(type):\n                         raise FieldError(\n                             \"Auto-generated field '%s' in class %r for \"\n                             \"parent_link to base class %r clashes with \"\n-                            \"declared field of the same name.\" % (\n+                            \"declared field of the same name.\"\n+                            % (\n                                 attr_name,\n                                 name,\n                                 base.__name__,\n@@ -271,9 +315,11 @@ class ModelBase(type):\n \n                 # Add fields from abstract base class if it wasn't overridden.\n                 for field in parent_fields:\n-                    if (field.name not in field_names and\n-                            field.name not in new_class.__dict__ and\n-                            field.name not in inherited_attributes):\n+                    if (\n+                        field.name not in field_names\n+                        and field.name not in new_class.__dict__\n+                        and field.name not in inherited_attributes\n+                    ):\n                         new_field = copy.deepcopy(field)\n                         new_class.add_to_class(field.name, new_field)\n                         # Replace parent links defined on this base by the new\n@@ -292,8 +338,9 @@ class ModelBase(type):\n                 if field.name in field_names:\n                     if not base._meta.abstract:\n                         raise FieldError(\n-                            'Local field %r in class %r clashes with field of '\n-                            'the same name from base class %r.' % (\n+                            \"Local field %r in class %r clashes with field of \"\n+                            \"the same name from base class %r.\"\n+                            % (\n                                 field.name,\n                                 name,\n                                 base.__name__,\n@@ -307,7 +354,9 @@ class ModelBase(type):\n \n         # Copy indexes so that index names are unique when models extend an\n         # abstract model.\n-        new_class._meta.indexes = [copy.deepcopy(idx) for idx in new_class._meta.indexes]\n+        new_class._meta.indexes = [\n+            copy.deepcopy(idx) for idx in new_class._meta.indexes\n+        ]\n \n         if abstract:\n             # Abstract base models can't be instantiated and don't appear in\n@@ -333,8 +382,12 @@ class ModelBase(type):\n         opts._prepare(cls)\n \n         if opts.order_with_respect_to:\n-            cls.get_next_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=True)\n-            cls.get_previous_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=False)\n+            cls.get_next_in_order = partialmethod(\n+                cls._get_next_or_previous_in_order, is_next=True\n+            )\n+            cls.get_previous_in_order = partialmethod(\n+                cls._get_next_or_previous_in_order, is_next=False\n+            )\n \n             # Defer creating accessors on the foreign class until it has been\n             # created and registered. If remote_field is None, we're ordering\n@@ -348,21 +401,26 @@ class ModelBase(type):\n \n         # Give the class a docstring -- its definition.\n         if cls.__doc__ is None:\n-            cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n+            cls.__doc__ = \"%s(%s)\" % (\n+                cls.__name__,\n+                \", \".join(f.name for f in opts.fields),\n+            )\n \n-        get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(opts.label_lower)\n+        get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(\n+            opts.label_lower\n+        )\n         if get_absolute_url_override:\n-            setattr(cls, 'get_absolute_url', get_absolute_url_override)\n+            setattr(cls, \"get_absolute_url\", get_absolute_url_override)\n \n         if not opts.managers:\n-            if any(f.name == 'objects' for f in opts.fields):\n+            if any(f.name == \"objects\" for f in opts.fields):\n                 raise ValueError(\n                     \"Model %s must specify a custom Manager, because it has a \"\n                     \"field named 'objects'.\" % cls.__name__\n                 )\n             manager = Manager()\n             manager.auto_created = True\n-            cls.add_to_class('objects', manager)\n+            cls.add_to_class(\"objects\", manager)\n \n         # Set the name of _meta.indexes. This can't be done in\n         # Options.contribute_to_class() because fields haven't been added to\n@@ -392,6 +450,7 @@ class ModelStateFieldsCacheDescriptor:\n \n class ModelState:\n     \"\"\"Store model instance state.\"\"\"\n+\n     db = None\n     # If true, uniqueness validation checks will consider this a new, unsaved\n     # object. Necessary for correct validation of new instances of objects with\n@@ -402,7 +461,6 @@ class ModelState:\n \n \n class Model(metaclass=ModelBase):\n-\n     def __init__(self, *args, **kwargs):\n         # Alias some things as locals to avoid repeat global lookups\n         cls = self.__class__\n@@ -410,7 +468,7 @@ class Model(metaclass=ModelBase):\n         _setattr = setattr\n         _DEFERRED = DEFERRED\n         if opts.abstract:\n-            raise TypeError('Abstract models cannot be instantiated.')\n+            raise TypeError(\"Abstract models cannot be instantiated.\")\n \n         pre_init.send(sender=cls, args=args, kwargs=kwargs)\n \n@@ -500,7 +558,10 @@ class Model(metaclass=ModelBase):\n                 except (AttributeError, FieldDoesNotExist):\n                     pass\n             for kwarg in kwargs:\n-                raise TypeError(\"%s() got an unexpected keyword argument '%s'\" % (cls.__name__, kwarg))\n+                raise TypeError(\n+                    \"%s() got an unexpected keyword argument '%s'\"\n+                    % (cls.__name__, kwarg)\n+                )\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n \n@@ -518,10 +579,10 @@ class Model(metaclass=ModelBase):\n         return new\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def __str__(self):\n-        return '%s object (%s)' % (self.__class__.__name__, self.pk)\n+        return \"%s object (%s)\" % (self.__class__.__name__, self.pk)\n \n     def __eq__(self, other):\n         if not isinstance(other, Model):\n@@ -547,8 +608,8 @@ class Model(metaclass=ModelBase):\n     def __getstate__(self):\n         \"\"\"Hook to allow choosing the attributes to pickle.\"\"\"\n         state = self.__dict__.copy()\n-        state['_state'] = copy.copy(state['_state'])\n-        state['_state'].fields_cache = state['_state'].fields_cache.copy()\n+        state[\"_state\"] = copy.copy(state[\"_state\"])\n+        state[\"_state\"].fields_cache = state[\"_state\"].fields_cache.copy()\n         return state\n \n     def __setstate__(self, state):\n@@ -587,7 +648,8 @@ class Model(metaclass=ModelBase):\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n         return {\n-            f.attname for f in self._meta.concrete_fields\n+            f.attname\n+            for f in self._meta.concrete_fields\n             if f.attname not in self.__dict__\n         }\n \n@@ -609,7 +671,7 @@ class Model(metaclass=ModelBase):\n         if fields is None:\n             self._prefetched_objects_cache = {}\n         else:\n-            prefetched_objects_cache = getattr(self, '_prefetched_objects_cache', ())\n+            prefetched_objects_cache = getattr(self, \"_prefetched_objects_cache\", ())\n             for field in fields:\n                 if field in prefetched_objects_cache:\n                     del prefetched_objects_cache[field]\n@@ -619,10 +681,13 @@ class Model(metaclass=ModelBase):\n             if any(LOOKUP_SEP in f for f in fields):\n                 raise ValueError(\n                     'Found \"%s\" in fields argument. Relations and transforms '\n-                    'are not allowed in fields.' % LOOKUP_SEP)\n+                    \"are not allowed in fields.\" % LOOKUP_SEP\n+                )\n \n-        hints = {'instance': self}\n-        db_instance_qs = self.__class__._base_manager.db_manager(using, hints=hints).filter(pk=self.pk)\n+        hints = {\"instance\": self}\n+        db_instance_qs = self.__class__._base_manager.db_manager(\n+            using, hints=hints\n+        ).filter(pk=self.pk)\n \n         # Use provided fields, if not set then reload all non-deferred fields.\n         deferred_fields = self.get_deferred_fields()\n@@ -630,8 +695,11 @@ class Model(metaclass=ModelBase):\n             fields = list(fields)\n             db_instance_qs = db_instance_qs.only(*fields)\n         elif deferred_fields:\n-            fields = [f.attname for f in self._meta.concrete_fields\n-                      if f.attname not in deferred_fields]\n+            fields = [\n+                f.attname\n+                for f in self._meta.concrete_fields\n+                if f.attname not in deferred_fields\n+            ]\n             db_instance_qs = db_instance_qs.only(*fields)\n \n         db_instance = db_instance_qs.get()\n@@ -669,8 +737,9 @@ class Model(metaclass=ModelBase):\n             return getattr(self, field_name)\n         return getattr(self, field.attname)\n \n-    def save(self, force_insert=False, force_update=False, using=None,\n-             update_fields=None):\n+    def save(\n+        self, force_insert=False, force_update=False, using=None, update_fields=None\n+    ):\n         \"\"\"\n         Save the current instance. Override this in a subclass if you want to\n         control the saving process.\n@@ -679,7 +748,7 @@ class Model(metaclass=ModelBase):\n         that the \"save\" must be an SQL insert or update (or equivalent for\n         non-SQL backends), respectively. Normally, they should not be set.\n         \"\"\"\n-        self._prepare_related_fields_for_save(operation_name='save')\n+        self._prepare_related_fields_for_save(operation_name=\"save\")\n \n         using = using or router.db_for_write(self.__class__, instance=self)\n         if force_insert and (force_update or update_fields):\n@@ -707,9 +776,9 @@ class Model(metaclass=ModelBase):\n \n             if non_model_fields:\n                 raise ValueError(\n-                    'The following fields do not exist in this model, are m2m '\n-                    'fields, or are non-concrete fields: %s'\n-                    % ', '.join(non_model_fields)\n+                    \"The following fields do not exist in this model, are m2m \"\n+                    \"fields, or are non-concrete fields: %s\"\n+                    % \", \".join(non_model_fields)\n                 )\n \n         # If saving to the same database, and this model is deferred, then\n@@ -717,18 +786,29 @@ class Model(metaclass=ModelBase):\n         elif not force_insert and deferred_fields and using == self._state.db:\n             field_names = set()\n             for field in self._meta.concrete_fields:\n-                if not field.primary_key and not hasattr(field, 'through'):\n+                if not field.primary_key and not hasattr(field, \"through\"):\n                     field_names.add(field.attname)\n             loaded_fields = field_names.difference(deferred_fields)\n             if loaded_fields:\n                 update_fields = frozenset(loaded_fields)\n \n-        self.save_base(using=using, force_insert=force_insert,\n-                       force_update=force_update, update_fields=update_fields)\n+        self.save_base(\n+            using=using,\n+            force_insert=force_insert,\n+            force_update=force_update,\n+            update_fields=update_fields,\n+        )\n+\n     save.alters_data = True\n \n-    def save_base(self, raw=False, force_insert=False,\n-                  force_update=False, using=None, update_fields=None):\n+    def save_base(\n+        self,\n+        raw=False,\n+        force_insert=False,\n+        force_update=False,\n+        using=None,\n+        update_fields=None,\n+    ):\n         \"\"\"\n         Handle the parts of saving which should be done only once per save,\n         yet need to be done in raw saves, too. This includes some sanity\n@@ -748,7 +828,10 @@ class Model(metaclass=ModelBase):\n         meta = cls._meta\n         if not meta.auto_created:\n             pre_save.send(\n-                sender=origin, instance=self, raw=raw, using=using,\n+                sender=origin,\n+                instance=self,\n+                raw=raw,\n+                using=using,\n                 update_fields=update_fields,\n             )\n         # A transaction isn't needed if one query is issued.\n@@ -761,8 +844,12 @@ class Model(metaclass=ModelBase):\n             if not raw:\n                 parent_inserted = self._save_parents(cls, using, update_fields)\n             updated = self._save_table(\n-                raw, cls, force_insert or parent_inserted,\n-                force_update, using, update_fields,\n+                raw,\n+                cls,\n+                force_insert or parent_inserted,\n+                force_update,\n+                using,\n+                update_fields,\n             )\n         # Store the database on which the object was saved\n         self._state.db = using\n@@ -772,8 +859,12 @@ class Model(metaclass=ModelBase):\n         # Signal that the save is complete\n         if not meta.auto_created:\n             post_save.send(\n-                sender=origin, instance=self, created=(not updated),\n-                update_fields=update_fields, raw=raw, using=using,\n+                sender=origin,\n+                instance=self,\n+                created=(not updated),\n+                update_fields=update_fields,\n+                raw=raw,\n+                using=using,\n             )\n \n     save_base.alters_data = True\n@@ -784,12 +875,19 @@ class Model(metaclass=ModelBase):\n         inserted = False\n         for parent, field in meta.parents.items():\n             # Make sure the link fields are synced between parent and self.\n-            if (field and getattr(self, parent._meta.pk.attname) is None and\n-                    getattr(self, field.attname) is not None):\n+            if (\n+                field\n+                and getattr(self, parent._meta.pk.attname) is None\n+                and getattr(self, field.attname) is not None\n+            ):\n                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n-            parent_inserted = self._save_parents(cls=parent, using=using, update_fields=update_fields)\n+            parent_inserted = self._save_parents(\n+                cls=parent, using=using, update_fields=update_fields\n+            )\n             updated = self._save_table(\n-                cls=parent, using=using, update_fields=update_fields,\n+                cls=parent,\n+                using=using,\n+                update_fields=update_fields,\n                 force_insert=parent_inserted,\n             )\n             if not updated:\n@@ -806,8 +904,15 @@ class Model(metaclass=ModelBase):\n                     field.delete_cached_value(self)\n         return inserted\n \n-    def _save_table(self, raw=False, cls=None, force_insert=False,\n-                    force_update=False, using=None, update_fields=None):\n+    def _save_table(\n+        self,\n+        raw=False,\n+        cls=None,\n+        force_insert=False,\n+        force_update=False,\n+        using=None,\n+        update_fields=None,\n+    ):\n         \"\"\"\n         Do the heavy-lifting involved in saving. Update or insert the data\n         for a single table.\n@@ -816,8 +921,11 @@ class Model(metaclass=ModelBase):\n         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]\n \n         if update_fields:\n-            non_pks = [f for f in non_pks\n-                       if f.name in update_fields or f.attname in update_fields]\n+            non_pks = [\n+                f\n+                for f in non_pks\n+                if f.name in update_fields or f.attname in update_fields\n+            ]\n \n         pk_val = self._get_pk_val(meta)\n         if pk_val is None:\n@@ -829,21 +937,28 @@ class Model(metaclass=ModelBase):\n         updated = False\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n-            not raw and\n-            not force_insert and\n-            self._state.adding and\n-            meta.pk.default and\n-            meta.pk.default is not NOT_PROVIDED\n+            not raw\n+            and not force_insert\n+            and self._state.adding\n+            and meta.pk.default\n+            and meta.pk.default is not NOT_PROVIDED\n         ):\n             force_insert = True\n         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n         if pk_set and not force_insert:\n             base_qs = cls._base_manager.using(using)\n-            values = [(f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False)))\n-                      for f in non_pks]\n+            values = [\n+                (\n+                    f,\n+                    None,\n+                    (getattr(self, f.attname) if raw else f.pre_save(self, False)),\n+                )\n+                for f in non_pks\n+            ]\n             forced_update = update_fields or force_update\n-            updated = self._do_update(base_qs, using, pk_val, values, update_fields,\n-                                      forced_update)\n+            updated = self._do_update(\n+                base_qs, using, pk_val, values, update_fields, forced_update\n+            )\n             if force_update and not updated:\n                 raise DatabaseError(\"Forced update did not affect any rows.\")\n             if update_fields and not updated:\n@@ -854,18 +969,26 @@ class Model(metaclass=ModelBase):\n                 # autopopulate the _order field\n                 field = meta.order_with_respect_to\n                 filter_args = field.get_filter_kwargs_for_object(self)\n-                self._order = cls._base_manager.using(using).filter(**filter_args).aggregate(\n-                    _order__max=Coalesce(\n-                        ExpressionWrapper(Max('_order') + Value(1), output_field=IntegerField()),\n-                        Value(0),\n-                    ),\n-                )['_order__max']\n+                self._order = (\n+                    cls._base_manager.using(using)\n+                    .filter(**filter_args)\n+                    .aggregate(\n+                        _order__max=Coalesce(\n+                            ExpressionWrapper(\n+                                Max(\"_order\") + Value(1), output_field=IntegerField()\n+                            ),\n+                            Value(0),\n+                        ),\n+                    )[\"_order__max\"]\n+                )\n             fields = meta.local_concrete_fields\n             if not pk_set:\n                 fields = [f for f in fields if f is not meta.auto_field]\n \n             returning_fields = meta.db_returning_fields\n-            results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)\n+            results = self._do_insert(\n+                cls._base_manager, using, fields, returning_fields, raw\n+            )\n             if results:\n                 for value, field in zip(results[0], returning_fields):\n                     setattr(self, field.attname, value)\n@@ -886,7 +1009,8 @@ class Model(metaclass=ModelBase):\n             return update_fields is not None or filtered.exists()\n         if self._meta.select_on_save and not forced_update:\n             return (\n-                filtered.exists() and\n+                filtered.exists()\n+                and\n                 # It may happen that the object is deleted from the DB right after\n                 # this check, causing the subsequent UPDATE to return zero matching\n                 # rows. The same result can occur in some rare cases when the\n@@ -904,8 +1028,11 @@ class Model(metaclass=ModelBase):\n         return the newly created data for the model.\n         \"\"\"\n         return manager._insert(\n-            [self], fields=fields, returning_fields=returning_fields,\n-            using=using, raw=raw,\n+            [self],\n+            fields=fields,\n+            returning_fields=returning_fields,\n+            using=using,\n+            raw=raw,\n         )\n \n     def _prepare_related_fields_for_save(self, operation_name):\n@@ -938,15 +1065,18 @@ class Model(metaclass=ModelBase):\n                     # an assignment.\n                     setattr(self, field.attname, obj.pk)\n                 # If the relationship's pk/to_field was changed, clear the\n-                # cached relationship.\n-                if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n+                # cached relationship and update the FK value.\n+                if getattr(obj, field.target_field.attname) != getattr(\n+                    self, field.attname\n+                ):\n+                    setattr(self, field.attname, obj.pk)\n                     field.delete_cached_value(self)\n \n     def delete(self, using=None, keep_parents=False):\n         using = using or router.db_for_write(self.__class__, instance=self)\n         assert self.pk is not None, (\n-            \"%s object can't be deleted because its %s attribute is set to None.\" %\n-            (self._meta.object_name, self._meta.pk.attname)\n+            \"%s object can't be deleted because its %s attribute is set to None.\"\n+            % (self._meta.object_name, self._meta.pk.attname)\n         )\n \n         collector = Collector(using=using)\n@@ -959,42 +1089,58 @@ class Model(metaclass=ModelBase):\n         value = getattr(self, field.attname)\n         choices_dict = dict(make_hashable(field.flatchoices))\n         # force_str() to coerce lazy strings.\n-        return force_str(choices_dict.get(make_hashable(value), value), strings_only=True)\n+        return force_str(\n+            choices_dict.get(make_hashable(value), value), strings_only=True\n+        )\n \n     def _get_next_or_previous_by_FIELD(self, field, is_next, **kwargs):\n         if not self.pk:\n             raise ValueError(\"get_next/get_previous cannot be used on unsaved objects.\")\n-        op = 'gt' if is_next else 'lt'\n-        order = '' if is_next else '-'\n+        op = \"gt\" if is_next else \"lt\"\n+        order = \"\" if is_next else \"-\"\n         param = getattr(self, field.attname)\n-        q = Q(**{'%s__%s' % (field.name, op): param})\n-        q = q | Q(**{field.name: param, 'pk__%s' % op: self.pk})\n-        qs = self.__class__._default_manager.using(self._state.db).filter(**kwargs).filter(q).order_by(\n-            '%s%s' % (order, field.name), '%spk' % order\n+        q = Q(**{\"%s__%s\" % (field.name, op): param})\n+        q = q | Q(**{field.name: param, \"pk__%s\" % op: self.pk})\n+        qs = (\n+            self.__class__._default_manager.using(self._state.db)\n+            .filter(**kwargs)\n+            .filter(q)\n+            .order_by(\"%s%s\" % (order, field.name), \"%spk\" % order)\n         )\n         try:\n             return qs[0]\n         except IndexError:\n-            raise self.DoesNotExist(\"%s matching query does not exist.\" % self.__class__._meta.object_name)\n+            raise self.DoesNotExist(\n+                \"%s matching query does not exist.\" % self.__class__._meta.object_name\n+            )\n \n     def _get_next_or_previous_in_order(self, is_next):\n         cachename = \"__%s_order_cache\" % is_next\n         if not hasattr(self, cachename):\n-            op = 'gt' if is_next else 'lt'\n-            order = '_order' if is_next else '-_order'\n+            op = \"gt\" if is_next else \"lt\"\n+            order = \"_order\" if is_next else \"-_order\"\n             order_field = self._meta.order_with_respect_to\n             filter_args = order_field.get_filter_kwargs_for_object(self)\n-            obj = self.__class__._default_manager.filter(**filter_args).filter(**{\n-                '_order__%s' % op: self.__class__._default_manager.values('_order').filter(**{\n-                    self._meta.pk.name: self.pk\n-                })\n-            }).order_by(order)[:1].get()\n+            obj = (\n+                self.__class__._default_manager.filter(**filter_args)\n+                .filter(\n+                    **{\n+                        \"_order__%s\" % op: self.__class__._default_manager.values(\n+                            \"_order\"\n+                        ).filter(**{self._meta.pk.name: self.pk})\n+                    }\n+                )\n+                .order_by(order)[:1]\n+                .get()\n+            )\n             setattr(self, cachename, obj)\n         return getattr(self, cachename)\n \n     def prepare_database_save(self, field):\n         if self.pk is None:\n-            raise ValueError(\"Unsaved model instance %r cannot be used in an ORM query.\" % self)\n+            raise ValueError(\n+                \"Unsaved model instance %r cannot be used in an ORM query.\" % self\n+            )\n         return getattr(self, field.remote_field.get_related_field().attname)\n \n     def clean(self):\n@@ -1038,7 +1184,9 @@ class Model(metaclass=ModelBase):\n         constraints = [(self.__class__, self._meta.total_unique_constraints)]\n         for parent_class in self._meta.get_parent_list():\n             if parent_class._meta.unique_together:\n-                unique_togethers.append((parent_class, parent_class._meta.unique_together))\n+                unique_togethers.append(\n+                    (parent_class, parent_class._meta.unique_together)\n+                )\n             if parent_class._meta.total_unique_constraints:\n                 constraints.append(\n                     (parent_class, parent_class._meta.total_unique_constraints)\n@@ -1073,11 +1221,11 @@ class Model(metaclass=ModelBase):\n                 if f.unique:\n                     unique_checks.append((model_class, (name,)))\n                 if f.unique_for_date and f.unique_for_date not in exclude:\n-                    date_checks.append((model_class, 'date', name, f.unique_for_date))\n+                    date_checks.append((model_class, \"date\", name, f.unique_for_date))\n                 if f.unique_for_year and f.unique_for_year not in exclude:\n-                    date_checks.append((model_class, 'year', name, f.unique_for_year))\n+                    date_checks.append((model_class, \"year\", name, f.unique_for_year))\n                 if f.unique_for_month and f.unique_for_month not in exclude:\n-                    date_checks.append((model_class, 'month', name, f.unique_for_month))\n+                    date_checks.append((model_class, \"month\", name, f.unique_for_month))\n         return unique_checks, date_checks\n \n     def _perform_unique_checks(self, unique_checks):\n@@ -1092,8 +1240,10 @@ class Model(metaclass=ModelBase):\n                 f = self._meta.get_field(field_name)\n                 lookup_value = getattr(self, f.attname)\n                 # TODO: Handle multiple backends with different feature flags.\n-                if (lookup_value is None or\n-                        (lookup_value == '' and connection.features.interprets_empty_strings_as_nulls)):\n+                if lookup_value is None or (\n+                    lookup_value == \"\"\n+                    and connection.features.interprets_empty_strings_as_nulls\n+                ):\n                     # no value, skip the lookup\n                     continue\n                 if f.primary_key and not self._state.adding:\n@@ -1121,7 +1271,9 @@ class Model(metaclass=ModelBase):\n                     key = unique_check[0]\n                 else:\n                     key = NON_FIELD_ERRORS\n-                errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))\n+                errors.setdefault(key, []).append(\n+                    self.unique_error_message(model_class, unique_check)\n+                )\n \n         return errors\n \n@@ -1134,12 +1286,14 @@ class Model(metaclass=ModelBase):\n             date = getattr(self, unique_for)\n             if date is None:\n                 continue\n-            if lookup_type == 'date':\n-                lookup_kwargs['%s__day' % unique_for] = date.day\n-                lookup_kwargs['%s__month' % unique_for] = date.month\n-                lookup_kwargs['%s__year' % unique_for] = date.year\n+            if lookup_type == \"date\":\n+                lookup_kwargs[\"%s__day\" % unique_for] = date.day\n+                lookup_kwargs[\"%s__month\" % unique_for] = date.month\n+                lookup_kwargs[\"%s__year\" % unique_for] = date.year\n             else:\n-                lookup_kwargs['%s__%s' % (unique_for, lookup_type)] = getattr(date, lookup_type)\n+                lookup_kwargs[\"%s__%s\" % (unique_for, lookup_type)] = getattr(\n+                    date, lookup_type\n+                )\n             lookup_kwargs[field] = getattr(self, field)\n \n             qs = model_class._default_manager.filter(**lookup_kwargs)\n@@ -1158,46 +1312,48 @@ class Model(metaclass=ModelBase):\n         opts = self._meta\n         field = opts.get_field(field_name)\n         return ValidationError(\n-            message=field.error_messages['unique_for_date'],\n-            code='unique_for_date',\n+            message=field.error_messages[\"unique_for_date\"],\n+            code=\"unique_for_date\",\n             params={\n-                'model': self,\n-                'model_name': capfirst(opts.verbose_name),\n-                'lookup_type': lookup_type,\n-                'field': field_name,\n-                'field_label': capfirst(field.verbose_name),\n-                'date_field': unique_for,\n-                'date_field_label': capfirst(opts.get_field(unique_for).verbose_name),\n-            }\n+                \"model\": self,\n+                \"model_name\": capfirst(opts.verbose_name),\n+                \"lookup_type\": lookup_type,\n+                \"field\": field_name,\n+                \"field_label\": capfirst(field.verbose_name),\n+                \"date_field\": unique_for,\n+                \"date_field_label\": capfirst(opts.get_field(unique_for).verbose_name),\n+            },\n         )\n \n     def unique_error_message(self, model_class, unique_check):\n         opts = model_class._meta\n \n         params = {\n-            'model': self,\n-            'model_class': model_class,\n-            'model_name': capfirst(opts.verbose_name),\n-            'unique_check': unique_check,\n+            \"model\": self,\n+            \"model_class\": model_class,\n+            \"model_name\": capfirst(opts.verbose_name),\n+            \"unique_check\": unique_check,\n         }\n \n         # A unique field\n         if len(unique_check) == 1:\n             field = opts.get_field(unique_check[0])\n-            params['field_label'] = capfirst(field.verbose_name)\n+            params[\"field_label\"] = capfirst(field.verbose_name)\n             return ValidationError(\n-                message=field.error_messages['unique'],\n-                code='unique',\n+                message=field.error_messages[\"unique\"],\n+                code=\"unique\",\n                 params=params,\n             )\n \n         # unique_together\n         else:\n-            field_labels = [capfirst(opts.get_field(f).verbose_name) for f in unique_check]\n-            params['field_labels'] = get_text_list(field_labels, _('and'))\n+            field_labels = [\n+                capfirst(opts.get_field(f).verbose_name) for f in unique_check\n+            ]\n+            params[\"field_labels\"] = get_text_list(field_labels, _(\"and\"))\n             return ValidationError(\n                 message=_(\"%(model_name)s with this %(field_labels)s already exists.\"),\n-                code='unique_together',\n+                code=\"unique_together\",\n                 params=params,\n             )\n \n@@ -1264,9 +1420,13 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def check(cls, **kwargs):\n-        errors = [*cls._check_swappable(), *cls._check_model(), *cls._check_managers(**kwargs)]\n+        errors = [\n+            *cls._check_swappable(),\n+            *cls._check_model(),\n+            *cls._check_managers(**kwargs),\n+        ]\n         if not cls._meta.swapped:\n-            databases = kwargs.get('databases') or []\n+            databases = kwargs.get(\"databases\") or []\n             errors += [\n                 *cls._check_fields(**kwargs),\n                 *cls._check_m2m_through_same_relationship(),\n@@ -1298,14 +1458,15 @@ class Model(metaclass=ModelBase):\n     @classmethod\n     def _check_default_pk(cls):\n         if (\n-            cls._meta.pk.auto_created and\n+            cls._meta.pk.auto_created\n+            and\n             # Inherited PKs are checked in parents models.\n             not (\n-                isinstance(cls._meta.pk, OneToOneField) and\n-                cls._meta.pk.remote_field.parent_link\n-            ) and\n-            not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n-            not cls._meta.app_config._is_default_auto_field_overridden\n+                isinstance(cls._meta.pk, OneToOneField)\n+                and cls._meta.pk.remote_field.parent_link\n+            )\n+            and not settings.is_overridden(\"DEFAULT_AUTO_FIELD\")\n+            and not cls._meta.app_config._is_default_auto_field_overridden\n         ):\n             return [\n                 checks.Warning(\n@@ -1319,7 +1480,7 @@ class Model(metaclass=ModelBase):\n                         f\"of AutoField, e.g. 'django.db.models.BigAutoField'.\"\n                     ),\n                     obj=cls,\n-                    id='models.W042',\n+                    id=\"models.W042\",\n                 ),\n             ]\n         return []\n@@ -1334,19 +1495,19 @@ class Model(metaclass=ModelBase):\n             except ValueError:\n                 errors.append(\n                     checks.Error(\n-                        \"'%s' is not of the form 'app_label.app_name'.\" % cls._meta.swappable,\n-                        id='models.E001',\n+                        \"'%s' is not of the form 'app_label.app_name'.\"\n+                        % cls._meta.swappable,\n+                        id=\"models.E001\",\n                     )\n                 )\n             except LookupError:\n-                app_label, model_name = cls._meta.swapped.split('.')\n+                app_label, model_name = cls._meta.swapped.split(\".\")\n                 errors.append(\n                     checks.Error(\n                         \"'%s' references '%s.%s', which has not been \"\n-                        \"installed, or is abstract.\" % (\n-                            cls._meta.swappable, app_label, model_name\n-                        ),\n-                        id='models.E002',\n+                        \"installed, or is abstract.\"\n+                        % (cls._meta.swappable, app_label, model_name),\n+                        id=\"models.E002\",\n                     )\n                 )\n         return errors\n@@ -1359,7 +1520,7 @@ class Model(metaclass=ModelBase):\n                 errors.append(\n                     checks.Error(\n                         \"Proxy model '%s' contains model fields.\" % cls.__name__,\n-                        id='models.E017',\n+                        id=\"models.E017\",\n                     )\n                 )\n         return errors\n@@ -1384,8 +1545,7 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def _check_m2m_through_same_relationship(cls):\n-        \"\"\" Check if no relationship model is used by more than one m2m field.\n-        \"\"\"\n+        \"\"\"Check if no relationship model is used by more than one m2m field.\"\"\"\n \n         errors = []\n         seen_intermediary_signatures = []\n@@ -1399,15 +1559,20 @@ class Model(metaclass=ModelBase):\n         fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))\n \n         for f in fields:\n-            signature = (f.remote_field.model, cls, f.remote_field.through, f.remote_field.through_fields)\n+            signature = (\n+                f.remote_field.model,\n+                cls,\n+                f.remote_field.through,\n+                f.remote_field.through_fields,\n+            )\n             if signature in seen_intermediary_signatures:\n                 errors.append(\n                     checks.Error(\n                         \"The model has two identical many-to-many relations \"\n-                        \"through the intermediate model '%s'.\" %\n-                        f.remote_field.through._meta.label,\n+                        \"through the intermediate model '%s'.\"\n+                        % f.remote_field.through._meta.label,\n                         obj=cls,\n-                        id='models.E003',\n+                        id=\"models.E003\",\n                     )\n                 )\n             else:\n@@ -1417,15 +1582,17 @@ class Model(metaclass=ModelBase):\n     @classmethod\n     def _check_id_field(cls):\n         \"\"\"Check if `id` field is a primary key.\"\"\"\n-        fields = [f for f in cls._meta.local_fields if f.name == 'id' and f != cls._meta.pk]\n+        fields = [\n+            f for f in cls._meta.local_fields if f.name == \"id\" and f != cls._meta.pk\n+        ]\n         # fields is empty or consists of the invalid \"id\" field\n-        if fields and not fields[0].primary_key and cls._meta.pk.name == 'id':\n+        if fields and not fields[0].primary_key and cls._meta.pk.name == \"id\":\n             return [\n                 checks.Error(\n                     \"'id' can only be used as a field name if the field also \"\n                     \"sets 'primary_key=True'.\",\n                     obj=cls,\n-                    id='models.E004',\n+                    id=\"models.E004\",\n                 )\n             ]\n         else:\n@@ -1446,12 +1613,10 @@ class Model(metaclass=ModelBase):\n                         checks.Error(\n                             \"The field '%s' from parent model \"\n                             \"'%s' clashes with the field '%s' \"\n-                            \"from parent model '%s'.\" % (\n-                                clash.name, clash.model._meta,\n-                                f.name, f.model._meta\n-                            ),\n+                            \"from parent model '%s'.\"\n+                            % (clash.name, clash.model._meta, f.name, f.model._meta),\n                             obj=cls,\n-                            id='models.E005',\n+                            id=\"models.E005\",\n                         )\n                     )\n                 used_fields[f.name] = f\n@@ -1471,16 +1636,16 @@ class Model(metaclass=ModelBase):\n             # field \"id\" and automatically added unique field \"id\", both\n             # defined at the same model. This special case is considered in\n             # _check_id_field and here we ignore it.\n-            id_conflict = f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n+            id_conflict = (\n+                f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n+            )\n             if clash and not id_conflict:\n                 errors.append(\n                     checks.Error(\n                         \"The field '%s' clashes with the field '%s' \"\n-                        \"from model '%s'.\" % (\n-                            f.name, clash.name, clash.model._meta\n-                        ),\n+                        \"from model '%s'.\" % (f.name, clash.name, clash.model._meta),\n                         obj=f,\n-                        id='models.E006',\n+                        id=\"models.E006\",\n                     )\n                 )\n             used_fields[f.name] = f\n@@ -1505,7 +1670,7 @@ class Model(metaclass=ModelBase):\n                         \"another field.\" % (f.name, column_name),\n                         hint=\"Specify a 'db_column' for the field.\",\n                         obj=cls,\n-                        id='models.E007'\n+                        id=\"models.E007\",\n                     )\n                 )\n             else:\n@@ -1517,13 +1682,13 @@ class Model(metaclass=ModelBase):\n     def _check_model_name_db_lookup_clashes(cls):\n         errors = []\n         model_name = cls.__name__\n-        if model_name.startswith('_') or model_name.endswith('_'):\n+        if model_name.startswith(\"_\") or model_name.endswith(\"_\"):\n             errors.append(\n                 checks.Error(\n                     \"The model name '%s' cannot start or end with an underscore \"\n                     \"as it collides with the query lookup syntax.\" % model_name,\n                     obj=cls,\n-                    id='models.E023'\n+                    id=\"models.E023\",\n                 )\n             )\n         elif LOOKUP_SEP in model_name:\n@@ -1532,7 +1697,7 @@ class Model(metaclass=ModelBase):\n                     \"The model name '%s' cannot contain double underscores as \"\n                     \"it collides with the query lookup syntax.\" % model_name,\n                     obj=cls,\n-                    id='models.E024'\n+                    id=\"models.E024\",\n                 )\n             )\n         return errors\n@@ -1542,7 +1707,8 @@ class Model(metaclass=ModelBase):\n         errors = []\n         property_names = cls._meta._property_names\n         related_field_accessors = (\n-            f.get_attname() for f in cls._meta._get_fields(reverse=False)\n+            f.get_attname()\n+            for f in cls._meta._get_fields(reverse=False)\n             if f.is_relation and f.related_model is not None\n         )\n         for accessor in related_field_accessors:\n@@ -1552,7 +1718,7 @@ class Model(metaclass=ModelBase):\n                         \"The property '%s' clashes with a related field \"\n                         \"accessor.\" % accessor,\n                         obj=cls,\n-                        id='models.E025',\n+                        id=\"models.E025\",\n                     )\n                 )\n         return errors\n@@ -1566,7 +1732,7 @@ class Model(metaclass=ModelBase):\n                     \"The model cannot have more than one field with \"\n                     \"'primary_key=True'.\",\n                     obj=cls,\n-                    id='models.E026',\n+                    id=\"models.E026\",\n                 )\n             )\n         return errors\n@@ -1579,16 +1745,18 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'index_together' must be a list or tuple.\",\n                     obj=cls,\n-                    id='models.E008',\n+                    id=\"models.E008\",\n                 )\n             ]\n \n-        elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together):\n+        elif any(\n+            not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together\n+        ):\n             return [\n                 checks.Error(\n                     \"All 'index_together' elements must be lists or tuples.\",\n                     obj=cls,\n-                    id='models.E009',\n+                    id=\"models.E009\",\n                 )\n             ]\n \n@@ -1606,16 +1774,19 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'unique_together' must be a list or tuple.\",\n                     obj=cls,\n-                    id='models.E010',\n+                    id=\"models.E010\",\n                 )\n             ]\n \n-        elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.unique_together):\n+        elif any(\n+            not isinstance(fields, (tuple, list))\n+            for fields in cls._meta.unique_together\n+        ):\n             return [\n                 checks.Error(\n                     \"All 'unique_together' elements must be lists or tuples.\",\n                     obj=cls,\n-                    id='models.E011',\n+                    id=\"models.E011\",\n                 )\n             ]\n \n@@ -1633,13 +1804,13 @@ class Model(metaclass=ModelBase):\n         for index in cls._meta.indexes:\n             # Index name can't start with an underscore or a number, restricted\n             # for cross-database compatibility with Oracle.\n-            if index.name[0] == '_' or index.name[0].isdigit():\n+            if index.name[0] == \"_\" or index.name[0].isdigit():\n                 errors.append(\n                     checks.Error(\n                         \"The index name '%s' cannot start with an underscore \"\n                         \"or a number.\" % index.name,\n                         obj=cls,\n-                        id='models.E033',\n+                        id=\"models.E033\",\n                     ),\n                 )\n             if len(index.name) > index.max_name_length:\n@@ -1648,7 +1819,7 @@ class Model(metaclass=ModelBase):\n                         \"The index name '%s' cannot be longer than %d \"\n                         \"characters.\" % (index.name, index.max_name_length),\n                         obj=cls,\n-                        id='models.E034',\n+                        id=\"models.E034\",\n                     ),\n                 )\n             if index.contains_expressions:\n@@ -1661,57 +1832,59 @@ class Model(metaclass=ModelBase):\n                 continue\n             connection = connections[db]\n             if not (\n-                connection.features.supports_partial_indexes or\n-                'supports_partial_indexes' in cls._meta.required_db_features\n+                connection.features.supports_partial_indexes\n+                or \"supports_partial_indexes\" in cls._meta.required_db_features\n             ) and any(index.condition is not None for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes with conditions.'\n+                        \"%s does not support indexes with conditions.\"\n                         % connection.display_name,\n                         hint=(\n                             \"Conditions will be ignored. Silence this warning \"\n                             \"if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W037',\n+                        id=\"models.W037\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_covering_indexes or\n-                'supports_covering_indexes' in cls._meta.required_db_features\n+                connection.features.supports_covering_indexes\n+                or \"supports_covering_indexes\" in cls._meta.required_db_features\n             ) and any(index.include for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes with non-key columns.'\n+                        \"%s does not support indexes with non-key columns.\"\n                         % connection.display_name,\n                         hint=(\n                             \"Non-key columns will be ignored. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W040',\n+                        id=\"models.W040\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_expression_indexes or\n-                'supports_expression_indexes' in cls._meta.required_db_features\n+                connection.features.supports_expression_indexes\n+                or \"supports_expression_indexes\" in cls._meta.required_db_features\n             ) and any(index.contains_expressions for index in cls._meta.indexes):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support indexes on expressions.'\n+                        \"%s does not support indexes on expressions.\"\n                         % connection.display_name,\n                         hint=(\n                             \"An index won't be created. Silence this warning \"\n                             \"if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W043',\n+                        id=\"models.W043\",\n                     )\n                 )\n-        fields = [field for index in cls._meta.indexes for field, _ in index.fields_orders]\n+        fields = [\n+            field for index in cls._meta.indexes for field, _ in index.fields_orders\n+        ]\n         fields += [include for index in cls._meta.indexes for include in index.include]\n         fields += references\n-        errors.extend(cls._check_local_fields(fields, 'indexes'))\n+        errors.extend(cls._check_local_fields(fields, \"indexes\"))\n         return errors\n \n     @classmethod\n@@ -1723,7 +1896,7 @@ class Model(metaclass=ModelBase):\n         forward_fields_map = {}\n         for field in cls._meta._get_fields(reverse=False):\n             forward_fields_map[field.name] = field\n-            if hasattr(field, 'attname'):\n+            if hasattr(field, \"attname\"):\n                 forward_fields_map[field.attname] = field\n \n         errors = []\n@@ -1733,11 +1906,13 @@ class Model(metaclass=ModelBase):\n             except KeyError:\n                 errors.append(\n                     checks.Error(\n-                        \"'%s' refers to the nonexistent field '%s'.\" % (\n-                            option, field_name,\n+                        \"'%s' refers to the nonexistent field '%s'.\"\n+                        % (\n+                            option,\n+                            field_name,\n                         ),\n                         obj=cls,\n-                        id='models.E012',\n+                        id=\"models.E012\",\n                     )\n                 )\n             else:\n@@ -1745,11 +1920,14 @@ class Model(metaclass=ModelBase):\n                     errors.append(\n                         checks.Error(\n                             \"'%s' refers to a ManyToManyField '%s', but \"\n-                            \"ManyToManyFields are not permitted in '%s'.\" % (\n-                                option, field_name, option,\n+                            \"ManyToManyFields are not permitted in '%s'.\"\n+                            % (\n+                                option,\n+                                field_name,\n+                                option,\n                             ),\n                             obj=cls,\n-                            id='models.E013',\n+                            id=\"models.E013\",\n                         )\n                     )\n                 elif field not in cls._meta.local_fields:\n@@ -1759,7 +1937,7 @@ class Model(metaclass=ModelBase):\n                             % (option, field_name, cls._meta.object_name),\n                             hint=\"This issue may be caused by multi-table inheritance.\",\n                             obj=cls,\n-                            id='models.E016',\n+                            id=\"models.E016\",\n                         )\n                     )\n         return errors\n@@ -1775,7 +1953,7 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n                     obj=cls,\n-                    id='models.E021',\n+                    id=\"models.E021\",\n                 ),\n             ]\n \n@@ -1787,7 +1965,7 @@ class Model(metaclass=ModelBase):\n                 checks.Error(\n                     \"'ordering' must be a tuple or list (even if you want to order by only one field).\",\n                     obj=cls,\n-                    id='models.E014',\n+                    id=\"models.E014\",\n                 )\n             ]\n \n@@ -1795,10 +1973,10 @@ class Model(metaclass=ModelBase):\n         fields = cls._meta.ordering\n \n         # Skip expressions and '?' fields.\n-        fields = (f for f in fields if isinstance(f, str) and f != '?')\n+        fields = (f for f in fields if isinstance(f, str) and f != \"?\")\n \n         # Convert \"-field\" to \"field\".\n-        fields = ((f[1:] if f.startswith('-') else f) for f in fields)\n+        fields = ((f[1:] if f.startswith(\"-\") else f) for f in fields)\n \n         # Separate related fields and non-related fields.\n         _fields = []\n@@ -1817,7 +1995,7 @@ class Model(metaclass=ModelBase):\n             for part in field.split(LOOKUP_SEP):\n                 try:\n                     # pk is an alias that won't be found by opts.get_field.\n-                    if part == 'pk':\n+                    if part == \"pk\":\n                         fld = _cls._meta.pk\n                     else:\n                         fld = _cls._meta.get_field(part)\n@@ -1834,13 +2012,13 @@ class Model(metaclass=ModelBase):\n                                 \"'ordering' refers to the nonexistent field, \"\n                                 \"related field, or lookup '%s'.\" % field,\n                                 obj=cls,\n-                                id='models.E015',\n+                                id=\"models.E015\",\n                             )\n                         )\n \n         # Skip ordering on pk. This is always a valid order_by field\n         # but is an alias and therefore won't be found by opts.get_field.\n-        fields = {f for f in fields if f != 'pk'}\n+        fields = {f for f in fields if f != \"pk\"}\n \n         # Check for invalid or nonexistent fields in ordering.\n         invalid_fields = []\n@@ -1848,10 +2026,14 @@ class Model(metaclass=ModelBase):\n         # Any field name that is not present in field_names does not exist.\n         # Also, ordering by m2m fields is not allowed.\n         opts = cls._meta\n-        valid_fields = set(chain.from_iterable(\n-            (f.name, f.attname) if not (f.auto_created and not f.concrete) else (f.field.related_query_name(),)\n-            for f in chain(opts.fields, opts.related_objects)\n-        ))\n+        valid_fields = set(\n+            chain.from_iterable(\n+                (f.name, f.attname)\n+                if not (f.auto_created and not f.concrete)\n+                else (f.field.related_query_name(),)\n+                for f in chain(opts.fields, opts.related_objects)\n+            )\n+        )\n \n         invalid_fields.extend(fields - valid_fields)\n \n@@ -1861,7 +2043,7 @@ class Model(metaclass=ModelBase):\n                     \"'ordering' refers to the nonexistent field, related \"\n                     \"field, or lookup '%s'.\" % invalid_field,\n                     obj=cls,\n-                    id='models.E015',\n+                    id=\"models.E015\",\n                 )\n             )\n         return errors\n@@ -1903,7 +2085,11 @@ class Model(metaclass=ModelBase):\n \n             # Check if auto-generated name for the field is too long\n             # for the database.\n-            if f.db_column is None and column_name is not None and len(column_name) > allowed_len:\n+            if (\n+                f.db_column is None\n+                and column_name is not None\n+                and len(column_name) > allowed_len\n+            ):\n                 errors.append(\n                     checks.Error(\n                         'Autogenerated column name too long for field \"%s\". '\n@@ -1911,7 +2097,7 @@ class Model(metaclass=ModelBase):\n                         % (column_name, allowed_len, db_alias),\n                         hint=\"Set the column name manually using 'db_column'.\",\n                         obj=cls,\n-                        id='models.E018',\n+                        id=\"models.E018\",\n                     )\n                 )\n \n@@ -1924,10 +2110,14 @@ class Model(metaclass=ModelBase):\n             # for the database.\n             for m2m in f.remote_field.through._meta.local_fields:\n                 _, rel_name = m2m.get_attname_column()\n-                if m2m.db_column is None and rel_name is not None and len(rel_name) > allowed_len:\n+                if (\n+                    m2m.db_column is None\n+                    and rel_name is not None\n+                    and len(rel_name) > allowed_len\n+                ):\n                     errors.append(\n                         checks.Error(\n-                            'Autogenerated column name too long for M2M field '\n+                            \"Autogenerated column name too long for M2M field \"\n                             '\"%s\". Maximum length is \"%s\" for database \"%s\".'\n                             % (rel_name, allowed_len, db_alias),\n                             hint=(\n@@ -1935,7 +2125,7 @@ class Model(metaclass=ModelBase):\n                                 \"M2M and then set column_name using 'db_column'.\"\n                             ),\n                             obj=cls,\n-                            id='models.E019',\n+                            id=\"models.E019\",\n                         )\n                     )\n \n@@ -1953,7 +2143,7 @@ class Model(metaclass=ModelBase):\n                     yield from cls._get_expr_references(child)\n         elif isinstance(expr, F):\n             yield tuple(expr.name.split(LOOKUP_SEP))\n-        elif hasattr(expr, 'get_source_expressions'):\n+        elif hasattr(expr, \"get_source_expressions\"):\n             for src_expr in expr.get_source_expressions():\n                 yield from cls._get_expr_references(src_expr)\n \n@@ -1965,107 +2155,118 @@ class Model(metaclass=ModelBase):\n                 continue\n             connection = connections[db]\n             if not (\n-                connection.features.supports_table_check_constraints or\n-                'supports_table_check_constraints' in cls._meta.required_db_features\n+                connection.features.supports_table_check_constraints\n+                or \"supports_table_check_constraints\" in cls._meta.required_db_features\n             ) and any(\n                 isinstance(constraint, CheckConstraint)\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support check constraints.' % connection.display_name,\n+                        \"%s does not support check constraints.\"\n+                        % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W027',\n+                        id=\"models.W027\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_partial_indexes or\n-                'supports_partial_indexes' in cls._meta.required_db_features\n+                connection.features.supports_partial_indexes\n+                or \"supports_partial_indexes\" in cls._meta.required_db_features\n             ) and any(\n-                isinstance(constraint, UniqueConstraint) and constraint.condition is not None\n+                isinstance(constraint, UniqueConstraint)\n+                and constraint.condition is not None\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support unique constraints with '\n-                        'conditions.' % connection.display_name,\n+                        \"%s does not support unique constraints with \"\n+                        \"conditions.\" % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W036',\n+                        id=\"models.W036\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_deferrable_unique_constraints or\n-                'supports_deferrable_unique_constraints' in cls._meta.required_db_features\n+                connection.features.supports_deferrable_unique_constraints\n+                or \"supports_deferrable_unique_constraints\"\n+                in cls._meta.required_db_features\n             ) and any(\n-                isinstance(constraint, UniqueConstraint) and constraint.deferrable is not None\n+                isinstance(constraint, UniqueConstraint)\n+                and constraint.deferrable is not None\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support deferrable unique constraints.'\n+                        \"%s does not support deferrable unique constraints.\"\n                         % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W038',\n+                        id=\"models.W038\",\n                     )\n                 )\n             if not (\n-                connection.features.supports_covering_indexes or\n-                'supports_covering_indexes' in cls._meta.required_db_features\n+                connection.features.supports_covering_indexes\n+                or \"supports_covering_indexes\" in cls._meta.required_db_features\n             ) and any(\n                 isinstance(constraint, UniqueConstraint) and constraint.include\n                 for constraint in cls._meta.constraints\n             ):\n                 errors.append(\n                     checks.Warning(\n-                        '%s does not support unique constraints with non-key '\n-                        'columns.' % connection.display_name,\n+                        \"%s does not support unique constraints with non-key \"\n+                        \"columns.\" % connection.display_name,\n                         hint=(\n                             \"A constraint won't be created. Silence this \"\n                             \"warning if you don't care about it.\"\n                         ),\n                         obj=cls,\n-                        id='models.W039',\n+                        id=\"models.W039\",\n                     )\n                 )\n-            fields = set(chain.from_iterable(\n-                (*constraint.fields, *constraint.include)\n-                for constraint in cls._meta.constraints if isinstance(constraint, UniqueConstraint)\n-            ))\n+            fields = set(\n+                chain.from_iterable(\n+                    (*constraint.fields, *constraint.include)\n+                    for constraint in cls._meta.constraints\n+                    if isinstance(constraint, UniqueConstraint)\n+                )\n+            )\n             references = set()\n             for constraint in cls._meta.constraints:\n                 if isinstance(constraint, UniqueConstraint):\n                     if (\n-                        connection.features.supports_partial_indexes or\n-                        'supports_partial_indexes' not in cls._meta.required_db_features\n+                        connection.features.supports_partial_indexes\n+                        or \"supports_partial_indexes\"\n+                        not in cls._meta.required_db_features\n                     ) and isinstance(constraint.condition, Q):\n-                        references.update(cls._get_expr_references(constraint.condition))\n+                        references.update(\n+                            cls._get_expr_references(constraint.condition)\n+                        )\n                 elif isinstance(constraint, CheckConstraint):\n                     if (\n-                        connection.features.supports_table_check_constraints or\n-                        'supports_table_check_constraints' not in cls._meta.required_db_features\n+                        connection.features.supports_table_check_constraints\n+                        or \"supports_table_check_constraints\"\n+                        not in cls._meta.required_db_features\n                     ) and isinstance(constraint.check, Q):\n                         references.update(cls._get_expr_references(constraint.check))\n             for field_name, *lookups in references:\n                 # pk is an alias that won't be found by opts.get_field.\n-                if field_name != 'pk':\n+                if field_name != \"pk\":\n                     fields.add(field_name)\n                 if not lookups:\n                     # If it has no lookups it cannot result in a JOIN.\n                     continue\n                 try:\n-                    if field_name == 'pk':\n+                    if field_name == \"pk\":\n                         field = cls._meta.pk\n                     else:\n                         field = cls._meta.get_field(field_name)\n@@ -2076,18 +2277,18 @@ class Model(metaclass=ModelBase):\n                 # JOIN must happen at the first lookup.\n                 first_lookup = lookups[0]\n                 if (\n-                    field.get_transform(first_lookup) is None and\n-                    field.get_lookup(first_lookup) is None\n+                    field.get_transform(first_lookup) is None\n+                    and field.get_lookup(first_lookup) is None\n                 ):\n                     errors.append(\n                         checks.Error(\n                             \"'constraints' refers to the joined field '%s'.\"\n                             % LOOKUP_SEP.join([field_name] + lookups),\n                             obj=cls,\n-                            id='models.E041',\n+                            id=\"models.E041\",\n                         )\n                     )\n-            errors.extend(cls._check_local_fields(fields, 'constraints'))\n+            errors.extend(cls._check_local_fields(fields, \"constraints\"))\n         return errors\n \n \n@@ -2097,14 +2298,16 @@ class Model(metaclass=ModelBase):\n \n # ORDERING METHODS #########################\n \n+\n def method_set_order(self, ordered_obj, id_list, using=None):\n     if using is None:\n         using = DEFAULT_DB_ALIAS\n     order_wrt = ordered_obj._meta.order_with_respect_to\n     filter_args = order_wrt.get_forward_related_filter(self)\n-    ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update([\n-        ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)\n-    ], ['_order'])\n+    ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update(\n+        [ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)],\n+        [\"_order\"],\n+    )\n \n \n def method_get_order(self, ordered_obj):\n@@ -2117,15 +2320,16 @@ def method_get_order(self, ordered_obj):\n def make_foreign_order_accessors(model, related_model):\n     setattr(\n         related_model,\n-        'get_%s_order' % model.__name__.lower(),\n-        partialmethod(method_get_order, model)\n+        \"get_%s_order\" % model.__name__.lower(),\n+        partialmethod(method_get_order, model),\n     )\n     setattr(\n         related_model,\n-        'set_%s_order' % model.__name__.lower(),\n-        partialmethod(method_set_order, model)\n+        \"set_%s_order\" % model.__name__.lower(),\n+        partialmethod(method_set_order, model),\n     )\n \n+\n ########\n # MISC #\n ########\n"}
{"instance_id": "django__django-14016", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c2623f099f..e8acddf8f1 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -46,10 +46,10 @@ class Q(tree.Node):\n \n         # If the other Q() is empty, ignore it and just use `self`.\n         if not other:\n-            return copy.deepcopy(self)\n+            return type(self)(*self.children, _connector=self.connector, _negated=self.negated)\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n-            return copy.deepcopy(other)\n+            return type(self)(*other.children, _connector=other.connector, _negated=other.negated)\n \n         obj = type(self)()\n         obj.connector = conn\n"}
{"instance_id": "django__django-14017", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..0694cea2e5 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -5,6 +5,7 @@ Factored out from django.db.models.query to avoid making the main module very\n large and/or so that they can be used by other modules without getting into\n circular import difficulties.\n \"\"\"\n+\n import functools\n import inspect\n from collections import namedtuple\n@@ -16,7 +17,10 @@ from django.utils import tree\n # PathInfo is used when converting lookups (fk__somecol). The contents\n # describe the relation in Model terms (model Options and Fields for both\n # sides of the relation. The join_field is the field backing the relation.\n-PathInfo = namedtuple('PathInfo', 'from_opts to_opts target_fields join_field m2m direct filtered_relation')\n+PathInfo = namedtuple(\n+    \"PathInfo\",\n+    \"from_opts to_opts target_fields join_field m2m direct filtered_relation\",\n+)\n \n \n def subclasses(cls):\n@@ -30,27 +34,33 @@ class Q(tree.Node):\n     Encapsulate filters as objects that can then be combined logically (using\n     `&` and `|`).\n     \"\"\"\n+\n     # Connection types\n-    AND = 'AND'\n-    OR = 'OR'\n+    AND = \"AND\"\n+    OR = \"OR\"\n     default = AND\n     conditional = True\n \n     def __init__(self, *args, _connector=None, _negated=False, **kwargs):\n-        super().__init__(children=[*args, *sorted(kwargs.items())], connector=_connector, negated=_negated)\n+        super().__init__(\n+            children=[*args, *sorted(kwargs.items())],\n+            connector=_connector,\n+            negated=_negated,\n+        )\n \n     def _combine(self, other, conn):\n         if not isinstance(other, Q):\n-            raise TypeError(other)\n+            if getattr(other, \"conditional\", False):\n+                other = type(self)(other)\n+            else:\n+                raise TypeError(other)\n \n         # If the other Q() is empty, ignore it and just use `self`.\n         if not other:\n-            _, args, kwargs = self.deconstruct()\n-            return type(self)(*args, **kwargs)\n+            return self\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n-            _, args, kwargs = other.deconstruct()\n-            return type(other)(*args, **kwargs)\n+            return other\n \n         obj = type(self)()\n         obj.connector = conn\n@@ -70,20 +80,25 @@ class Q(tree.Node):\n         obj.negate()\n         return obj\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         # We must promote any new joins to left outer joins so that when Q is\n         # used as an expression, rows aren't filtered due to joins.\n         clause, joins = query._add_q(\n-            self, reuse, allow_joins=allow_joins, split_subq=False,\n+            self,\n+            reuse,\n+            allow_joins=allow_joins,\n+            split_subq=False,\n             check_filterable=False,\n         )\n         query.promote_joins(joins)\n         return clause\n \n     def deconstruct(self):\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)\n-        if path.startswith('django.db.models.query_utils'):\n-            path = path.replace('django.db.models.query_utils', 'django.db.models')\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n+        if path.startswith(\"django.db.models.query_utils\"):\n+            path = path.replace(\"django.db.models.query_utils\", \"django.db.models\")\n         args, kwargs = (), {}\n         if len(self.children) == 1 and not isinstance(self.children[0], Q):\n             child = self.children[0]\n@@ -91,9 +106,9 @@ class Q(tree.Node):\n         else:\n             args = tuple(self.children)\n             if self.connector != self.default:\n-                kwargs = {'_connector': self.connector}\n+                kwargs = {\"_connector\": self.connector}\n         if self.negated:\n-            kwargs['_negated'] = True\n+            kwargs[\"_negated\"] = True\n         return path, args, kwargs\n \n \n@@ -102,6 +117,7 @@ class DeferredAttribute:\n     A wrapper for a deferred-loading field. When the value is read from this\n     object the first time, the query is executed.\n     \"\"\"\n+\n     def __init__(self, field):\n         self.field = field\n \n@@ -138,7 +154,6 @@ class DeferredAttribute:\n \n \n class RegisterLookupMixin:\n-\n     @classmethod\n     def _get_lookup(cls, lookup_name):\n         return cls.get_lookups().get(lookup_name, None)\n@@ -146,13 +161,16 @@ class RegisterLookupMixin:\n     @classmethod\n     @functools.lru_cache(maxsize=None)\n     def get_lookups(cls):\n-        class_lookups = [parent.__dict__.get('class_lookups', {}) for parent in inspect.getmro(cls)]\n+        class_lookups = [\n+            parent.__dict__.get(\"class_lookups\", {}) for parent in inspect.getmro(cls)\n+        ]\n         return cls.merge_dicts(class_lookups)\n \n     def get_lookup(self, lookup_name):\n         from django.db.models.lookups import Lookup\n+\n         found = self._get_lookup(lookup_name)\n-        if found is None and hasattr(self, 'output_field'):\n+        if found is None and hasattr(self, \"output_field\"):\n             return self.output_field.get_lookup(lookup_name)\n         if found is not None and not issubclass(found, Lookup):\n             return None\n@@ -160,8 +178,9 @@ class RegisterLookupMixin:\n \n     def get_transform(self, lookup_name):\n         from django.db.models.lookups import Transform\n+\n         found = self._get_lookup(lookup_name)\n-        if found is None and hasattr(self, 'output_field'):\n+        if found is None and hasattr(self, \"output_field\"):\n             return self.output_field.get_transform(lookup_name)\n         if found is not None and not issubclass(found, Transform):\n             return None\n@@ -187,7 +206,7 @@ class RegisterLookupMixin:\n     def register_lookup(cls, lookup, lookup_name=None):\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n-        if 'class_lookups' not in cls.__dict__:\n+        if \"class_lookups\" not in cls.__dict__:\n             cls.class_lookups = {}\n         cls.class_lookups[lookup_name] = lookup\n         cls._clear_cached_lookups()\n@@ -234,8 +253,8 @@ def select_related_descend(field, restricted, requested, load_fields, reverse=Fa\n         if field.attname not in load_fields:\n             if restricted and field.name in requested:\n                 msg = (\n-                    'Field %s.%s cannot be both deferred and traversed using '\n-                    'select_related at the same time.'\n+                    \"Field %s.%s cannot be both deferred and traversed using \"\n+                    \"select_related at the same time.\"\n                 ) % (field.model._meta.object_name, field.name)\n                 raise FieldError(msg)\n     return True\n@@ -261,12 +280,14 @@ def check_rel_lookup_compatibility(model, target_opts, field):\n       1) model and opts match (where proxy inheritance is removed)\n       2) model is parent of opts' model or the other way around\n     \"\"\"\n+\n     def check(opts):\n         return (\n-            model._meta.concrete_model == opts.concrete_model or\n-            opts.concrete_model in model._meta.get_parent_list() or\n-            model in opts.get_parent_list()\n+            model._meta.concrete_model == opts.concrete_model\n+            or opts.concrete_model in model._meta.get_parent_list()\n+            or model in opts.get_parent_list()\n         )\n+\n     # If the field is a primary key, then doing a query against the field's\n     # model is ok, too. Consider the case:\n     # class Restaurant(models.Model):\n@@ -276,9 +297,8 @@ def check_rel_lookup_compatibility(model, target_opts, field):\n     # give Place's opts as the target opts, but Restaurant isn't compatible\n     # with that. This logic applies only to primary keys, as when doing __in=qs,\n     # we are going to turn this into __in=qs.values('pk') later on.\n-    return (\n-        check(target_opts) or\n-        (getattr(field, 'primary_key', False) and check(field.model._meta))\n+    return check(target_opts) or (\n+        getattr(field, \"primary_key\", False) and check(field.model._meta)\n     )\n \n \n@@ -287,11 +307,11 @@ class FilteredRelation:\n \n     def __init__(self, relation_name, *, condition=Q()):\n         if not relation_name:\n-            raise ValueError('relation_name cannot be empty.')\n+            raise ValueError(\"relation_name cannot be empty.\")\n         self.relation_name = relation_name\n         self.alias = None\n         if not isinstance(condition, Q):\n-            raise ValueError('condition argument must be a Q() instance.')\n+            raise ValueError(\"condition argument must be a Q() instance.\")\n         self.condition = condition\n         self.path = []\n \n@@ -299,9 +319,9 @@ class FilteredRelation:\n         if not isinstance(other, self.__class__):\n             return NotImplemented\n         return (\n-            self.relation_name == other.relation_name and\n-            self.alias == other.alias and\n-            self.condition == other.condition\n+            self.relation_name == other.relation_name\n+            and self.alias == other.alias\n+            and self.condition == other.condition\n         )\n \n     def clone(self):\n@@ -315,7 +335,7 @@ class FilteredRelation:\n         QuerySet.annotate() only accepts expression-like arguments\n         (with a resolve_expression() method).\n         \"\"\"\n-        raise NotImplementedError('FilteredRelation.resolve_expression() is unused.')\n+        raise NotImplementedError(\"FilteredRelation.resolve_expression() is unused.\")\n \n     def as_sql(self, compiler, connection):\n         # Resolve the condition in Join.filtered_relation.\n"}
{"instance_id": "django__django-14155", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..0e54444e42 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -45,6 +45,10 @@ class ResolverMatch:\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n         self.namespace = ':'.join(self.namespaces)\n \n+        # Unwrap functools.partial objects.\n+        while isinstance(func, functools.partial):\n+            func = func.func\n+\n         if not hasattr(func, '__name__'):\n             # A class-based view\n             self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n"}
{"instance_id": "django__django-14238", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..b2267408d7 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -18,7 +18,10 @@ from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import (\n-    parse_date, parse_datetime, parse_duration, parse_time,\n+    parse_date,\n+    parse_datetime,\n+    parse_duration,\n+    parse_time,\n )\n from django.utils.duration import duration_microseconds, duration_string\n from django.utils.functional import Promise, cached_property\n@@ -28,14 +31,38 @@ from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n \n __all__ = [\n-    'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n-    'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField',\n-    'DateField', 'DateTimeField', 'DecimalField', 'DurationField',\n-    'EmailField', 'Empty', 'Field', 'FilePathField', 'FloatField',\n-    'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED',\n-    'NullBooleanField', 'PositiveBigIntegerField', 'PositiveIntegerField',\n-    'PositiveSmallIntegerField', 'SlugField', 'SmallAutoField',\n-    'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField',\n+    \"AutoField\",\n+    \"BLANK_CHOICE_DASH\",\n+    \"BigAutoField\",\n+    \"BigIntegerField\",\n+    \"BinaryField\",\n+    \"BooleanField\",\n+    \"CharField\",\n+    \"CommaSeparatedIntegerField\",\n+    \"DateField\",\n+    \"DateTimeField\",\n+    \"DecimalField\",\n+    \"DurationField\",\n+    \"EmailField\",\n+    \"Empty\",\n+    \"Field\",\n+    \"FilePathField\",\n+    \"FloatField\",\n+    \"GenericIPAddressField\",\n+    \"IPAddressField\",\n+    \"IntegerField\",\n+    \"NOT_PROVIDED\",\n+    \"NullBooleanField\",\n+    \"PositiveBigIntegerField\",\n+    \"PositiveIntegerField\",\n+    \"PositiveSmallIntegerField\",\n+    \"SlugField\",\n+    \"SmallAutoField\",\n+    \"SmallIntegerField\",\n+    \"TextField\",\n+    \"TimeField\",\n+    \"URLField\",\n+    \"UUIDField\",\n ]\n \n \n@@ -71,6 +98,7 @@ def _load_field(app_label, model_name, field_name):\n #\n #     getattr(obj, opts.pk.attname)\n \n+\n def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n@@ -97,15 +125,15 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n+        \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n+        \"null\": _(\"This field cannot be null.\"),\n+        \"blank\": _(\"This field cannot be blank.\"),\n+        \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n         # Eg: \"Title must be unique for pub_date year\"\n-        'unique_for_date': _(\"%(field_label)s must be unique for \"\n-                             \"%(date_field_label)s %(lookup_type)s.\"),\n+        \"unique_for_date\": _(\n+            \"%(field_label)s must be unique for %(date_field_label)s %(lookup_type)s.\"\n+        ),\n     }\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n@@ -123,18 +151,37 @@ class Field(RegisterLookupMixin):\n \n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n-        return _('Field of type: %(field_type)s') % {\n-            'field_type': self.__class__.__name__\n+        return _(\"Field of type: %(field_type)s\") % {\n+            \"field_type\": self.__class__.__name__\n         }\n+\n     description = property(_description)\n \n-    def __init__(self, verbose_name=None, name=None, primary_key=False,\n-                 max_length=None, unique=False, blank=False, null=False,\n-                 db_index=False, rel=None, default=NOT_PROVIDED, editable=True,\n-                 serialize=True, unique_for_date=None, unique_for_month=None,\n-                 unique_for_year=None, choices=None, help_text='', db_column=None,\n-                 db_tablespace=None, auto_created=False, validators=(),\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        primary_key=False,\n+        max_length=None,\n+        unique=False,\n+        blank=False,\n+        null=False,\n+        db_index=False,\n+        rel=None,\n+        default=NOT_PROVIDED,\n+        editable=True,\n+        serialize=True,\n+        unique_for_date=None,\n+        unique_for_month=None,\n+        unique_for_year=None,\n+        choices=None,\n+        help_text=\"\",\n+        db_column=None,\n+        db_tablespace=None,\n+        auto_created=False,\n+        validators=(),\n+        error_messages=None,\n+    ):\n         self.name = name\n         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n         self._verbose_name = verbose_name  # Store original for deconstruction\n@@ -170,7 +217,7 @@ class Field(RegisterLookupMixin):\n \n         messages = {}\n         for c in reversed(self.__class__.__mro__):\n-            messages.update(getattr(c, 'default_error_messages', {}))\n+            messages.update(getattr(c, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self._error_messages = error_messages  # Store for deconstruction later\n         self.error_messages = messages\n@@ -180,18 +227,18 @@ class Field(RegisterLookupMixin):\n         Return \"app_label.model_label.field_name\" for fields attached to\n         models.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             return super().__str__()\n         model = self.model\n-        return '%s.%s' % (model._meta.label, self.name)\n+        return \"%s.%s\" % (model._meta.label, self.name)\n \n     def __repr__(self):\n         \"\"\"Display the module, class, and name of the field.\"\"\"\n-        path = '%s.%s' % (self.__class__.__module__, self.__class__.__qualname__)\n-        name = getattr(self, 'name', None)\n+        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n+        name = getattr(self, \"name\", None)\n         if name is not None:\n-            return '<%s: %s>' % (path, name)\n-        return '<%s>' % path\n+            return \"<%s: %s>\" % (path, name)\n+        return \"<%s>\" % path\n \n     def check(self, **kwargs):\n         return [\n@@ -209,12 +256,12 @@ class Field(RegisterLookupMixin):\n         Check if field name is valid, i.e. 1) does not end with an\n         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n         \"\"\"\n-        if self.name.endswith('_'):\n+        if self.name.endswith(\"_\"):\n             return [\n                 checks.Error(\n-                    'Field names must not end with an underscore.',\n+                    \"Field names must not end with an underscore.\",\n                     obj=self,\n-                    id='fields.E001',\n+                    id=\"fields.E001\",\n                 )\n             ]\n         elif LOOKUP_SEP in self.name:\n@@ -222,15 +269,15 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     'Field names must not contain \"%s\".' % LOOKUP_SEP,\n                     obj=self,\n-                    id='fields.E002',\n+                    id=\"fields.E002\",\n                 )\n             ]\n-        elif self.name == 'pk':\n+        elif self.name == \"pk\":\n             return [\n                 checks.Error(\n                     \"'pk' is a reserved word that cannot be used as a field name.\",\n                     obj=self,\n-                    id='fields.E003',\n+                    id=\"fields.E003\",\n                 )\n             ]\n         else:\n@@ -249,7 +296,7 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n                     obj=self,\n-                    id='fields.E004',\n+                    id=\"fields.E004\",\n                 )\n             ]\n \n@@ -268,14 +315,22 @@ class Field(RegisterLookupMixin):\n                 ):\n                     break\n                 if self.max_length is not None and group_choices:\n-                    choice_max_length = max([\n-                        choice_max_length,\n-                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n-                    ])\n+                    choice_max_length = max(\n+                        [\n+                            choice_max_length,\n+                            *(\n+                                len(value)\n+                                for value, _ in group_choices\n+                                if isinstance(value, str)\n+                            ),\n+                        ]\n+                    )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n                 value, human_name = group_name, group_choices\n-                if not self._choices_is_value(value) or not self._choices_is_value(human_name):\n+                if not self._choices_is_value(value) or not self._choices_is_value(\n+                    human_name\n+                ):\n                     break\n                 if self.max_length is not None and isinstance(value, str):\n                     choice_max_length = max(choice_max_length, len(value))\n@@ -290,7 +345,7 @@ class Field(RegisterLookupMixin):\n                         \"'max_length' is too small to fit the longest value \"\n                         \"in 'choices' (%d characters).\" % choice_max_length,\n                         obj=self,\n-                        id='fields.E009',\n+                        id=\"fields.E009\",\n                     ),\n                 ]\n             return []\n@@ -300,7 +355,7 @@ class Field(RegisterLookupMixin):\n                 \"'choices' must be an iterable containing \"\n                 \"(actual value, human readable name) tuples.\",\n                 obj=self,\n-                id='fields.E005',\n+                id=\"fields.E005\",\n             )\n         ]\n \n@@ -310,25 +365,30 @@ class Field(RegisterLookupMixin):\n                 checks.Error(\n                     \"'db_index' must be None, True or False.\",\n                     obj=self,\n-                    id='fields.E006',\n+                    id=\"fields.E006\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_null_allowed_for_primary_keys(self):\n-        if (self.primary_key and self.null and\n-                not connection.features.interprets_empty_strings_as_nulls):\n+        if (\n+            self.primary_key\n+            and self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             # We cannot reliably check this for backends like Oracle which\n             # consider NULL and '' to be equal (and thus set up\n             # character-based fields a little differently).\n             return [\n                 checks.Error(\n-                    'Primary keys must not have null=True.',\n-                    hint=('Set null=False on the field, or '\n-                          'remove primary_key=True argument.'),\n+                    \"Primary keys must not have null=True.\",\n+                    hint=(\n+                        \"Set null=False on the field, or \"\n+                        \"remove primary_key=True argument.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E007',\n+                    id=\"fields.E007\",\n                 )\n             ]\n         else:\n@@ -340,7 +400,9 @@ class Field(RegisterLookupMixin):\n         app_label = self.model._meta.app_label\n         errors = []\n         for alias in databases:\n-            if router.allow_migrate(alias, app_label, model_name=self.model._meta.model_name):\n+            if router.allow_migrate(\n+                alias, app_label, model_name=self.model._meta.model_name\n+            ):\n                 errors.extend(connections[alias].validation.check_field(self, **kwargs))\n         return errors\n \n@@ -354,11 +416,12 @@ class Field(RegisterLookupMixin):\n                         hint=(\n                             \"validators[{i}] ({repr}) isn't a function or \"\n                             \"instance of a validator class.\".format(\n-                                i=i, repr=repr(validator),\n+                                i=i,\n+                                repr=repr(validator),\n                             )\n                         ),\n                         obj=self,\n-                        id='fields.E008',\n+                        id=\"fields.E008\",\n                     )\n                 )\n         return errors\n@@ -368,25 +431,24 @@ class Field(RegisterLookupMixin):\n             return [\n                 checks.Error(\n                     self.system_check_removed_details.get(\n-                        'msg',\n-                        '%s has been removed except for support in historical '\n-                        'migrations.' % self.__class__.__name__\n+                        \"msg\",\n+                        \"%s has been removed except for support in historical \"\n+                        \"migrations.\" % self.__class__.__name__,\n                     ),\n-                    hint=self.system_check_removed_details.get('hint'),\n+                    hint=self.system_check_removed_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_removed_details.get('id', 'fields.EXXX'),\n+                    id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n                 )\n             ]\n         elif self.system_check_deprecated_details is not None:\n             return [\n                 checks.Warning(\n                     self.system_check_deprecated_details.get(\n-                        'msg',\n-                        '%s has been deprecated.' % self.__class__.__name__\n+                        \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n                     ),\n-                    hint=self.system_check_deprecated_details.get('hint'),\n+                    hint=self.system_check_deprecated_details.get(\"hint\"),\n                     obj=self,\n-                    id=self.system_check_deprecated_details.get('id', 'fields.WXXX'),\n+                    id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n                 )\n             ]\n         return []\n@@ -396,6 +458,7 @@ class Field(RegisterLookupMixin):\n             output_field = self\n         if alias != self.model._meta.db_table or output_field != self:\n             from django.db.models.expressions import Col\n+\n             return Col(alias, self, output_field)\n         else:\n             return self.cached_col\n@@ -403,6 +466,7 @@ class Field(RegisterLookupMixin):\n     @cached_property\n     def cached_col(self):\n         from django.db.models.expressions import Col\n+\n         return Col(self.model._meta.db_table, self)\n \n     def select_format(self, compiler, sql, params):\n@@ -462,7 +526,7 @@ class Field(RegisterLookupMixin):\n             \"unique_for_month\": None,\n             \"unique_for_year\": None,\n             \"choices\": None,\n-            \"help_text\": '',\n+            \"help_text\": \"\",\n             \"db_column\": None,\n             \"db_tablespace\": None,\n             \"auto_created\": False,\n@@ -495,8 +559,8 @@ class Field(RegisterLookupMixin):\n             path = path.replace(\"django.db.models.fields.related\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.files\"):\n             path = path.replace(\"django.db.models.fields.files\", \"django.db.models\")\n-        elif path.startswith('django.db.models.fields.json'):\n-            path = path.replace('django.db.models.fields.json', 'django.db.models')\n+        elif path.startswith(\"django.db.models.fields.json\"):\n+            path = path.replace(\"django.db.models.fields.json\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.proxy\"):\n             path = path.replace(\"django.db.models.fields.proxy\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields\"):\n@@ -515,10 +579,9 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return (\n-                self.creation_counter == other.creation_counter and\n-                getattr(self, 'model', None) == getattr(other, 'model', None)\n-            )\n+            return self.creation_counter == other.creation_counter and getattr(\n+                self, \"model\", None\n+            ) == getattr(other, \"model\", None)\n         return NotImplemented\n \n     def __lt__(self, other):\n@@ -526,26 +589,29 @@ class Field(RegisterLookupMixin):\n         # Order by creation_counter first for backward compatibility.\n         if isinstance(other, Field):\n             if (\n-                self.creation_counter != other.creation_counter or\n-                not hasattr(self, 'model') and not hasattr(other, 'model')\n+                self.creation_counter != other.creation_counter\n+                or not hasattr(self, \"model\")\n+                and not hasattr(other, \"model\")\n             ):\n                 return self.creation_counter < other.creation_counter\n-            elif hasattr(self, 'model') != hasattr(other, 'model'):\n-                return not hasattr(self, 'model')  # Order no-model fields first\n+            elif hasattr(self, \"model\") != hasattr(other, \"model\"):\n+                return not hasattr(self, \"model\")  # Order no-model fields first\n             else:\n                 # creation_counter's are equal, compare only models.\n-                return (\n-                    (self.model._meta.app_label, self.model._meta.model_name) <\n-                    (other.model._meta.app_label, other.model._meta.model_name)\n+                return (self.model._meta.app_label, self.model._meta.model_name) < (\n+                    other.model._meta.app_label,\n+                    other.model._meta.model_name,\n                 )\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash((\n-            self.creation_counter,\n-            self.model._meta.app_label if hasattr(self, 'model') else None,\n-            self.model._meta.model_name if hasattr(self, 'model') else None,\n-        ))\n+        return hash(\n+            (\n+                self.creation_counter,\n+                self.model._meta.app_label if hasattr(self, \"model\") else None,\n+                self.model._meta.model_name if hasattr(self, \"model\") else None,\n+            )\n+        )\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n@@ -553,7 +619,7 @@ class Field(RegisterLookupMixin):\n         obj = copy.copy(self)\n         if self.remote_field:\n             obj.remote_field = copy.copy(self.remote_field)\n-            if hasattr(self.remote_field, 'field') and self.remote_field.field is self:\n+            if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n                 obj.remote_field.field = obj\n         memodict[id(self)] = obj\n         return obj\n@@ -572,7 +638,7 @@ class Field(RegisterLookupMixin):\n         not a new copy of that field. So, use the app registry to load the\n         model and then the field back.\n         \"\"\"\n-        if not hasattr(self, 'model'):\n+        if not hasattr(self, \"model\"):\n             # Fields are sometimes used without attaching them to models (for\n             # example in aggregation). In this case give back a plain field\n             # instance. The code below will create a new empty instance of\n@@ -581,10 +647,13 @@ class Field(RegisterLookupMixin):\n             state = self.__dict__.copy()\n             # The _get_default cached_property can't be pickled due to lambda\n             # usage.\n-            state.pop('_get_default', None)\n+            state.pop(\"_get_default\", None)\n             return _empty, (self.__class__,), state\n-        return _load_field, (self.model._meta.app_label, self.model._meta.object_name,\n-                             self.name)\n+        return _load_field, (\n+            self.model._meta.app_label,\n+            self.model._meta.object_name,\n+            self.name,\n+        )\n \n     def get_pk_value_on_save(self, instance):\n         \"\"\"\n@@ -622,7 +691,7 @@ class Field(RegisterLookupMixin):\n             try:\n                 v(value)\n             except exceptions.ValidationError as e:\n-                if hasattr(e, 'code') and e.code in self.error_messages:\n+                if hasattr(e, \"code\") and e.code in self.error_messages:\n                     e.message = self.error_messages[e.code]\n                 errors.extend(e.error_list)\n \n@@ -649,16 +718,16 @@ class Field(RegisterLookupMixin):\n                 elif value == option_key:\n                     return\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n \n         if value is None and not self.null:\n-            raise exceptions.ValidationError(self.error_messages['null'], code='null')\n+            raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n \n         if not self.blank and value in self.empty_values:\n-            raise exceptions.ValidationError(self.error_messages['blank'], code='blank')\n+            raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n \n     def clean(self, value, model_instance):\n         \"\"\"\n@@ -672,7 +741,7 @@ class Field(RegisterLookupMixin):\n         return value\n \n     def db_type_parameters(self, connection):\n-        return DictWrapper(self.__dict__, connection.ops.quote_name, 'qn_')\n+        return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n \n     def db_check(self, connection):\n         \"\"\"\n@@ -682,7 +751,9 @@ class Field(RegisterLookupMixin):\n         \"\"\"\n         data = self.db_type_parameters(connection)\n         try:\n-            return connection.data_type_check_constraints[self.get_internal_type()] % data\n+            return (\n+                connection.data_type_check_constraints[self.get_internal_type()] % data\n+            )\n         except KeyError:\n             return None\n \n@@ -744,7 +815,7 @@ class Field(RegisterLookupMixin):\n         return connection.data_types_suffix.get(self.get_internal_type())\n \n     def get_db_converters(self, connection):\n-        if hasattr(self, 'from_db_value'):\n+        if hasattr(self, \"from_db_value\"):\n             return [self.from_db_value]\n         return []\n \n@@ -769,7 +840,7 @@ class Field(RegisterLookupMixin):\n         self.attname, self.column = self.get_attname_column()\n         self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n-            self.verbose_name = self.name.replace('_', ' ')\n+            self.verbose_name = self.name.replace(\"_\", \" \")\n \n     def contribute_to_class(self, cls, name, private_only=False):\n         \"\"\"\n@@ -792,10 +863,10 @@ class Field(RegisterLookupMixin):\n             # this class, but don't check methods derived from inheritance, to\n             # allow overriding inherited choices. For more complex inheritance\n             # structures users should override contribute_to_class().\n-            if 'get_%s_display' % self.name not in cls.__dict__:\n+            if \"get_%s_display\" % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n-                    'get_%s_display' % self.name,\n+                    \"get_%s_display\" % self.name,\n                     partialmethod(cls._get_FIELD_display, field=self),\n                 )\n \n@@ -856,11 +927,21 @@ class Field(RegisterLookupMixin):\n                 return self.default\n             return lambda: self.default\n \n-        if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls:\n+        if (\n+            not self.empty_strings_allowed\n+            or self.null\n+            and not connection.features.interprets_empty_strings_as_nulls\n+        ):\n             return return_None\n         return str  # return empty string\n \n-    def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH, limit_choices_to=None, ordering=()):\n+    def get_choices(\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n+    ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n         as <select> choices for this field.\n@@ -868,7 +949,9 @@ class Field(RegisterLookupMixin):\n         if self.choices is not None:\n             choices = list(self.choices)\n             if include_blank:\n-                blank_defined = any(choice in ('', None) for choice, _ in self.flatchoices)\n+                blank_defined = any(\n+                    choice in (\"\", None) for choice, _ in self.flatchoices\n+                )\n                 if not blank_defined:\n                     choices = blank_choice + choices\n             return choices\n@@ -876,8 +959,8 @@ class Field(RegisterLookupMixin):\n         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n         choice_func = operator.attrgetter(\n             self.remote_field.get_related_field().attname\n-            if hasattr(self.remote_field, 'get_related_field')\n-            else 'pk'\n+            if hasattr(self.remote_field, \"get_related_field\")\n+            else \"pk\"\n         )\n         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n@@ -904,6 +987,7 @@ class Field(RegisterLookupMixin):\n             else:\n                 flat.append((choice, value))\n         return flat\n+\n     flatchoices = property(_get_flatchoices)\n \n     def save_form_data(self, instance, data):\n@@ -912,24 +996,25 @@ class Field(RegisterLookupMixin):\n     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n         defaults = {\n-            'required': not self.blank,\n-            'label': capfirst(self.verbose_name),\n-            'help_text': self.help_text,\n+            \"required\": not self.blank,\n+            \"label\": capfirst(self.verbose_name),\n+            \"help_text\": self.help_text,\n         }\n         if self.has_default():\n             if callable(self.default):\n-                defaults['initial'] = self.default\n-                defaults['show_hidden_initial'] = True\n+                defaults[\"initial\"] = self.default\n+                defaults[\"show_hidden_initial\"] = True\n             else:\n-                defaults['initial'] = self.get_default()\n+                defaults[\"initial\"] = self.get_default()\n         if self.choices is not None:\n             # Fields with choices get special treatment.\n-            include_blank = (self.blank or\n-                             not (self.has_default() or 'initial' in kwargs))\n-            defaults['choices'] = self.get_choices(include_blank=include_blank)\n-            defaults['coerce'] = self.to_python\n+            include_blank = self.blank or not (\n+                self.has_default() or \"initial\" in kwargs\n+            )\n+            defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n+            defaults[\"coerce\"] = self.to_python\n             if self.null:\n-                defaults['empty_value'] = None\n+                defaults[\"empty_value\"] = None\n             if choices_form_class is not None:\n                 form_class = choices_form_class\n             else:\n@@ -938,9 +1023,19 @@ class Field(RegisterLookupMixin):\n             # max_value) don't apply for choice fields, so be sure to only pass\n             # the values that TypedChoiceField will understand.\n             for k in list(kwargs):\n-                if k not in ('coerce', 'empty_value', 'choices', 'required',\n-                             'widget', 'label', 'initial', 'help_text',\n-                             'error_messages', 'show_hidden_initial', 'disabled'):\n+                if k not in (\n+                    \"coerce\",\n+                    \"empty_value\",\n+                    \"choices\",\n+                    \"required\",\n+                    \"widget\",\n+                    \"label\",\n+                    \"initial\",\n+                    \"help_text\",\n+                    \"error_messages\",\n+                    \"show_hidden_initial\",\n+                    \"disabled\",\n+                ):\n                     del kwargs[k]\n         defaults.update(kwargs)\n         if form_class is None:\n@@ -955,8 +1050,8 @@ class Field(RegisterLookupMixin):\n class BooleanField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either True, False, or None.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n     }\n     description = _(\"Boolean (Either True or False)\")\n \n@@ -969,14 +1064,14 @@ class BooleanField(Field):\n         if value in (True, False):\n             # 1/0 are equal to True/False. bool() converts former to latter.\n             return bool(value)\n-        if value in ('t', 'True', '1'):\n+        if value in (\"t\", \"True\", \"1\"):\n             return True\n-        if value in ('f', 'False', '0'):\n+        if value in (\"f\", \"False\", \"0\"):\n             return False\n         raise exceptions.ValidationError(\n-            self.error_messages['invalid_nullable' if self.null else 'invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_prep_value(self, value):\n@@ -987,14 +1082,14 @@ class BooleanField(Field):\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n-            include_blank = not (self.has_default() or 'initial' in kwargs)\n-            defaults = {'choices': self.get_choices(include_blank=include_blank)}\n+            include_blank = not (self.has_default() or \"initial\" in kwargs)\n+            defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n         else:\n             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n             # In HTML checkboxes, 'required' means \"must be checked\" which is\n             # different from the choices case (\"must select some value\").\n             # required=False allows unchecked checkboxes.\n-            defaults = {'form_class': form_class, 'required': False}\n+            defaults = {\"form_class\": form_class, \"required\": False}\n         return super().formfield(**{**defaults, **kwargs})\n \n \n@@ -1007,7 +1102,7 @@ class CharField(Field):\n         self.validators.append(validators.MaxLengthValidator(self.max_length))\n \n     def check(self, **kwargs):\n-        databases = kwargs.get('databases') or []\n+        databases = kwargs.get(\"databases\") or []\n         return [\n             *super().check(**kwargs),\n             *self._check_db_collation(databases),\n@@ -1020,16 +1115,19 @@ class CharField(Field):\n                 checks.Error(\n                     \"CharFields must define a 'max_length' attribute.\",\n                     obj=self,\n-                    id='fields.E120',\n+                    id=\"fields.E120\",\n                 )\n             ]\n-        elif (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n-                self.max_length <= 0):\n+        elif (\n+            not isinstance(self.max_length, int)\n+            or isinstance(self.max_length, bool)\n+            or self.max_length <= 0\n+        ):\n             return [\n                 checks.Error(\n                     \"'max_length' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E121',\n+                    id=\"fields.E121\",\n                 )\n             ]\n         else:\n@@ -1042,16 +1140,17 @@ class CharField(Field):\n                 continue\n             connection = connections[db]\n             if not (\n-                self.db_collation is None or\n-                'supports_collation_on_charfield' in self.model._meta.required_db_features or\n-                connection.features.supports_collation_on_charfield\n+                self.db_collation is None\n+                or \"supports_collation_on_charfield\"\n+                in self.model._meta.required_db_features\n+                or connection.features.supports_collation_on_charfield\n             ):\n                 errors.append(\n                     checks.Error(\n-                        '%s does not support a database collation on '\n-                        'CharFields.' % connection.display_name,\n+                        \"%s does not support a database collation on \"\n+                        \"CharFields.\" % connection.display_name,\n                         obj=self,\n-                        id='fields.E190',\n+                        id=\"fields.E190\",\n                     ),\n                 )\n         return errors\n@@ -1077,17 +1176,17 @@ class CharField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        defaults = {'max_length': self.max_length}\n+        defaults = {\"max_length\": self.max_length}\n         # TODO: Handle multiple backends with different feature flags.\n         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n-            defaults['empty_value'] = None\n+            defaults[\"empty_value\"] = None\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.db_collation:\n-            kwargs['db_collation'] = self.db_collation\n+            kwargs[\"db_collation\"] = self.db_collation\n         return name, path, args, kwargs\n \n \n@@ -1095,20 +1194,18 @@ class CommaSeparatedIntegerField(CharField):\n     default_validators = [validators.validate_comma_separated_integer_list]\n     description = _(\"Comma-separated integers\")\n     system_check_removed_details = {\n-        'msg': (\n-            'CommaSeparatedIntegerField is removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"CommaSeparatedIntegerField is removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': (\n-            'Use CharField(validators=[validate_comma_separated_integer_list]) '\n-            'instead.'\n+        \"hint\": (\n+            \"Use CharField(validators=[validate_comma_separated_integer_list]) instead.\"\n         ),\n-        'id': 'fields.E901',\n+        \"id\": \"fields.E901\",\n     }\n \n \n class DateTimeCheckMixin:\n-\n     def check(self, **kwargs):\n         return [\n             *super().check(**kwargs),\n@@ -1120,8 +1217,14 @@ class DateTimeCheckMixin:\n         # auto_now, auto_now_add, and default are mutually exclusive\n         # options. The use of more than one of these options together\n         # will trigger an Error\n-        mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()]\n-        enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True)\n+        mutually_exclusive_options = [\n+            self.auto_now_add,\n+            self.auto_now,\n+            self.has_default(),\n+        ]\n+        enabled_options = [\n+            option not in (None, False) for option in mutually_exclusive_options\n+        ].count(True)\n         if enabled_options > 1:\n             return [\n                 checks.Error(\n@@ -1129,7 +1232,7 @@ class DateTimeCheckMixin:\n                     \"are mutually exclusive. Only one of these options \"\n                     \"may be present.\",\n                     obj=self,\n-                    id='fields.E160',\n+                    id=\"fields.E160\",\n                 )\n             ]\n         else:\n@@ -1142,19 +1245,24 @@ class DateTimeCheckMixin:\n class DateField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid date format. It must be '\n-                     'in YYYY-MM-DD format.'),\n-        'invalid_date': _('\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) '\n-                          'but it is an invalid date.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n+            \"in YYYY-MM-DD format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n+            \"but it is an invalid date.\"\n+        ),\n     }\n     description = _(\"Date (without time)\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -1185,13 +1293,13 @@ class DateField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1200,12 +1308,12 @@ class DateField(DateTimeCheckMixin, Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.auto_now:\n-            kwargs['auto_now'] = True\n+            kwargs[\"auto_now\"] = True\n         if self.auto_now_add:\n-            kwargs['auto_now_add'] = True\n+            kwargs[\"auto_now_add\"] = True\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['editable']\n-            del kwargs['blank']\n+            del kwargs[\"editable\"]\n+            del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1230,15 +1338,15 @@ class DateField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1253,12 +1361,18 @@ class DateField(DateTimeCheckMixin, Field):\n         super().contribute_to_class(cls, name, **kwargs)\n         if not self.null:\n             setattr(\n-                cls, 'get_next_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=True)\n+                cls,\n+                \"get_next_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n+                ),\n             )\n             setattr(\n-                cls, 'get_previous_by_%s' % self.name,\n-                partialmethod(cls._get_next_or_previous_by_FIELD, field=self, is_next=False)\n+                cls,\n+                \"get_previous_by_%s\" % self.name,\n+                partialmethod(\n+                    cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n+                ),\n             )\n \n     def get_prep_value(self, value):\n@@ -1273,25 +1387,33 @@ class DateField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DateTimeField(DateField):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'),\n-        'invalid_date': _(\"\u201c%(value)s\u201d value has the correct format \"\n-                          \"(YYYY-MM-DD) but it is an invalid date.\"),\n-        'invalid_datetime': _('\u201c%(value)s\u201d value has the correct format '\n-                              '(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) '\n-                              'but it is an invalid date/time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n+        ),\n+        \"invalid_date\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD) but it is an invalid date.\"\n+        ),\n+        \"invalid_datetime\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n+            \"but it is an invalid date/time.\"\n+        ),\n     }\n     description = _(\"Date (with time)\")\n \n@@ -1328,13 +1450,13 @@ class DateTimeField(DateField):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -1355,10 +1477,12 @@ class DateTimeField(DateField):\n                 # local time. This won't work during DST change, but we can't\n                 # do much about it, so we let the exceptions percolate up the\n                 # call stack.\n-                warnings.warn(\"DateTimeField %s.%s received a naive datetime \"\n-                              \"(%s) while time zone support is active.\" %\n-                              (self.model.__name__, self.name, value),\n-                              RuntimeWarning)\n+                warnings.warn(\n+                    \"DateTimeField %s.%s received a naive datetime \"\n+                    \"(%s) while time zone support is active.\"\n+                    % (self.model.__name__, self.name, value),\n+                    RuntimeWarning,\n+                )\n                 default_timezone = timezone.get_default_timezone()\n                 value = timezone.make_aware(value, default_timezone)\n             return value\n@@ -1369,9 +1493,9 @@ class DateTimeField(DateField):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_datetime'],\n-                code='invalid_datetime',\n-                params={'value': value},\n+                self.error_messages[\"invalid_datetime\"],\n+                code=\"invalid_datetime\",\n+                params={\"value\": value},\n             )\n \n         try:\n@@ -1380,15 +1504,15 @@ class DateTimeField(DateField):\n                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_date'],\n-                code='invalid_date',\n-                params={'value': value},\n+                self.error_messages[\"invalid_date\"],\n+                code=\"invalid_date\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -1410,13 +1534,14 @@ class DateTimeField(DateField):\n             # time. This won't work during DST change, but we can't do much\n             # about it, so we let the exceptions percolate up the call stack.\n             try:\n-                name = '%s.%s' % (self.model.__name__, self.name)\n+                name = \"%s.%s\" % (self.model.__name__, self.name)\n             except AttributeError:\n-                name = '(unbound)'\n-            warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n-                          \" while time zone support is active.\" %\n-                          (name, value),\n-                          RuntimeWarning)\n+                name = \"(unbound)\"\n+            warnings.warn(\n+                \"DateTimeField %s received a naive datetime (%s)\"\n+                \" while time zone support is active.\" % (name, value),\n+                RuntimeWarning,\n+            )\n             default_timezone = timezone.get_default_timezone()\n             value = timezone.make_aware(value, default_timezone)\n         return value\n@@ -1429,24 +1554,32 @@ class DateTimeField(DateField):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DateTimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DateTimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DecimalField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a decimal number.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n     }\n     description = _(\"Decimal number\")\n \n-    def __init__(self, verbose_name=None, name=None, max_digits=None,\n-                 decimal_places=None, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        max_digits=None,\n+        decimal_places=None,\n+        **kwargs,\n+    ):\n         self.max_digits, self.decimal_places = max_digits, decimal_places\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1473,7 +1606,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'decimal_places' attribute.\",\n                     obj=self,\n-                    id='fields.E130',\n+                    id=\"fields.E130\",\n                 )\n             ]\n         except ValueError:\n@@ -1481,7 +1614,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'decimal_places' must be a non-negative integer.\",\n                     obj=self,\n-                    id='fields.E131',\n+                    id=\"fields.E131\",\n                 )\n             ]\n         else:\n@@ -1497,7 +1630,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"DecimalFields must define a 'max_digits' attribute.\",\n                     obj=self,\n-                    id='fields.E132',\n+                    id=\"fields.E132\",\n                 )\n             ]\n         except ValueError:\n@@ -1505,7 +1638,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be a positive integer.\",\n                     obj=self,\n-                    id='fields.E133',\n+                    id=\"fields.E133\",\n                 )\n             ]\n         else:\n@@ -1517,7 +1650,7 @@ class DecimalField(Field):\n                 checks.Error(\n                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n                     obj=self,\n-                    id='fields.E134',\n+                    id=\"fields.E134\",\n                 )\n             ]\n         return []\n@@ -1535,9 +1668,9 @@ class DecimalField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.max_digits is not None:\n-            kwargs['max_digits'] = self.max_digits\n+            kwargs[\"max_digits\"] = self.max_digits\n         if self.decimal_places is not None:\n-            kwargs['decimal_places'] = self.decimal_places\n+            kwargs[\"decimal_places\"] = self.decimal_places\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1552,25 +1685,29 @@ class DecimalField(Field):\n             return decimal.Decimal(value)\n         except (decimal.InvalidOperation, TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def get_db_prep_save(self, value, connection):\n-        return connection.ops.adapt_decimalfield_value(self.to_python(value), self.max_digits, self.decimal_places)\n+        return connection.ops.adapt_decimalfield_value(\n+            self.to_python(value), self.max_digits, self.decimal_places\n+        )\n \n     def get_prep_value(self, value):\n         value = super().get_prep_value(value)\n         return self.to_python(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'max_digits': self.max_digits,\n-            'decimal_places': self.decimal_places,\n-            'form_class': forms.DecimalField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_digits\": self.max_digits,\n+                \"decimal_places\": self.decimal_places,\n+                \"form_class\": forms.DecimalField,\n+                **kwargs,\n+            }\n+        )\n \n \n class DurationField(Field):\n@@ -1580,10 +1717,13 @@ class DurationField(Field):\n     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n     of microseconds on other databases.\n     \"\"\"\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     '[DD] [[HH:]MM:]ss[.uuuuuu] format.')\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        )\n     }\n     description = _(\"Duration\")\n \n@@ -1604,9 +1744,9 @@ class DurationField(Field):\n                 return parsed\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1624,13 +1764,15 @@ class DurationField(Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else duration_string(val)\n+        return \"\" if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.DurationField,\n+                **kwargs,\n+            }\n+        )\n \n \n class EmailField(CharField):\n@@ -1639,7 +1781,7 @@ class EmailField(CharField):\n \n     def __init__(self, *args, **kwargs):\n         # max_length=254 to be compliant with RFCs 3696 and 5321\n-        kwargs.setdefault('max_length', 254)\n+        kwargs.setdefault(\"max_length\", 254)\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n@@ -1651,20 +1793,31 @@ class EmailField(CharField):\n     def formfield(self, **kwargs):\n         # As with CharField, this will cause email validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.EmailField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.EmailField,\n+                **kwargs,\n+            }\n+        )\n \n \n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n-                 recursive=False, allow_files=True, allow_folders=False, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        path=\"\",\n+        match=None,\n+        recursive=False,\n+        allow_files=True,\n+        allow_folders=False,\n+        **kwargs,\n+    ):\n         self.path, self.match, self.recursive = path, match, recursive\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n-        kwargs.setdefault('max_length', 100)\n+        kwargs.setdefault(\"max_length\", 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1679,23 +1832,23 @@ class FilePathField(Field):\n                 checks.Error(\n                     \"FilePathFields must have either 'allow_files' or 'allow_folders' set to True.\",\n                     obj=self,\n-                    id='fields.E140',\n+                    id=\"fields.E140\",\n                 )\n             ]\n         return []\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self.path != \"\":\n+            kwargs[\"path\"] = self.path\n         if self.match is not None:\n-            kwargs['match'] = self.match\n+            kwargs[\"match\"] = self.match\n         if self.recursive is not False:\n-            kwargs['recursive'] = self.recursive\n+            kwargs[\"recursive\"] = self.recursive\n         if self.allow_files is not True:\n-            kwargs['allow_files'] = self.allow_files\n+            kwargs[\"allow_files\"] = self.allow_files\n         if self.allow_folders is not False:\n-            kwargs['allow_folders'] = self.allow_folders\n+            kwargs[\"allow_folders\"] = self.allow_folders\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n@@ -1707,15 +1860,17 @@ class FilePathField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'path': self.path() if callable(self.path) else self.path,\n-            'match': self.match,\n-            'recursive': self.recursive,\n-            'form_class': forms.FilePathField,\n-            'allow_files': self.allow_files,\n-            'allow_folders': self.allow_folders,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"path\": self.path() if callable(self.path) else self.path,\n+                \"match\": self.match,\n+                \"recursive\": self.recursive,\n+                \"form_class\": forms.FilePathField,\n+                \"allow_files\": self.allow_files,\n+                \"allow_folders\": self.allow_folders,\n+                **kwargs,\n+            }\n+        )\n \n     def get_internal_type(self):\n         return \"FilePathField\"\n@@ -1724,7 +1879,7 @@ class FilePathField(Field):\n class FloatField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be a float.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n     }\n     description = _(\"Floating point number\")\n \n@@ -1749,22 +1904,24 @@ class FloatField(Field):\n             return float(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.FloatField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.FloatField,\n+                **kwargs,\n+            }\n+        )\n \n \n class IntegerField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be an integer.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n     }\n     description = _(\"Integer\")\n \n@@ -1778,10 +1935,11 @@ class IntegerField(Field):\n         if self.max_length is not None:\n             return [\n                 checks.Warning(\n-                    \"'max_length' is ignored when used with %s.\" % self.__class__.__name__,\n+                    \"'max_length' is ignored when used with %s.\"\n+                    % self.__class__.__name__,\n                     hint=\"Remove 'max_length' from field\",\n                     obj=self,\n-                    id='fields.W122',\n+                    id=\"fields.W122\",\n                 )\n             ]\n         return []\n@@ -1795,22 +1953,28 @@ class IntegerField(Field):\n         min_value, max_value = connection.ops.integer_field_range(internal_type)\n         if min_value is not None and not any(\n             (\n-                isinstance(validator, validators.MinValueValidator) and (\n+                isinstance(validator, validators.MinValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) >= min_value\n-            ) for validator in validators_\n+                )\n+                >= min_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MinValueValidator(min_value))\n         if max_value is not None and not any(\n             (\n-                isinstance(validator, validators.MaxValueValidator) and (\n+                isinstance(validator, validators.MaxValueValidator)\n+                and (\n                     validator.limit_value()\n                     if callable(validator.limit_value)\n                     else validator.limit_value\n-                ) <= max_value\n-            ) for validator in validators_\n+                )\n+                <= max_value\n+            )\n+            for validator in validators_\n         ):\n             validators_.append(validators.MaxValueValidator(max_value))\n         return validators_\n@@ -1836,16 +2000,18 @@ class IntegerField(Field):\n             return int(value)\n         except (TypeError, ValueError):\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.IntegerField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.IntegerField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BigIntegerField(IntegerField):\n@@ -1856,39 +2022,41 @@ class BigIntegerField(IntegerField):\n         return \"BigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': -BigIntegerField.MAX_BIGINT - 1,\n-            'max_value': BigIntegerField.MAX_BIGINT,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n+                \"max_value\": BigIntegerField.MAX_BIGINT,\n+                **kwargs,\n+            }\n+        )\n \n \n class SmallIntegerField(IntegerField):\n-    description = _('Small integer')\n+    description = _(\"Small integer\")\n \n     def get_internal_type(self):\n-        return 'SmallIntegerField'\n+        return \"SmallIntegerField\"\n \n \n class IPAddressField(Field):\n     empty_strings_allowed = False\n     description = _(\"IPv4 address\")\n     system_check_removed_details = {\n-        'msg': (\n-            'IPAddressField has been removed except for support in '\n-            'historical migrations.'\n+        \"msg\": (\n+            \"IPAddressField has been removed except for support in \"\n+            \"historical migrations.\"\n         ),\n-        'hint': 'Use GenericIPAddressField instead.',\n-        'id': 'fields.E900',\n+        \"hint\": \"Use GenericIPAddressField instead.\",\n+        \"id\": \"fields.E900\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['max_length'] = 15\n+        kwargs[\"max_length\"] = 15\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_prep_value(self, value):\n@@ -1906,14 +2074,22 @@ class GenericIPAddressField(Field):\n     description = _(\"IP address\")\n     default_error_messages = {}\n \n-    def __init__(self, verbose_name=None, name=None, protocol='both',\n-                 unpack_ipv4=False, *args, **kwargs):\n+    def __init__(\n+        self,\n+        verbose_name=None,\n+        name=None,\n+        protocol=\"both\",\n+        unpack_ipv4=False,\n+        *args,\n+        **kwargs,\n+    ):\n         self.unpack_ipv4 = unpack_ipv4\n         self.protocol = protocol\n-        self.default_validators, invalid_error_message = \\\n+        self.default_validators, invalid_error_message = (\n             validators.ip_address_validators(protocol, unpack_ipv4)\n-        self.default_error_messages['invalid'] = invalid_error_message\n-        kwargs['max_length'] = 39\n+        )\n+        self.default_error_messages[\"invalid\"] = invalid_error_message\n+        kwargs[\"max_length\"] = 39\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -1923,13 +2099,13 @@ class GenericIPAddressField(Field):\n         ]\n \n     def _check_blank_and_null_values(self, **kwargs):\n-        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+        if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n             return [\n                 checks.Error(\n-                    'GenericIPAddressFields cannot have blank=True if null=False, '\n-                    'as blank values are stored as nulls.',\n+                    \"GenericIPAddressFields cannot have blank=True if null=False, \"\n+                    \"as blank values are stored as nulls.\",\n                     obj=self,\n-                    id='fields.E150',\n+                    id=\"fields.E150\",\n                 )\n             ]\n         return []\n@@ -1937,11 +2113,11 @@ class GenericIPAddressField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.unpack_ipv4 is not False:\n-            kwargs['unpack_ipv4'] = self.unpack_ipv4\n+            kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n         if self.protocol != \"both\":\n-            kwargs['protocol'] = self.protocol\n+            kwargs[\"protocol\"] = self.protocol\n         if kwargs.get(\"max_length\") == 39:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -1953,8 +2129,10 @@ class GenericIPAddressField(Field):\n         if not isinstance(value, str):\n             value = str(value)\n         value = value.strip()\n-        if ':' in value:\n-            return clean_ipv6_address(value, self.unpack_ipv4, self.error_messages['invalid'])\n+        if \":\" in value:\n+            return clean_ipv6_address(\n+                value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n+            )\n         return value\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -1966,7 +2144,7 @@ class GenericIPAddressField(Field):\n         value = super().get_prep_value(value)\n         if value is None:\n             return None\n-        if value and ':' in value:\n+        if value and \":\" in value:\n             try:\n                 return clean_ipv6_address(value, self.unpack_ipv4)\n             except exceptions.ValidationError:\n@@ -1974,37 +2152,38 @@ class GenericIPAddressField(Field):\n         return str(value)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'protocol': self.protocol,\n-            'form_class': forms.GenericIPAddressField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"protocol\": self.protocol,\n+                \"form_class\": forms.GenericIPAddressField,\n+                **kwargs,\n+            }\n+        )\n \n \n class NullBooleanField(BooleanField):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n-        'invalid_nullable': _('\u201c%(value)s\u201d value must be either None, True or False.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n+        \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n     }\n     description = _(\"Boolean (Either True, False or None)\")\n     system_check_removed_details = {\n-        'msg': (\n-            'NullBooleanField is removed except for support in historical '\n-            'migrations.'\n+        \"msg\": (\n+            \"NullBooleanField is removed except for support in historical migrations.\"\n         ),\n-        'hint': 'Use BooleanField(null=True) instead.',\n-        'id': 'fields.E903',\n+        \"hint\": \"Use BooleanField(null=True) instead.\",\n+        \"id\": \"fields.E903\",\n     }\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['null'] = True\n-        kwargs['blank'] = True\n+        kwargs[\"null\"] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['null']\n-        del kwargs['blank']\n+        del kwargs[\"null\"]\n+        del kwargs[\"blank\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2014,7 +2193,7 @@ class NullBooleanField(BooleanField):\n class PositiveIntegerRelDbTypeMixin:\n     def __init_subclass__(cls, **kwargs):\n         super().__init_subclass__(**kwargs)\n-        if not hasattr(cls, 'integer_field_class'):\n+        if not hasattr(cls, \"integer_field_class\"):\n             cls.integer_field_class = next(\n                 (\n                     parent\n@@ -2040,16 +2219,18 @@ class PositiveIntegerRelDbTypeMixin:\n \n \n class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, BigIntegerField):\n-    description = _('Positive big integer')\n+    description = _(\"Positive big integer\")\n \n     def get_internal_type(self):\n-        return 'PositiveBigIntegerField'\n+        return \"PositiveBigIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n@@ -2059,10 +2240,12 @@ class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n         return \"PositiveIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, SmallIntegerField):\n@@ -2072,17 +2255,21 @@ class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, SmallIntegerField\n         return \"PositiveSmallIntegerField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'min_value': 0,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"min_value\": 0,\n+                **kwargs,\n+            }\n+        )\n \n \n class SlugField(CharField):\n     default_validators = [validators.validate_slug]\n     description = _(\"Slug (up to %(max_length)s)\")\n \n-    def __init__(self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs):\n+    def __init__(\n+        self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n+    ):\n         self.allow_unicode = allow_unicode\n         if self.allow_unicode:\n             self.default_validators = [validators.validate_unicode_slug]\n@@ -2091,24 +2278,26 @@ class SlugField(CharField):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 50:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         if self.db_index is False:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         else:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         if self.allow_unicode is not False:\n-            kwargs['allow_unicode'] = self.allow_unicode\n+            kwargs[\"allow_unicode\"] = self.allow_unicode\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n         return \"SlugField\"\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.SlugField,\n-            'allow_unicode': self.allow_unicode,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.SlugField,\n+                \"allow_unicode\": self.allow_unicode,\n+                **kwargs,\n+            }\n+        )\n \n \n class TextField(Field):\n@@ -2119,7 +2308,7 @@ class TextField(Field):\n         self.db_collation = db_collation\n \n     def check(self, **kwargs):\n-        databases = kwargs.get('databases') or []\n+        databases = kwargs.get(\"databases\") or []\n         return [\n             *super().check(**kwargs),\n             *self._check_db_collation(databases),\n@@ -2132,16 +2321,17 @@ class TextField(Field):\n                 continue\n             connection = connections[db]\n             if not (\n-                self.db_collation is None or\n-                'supports_collation_on_textfield' in self.model._meta.required_db_features or\n-                connection.features.supports_collation_on_textfield\n+                self.db_collation is None\n+                or \"supports_collation_on_textfield\"\n+                in self.model._meta.required_db_features\n+                or connection.features.supports_collation_on_textfield\n             ):\n                 errors.append(\n                     checks.Error(\n-                        '%s does not support a database collation on '\n-                        'TextFields.' % connection.display_name,\n+                        \"%s does not support a database collation on \"\n+                        \"TextFields.\" % connection.display_name,\n                         obj=self,\n-                        id='fields.E190',\n+                        id=\"fields.E190\",\n                     ),\n                 )\n         return errors\n@@ -2162,35 +2352,42 @@ class TextField(Field):\n         # Passing max_length to forms.CharField means that the value's length\n         # will be validated twice. This is considered acceptable since we want\n         # the value in the form field (to pass into widget for example).\n-        return super().formfield(**{\n-            'max_length': self.max_length,\n-            **({} if self.choices is not None else {'widget': forms.Textarea}),\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"max_length\": self.max_length,\n+                **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n+                **kwargs,\n+            }\n+        )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.db_collation:\n-            kwargs['db_collation'] = self.db_collation\n+            kwargs[\"db_collation\"] = self.db_collation\n         return name, path, args, kwargs\n \n \n class TimeField(DateTimeCheckMixin, Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d value has an invalid format. It must be in '\n-                     'HH:MM[:ss[.uuuuuu]] format.'),\n-        'invalid_time': _('\u201c%(value)s\u201d value has the correct format '\n-                          '(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.'),\n+        \"invalid\": _(\n+            \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n+            \"HH:MM[:ss[.uuuuuu]] format.\"\n+        ),\n+        \"invalid_time\": _(\n+            \"\u201c%(value)s\u201d value has the correct format \"\n+            \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n+        ),\n     }\n     description = _(\"Time\")\n \n-    def __init__(self, verbose_name=None, name=None, auto_now=False,\n-                 auto_now_add=False, **kwargs):\n+    def __init__(\n+        self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n+    ):\n         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n         if auto_now or auto_now_add:\n-            kwargs['editable'] = False\n-            kwargs['blank'] = True\n+            kwargs[\"editable\"] = False\n+            kwargs[\"blank\"] = True\n         super().__init__(verbose_name, name, **kwargs)\n \n     def _check_fix_default_value(self):\n@@ -2224,13 +2421,13 @@ class TimeField(DateTimeCheckMixin, Field):\n         if lower <= value <= upper:\n             return [\n                 checks.Warning(\n-                    'Fixed default value provided.',\n-                    hint='It seems you set a fixed date / time / datetime '\n-                         'value as default for this field. This may not be '\n-                         'what you want. If you want to have the current date '\n-                         'as default, use `django.utils.timezone.now`',\n+                    \"Fixed default value provided.\",\n+                    hint=\"It seems you set a fixed date / time / datetime \"\n+                    \"value as default for this field. This may not be \"\n+                    \"what you want. If you want to have the current date \"\n+                    \"as default, use `django.utils.timezone.now`\",\n                     obj=self,\n-                    id='fields.W161',\n+                    id=\"fields.W161\",\n                 )\n             ]\n \n@@ -2243,8 +2440,8 @@ class TimeField(DateTimeCheckMixin, Field):\n         if self.auto_now_add is not False:\n             kwargs[\"auto_now_add\"] = self.auto_now_add\n         if self.auto_now or self.auto_now_add:\n-            del kwargs['blank']\n-            del kwargs['editable']\n+            del kwargs[\"blank\"]\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2267,15 +2464,15 @@ class TimeField(DateTimeCheckMixin, Field):\n                 return parsed\n         except ValueError:\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid_time'],\n-                code='invalid_time',\n-                params={'value': value},\n+                self.error_messages[\"invalid_time\"],\n+                code=\"invalid_time\",\n+                params={\"value\": value},\n             )\n \n         raise exceptions.ValidationError(\n-            self.error_messages['invalid'],\n-            code='invalid',\n-            params={'value': value},\n+            self.error_messages[\"invalid\"],\n+            code=\"invalid\",\n+            params={\"value\": value},\n         )\n \n     def pre_save(self, model_instance, add):\n@@ -2298,13 +2495,15 @@ class TimeField(DateTimeCheckMixin, Field):\n \n     def value_to_string(self, obj):\n         val = self.value_from_object(obj)\n-        return '' if val is None else val.isoformat()\n+        return \"\" if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.TimeField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.TimeField,\n+                **kwargs,\n+            }\n+        )\n \n \n class URLField(CharField):\n@@ -2312,30 +2511,32 @@ class URLField(CharField):\n     description = _(\"URL\")\n \n     def __init__(self, verbose_name=None, name=None, **kwargs):\n-        kwargs.setdefault('max_length', 200)\n+        kwargs.setdefault(\"max_length\", 200)\n         super().__init__(verbose_name, name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if kwargs.get(\"max_length\") == 200:\n-            del kwargs['max_length']\n+            del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n         # As with CharField, this will cause URL validation to be performed\n         # twice.\n-        return super().formfield(**{\n-            'form_class': forms.URLField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.URLField,\n+                **kwargs,\n+            }\n+        )\n \n \n class BinaryField(Field):\n     description = _(\"Raw binary data\")\n-    empty_values = [None, b'']\n+    empty_values = [None, b\"\"]\n \n     def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('editable', False)\n+        kwargs.setdefault(\"editable\", False)\n         super().__init__(*args, **kwargs)\n         if self.max_length is not None:\n             self.validators.append(validators.MaxLengthValidator(self.max_length))\n@@ -2350,7 +2551,7 @@ class BinaryField(Field):\n                     \"BinaryField's default cannot be a string. Use bytes \"\n                     \"content instead.\",\n                     obj=self,\n-                    id='fields.E170',\n+                    id=\"fields.E170\",\n                 )\n             ]\n         return []\n@@ -2358,9 +2559,9 @@ class BinaryField(Field):\n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self.editable:\n-            kwargs['editable'] = True\n+            kwargs[\"editable\"] = True\n         else:\n-            del kwargs['editable']\n+            del kwargs[\"editable\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2373,8 +2574,8 @@ class BinaryField(Field):\n         if self.has_default() and not callable(self.default):\n             return self.default\n         default = super().get_default()\n-        if default == '':\n-            return b''\n+        if default == \"\":\n+            return b\"\"\n         return default\n \n     def get_db_prep_value(self, value, connection, prepared=False):\n@@ -2385,29 +2586,29 @@ class BinaryField(Field):\n \n     def value_to_string(self, obj):\n         \"\"\"Binary data is serialized as base64\"\"\"\n-        return b64encode(self.value_from_object(obj)).decode('ascii')\n+        return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n \n     def to_python(self, value):\n         # If it's a string, it should be base64-encoded data\n         if isinstance(value, str):\n-            return memoryview(b64decode(value.encode('ascii')))\n+            return memoryview(b64decode(value.encode(\"ascii\")))\n         return value\n \n \n class UUIDField(Field):\n     default_error_messages = {\n-        'invalid': _('\u201c%(value)s\u201d is not a valid UUID.'),\n+        \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n     }\n-    description = _('Universally unique identifier')\n+    description = _(\"Universally unique identifier\")\n     empty_strings_allowed = False\n \n     def __init__(self, verbose_name=None, **kwargs):\n-        kwargs['max_length'] = 32\n+        kwargs[\"max_length\"] = 32\n         super().__init__(verbose_name, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['max_length']\n+        del kwargs[\"max_length\"]\n         return name, path, args, kwargs\n \n     def get_internal_type(self):\n@@ -2429,29 +2630,31 @@ class UUIDField(Field):\n \n     def to_python(self, value):\n         if value is not None and not isinstance(value, uuid.UUID):\n-            input_form = 'int' if isinstance(value, int) else 'hex'\n+            input_form = \"int\" if isinstance(value, int) else \"hex\"\n             try:\n                 return uuid.UUID(**{input_form: value})\n             except (AttributeError, ValueError):\n                 raise exceptions.ValidationError(\n-                    self.error_messages['invalid'],\n-                    code='invalid',\n-                    params={'value': value},\n+                    self.error_messages[\"invalid\"],\n+                    code=\"invalid\",\n+                    params={\"value\": value},\n                 )\n         return value\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.UUIDField,\n-            **kwargs,\n-        })\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.UUIDField,\n+                **kwargs,\n+            }\n+        )\n \n \n class AutoFieldMixin:\n     db_returning = True\n \n     def __init__(self, *args, **kwargs):\n-        kwargs['blank'] = True\n+        kwargs[\"blank\"] = True\n         super().__init__(*args, **kwargs)\n \n     def check(self, **kwargs):\n@@ -2464,9 +2667,9 @@ class AutoFieldMixin:\n         if not self.primary_key:\n             return [\n                 checks.Error(\n-                    'AutoFields must set primary_key=True.',\n+                    \"AutoFields must set primary_key=True.\",\n                     obj=self,\n-                    id='fields.E100',\n+                    id=\"fields.E100\",\n                 ),\n             ]\n         else:\n@@ -2474,8 +2677,8 @@ class AutoFieldMixin:\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['blank']\n-        kwargs['primary_key'] = True\n+        del kwargs[\"blank\"]\n+        kwargs[\"primary_key\"] = True\n         return name, path, args, kwargs\n \n     def validate(self, value, model_instance):\n@@ -2489,8 +2692,7 @@ class AutoFieldMixin:\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         assert not cls._meta.auto_field, (\n-            \"Model %s can't have more than one auto-generated field.\"\n-            % cls._meta.label\n+            \"Model %s can't have more than one auto-generated field.\" % cls._meta.label\n         )\n         super().contribute_to_class(cls, name, **kwargs)\n         cls._meta.auto_field = self\n@@ -2521,34 +2723,35 @@ class AutoFieldMeta(type):\n         return (BigAutoField, SmallAutoField)\n \n     def __instancecheck__(self, instance):\n-        return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n+        return isinstance(instance, self._subclasses) or super().__instancecheck__(\n+            instance\n+        )\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return issubclass(subclass, self._subclasses) or super().__subclasscheck__(\n+            subclass\n+        )\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n-\n     def get_internal_type(self):\n-        return 'AutoField'\n+        return \"AutoField\"\n \n     def rel_db_type(self, connection):\n         return IntegerField().db_type(connection=connection)\n \n \n class BigAutoField(AutoFieldMixin, BigIntegerField):\n-\n     def get_internal_type(self):\n-        return 'BigAutoField'\n+        return \"BigAutoField\"\n \n     def rel_db_type(self, connection):\n         return BigIntegerField().db_type(connection=connection)\n \n \n class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n-\n     def get_internal_type(self):\n-        return 'SmallAutoField'\n+        return \"SmallAutoField\"\n \n     def rel_db_type(self, connection):\n         return SmallIntegerField().db_type(connection=connection)\n"}
{"instance_id": "django__django-14382", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..8e681e0aca 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -28,38 +28,49 @@ class TemplateCommand(BaseCommand):\n     :param directory: The directory to which the template should be copied.\n     :param options: The additional variables passed to project or app templates\n     \"\"\"\n+\n     requires_system_checks = []\n     # The supported URL schemes\n-    url_schemes = ['http', 'https', 'ftp']\n+    url_schemes = [\"http\", \"https\", \"ftp\"]\n     # Rewrite the following suffixes when determining the target filename.\n     rewrite_template_suffixes = (\n         # Allow shipping invalid .py files without byte-compilation.\n-        ('.py-tpl', '.py'),\n+        (\".py-tpl\", \".py\"),\n     )\n \n     def add_arguments(self, parser):\n-        parser.add_argument('name', help='Name of the application or project.')\n-        parser.add_argument('directory', nargs='?', help='Optional destination directory')\n-        parser.add_argument('--template', help='The path or URL to load the template from.')\n+        parser.add_argument(\"name\", help=\"Name of the application or project.\")\n+        parser.add_argument(\n+            \"directory\", nargs=\"?\", help=\"Optional destination directory\"\n+        )\n+        parser.add_argument(\n+            \"--template\", help=\"The path or URL to load the template from.\"\n+        )\n         parser.add_argument(\n-            '--extension', '-e', dest='extensions',\n-            action='append', default=['py'],\n+            \"--extension\",\n+            \"-e\",\n+            dest=\"extensions\",\n+            action=\"append\",\n+            default=[\"py\"],\n             help='The file extension(s) to render (default: \"py\"). '\n-                 'Separate multiple extensions with commas, or use '\n-                 '-e multiple times.'\n+            \"Separate multiple extensions with commas, or use \"\n+            \"-e multiple times.\",\n         )\n         parser.add_argument(\n-            '--name', '-n', dest='files',\n-            action='append', default=[],\n-            help='The file name(s) to render. Separate multiple file names '\n-                 'with commas, or use -n multiple times.'\n+            \"--name\",\n+            \"-n\",\n+            dest=\"files\",\n+            action=\"append\",\n+            default=[],\n+            help=\"The file name(s) to render. Separate multiple file names \"\n+            \"with commas, or use -n multiple times.\",\n         )\n \n     def handle(self, app_or_project, name, target=None, **options):\n         self.app_or_project = app_or_project\n-        self.a_or_an = 'an' if app_or_project == 'app' else 'a'\n+        self.a_or_an = \"an\" if app_or_project == \"app\" else \"a\"\n         self.paths_to_remove = []\n-        self.verbosity = options['verbosity']\n+        self.verbosity = options[\"verbosity\"]\n \n         self.validate_name(name)\n \n@@ -73,52 +84,55 @@ class TemplateCommand(BaseCommand):\n             except OSError as e:\n                 raise CommandError(e)\n         else:\n-            if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+            if app_or_project == \"app\":\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), \"directory\")\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n-                raise CommandError(\"Destination directory '%s' does not \"\n-                                   \"exist, please create it first.\" % top_dir)\n+                raise CommandError(\n+                    \"Destination directory '%s' does not \"\n+                    \"exist, please create it first.\" % top_dir\n+                )\n \n-        extensions = tuple(handle_extensions(options['extensions']))\n+        extensions = tuple(handle_extensions(options[\"extensions\"]))\n         extra_files = []\n-        for file in options['files']:\n-            extra_files.extend(map(lambda x: x.strip(), file.split(',')))\n+        for file in options[\"files\"]:\n+            extra_files.extend(map(lambda x: x.strip(), file.split(\",\")))\n         if self.verbosity >= 2:\n             self.stdout.write(\n-                'Rendering %s template files with extensions: %s'\n-                % (app_or_project, ', '.join(extensions))\n+                \"Rendering %s template files with extensions: %s\"\n+                % (app_or_project, \", \".join(extensions))\n             )\n             self.stdout.write(\n-                'Rendering %s template files with filenames: %s'\n-                % (app_or_project, ', '.join(extra_files))\n+                \"Rendering %s template files with filenames: %s\"\n+                % (app_or_project, \", \".join(extra_files))\n             )\n-        base_name = '%s_name' % app_or_project\n-        base_subdir = '%s_template' % app_or_project\n-        base_directory = '%s_directory' % app_or_project\n-        camel_case_name = 'camel_case_%s_name' % app_or_project\n-        camel_case_value = ''.join(x for x in name.title() if x != '_')\n-\n-        context = Context({\n-            **options,\n-            base_name: name,\n-            base_directory: top_dir,\n-            camel_case_name: camel_case_value,\n-            'docs_version': get_docs_version(),\n-            'django_version': django.__version__,\n-        }, autoescape=False)\n+        base_name = \"%s_name\" % app_or_project\n+        base_subdir = \"%s_template\" % app_or_project\n+        base_directory = \"%s_directory\" % app_or_project\n+        camel_case_name = \"camel_case_%s_name\" % app_or_project\n+        camel_case_value = \"\".join(x for x in name.title() if x != \"_\")\n+\n+        context = Context(\n+            {\n+                **options,\n+                base_name: name,\n+                base_directory: top_dir,\n+                camel_case_name: camel_case_value,\n+                \"docs_version\": get_docs_version(),\n+                \"django_version\": django.__version__,\n+            },\n+            autoescape=False,\n+        )\n \n         # Setup a stub settings environment for template rendering\n         if not settings.configured:\n             settings.configure()\n             django.setup()\n \n-        template_dir = self.handle_template(options['template'],\n-                                            base_subdir)\n+        template_dir = self.handle_template(options[\"template\"], base_subdir)\n         prefix_length = len(template_dir) + 1\n \n         for root, dirs, files in os.walk(template_dir):\n-\n             path_rest = root[prefix_length:]\n             relative_dir = path_rest.replace(base_name, name)\n             if relative_dir:\n@@ -126,11 +140,11 @@ class TemplateCommand(BaseCommand):\n                 os.makedirs(target_dir, exist_ok=True)\n \n             for dirname in dirs[:]:\n-                if dirname.startswith('.') or dirname == '__pycache__':\n+                if dirname.startswith(\".\") or dirname == \"__pycache__\":\n                     dirs.remove(dirname)\n \n             for filename in files:\n-                if filename.endswith(('.pyo', '.pyc', '.py.class')):\n+                if filename.endswith((\".pyo\", \".pyc\", \".py.class\")):\n                     # Ignore some files as they cause various breakages.\n                     continue\n                 old_path = os.path.join(root, filename)\n@@ -139,31 +153,34 @@ class TemplateCommand(BaseCommand):\n                 )\n                 for old_suffix, new_suffix in self.rewrite_template_suffixes:\n                     if new_path.endswith(old_suffix):\n-                        new_path = new_path[:-len(old_suffix)] + new_suffix\n+                        new_path = new_path[: -len(old_suffix)] + new_suffix\n                         break  # Only rewrite once\n \n                 if os.path.exists(new_path):\n                     raise CommandError(\n                         \"%s already exists. Overlaying %s %s into an existing \"\n-                        \"directory won't replace conflicting files.\" % (\n-                            new_path, self.a_or_an, app_or_project,\n+                        \"directory won't replace conflicting files.\"\n+                        % (\n+                            new_path,\n+                            self.a_or_an,\n+                            app_or_project,\n                         )\n                     )\n \n                 # Only render the Python files, as we don't want to\n                 # accidentally render Django templates files\n                 if new_path.endswith(extensions) or filename in extra_files:\n-                    with open(old_path, encoding='utf-8') as template_file:\n+                    with open(old_path, encoding=\"utf-8\") as template_file:\n                         content = template_file.read()\n                     template = Engine().from_string(content)\n                     content = template.render(context)\n-                    with open(new_path, 'w', encoding='utf-8') as new_file:\n+                    with open(new_path, \"w\", encoding=\"utf-8\") as new_file:\n                         new_file.write(content)\n                 else:\n                     shutil.copyfile(old_path, new_path)\n \n                 if self.verbosity >= 2:\n-                    self.stdout.write('Creating %s' % new_path)\n+                    self.stdout.write(\"Creating %s\" % new_path)\n                 try:\n                     shutil.copymode(old_path, new_path)\n                     self.make_writeable(new_path)\n@@ -171,11 +188,13 @@ class TemplateCommand(BaseCommand):\n                     self.stderr.write(\n                         \"Notice: Couldn't set permission bits on %s. You're \"\n                         \"probably using an uncommon filesystem setup. No \"\n-                        \"problem.\" % new_path, self.style.NOTICE)\n+                        \"problem.\" % new_path,\n+                        self.style.NOTICE,\n+                    )\n \n         if self.paths_to_remove:\n             if self.verbosity >= 2:\n-                self.stdout.write('Cleaning up temporary files.')\n+                self.stdout.write(\"Cleaning up temporary files.\")\n             for path_to_remove in self.paths_to_remove:\n                 if os.path.isfile(path_to_remove):\n                     os.remove(path_to_remove)\n@@ -189,9 +208,9 @@ class TemplateCommand(BaseCommand):\n         directory isn't known.\n         \"\"\"\n         if template is None:\n-            return os.path.join(django.__path__[0], 'conf', subdir)\n+            return os.path.join(django.__path__[0], \"conf\", subdir)\n         else:\n-            if template.startswith('file://'):\n+            if template.startswith(\"file://\"):\n                 template = template[7:]\n             expanded_template = os.path.expanduser(template)\n             expanded_template = os.path.normpath(expanded_template)\n@@ -205,15 +224,18 @@ class TemplateCommand(BaseCommand):\n             if os.path.exists(absolute_path):\n                 return self.extract(absolute_path)\n \n-        raise CommandError(\"couldn't handle %s template %s.\" %\n-                           (self.app_or_project, template))\n+        raise CommandError(\n+            \"couldn't handle %s template %s.\" % (self.app_or_project, template)\n+        )\n \n-    def validate_name(self, name, name_or_dir='name'):\n+    def validate_name(self, name, name_or_dir=\"name\"):\n         if name is None:\n-            raise CommandError('you must provide {an} {app} name'.format(\n-                an=self.a_or_an,\n-                app=self.app_or_project,\n-            ))\n+            raise CommandError(\n+                \"you must provide {an} {app} name\".format(\n+                    an=self.a_or_an,\n+                    app=self.app_or_project,\n+                )\n+            )\n         # Check it's a valid directory name.\n         if not name.isidentifier():\n             raise CommandError(\n@@ -245,41 +267,43 @@ class TemplateCommand(BaseCommand):\n         \"\"\"\n         Download the given URL and return the file name.\n         \"\"\"\n+\n         def cleanup_url(url):\n-            tmp = url.rstrip('/')\n-            filename = tmp.split('/')[-1]\n-            if url.endswith('/'):\n-                display_url = tmp + '/'\n+            tmp = url.rstrip(\"/\")\n+            filename = tmp.split(\"/\")[-1]\n+            if url.endswith(\"/\"):\n+                display_url = tmp + \"/\"\n             else:\n                 display_url = url\n             return filename, display_url\n \n-        prefix = 'django_%s_template_' % self.app_or_project\n-        tempdir = tempfile.mkdtemp(prefix=prefix, suffix='_download')\n+        prefix = \"django_%s_template_\" % self.app_or_project\n+        tempdir = tempfile.mkdtemp(prefix=prefix, suffix=\"_download\")\n         self.paths_to_remove.append(tempdir)\n         filename, display_url = cleanup_url(url)\n \n         if self.verbosity >= 2:\n-            self.stdout.write('Downloading %s' % display_url)\n+            self.stdout.write(\"Downloading %s\" % display_url)\n         try:\n             the_path, info = urlretrieve(url, os.path.join(tempdir, filename))\n         except OSError as e:\n-            raise CommandError(\"couldn't download URL %s to %s: %s\" %\n-                               (url, filename, e))\n+            raise CommandError(\n+                \"couldn't download URL %s to %s: %s\" % (url, filename, e)\n+            )\n \n-        used_name = the_path.split('/')[-1]\n+        used_name = the_path.split(\"/\")[-1]\n \n         # Trying to get better name from response headers\n-        content_disposition = info.get('content-disposition')\n+        content_disposition = info.get(\"content-disposition\")\n         if content_disposition:\n             _, params = cgi.parse_header(content_disposition)\n-            guessed_filename = params.get('filename') or used_name\n+            guessed_filename = params.get(\"filename\") or used_name\n         else:\n             guessed_filename = used_name\n \n         # Falling back to content type guessing\n         ext = self.splitext(guessed_filename)[1]\n-        content_type = info.get('content-type')\n+        content_type = info.get(\"content-type\")\n         if not ext and content_type:\n             ext = mimetypes.guess_extension(content_type)\n             if ext:\n@@ -300,7 +324,7 @@ class TemplateCommand(BaseCommand):\n         Like os.path.splitext, but takes off .tar, too\n         \"\"\"\n         base, ext = posixpath.splitext(the_path)\n-        if base.lower().endswith('.tar'):\n+        if base.lower().endswith(\".tar\"):\n             ext = base[-4:] + ext\n             base = base[:-4]\n         return base, ext\n@@ -310,23 +334,24 @@ class TemplateCommand(BaseCommand):\n         Extract the given file to a temporary directory and return\n         the path of the directory with the extracted content.\n         \"\"\"\n-        prefix = 'django_%s_template_' % self.app_or_project\n-        tempdir = tempfile.mkdtemp(prefix=prefix, suffix='_extract')\n+        prefix = \"django_%s_template_\" % self.app_or_project\n+        tempdir = tempfile.mkdtemp(prefix=prefix, suffix=\"_extract\")\n         self.paths_to_remove.append(tempdir)\n         if self.verbosity >= 2:\n-            self.stdout.write('Extracting %s' % filename)\n+            self.stdout.write(\"Extracting %s\" % filename)\n         try:\n             archive.extract(filename, tempdir)\n             return tempdir\n         except (archive.ArchiveException, OSError) as e:\n-            raise CommandError(\"couldn't extract file %s to %s: %s\" %\n-                               (filename, tempdir, e))\n+            raise CommandError(\n+                \"couldn't extract file %s to %s: %s\" % (filename, tempdir, e)\n+            )\n \n     def is_url(self, template):\n         \"\"\"Return True if the name looks like a URL.\"\"\"\n-        if ':' not in template:\n+        if \":\" not in template:\n             return False\n-        scheme = template.split(':', 1)[0].lower()\n+        scheme = template.split(\":\", 1)[0].lower()\n         return scheme in self.url_schemes\n \n     def make_writeable(self, filename):\n"}
{"instance_id": "django__django-14411", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex 20d8922799..5a95e5c9f2 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -2,10 +2,13 @@ import unicodedata\n \n from django import forms\n from django.contrib.auth import (\n-    authenticate, get_user_model, password_validation,\n+    authenticate,\n+    get_user_model,\n+    password_validation,\n )\n from django.contrib.auth.hashers import (\n-    UNUSABLE_PASSWORD_PREFIX, identify_hasher,\n+    UNUSABLE_PASSWORD_PREFIX,\n+    identify_hasher,\n )\n from django.contrib.auth.models import User\n from django.contrib.auth.tokens import default_token_generator\n@@ -27,27 +30,39 @@ def _unicode_ci_compare(s1, s2):\n     recommended algorithm from Unicode Technical Report 36, section\n     2.11.2(B)(2).\n     \"\"\"\n-    return unicodedata.normalize('NFKC', s1).casefold() == unicodedata.normalize('NFKC', s2).casefold()\n+    return (\n+        unicodedata.normalize(\"NFKC\", s1).casefold()\n+        == unicodedata.normalize(\"NFKC\", s2).casefold()\n+    )\n \n \n class ReadOnlyPasswordHashWidget(forms.Widget):\n-    template_name = 'auth/widgets/read_only_password_hash.html'\n+    template_name = \"auth/widgets/read_only_password_hash.html\"\n     read_only = True\n \n+    def id_for_label(self, id_):\n+        return None\n+\n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         summary = []\n         if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n-            summary.append({'label': gettext(\"No password set.\")})\n+            summary.append({\"label\": gettext(\"No password set.\")})\n         else:\n             try:\n                 hasher = identify_hasher(value)\n             except ValueError:\n-                summary.append({'label': gettext(\"Invalid password format or unknown hashing algorithm.\")})\n+                summary.append(\n+                    {\n+                        \"label\": gettext(\n+                            \"Invalid password format or unknown hashing algorithm.\"\n+                        )\n+                    }\n+                )\n             else:\n                 for key, value_ in hasher.safe_summary(value).items():\n-                    summary.append({'label': gettext(key), 'value': value_})\n-        context['summary'] = summary\n+                    summary.append({\"label\": gettext(key), \"value\": value_})\n+        context[\"summary\"] = summary\n         return context\n \n \n@@ -56,19 +71,19 @@ class ReadOnlyPasswordHashField(forms.Field):\n \n     def __init__(self, *args, **kwargs):\n         kwargs.setdefault(\"required\", False)\n-        kwargs.setdefault('disabled', True)\n+        kwargs.setdefault(\"disabled\", True)\n         super().__init__(*args, **kwargs)\n \n \n class UsernameField(forms.CharField):\n     def to_python(self, value):\n-        return unicodedata.normalize('NFKC', super().to_python(value))\n+        return unicodedata.normalize(\"NFKC\", super().to_python(value))\n \n     def widget_attrs(self, widget):\n         return {\n             **super().widget_attrs(widget),\n-            'autocapitalize': 'none',\n-            'autocomplete': 'username',\n+            \"autocapitalize\": \"none\",\n+            \"autocomplete\": \"username\",\n         }\n \n \n@@ -77,18 +92,19 @@ class UserCreationForm(forms.ModelForm):\n     A form that creates a user, with no privileges, from the given username and\n     password.\n     \"\"\"\n+\n     error_messages = {\n-        'password_mismatch': _('The two password fields didn\u2019t match.'),\n+        \"password_mismatch\": _(\"The two password fields didn\u2019t match.\"),\n     }\n     password1 = forms.CharField(\n         label=_(\"Password\"),\n         strip=False,\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"new-password\"}),\n         help_text=password_validation.password_validators_help_text_html(),\n     )\n     password2 = forms.CharField(\n         label=_(\"Password confirmation\"),\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"new-password\"}),\n         strip=False,\n         help_text=_(\"Enter the same password as before, for verification.\"),\n     )\n@@ -96,20 +112,22 @@ class UserCreationForm(forms.ModelForm):\n     class Meta:\n         model = User\n         fields = (\"username\",)\n-        field_classes = {'username': UsernameField}\n+        field_classes = {\"username\": UsernameField}\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         if self._meta.model.USERNAME_FIELD in self.fields:\n-            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs['autofocus'] = True\n+            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs[\"autofocus\"] = (\n+                True\n+            )\n \n     def clean_password2(self):\n         password1 = self.cleaned_data.get(\"password1\")\n         password2 = self.cleaned_data.get(\"password2\")\n         if password1 and password2 and password1 != password2:\n             raise ValidationError(\n-                self.error_messages['password_mismatch'],\n-                code='password_mismatch',\n+                self.error_messages[\"password_mismatch\"],\n+                code=\"password_mismatch\",\n             )\n         return password2\n \n@@ -117,12 +135,12 @@ class UserCreationForm(forms.ModelForm):\n         super()._post_clean()\n         # Validate the password after self.instance is updated with form data\n         # by super().\n-        password = self.cleaned_data.get('password2')\n+        password = self.cleaned_data.get(\"password2\")\n         if password:\n             try:\n                 password_validation.validate_password(password, self.instance)\n             except ValidationError as error:\n-                self.add_error('password2', error)\n+                self.add_error(\"password2\", error)\n \n     def save(self, commit=True):\n         user = super().save(commit=False)\n@@ -136,25 +154,27 @@ class UserChangeForm(forms.ModelForm):\n     password = ReadOnlyPasswordHashField(\n         label=_(\"Password\"),\n         help_text=_(\n-            'Raw passwords are not stored, so there is no way to see this '\n-            'user\u2019s password, but you can change the password using '\n+            \"Raw passwords are not stored, so there is no way to see this \"\n+            \"user\u2019s password, but you can change the password using \"\n             '<a href=\"{}\">this form</a>.'\n         ),\n     )\n \n     class Meta:\n         model = User\n-        fields = '__all__'\n-        field_classes = {'username': UsernameField}\n+        fields = \"__all__\"\n+        field_classes = {\"username\": UsernameField}\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        password = self.fields.get('password')\n+        password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format('../password/')\n-        user_permissions = self.fields.get('user_permissions')\n+            password.help_text = password.help_text.format(\"../password/\")\n+        user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n-            user_permissions.queryset = user_permissions.queryset.select_related('content_type')\n+            user_permissions.queryset = user_permissions.queryset.select_related(\n+                \"content_type\"\n+            )\n \n \n class AuthenticationForm(forms.Form):\n@@ -162,19 +182,20 @@ class AuthenticationForm(forms.Form):\n     Base class for authenticating users. Extend this to get a form that accepts\n     username/password logins.\n     \"\"\"\n-    username = UsernameField(widget=forms.TextInput(attrs={'autofocus': True}))\n+\n+    username = UsernameField(widget=forms.TextInput(attrs={\"autofocus\": True}))\n     password = forms.CharField(\n         label=_(\"Password\"),\n         strip=False,\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"current-password\"}),\n     )\n \n     error_messages = {\n-        'invalid_login': _(\n+        \"invalid_login\": _(\n             \"Please enter a correct %(username)s and password. Note that both \"\n             \"fields may be case-sensitive.\"\n         ),\n-        'inactive': _(\"This account is inactive.\"),\n+        \"inactive\": _(\"This account is inactive.\"),\n     }\n \n     def __init__(self, request=None, *args, **kwargs):\n@@ -189,17 +210,19 @@ class AuthenticationForm(forms.Form):\n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n         username_max_length = self.username_field.max_length or 254\n-        self.fields['username'].max_length = username_max_length\n-        self.fields['username'].widget.attrs['maxlength'] = username_max_length\n-        if self.fields['username'].label is None:\n-            self.fields['username'].label = capfirst(self.username_field.verbose_name)\n+        self.fields[\"username\"].max_length = username_max_length\n+        self.fields[\"username\"].widget.attrs[\"maxlength\"] = username_max_length\n+        if self.fields[\"username\"].label is None:\n+            self.fields[\"username\"].label = capfirst(self.username_field.verbose_name)\n \n     def clean(self):\n-        username = self.cleaned_data.get('username')\n-        password = self.cleaned_data.get('password')\n+        username = self.cleaned_data.get(\"username\")\n+        password = self.cleaned_data.get(\"password\")\n \n         if username is not None and password:\n-            self.user_cache = authenticate(self.request, username=username, password=password)\n+            self.user_cache = authenticate(\n+                self.request, username=username, password=password\n+            )\n             if self.user_cache is None:\n                 raise self.get_invalid_login_error()\n             else:\n@@ -220,8 +243,8 @@ class AuthenticationForm(forms.Form):\n         \"\"\"\n         if not user.is_active:\n             raise ValidationError(\n-                self.error_messages['inactive'],\n-                code='inactive',\n+                self.error_messages[\"inactive\"],\n+                code=\"inactive\",\n             )\n \n     def get_user(self):\n@@ -229,9 +252,9 @@ class AuthenticationForm(forms.Form):\n \n     def get_invalid_login_error(self):\n         return ValidationError(\n-            self.error_messages['invalid_login'],\n-            code='invalid_login',\n-            params={'username': self.username_field.verbose_name},\n+            self.error_messages[\"invalid_login\"],\n+            code=\"invalid_login\",\n+            params={\"username\": self.username_field.verbose_name},\n         )\n \n \n@@ -239,23 +262,30 @@ class PasswordResetForm(forms.Form):\n     email = forms.EmailField(\n         label=_(\"Email\"),\n         max_length=254,\n-        widget=forms.EmailInput(attrs={'autocomplete': 'email'})\n+        widget=forms.EmailInput(attrs={\"autocomplete\": \"email\"}),\n     )\n \n-    def send_mail(self, subject_template_name, email_template_name,\n-                  context, from_email, to_email, html_email_template_name=None):\n+    def send_mail(\n+        self,\n+        subject_template_name,\n+        email_template_name,\n+        context,\n+        from_email,\n+        to_email,\n+        html_email_template_name=None,\n+    ):\n         \"\"\"\n         Send a django.core.mail.EmailMultiAlternatives to `to_email`.\n         \"\"\"\n         subject = loader.render_to_string(subject_template_name, context)\n         # Email subject *must not* contain newlines\n-        subject = ''.join(subject.splitlines())\n+        subject = \"\".join(subject.splitlines())\n         body = loader.render_to_string(email_template_name, context)\n \n         email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])\n         if html_email_template_name is not None:\n             html_email = loader.render_to_string(html_email_template_name, context)\n-            email_message.attach_alternative(html_email, 'text/html')\n+            email_message.attach_alternative(html_email, \"text/html\")\n \n         email_message.send()\n \n@@ -267,22 +297,31 @@ class PasswordResetForm(forms.Form):\n         resetting their password.\n         \"\"\"\n         email_field_name = UserModel.get_email_field_name()\n-        active_users = UserModel._default_manager.filter(**{\n-            '%s__iexact' % email_field_name: email,\n-            'is_active': True,\n-        })\n+        active_users = UserModel._default_manager.filter(\n+            **{\n+                \"%s__iexact\" % email_field_name: email,\n+                \"is_active\": True,\n+            }\n+        )\n         return (\n-            u for u in active_users\n-            if u.has_usable_password() and\n-            _unicode_ci_compare(email, getattr(u, email_field_name))\n+            u\n+            for u in active_users\n+            if u.has_usable_password()\n+            and _unicode_ci_compare(email, getattr(u, email_field_name))\n         )\n \n-    def save(self, domain_override=None,\n-             subject_template_name='registration/password_reset_subject.txt',\n-             email_template_name='registration/password_reset_email.html',\n-             use_https=False, token_generator=default_token_generator,\n-             from_email=None, request=None, html_email_template_name=None,\n-             extra_email_context=None):\n+    def save(\n+        self,\n+        domain_override=None,\n+        subject_template_name=\"registration/password_reset_subject.txt\",\n+        email_template_name=\"registration/password_reset_email.html\",\n+        use_https=False,\n+        token_generator=default_token_generator,\n+        from_email=None,\n+        request=None,\n+        html_email_template_name=None,\n+        extra_email_context=None,\n+    ):\n         \"\"\"\n         Generate a one-use only link for resetting password and send it to the\n         user.\n@@ -298,18 +337,22 @@ class PasswordResetForm(forms.Form):\n         for user in self.get_users(email):\n             user_email = getattr(user, email_field_name)\n             context = {\n-                'email': user_email,\n-                'domain': domain,\n-                'site_name': site_name,\n-                'uid': urlsafe_base64_encode(force_bytes(user.pk)),\n-                'user': user,\n-                'token': token_generator.make_token(user),\n-                'protocol': 'https' if use_https else 'http',\n+                \"email\": user_email,\n+                \"domain\": domain,\n+                \"site_name\": site_name,\n+                \"uid\": urlsafe_base64_encode(force_bytes(user.pk)),\n+                \"user\": user,\n+                \"token\": token_generator.make_token(user),\n+                \"protocol\": \"https\" if use_https else \"http\",\n                 **(extra_email_context or {}),\n             }\n             self.send_mail(\n-                subject_template_name, email_template_name, context, from_email,\n-                user_email, html_email_template_name=html_email_template_name,\n+                subject_template_name,\n+                email_template_name,\n+                context,\n+                from_email,\n+                user_email,\n+                html_email_template_name=html_email_template_name,\n             )\n \n \n@@ -318,19 +361,20 @@ class SetPasswordForm(forms.Form):\n     A form that lets a user change set their password without entering the old\n     password\n     \"\"\"\n+\n     error_messages = {\n-        'password_mismatch': _('The two password fields didn\u2019t match.'),\n+        \"password_mismatch\": _(\"The two password fields didn\u2019t match.\"),\n     }\n     new_password1 = forms.CharField(\n         label=_(\"New password\"),\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"new-password\"}),\n         strip=False,\n         help_text=password_validation.password_validators_help_text_html(),\n     )\n     new_password2 = forms.CharField(\n         label=_(\"New password confirmation\"),\n         strip=False,\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"new-password\"}),\n     )\n \n     def __init__(self, user, *args, **kwargs):\n@@ -338,13 +382,13 @@ class SetPasswordForm(forms.Form):\n         super().__init__(*args, **kwargs)\n \n     def clean_new_password2(self):\n-        password1 = self.cleaned_data.get('new_password1')\n-        password2 = self.cleaned_data.get('new_password2')\n+        password1 = self.cleaned_data.get(\"new_password1\")\n+        password2 = self.cleaned_data.get(\"new_password2\")\n         if password1 and password2:\n             if password1 != password2:\n                 raise ValidationError(\n-                    self.error_messages['password_mismatch'],\n-                    code='password_mismatch',\n+                    self.error_messages[\"password_mismatch\"],\n+                    code=\"password_mismatch\",\n                 )\n         password_validation.validate_password(password2, self.user)\n         return password2\n@@ -362,17 +406,22 @@ class PasswordChangeForm(SetPasswordForm):\n     A form that lets a user change their password by entering their old\n     password.\n     \"\"\"\n+\n     error_messages = {\n         **SetPasswordForm.error_messages,\n-        'password_incorrect': _(\"Your old password was entered incorrectly. Please enter it again.\"),\n+        \"password_incorrect\": _(\n+            \"Your old password was entered incorrectly. Please enter it again.\"\n+        ),\n     }\n     old_password = forms.CharField(\n         label=_(\"Old password\"),\n         strip=False,\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password', 'autofocus': True}),\n+        widget=forms.PasswordInput(\n+            attrs={\"autocomplete\": \"current-password\", \"autofocus\": True}\n+        ),\n     )\n \n-    field_order = ['old_password', 'new_password1', 'new_password2']\n+    field_order = [\"old_password\", \"new_password1\", \"new_password2\"]\n \n     def clean_old_password(self):\n         \"\"\"\n@@ -381,8 +430,8 @@ class PasswordChangeForm(SetPasswordForm):\n         old_password = self.cleaned_data[\"old_password\"]\n         if not self.user.check_password(old_password):\n             raise ValidationError(\n-                self.error_messages['password_incorrect'],\n-                code='password_incorrect',\n+                self.error_messages[\"password_incorrect\"],\n+                code=\"password_incorrect\",\n             )\n         return old_password\n \n@@ -391,19 +440,22 @@ class AdminPasswordChangeForm(forms.Form):\n     \"\"\"\n     A form used to change the password of a user in the admin interface.\n     \"\"\"\n+\n     error_messages = {\n-        'password_mismatch': _('The two password fields didn\u2019t match.'),\n+        \"password_mismatch\": _(\"The two password fields didn\u2019t match.\"),\n     }\n-    required_css_class = 'required'\n+    required_css_class = \"required\"\n     password1 = forms.CharField(\n         label=_(\"Password\"),\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password', 'autofocus': True}),\n+        widget=forms.PasswordInput(\n+            attrs={\"autocomplete\": \"new-password\", \"autofocus\": True}\n+        ),\n         strip=False,\n         help_text=password_validation.password_validators_help_text_html(),\n     )\n     password2 = forms.CharField(\n         label=_(\"Password (again)\"),\n-        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n+        widget=forms.PasswordInput(attrs={\"autocomplete\": \"new-password\"}),\n         strip=False,\n         help_text=_(\"Enter the same password as before, for verification.\"),\n     )\n@@ -413,12 +465,12 @@ class AdminPasswordChangeForm(forms.Form):\n         super().__init__(*args, **kwargs)\n \n     def clean_password2(self):\n-        password1 = self.cleaned_data.get('password1')\n-        password2 = self.cleaned_data.get('password2')\n+        password1 = self.cleaned_data.get(\"password1\")\n+        password2 = self.cleaned_data.get(\"password2\")\n         if password1 and password2 and password1 != password2:\n             raise ValidationError(\n-                self.error_messages['password_mismatch'],\n-                code='password_mismatch',\n+                self.error_messages[\"password_mismatch\"],\n+                code=\"password_mismatch\",\n             )\n         password_validation.validate_password(password2, self.user)\n         return password2\n@@ -437,4 +489,4 @@ class AdminPasswordChangeForm(forms.Form):\n         for name in self.fields:\n             if name not in data:\n                 return []\n-        return ['password']\n+        return [\"password\"]\n"}
{"instance_id": "django__django-14534", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..4844184683 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -8,12 +8,13 @@ from django.utils.html import conditional_escape, format_html, html_safe\n from django.utils.safestring import mark_safe\n from django.utils.translation import gettext_lazy as _\n \n-__all__ = ('BoundField',)\n+__all__ = (\"BoundField\",)\n \n \n @html_safe\n class BoundField:\n     \"A Field plus data\"\n+\n     def __init__(self, form, field, name):\n         self.form = form\n         self.field = field\n@@ -25,7 +26,7 @@ class BoundField:\n             self.label = pretty_name(name)\n         else:\n             self.label = self.field.label\n-        self.help_text = field.help_text or ''\n+        self.help_text = field.help_text or \"\"\n \n     def __str__(self):\n         \"\"\"Render this field as an HTML widget.\"\"\"\n@@ -42,12 +43,14 @@ class BoundField:\n         This property is cached so that only one database query occurs when\n         rendering ModelChoiceFields.\n         \"\"\"\n-        id_ = self.field.widget.attrs.get('id') or self.auto_id\n-        attrs = {'id': id_} if id_ else {}\n+        id_ = self.field.widget.attrs.get(\"id\") or self.auto_id\n+        attrs = {\"id\": id_} if id_ else {}\n         attrs = self.build_widget_attrs(attrs)\n         return [\n             BoundWidget(self.field.widget, widget, self.form.renderer)\n-            for widget in self.field.widget.subwidgets(self.html_name, self.value(), attrs=attrs)\n+            for widget in self.field.widget.subwidgets(\n+                self.html_name, self.value(), attrs=attrs\n+            )\n         ]\n \n     def __bool__(self):\n@@ -65,7 +68,7 @@ class BoundField:\n         # from templates.\n         if not isinstance(idx, (int, slice)):\n             raise TypeError(\n-                'BoundField indices must be integers or slices, not %s.'\n+                \"BoundField indices must be integers or slices, not %s.\"\n                 % type(idx).__name__\n             )\n         return self.subwidgets[idx]\n@@ -88,8 +91,10 @@ class BoundField:\n             widget.is_localized = True\n         attrs = attrs or {}\n         attrs = self.build_widget_attrs(attrs, widget)\n-        if self.auto_id and 'id' not in widget.attrs:\n-            attrs.setdefault('id', self.html_initial_id if only_initial else self.auto_id)\n+        if self.auto_id and \"id\" not in widget.attrs:\n+            attrs.setdefault(\n+                \"id\", self.html_initial_id if only_initial else self.auto_id\n+            )\n         return widget.render(\n             name=self.html_initial_name if only_initial else self.html_name,\n             value=self.value(),\n@@ -135,7 +140,8 @@ class BoundField:\n         if field.show_hidden_initial:\n             hidden_widget = field.hidden_widget()\n             initial_value = self.form._widget_data_value(\n-                hidden_widget, self.html_initial_name,\n+                hidden_widget,\n+                self.html_initial_name,\n             )\n             try:\n                 initial_value = field.to_python(initial_value)\n@@ -158,27 +164,30 @@ class BoundField:\n         \"\"\"\n         contents = contents or self.label\n         if label_suffix is None:\n-            label_suffix = (self.field.label_suffix if self.field.label_suffix is not None\n-                            else self.form.label_suffix)\n+            label_suffix = (\n+                self.field.label_suffix\n+                if self.field.label_suffix is not None\n+                else self.form.label_suffix\n+            )\n         # Only add the suffix if the label does not end in punctuation.\n         # Translators: If found as last label character, these punctuation\n         # characters will prevent the default label_suffix to be appended to the label\n-        if label_suffix and contents and contents[-1] not in _(':?.!'):\n-            contents = format_html('{}{}', contents, label_suffix)\n+        if label_suffix and contents and contents[-1] not in _(\":?.!\"):\n+            contents = format_html(\"{}{}\", contents, label_suffix)\n         widget = self.field.widget\n-        id_ = widget.attrs.get('id') or self.auto_id\n+        id_ = widget.attrs.get(\"id\") or self.auto_id\n         if id_:\n             id_for_label = widget.id_for_label(id_)\n             if id_for_label:\n-                attrs = {**(attrs or {}), 'for': id_for_label}\n-            if self.field.required and hasattr(self.form, 'required_css_class'):\n+                attrs = {**(attrs or {}), \"for\": id_for_label}\n+            if self.field.required and hasattr(self.form, \"required_css_class\"):\n                 attrs = attrs or {}\n-                if 'class' in attrs:\n-                    attrs['class'] += ' ' + self.form.required_css_class\n+                if \"class\" in attrs:\n+                    attrs[\"class\"] += \" \" + self.form.required_css_class\n                 else:\n-                    attrs['class'] = self.form.required_css_class\n-            attrs = flatatt(attrs) if attrs else ''\n-            contents = format_html('<label{}>{}</label>', attrs, contents)\n+                    attrs[\"class\"] = self.form.required_css_class\n+            attrs = flatatt(attrs) if attrs else \"\"\n+            contents = format_html(\"<label{}>{}</label>\", attrs, contents)\n         else:\n             contents = conditional_escape(contents)\n         return mark_safe(contents)\n@@ -187,14 +196,14 @@ class BoundField:\n         \"\"\"\n         Return a string of space-separated CSS classes for this field.\n         \"\"\"\n-        if hasattr(extra_classes, 'split'):\n+        if hasattr(extra_classes, \"split\"):\n             extra_classes = extra_classes.split()\n         extra_classes = set(extra_classes or [])\n-        if self.errors and hasattr(self.form, 'error_css_class'):\n+        if self.errors and hasattr(self.form, \"error_css_class\"):\n             extra_classes.add(self.form.error_css_class)\n-        if self.field.required and hasattr(self.form, 'required_css_class'):\n+        if self.field.required and hasattr(self.form, \"required_css_class\"):\n             extra_classes.add(self.form.required_css_class)\n-        return ' '.join(extra_classes)\n+        return \" \".join(extra_classes)\n \n     @property\n     def is_hidden(self):\n@@ -208,11 +217,11 @@ class BoundField:\n         associated Form has specified auto_id. Return an empty string otherwise.\n         \"\"\"\n         auto_id = self.form.auto_id  # Boolean or string\n-        if auto_id and '%s' in str(auto_id):\n+        if auto_id and \"%s\" in str(auto_id):\n             return auto_id % self.html_name\n         elif auto_id:\n             return self.html_name\n-        return ''\n+        return \"\"\n \n     @property\n     def id_for_label(self):\n@@ -222,7 +231,7 @@ class BoundField:\n         it has a single widget or a MultiWidget.\n         \"\"\"\n         widget = self.field.widget\n-        id_ = widget.attrs.get('id') or self.auto_id\n+        id_ = widget.attrs.get(\"id\") or self.auto_id\n         return widget.id_for_label(id_)\n \n     @cached_property\n@@ -232,15 +241,21 @@ class BoundField:\n     def build_widget_attrs(self, attrs, widget=None):\n         widget = widget or self.field.widget\n         attrs = dict(attrs)  # Copy attrs to avoid modifying the argument.\n-        if widget.use_required_attribute(self.initial) and self.field.required and self.form.use_required_attribute:\n-            attrs['required'] = True\n+        if (\n+            widget.use_required_attribute(self.initial)\n+            and self.field.required\n+            and self.form.use_required_attribute\n+        ):\n+            attrs[\"required\"] = True\n         if self.field.disabled:\n-            attrs['disabled'] = True\n+            attrs[\"disabled\"] = True\n         return attrs\n \n     @property\n     def widget_type(self):\n-        return re.sub(r'widget$|input$', '', self.field.widget.__class__.__name__.lower())\n+        return re.sub(\n+            r\"widget$|input$\", \"\", self.field.widget.__class__.__name__.lower()\n+        )\n \n \n @html_safe\n@@ -257,6 +272,7 @@ class BoundWidget:\n       </label>\n     {% endfor %}\n     \"\"\"\n+\n     def __init__(self, parent_widget, data, renderer):\n         self.parent_widget = parent_widget\n         self.data = data\n@@ -266,19 +282,19 @@ class BoundWidget:\n         return self.tag(wrap_label=True)\n \n     def tag(self, wrap_label=False):\n-        context = {'widget': {**self.data, 'wrap_label': wrap_label}}\n+        context = {\"widget\": {**self.data, \"wrap_label\": wrap_label}}\n         return self.parent_widget._render(self.template_name, context, self.renderer)\n \n     @property\n     def template_name(self):\n-        if 'template_name' in self.data:\n-            return self.data['template_name']\n+        if \"template_name\" in self.data:\n+            return self.data[\"template_name\"]\n         return self.parent_widget.template_name\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data[\"attrs\"][\"id\"]\n \n     @property\n     def choice_label(self):\n-        return self.data['label']\n+        return self.data[\"label\"]\n"}
{"instance_id": "django__django-14580", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex e19c881cda..072a2efc14 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ class TupleSerializer(BaseSequenceSerializer):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", [\"from django.db import models\"]),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n"}
{"instance_id": "django__django-14608", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..16e26b34b9 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -8,15 +8,15 @@ from django.utils.html import html_safe\n from django.utils.safestring import mark_safe\n from django.utils.translation import gettext_lazy as _, ngettext\n \n-__all__ = ('BaseFormSet', 'formset_factory', 'all_valid')\n+__all__ = (\"BaseFormSet\", \"formset_factory\", \"all_valid\")\n \n # special field names\n-TOTAL_FORM_COUNT = 'TOTAL_FORMS'\n-INITIAL_FORM_COUNT = 'INITIAL_FORMS'\n-MIN_NUM_FORM_COUNT = 'MIN_NUM_FORMS'\n-MAX_NUM_FORM_COUNT = 'MAX_NUM_FORMS'\n-ORDERING_FIELD_NAME = 'ORDER'\n-DELETION_FIELD_NAME = 'DELETE'\n+TOTAL_FORM_COUNT = \"TOTAL_FORMS\"\n+INITIAL_FORM_COUNT = \"INITIAL_FORMS\"\n+MIN_NUM_FORM_COUNT = \"MIN_NUM_FORMS\"\n+MAX_NUM_FORM_COUNT = \"MAX_NUM_FORMS\"\n+ORDERING_FIELD_NAME = \"ORDER\"\n+DELETION_FIELD_NAME = \"DELETE\"\n \n # default minimum number of forms in a formset\n DEFAULT_MIN_NUM = 0\n@@ -31,14 +31,19 @@ class ManagementForm(Form):\n     new forms via JavaScript, you should increment the count field of this form\n     as well.\n     \"\"\"\n+\n     def __init__(self, *args, **kwargs):\n         self.base_fields[TOTAL_FORM_COUNT] = IntegerField(widget=HiddenInput)\n         self.base_fields[INITIAL_FORM_COUNT] = IntegerField(widget=HiddenInput)\n         # MIN_NUM_FORM_COUNT and MAX_NUM_FORM_COUNT are output with the rest of\n         # the management form, but only for the convenience of client-side\n         # code. The POST value of them returned from the client is not checked.\n-        self.base_fields[MIN_NUM_FORM_COUNT] = IntegerField(required=False, widget=HiddenInput)\n-        self.base_fields[MAX_NUM_FORM_COUNT] = IntegerField(required=False, widget=HiddenInput)\n+        self.base_fields[MIN_NUM_FORM_COUNT] = IntegerField(\n+            required=False, widget=HiddenInput\n+        )\n+        self.base_fields[MAX_NUM_FORM_COUNT] = IntegerField(\n+            required=False, widget=HiddenInput\n+        )\n         super().__init__(*args, **kwargs)\n \n     def clean(self):\n@@ -55,17 +60,26 @@ class BaseFormSet:\n     \"\"\"\n     A collection of instances of the same Form class.\n     \"\"\"\n+\n     ordering_widget = NumberInput\n     default_error_messages = {\n-        'missing_management_form': _(\n-            'ManagementForm data is missing or has been tampered with. Missing fields: '\n-            '%(field_names)s. You may need to file a bug report if the issue persists.'\n+        \"missing_management_form\": _(\n+            \"ManagementForm data is missing or has been tampered with. Missing fields: \"\n+            \"%(field_names)s. You may need to file a bug report if the issue persists.\"\n         ),\n     }\n \n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 initial=None, error_class=ErrorList, form_kwargs=None,\n-                 error_messages=None):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        initial=None,\n+        error_class=ErrorList,\n+        form_kwargs=None,\n+        error_messages=None,\n+    ):\n         self.is_bound = data is not None or files is not None\n         self.prefix = prefix or self.get_default_prefix()\n         self.auto_id = auto_id\n@@ -79,7 +93,7 @@ class BaseFormSet:\n \n         messages = {}\n         for cls in reversed(type(self).__mro__):\n-            messages.update(getattr(cls, 'default_error_messages', {}))\n+            messages.update(getattr(cls, \"default_error_messages\", {}))\n         if error_messages is not None:\n             messages.update(error_messages)\n         self.error_messages = messages\n@@ -112,12 +126,16 @@ class BaseFormSet:\n             form = ManagementForm(self.data, auto_id=self.auto_id, prefix=self.prefix)\n             form.full_clean()\n         else:\n-            form = ManagementForm(auto_id=self.auto_id, prefix=self.prefix, initial={\n-                TOTAL_FORM_COUNT: self.total_form_count(),\n-                INITIAL_FORM_COUNT: self.initial_form_count(),\n-                MIN_NUM_FORM_COUNT: self.min_num,\n-                MAX_NUM_FORM_COUNT: self.max_num\n-            })\n+            form = ManagementForm(\n+                auto_id=self.auto_id,\n+                prefix=self.prefix,\n+                initial={\n+                    TOTAL_FORM_COUNT: self.total_form_count(),\n+                    INITIAL_FORM_COUNT: self.initial_form_count(),\n+                    MIN_NUM_FORM_COUNT: self.min_num,\n+                    MAX_NUM_FORM_COUNT: self.max_num,\n+                },\n+            )\n         return form\n \n     def total_form_count(self):\n@@ -127,7 +145,9 @@ class BaseFormSet:\n             # count in the data; this is DoS protection to prevent clients\n             # from forcing the server to instantiate arbitrary numbers of\n             # forms\n-            return min(self.management_form.cleaned_data[TOTAL_FORM_COUNT], self.absolute_max)\n+            return min(\n+                self.management_form.cleaned_data[TOTAL_FORM_COUNT], self.absolute_max\n+            )\n         else:\n             initial_forms = self.initial_form_count()\n             total_forms = max(initial_forms, self.min_num) + self.extra\n@@ -169,26 +189,26 @@ class BaseFormSet:\n     def _construct_form(self, i, **kwargs):\n         \"\"\"Instantiate and return the i-th form instance in a formset.\"\"\"\n         defaults = {\n-            'auto_id': self.auto_id,\n-            'prefix': self.add_prefix(i),\n-            'error_class': self.error_class,\n+            \"auto_id\": self.auto_id,\n+            \"prefix\": self.add_prefix(i),\n+            \"error_class\": self.error_class,\n             # Don't render the HTML 'required' attribute as it may cause\n             # incorrect validation for extra, optional, and deleted\n             # forms in the formset.\n-            'use_required_attribute': False,\n+            \"use_required_attribute\": False,\n         }\n         if self.is_bound:\n-            defaults['data'] = self.data\n-            defaults['files'] = self.files\n-        if self.initial and 'initial' not in kwargs:\n+            defaults[\"data\"] = self.data\n+            defaults[\"files\"] = self.files\n+        if self.initial and \"initial\" not in kwargs:\n             try:\n-                defaults['initial'] = self.initial[i]\n+                defaults[\"initial\"] = self.initial[i]\n             except IndexError:\n                 pass\n         # Allow extra forms to be empty, unless they're part of\n         # the minimum forms.\n         if i >= self.initial_form_count() and i >= self.min_num:\n-            defaults['empty_permitted'] = True\n+            defaults[\"empty_permitted\"] = True\n         defaults.update(kwargs)\n         form = self.form(**defaults)\n         self.add_fields(form, i)\n@@ -197,21 +217,21 @@ class BaseFormSet:\n     @property\n     def initial_forms(self):\n         \"\"\"Return a list of all the initial forms in this formset.\"\"\"\n-        return self.forms[:self.initial_form_count()]\n+        return self.forms[: self.initial_form_count()]\n \n     @property\n     def extra_forms(self):\n         \"\"\"Return a list of all the extra forms in this formset.\"\"\"\n-        return self.forms[self.initial_form_count():]\n+        return self.forms[self.initial_form_count() :]\n \n     @property\n     def empty_form(self):\n         form = self.form(\n             auto_id=self.auto_id,\n-            prefix=self.add_prefix('__prefix__'),\n+            prefix=self.add_prefix(\"__prefix__\"),\n             empty_permitted=True,\n             use_required_attribute=False,\n-            **self.get_form_kwargs(None)\n+            **self.get_form_kwargs(None),\n         )\n         self.add_fields(form, None)\n         return form\n@@ -222,7 +242,9 @@ class BaseFormSet:\n         Return a list of form.cleaned_data dicts for every form in self.forms.\n         \"\"\"\n         if not self.is_valid():\n-            raise AttributeError(\"'%s' object has no attribute 'cleaned_data'\" % self.__class__.__name__)\n+            raise AttributeError(\n+                \"'%s' object has no attribute 'cleaned_data'\" % self.__class__.__name__\n+            )\n         return [form.cleaned_data for form in self.forms]\n \n     @property\n@@ -232,7 +254,7 @@ class BaseFormSet:\n             return []\n         # construct _deleted_form_indexes which is just a list of form indexes\n         # that have had their deletion widget set to True\n-        if not hasattr(self, '_deleted_form_indexes'):\n+        if not hasattr(self, \"_deleted_form_indexes\"):\n             self._deleted_form_indexes = []\n             for i, form in enumerate(self.forms):\n                 # if this is an extra form and hasn't changed, don't consider it\n@@ -249,12 +271,14 @@ class BaseFormSet:\n         Raise an AttributeError if ordering is not allowed.\n         \"\"\"\n         if not self.is_valid() or not self.can_order:\n-            raise AttributeError(\"'%s' object has no attribute 'ordered_forms'\" % self.__class__.__name__)\n+            raise AttributeError(\n+                \"'%s' object has no attribute 'ordered_forms'\" % self.__class__.__name__\n+            )\n         # Construct _ordering, which is a list of (form_index, order_field_value)\n         # tuples. After constructing this list, we'll sort it by order_field_value\n         # so we have a way to get to the form indexes in the order specified\n         # by the form data.\n-        if not hasattr(self, '_ordering'):\n+        if not hasattr(self, \"_ordering\"):\n             self._ordering = []\n             for i, form in enumerate(self.forms):\n                 # if this is an extra form and hasn't changed, don't consider it\n@@ -274,6 +298,7 @@ class BaseFormSet:\n                 if k[1] is None:\n                     return (1, 0)  # +infinity, larger than any number\n                 return (0, k[1])\n+\n             self._ordering.sort(key=compare_ordering_key)\n         # Return a list of form.cleaned_data dicts in the order specified by\n         # the form data.\n@@ -281,7 +306,7 @@ class BaseFormSet:\n \n     @classmethod\n     def get_default_prefix(cls):\n-        return 'form'\n+        return \"form\"\n \n     @classmethod\n     def get_ordering_widget(cls):\n@@ -306,8 +331,9 @@ class BaseFormSet:\n \n     def total_error_count(self):\n         \"\"\"Return the number of errors across all forms in the formset.\"\"\"\n-        return len(self.non_form_errors()) +\\\n-            sum(len(form_errors) for form_errors in self.errors)\n+        return len(self.non_form_errors()) + sum(\n+            len(form_errors) for form_errors in self.errors\n+        )\n \n     def _should_delete_form(self, form):\n         \"\"\"Return whether or not the form was marked for deletion.\"\"\"\n@@ -321,10 +347,13 @@ class BaseFormSet:\n         self.errors\n         # List comprehension ensures is_valid() is called for all forms.\n         # Forms due to be deleted shouldn't cause the formset to be invalid.\n-        forms_valid = all([\n-            form.is_valid() for form in self.forms\n-            if not (self.can_delete and self._should_delete_form(form))\n-        ])\n+        forms_valid = all(\n+            [\n+                form.is_valid()\n+                for form in self.forms\n+                if not (self.can_delete and self._should_delete_form(form))\n+            ]\n+        )\n         return forms_valid and not self.non_form_errors()\n \n     def full_clean(self):\n@@ -333,7 +362,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class=\"nonform\")\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\n@@ -341,14 +370,14 @@ class BaseFormSet:\n \n         if not self.management_form.is_valid():\n             error = ValidationError(\n-                self.error_messages['missing_management_form'],\n+                self.error_messages[\"missing_management_form\"],\n                 params={\n-                    'field_names': ', '.join(\n+                    \"field_names\": \", \".join(\n                         self.management_form.add_prefix(field_name)\n                         for field_name in self.management_form.errors\n                     ),\n                 },\n-                code='missing_management_form',\n+                code=\"missing_management_form\",\n             )\n             self._non_form_errors.append(error)\n \n@@ -363,24 +392,43 @@ class BaseFormSet:\n                 continue\n             self._errors.append(form_errors)\n         try:\n-            if (self.validate_max and\n-                    self.total_form_count() - len(self.deleted_forms) > self.max_num) or \\\n-                    self.management_form.cleaned_data[TOTAL_FORM_COUNT] > self.absolute_max:\n-                raise ValidationError(ngettext(\n-                    \"Please submit at most %d form.\",\n-                    \"Please submit at most %d forms.\", self.max_num) % self.max_num,\n-                    code='too_many_forms',\n+            if (\n+                self.validate_max\n+                and self.total_form_count() - len(self.deleted_forms) > self.max_num\n+            ) or self.management_form.cleaned_data[\n+                TOTAL_FORM_COUNT\n+            ] > self.absolute_max:\n+                raise ValidationError(\n+                    ngettext(\n+                        \"Please submit at most %d form.\",\n+                        \"Please submit at most %d forms.\",\n+                        self.max_num,\n+                    )\n+                    % self.max_num,\n+                    code=\"too_many_forms\",\n+                )\n+            if (\n+                self.validate_min\n+                and self.total_form_count()\n+                - len(self.deleted_forms)\n+                - empty_forms_count\n+                < self.min_num\n+            ):\n+                raise ValidationError(\n+                    ngettext(\n+                        \"Please submit at least %d form.\",\n+                        \"Please submit at least %d forms.\",\n+                        self.min_num,\n+                    )\n+                    % self.min_num,\n+                    code=\"too_few_forms\",\n                 )\n-            if (self.validate_min and\n-                    self.total_form_count() - len(self.deleted_forms) - empty_forms_count < self.min_num):\n-                raise ValidationError(ngettext(\n-                    \"Please submit at least %d form.\",\n-                    \"Please submit at least %d forms.\", self.min_num) % self.min_num,\n-                    code='too_few_forms')\n             # Give self.clean() a chance to do cross-form validation.\n             self.clean()\n         except ValidationError as e:\n-            self._non_form_errors = self.error_class(e.error_list)\n+            self._non_form_errors = self.error_class(\n+                e.error_list, error_class=\"nonform\"\n+            )\n \n     def clean(self):\n         \"\"\"\n@@ -402,22 +450,24 @@ class BaseFormSet:\n             # Only pre-fill the ordering field for initial forms.\n             if index is not None and index < initial_form_count:\n                 form.fields[ORDERING_FIELD_NAME] = IntegerField(\n-                    label=_('Order'),\n+                    label=_(\"Order\"),\n                     initial=index + 1,\n                     required=False,\n                     widget=self.get_ordering_widget(),\n                 )\n             else:\n                 form.fields[ORDERING_FIELD_NAME] = IntegerField(\n-                    label=_('Order'),\n+                    label=_(\"Order\"),\n                     required=False,\n                     widget=self.get_ordering_widget(),\n                 )\n         if self.can_delete and (self.can_delete_extra or index < initial_form_count):\n-            form.fields[DELETION_FIELD_NAME] = BooleanField(label=_('Delete'), required=False)\n+            form.fields[DELETION_FIELD_NAME] = BooleanField(\n+                label=_(\"Delete\"), required=False\n+            )\n \n     def add_prefix(self, index):\n-        return '%s-%s' % (self.prefix, index)\n+        return \"%s-%s\" % (self.prefix, index)\n \n     def is_multipart(self):\n         \"\"\"\n@@ -443,24 +493,33 @@ class BaseFormSet:\n         # XXX: there is no semantic division between forms here, there\n         # probably should be. It might make sense to render each form as a\n         # table row with each field as a td.\n-        forms = ' '.join(form.as_table() for form in self)\n-        return mark_safe(str(self.management_form) + '\\n' + forms)\n+        forms = \" \".join(form.as_table() for form in self)\n+        return mark_safe(str(self.management_form) + \"\\n\" + forms)\n \n     def as_p(self):\n         \"Return this formset rendered as HTML <p>s.\"\n-        forms = ' '.join(form.as_p() for form in self)\n-        return mark_safe(str(self.management_form) + '\\n' + forms)\n+        forms = \" \".join(form.as_p() for form in self)\n+        return mark_safe(str(self.management_form) + \"\\n\" + forms)\n \n     def as_ul(self):\n         \"Return this formset rendered as HTML <li>s.\"\n-        forms = ' '.join(form.as_ul() for form in self)\n-        return mark_safe(str(self.management_form) + '\\n' + forms)\n-\n-\n-def formset_factory(form, formset=BaseFormSet, extra=1, can_order=False,\n-                    can_delete=False, max_num=None, validate_max=False,\n-                    min_num=None, validate_min=False, absolute_max=None,\n-                    can_delete_extra=True):\n+        forms = \" \".join(form.as_ul() for form in self)\n+        return mark_safe(str(self.management_form) + \"\\n\" + forms)\n+\n+\n+def formset_factory(\n+    form,\n+    formset=BaseFormSet,\n+    extra=1,\n+    can_order=False,\n+    can_delete=False,\n+    max_num=None,\n+    validate_max=False,\n+    min_num=None,\n+    validate_min=False,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+):\n     \"\"\"Return a FormSet for the given form class.\"\"\"\n     if min_num is None:\n         min_num = DEFAULT_MIN_NUM\n@@ -472,22 +531,20 @@ def formset_factory(form, formset=BaseFormSet, extra=1, can_order=False,\n     if absolute_max is None:\n         absolute_max = max_num + DEFAULT_MAX_NUM\n     if max_num > absolute_max:\n-        raise ValueError(\n-            \"'absolute_max' must be greater or equal to 'max_num'.\"\n-        )\n+        raise ValueError(\"'absolute_max' must be greater or equal to 'max_num'.\")\n     attrs = {\n-        'form': form,\n-        'extra': extra,\n-        'can_order': can_order,\n-        'can_delete': can_delete,\n-        'can_delete_extra': can_delete_extra,\n-        'min_num': min_num,\n-        'max_num': max_num,\n-        'absolute_max': absolute_max,\n-        'validate_min': validate_min,\n-        'validate_max': validate_max,\n+        \"form\": form,\n+        \"extra\": extra,\n+        \"can_order\": can_order,\n+        \"can_delete\": can_delete,\n+        \"can_delete_extra\": can_delete_extra,\n+        \"min_num\": min_num,\n+        \"max_num\": max_num,\n+        \"absolute_max\": absolute_max,\n+        \"validate_min\": validate_min,\n+        \"validate_max\": validate_max,\n     }\n-    return type(form.__name__ + 'FormSet', (formset,), attrs)\n+    return type(form.__name__ + \"FormSet\", (formset,), attrs)\n \n \n def all_valid(formsets):\n"}
{"instance_id": "django__django-14667", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 8837881579..76397048f7 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -679,7 +679,8 @@ class Query(BaseExpression):\n         \"\"\"\n         field_names, defer = self.deferred_loading\n         if not field_names:\n-            return\n+            if defer:\n+                return\n         orig_opts = self.get_meta()\n         seen = {}\n         must_include = {orig_opts.concrete_model: {orig_opts.pk}}\n"}
{"instance_id": "django__django-14672", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..4a3e8279e0 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -36,8 +36,16 @@ class ForeignObjectRel(FieldCacheMixin):\n     null = True\n     empty_strings_allowed = False\n \n-    def __init__(self, field, to, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, parent_link=False, on_delete=None):\n+    def __init__(\n+        self,\n+        field,\n+        to,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        on_delete=None,\n+    ):\n         self.field = field\n         self.model = to\n         self.related_name = related_name\n@@ -73,14 +81,17 @@ class ForeignObjectRel(FieldCacheMixin):\n         \"\"\"\n         target_fields = self.get_path_info()[-1].target_fields\n         if len(target_fields) > 1:\n-            raise exceptions.FieldError(\"Can't use target_field for multicolumn relations.\")\n+            raise exceptions.FieldError(\n+                \"Can't use target_field for multicolumn relations.\"\n+            )\n         return target_fields[0]\n \n     @cached_property\n     def related_model(self):\n         if not self.field.model:\n             raise AttributeError(\n-                \"This property can't be accessed before self.field.contribute_to_class has been called.\")\n+                \"This property can't be accessed before self.field.contribute_to_class has been called.\"\n+            )\n         return self.field.model\n \n     @cached_property\n@@ -110,7 +121,7 @@ class ForeignObjectRel(FieldCacheMixin):\n         return self.field.db_type\n \n     def __repr__(self):\n-        return '<%s: %s.%s>' % (\n+        return \"<%s: %s.%s>\" % (\n             type(self).__name__,\n             self.related_model._meta.app_label,\n             self.related_model._meta.model_name,\n@@ -139,8 +150,11 @@ class ForeignObjectRel(FieldCacheMixin):\n         return hash(self.identity)\n \n     def get_choices(\n-        self, include_blank=True, blank_choice=BLANK_CHOICE_DASH,\n-        limit_choices_to=None, ordering=(),\n+        self,\n+        include_blank=True,\n+        blank_choice=BLANK_CHOICE_DASH,\n+        limit_choices_to=None,\n+        ordering=(),\n     ):\n         \"\"\"\n         Return choices with a default blank choices included, for use\n@@ -153,13 +167,11 @@ class ForeignObjectRel(FieldCacheMixin):\n         qs = self.related_model._default_manager.complex_filter(limit_choices_to)\n         if ordering:\n             qs = qs.order_by(*ordering)\n-        return (blank_choice if include_blank else []) + [\n-            (x.pk, str(x)) for x in qs\n-        ]\n+        return (blank_choice if include_blank else []) + [(x.pk, str(x)) for x in qs]\n \n     def is_hidden(self):\n         \"\"\"Should the related object be hidden?\"\"\"\n-        return bool(self.related_name) and self.related_name[-1] == '+'\n+        return bool(self.related_name) and self.related_name[-1] == \"+\"\n \n     def get_joining_columns(self):\n         return self.field.get_reverse_joining_columns()\n@@ -192,7 +204,7 @@ class ForeignObjectRel(FieldCacheMixin):\n                 return None\n         if self.related_name:\n             return self.related_name\n-        return opts.model_name + ('_set' if self.multiple else '')\n+        return opts.model_name + (\"_set\" if self.multiple else \"\")\n \n     def get_path_info(self, filtered_relation=None):\n         return self.field.get_reverse_path_info(filtered_relation)\n@@ -220,10 +232,20 @@ class ManyToOneRel(ForeignObjectRel):\n     reverse relations into actual fields.\n     \"\"\"\n \n-    def __init__(self, field, to, field_name, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, parent_link=False, on_delete=None):\n+    def __init__(\n+        self,\n+        field,\n+        to,\n+        field_name,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        on_delete=None,\n+    ):\n         super().__init__(\n-            field, to,\n+            field,\n+            to,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n@@ -235,7 +257,7 @@ class ManyToOneRel(ForeignObjectRel):\n \n     def __getstate__(self):\n         state = self.__dict__.copy()\n-        state.pop('related_model', None)\n+        state.pop(\"related_model\", None)\n         return state\n \n     @property\n@@ -248,7 +270,9 @@ class ManyToOneRel(ForeignObjectRel):\n         \"\"\"\n         field = self.model._meta.get_field(self.field_name)\n         if not field.concrete:\n-            raise exceptions.FieldDoesNotExist(\"No related field named '%s'\" % self.field_name)\n+            raise exceptions.FieldDoesNotExist(\n+                \"No related field named '%s'\" % self.field_name\n+            )\n         return field\n \n     def set_field_name(self):\n@@ -263,10 +287,21 @@ class OneToOneRel(ManyToOneRel):\n     flags for the reverse relation.\n     \"\"\"\n \n-    def __init__(self, field, to, field_name, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, parent_link=False, on_delete=None):\n+    def __init__(\n+        self,\n+        field,\n+        to,\n+        field_name,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        on_delete=None,\n+    ):\n         super().__init__(\n-            field, to, field_name,\n+            field,\n+            to,\n+            field_name,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n@@ -285,11 +320,21 @@ class ManyToManyRel(ForeignObjectRel):\n     flags for the reverse relation.\n     \"\"\"\n \n-    def __init__(self, field, to, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, symmetrical=True, through=None,\n-                 through_fields=None, db_constraint=True):\n+    def __init__(\n+        self,\n+        field,\n+        to,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        symmetrical=True,\n+        through=None,\n+        through_fields=None,\n+        db_constraint=True,\n+    ):\n         super().__init__(\n-            field, to,\n+            field,\n+            to,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n@@ -310,7 +355,7 @@ class ManyToManyRel(ForeignObjectRel):\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n \n@@ -324,7 +369,7 @@ class ManyToManyRel(ForeignObjectRel):\n             field = opts.get_field(self.through_fields[0])\n         else:\n             for field in opts.fields:\n-                rel = getattr(field, 'remote_field', None)\n+                rel = getattr(field, \"remote_field\", None)\n                 if rel and rel.model == self.model:\n                     break\n         return field.foreign_related_fields[0]\n"}
{"instance_id": "django__django-14730", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex febaadbb5b..7d588eef13 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -19,19 +19,30 @@ from django.utils.translation import gettext_lazy as _\n from . import Field\n from .mixins import FieldCacheMixin\n from .related_descriptors import (\n-    ForeignKeyDeferredAttribute, ForwardManyToOneDescriptor,\n-    ForwardOneToOneDescriptor, ManyToManyDescriptor,\n-    ReverseManyToOneDescriptor, ReverseOneToOneDescriptor,\n+    ForeignKeyDeferredAttribute,\n+    ForwardManyToOneDescriptor,\n+    ForwardOneToOneDescriptor,\n+    ManyToManyDescriptor,\n+    ReverseManyToOneDescriptor,\n+    ReverseOneToOneDescriptor,\n )\n from .related_lookups import (\n-    RelatedExact, RelatedGreaterThan, RelatedGreaterThanOrEqual, RelatedIn,\n-    RelatedIsNull, RelatedLessThan, RelatedLessThanOrEqual,\n+    RelatedExact,\n+    RelatedGreaterThan,\n+    RelatedGreaterThanOrEqual,\n+    RelatedIn,\n+    RelatedIsNull,\n+    RelatedLessThan,\n+    RelatedLessThanOrEqual,\n )\n from .reverse_related import (\n-    ForeignObjectRel, ManyToManyRel, ManyToOneRel, OneToOneRel,\n+    ForeignObjectRel,\n+    ManyToManyRel,\n+    ManyToOneRel,\n+    OneToOneRel,\n )\n \n-RECURSIVE_RELATIONSHIP_CONSTANT = 'self'\n+RECURSIVE_RELATIONSHIP_CONSTANT = \"self\"\n \n \n def resolve_relation(scope_model, relation):\n@@ -119,19 +130,25 @@ class RelatedField(FieldCacheMixin, Field):\n \n     def _check_related_name_is_valid(self):\n         import keyword\n+\n         related_name = self.remote_field.related_name\n         if related_name is None:\n             return []\n-        is_valid_id = not keyword.iskeyword(related_name) and related_name.isidentifier()\n-        if not (is_valid_id or related_name.endswith('+')):\n+        is_valid_id = (\n+            not keyword.iskeyword(related_name) and related_name.isidentifier()\n+        )\n+        if not (is_valid_id or related_name.endswith(\"+\")):\n             return [\n                 checks.Error(\n-                    \"The name '%s' is invalid related_name for field %s.%s\" %\n-                    (self.remote_field.related_name, self.model._meta.object_name,\n-                     self.name),\n+                    \"The name '%s' is invalid related_name for field %s.%s\"\n+                    % (\n+                        self.remote_field.related_name,\n+                        self.model._meta.object_name,\n+                        self.name,\n+                    ),\n                     hint=\"Related name must be a valid Python identifier or end with a '+'\",\n                     obj=self,\n-                    id='fields.E306',\n+                    id=\"fields.E306\",\n                 )\n             ]\n         return []\n@@ -141,15 +158,17 @@ class RelatedField(FieldCacheMixin, Field):\n             return []\n         rel_query_name = self.related_query_name()\n         errors = []\n-        if rel_query_name.endswith('_'):\n+        if rel_query_name.endswith(\"_\"):\n             errors.append(\n                 checks.Error(\n                     \"Reverse query name '%s' must not end with an underscore.\"\n                     % rel_query_name,\n-                    hint=(\"Add or change a related_name or related_query_name \"\n-                          \"argument for this field.\"),\n+                    hint=(\n+                        \"Add or change a related_name or related_query_name \"\n+                        \"argument for this field.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E308',\n+                    id=\"fields.E308\",\n                 )\n             )\n         if LOOKUP_SEP in rel_query_name:\n@@ -157,10 +176,12 @@ class RelatedField(FieldCacheMixin, Field):\n                 checks.Error(\n                     \"Reverse query name '%s' must not contain '%s'.\"\n                     % (rel_query_name, LOOKUP_SEP),\n-                    hint=(\"Add or change a related_name or related_query_name \"\n-                          \"argument for this field.\"),\n+                    hint=(\n+                        \"Add or change a related_name or related_query_name \"\n+                        \"argument for this field.\"\n+                    ),\n                     obj=self,\n-                    id='fields.E309',\n+                    id=\"fields.E309\",\n                 )\n             )\n         return errors\n@@ -168,29 +189,38 @@ class RelatedField(FieldCacheMixin, Field):\n     def _check_relation_model_exists(self):\n         rel_is_missing = self.remote_field.model not in self.opts.apps.get_models()\n         rel_is_string = isinstance(self.remote_field.model, str)\n-        model_name = self.remote_field.model if rel_is_string else self.remote_field.model._meta.object_name\n-        if rel_is_missing and (rel_is_string or not self.remote_field.model._meta.swapped):\n+        model_name = (\n+            self.remote_field.model\n+            if rel_is_string\n+            else self.remote_field.model._meta.object_name\n+        )\n+        if rel_is_missing and (\n+            rel_is_string or not self.remote_field.model._meta.swapped\n+        ):\n             return [\n                 checks.Error(\n                     \"Field defines a relation with model '%s', which is either \"\n                     \"not installed, or is abstract.\" % model_name,\n                     obj=self,\n-                    id='fields.E300',\n+                    id=\"fields.E300\",\n                 )\n             ]\n         return []\n \n     def _check_referencing_to_swapped_model(self):\n-        if (self.remote_field.model not in self.opts.apps.get_models() and\n-                not isinstance(self.remote_field.model, str) and\n-                self.remote_field.model._meta.swapped):\n+        if (\n+            self.remote_field.model not in self.opts.apps.get_models()\n+            and not isinstance(self.remote_field.model, str)\n+            and self.remote_field.model._meta.swapped\n+        ):\n             return [\n                 checks.Error(\n                     \"Field defines a relation with the model '%s', which has \"\n                     \"been swapped out.\" % self.remote_field.model._meta.label,\n-                    hint=\"Update the relation to point at 'settings.%s'.\" % self.remote_field.model._meta.swappable,\n+                    hint=\"Update the relation to point at 'settings.%s'.\"\n+                    % self.remote_field.model._meta.swappable,\n                     obj=self,\n-                    id='fields.E301',\n+                    id=\"fields.E301\",\n                 )\n             ]\n         return []\n@@ -227,7 +257,7 @@ class RelatedField(FieldCacheMixin, Field):\n         rel_name = self.remote_field.get_accessor_name()  # i. e. \"model_set\"\n         rel_query_name = self.related_query_name()  # i. e. \"model\"\n         # i.e. \"app_label.Model.field\".\n-        field_name = '%s.%s' % (opts.label, self.name)\n+        field_name = \"%s.%s\" % (opts.label, self.name)\n \n         # Check clashes between accessor or reverse query name of `field`\n         # and any other field name -- i.e. accessor for Model.foreign is\n@@ -235,26 +265,34 @@ class RelatedField(FieldCacheMixin, Field):\n         potential_clashes = rel_opts.fields + rel_opts.many_to_many\n         for clash_field in potential_clashes:\n             # i.e. \"app_label.Target.model_set\".\n-            clash_name = '%s.%s' % (rel_opts.label, clash_field.name)\n+            clash_name = \"%s.%s\" % (rel_opts.label, clash_field.name)\n             if not rel_is_hidden and clash_field.name == rel_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse accessor for '%s' clashes with field name '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Rename field '%s', or add/change a related_name \"\n-                              \"argument to the definition for field '%s'.\") % (clash_name, field_name),\n+                        \"Reverse accessor for '%s' clashes with field name '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Rename field '%s', or add/change a related_name \"\n+                            \"argument to the definition for field '%s'.\"\n+                        )\n+                        % (clash_name, field_name),\n                         obj=self,\n-                        id='fields.E302',\n+                        id=\"fields.E302\",\n                     )\n                 )\n \n             if clash_field.name == rel_query_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse query name for '%s' clashes with field name '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Rename field '%s', or add/change a related_name \"\n-                              \"argument to the definition for field '%s'.\") % (clash_name, field_name),\n+                        \"Reverse query name for '%s' clashes with field name '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Rename field '%s', or add/change a related_name \"\n+                            \"argument to the definition for field '%s'.\"\n+                        )\n+                        % (clash_name, field_name),\n                         obj=self,\n-                        id='fields.E303',\n+                        id=\"fields.E303\",\n                     )\n                 )\n \n@@ -264,18 +302,22 @@ class RelatedField(FieldCacheMixin, Field):\n         potential_clashes = (r for r in rel_opts.related_objects if r.field is not self)\n         for clash_field in potential_clashes:\n             # i.e. \"app_label.Model.m2m\".\n-            clash_name = '%s.%s' % (\n+            clash_name = \"%s.%s\" % (\n                 clash_field.related_model._meta.label,\n                 clash_field.field.name,\n             )\n             if not rel_is_hidden and clash_field.get_accessor_name() == rel_name:\n                 errors.append(\n                     checks.Error(\n-                        \"Reverse accessor for '%s' clashes with reverse accessor for '%s'.\" % (field_name, clash_name),\n-                        hint=(\"Add or change a related_name argument \"\n-                              \"to the definition for '%s' or '%s'.\") % (field_name, clash_name),\n+                        \"Reverse accessor for '%s' clashes with reverse accessor for '%s'.\"\n+                        % (field_name, clash_name),\n+                        hint=(\n+                            \"Add or change a related_name argument \"\n+                            \"to the definition for '%s' or '%s'.\"\n+                        )\n+                        % (field_name, clash_name),\n                         obj=self,\n-                        id='fields.E304',\n+                        id=\"fields.E304\",\n                     )\n                 )\n \n@@ -284,10 +326,13 @@ class RelatedField(FieldCacheMixin, Field):\n                     checks.Error(\n                         \"Reverse query name for '%s' clashes with reverse query name for '%s'.\"\n                         % (field_name, clash_name),\n-                        hint=(\"Add or change a related_name argument \"\n-                              \"to the definition for '%s' or '%s'.\") % (field_name, clash_name),\n+                        hint=(\n+                            \"Add or change a related_name argument \"\n+                            \"to the definition for '%s' or '%s'.\"\n+                        )\n+                        % (field_name, clash_name),\n                         obj=self,\n-                        id='fields.E305',\n+                        id=\"fields.E305\",\n                     )\n                 )\n \n@@ -299,7 +344,6 @@ class RelatedField(FieldCacheMixin, Field):\n         return None\n \n     def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n-\n         super().contribute_to_class(cls, name, private_only=private_only, **kwargs)\n \n         self.opts = cls._meta\n@@ -311,32 +355,35 @@ class RelatedField(FieldCacheMixin, Field):\n                 related_name = self.opts.default_related_name\n             if related_name:\n                 related_name = related_name % {\n-                    'class': cls.__name__.lower(),\n-                    'model_name': cls._meta.model_name.lower(),\n-                    'app_label': cls._meta.app_label.lower()\n+                    \"class\": cls.__name__.lower(),\n+                    \"model_name\": cls._meta.model_name.lower(),\n+                    \"app_label\": cls._meta.app_label.lower(),\n                 }\n                 self.remote_field.related_name = related_name\n \n             if self.remote_field.related_query_name:\n                 related_query_name = self.remote_field.related_query_name % {\n-                    'class': cls.__name__.lower(),\n-                    'app_label': cls._meta.app_label.lower(),\n+                    \"class\": cls.__name__.lower(),\n+                    \"app_label\": cls._meta.app_label.lower(),\n                 }\n                 self.remote_field.related_query_name = related_query_name\n \n             def resolve_related_class(model, related, field):\n                 field.remote_field.model = related\n                 field.do_related_class(related, model)\n-            lazy_related_operation(resolve_related_class, cls, self.remote_field.model, field=self)\n+\n+            lazy_related_operation(\n+                resolve_related_class, cls, self.remote_field.model, field=self\n+            )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if self._limit_choices_to:\n-            kwargs['limit_choices_to'] = self._limit_choices_to\n+            kwargs[\"limit_choices_to\"] = self._limit_choices_to\n         if self._related_name is not None:\n-            kwargs['related_name'] = self._related_name\n+            kwargs[\"related_name\"] = self._related_name\n         if self._related_query_name is not None:\n-            kwargs['related_query_name'] = self._related_query_name\n+            kwargs[\"related_query_name\"] = self._related_query_name\n         return name, path, args, kwargs\n \n     def get_forward_related_filter(self, obj):\n@@ -348,7 +395,7 @@ class RelatedField(FieldCacheMixin, Field):\n         self.related_field.model.\n         \"\"\"\n         return {\n-            '%s__%s' % (self.name, rh_field.name): getattr(obj, rh_field.attname)\n+            \"%s__%s\" % (self.name, rh_field.name): getattr(obj, rh_field.attname)\n             for _, rh_field in self.related_fields\n         }\n \n@@ -387,9 +434,10 @@ class RelatedField(FieldCacheMixin, Field):\n         return None\n \n     def set_attributes_from_rel(self):\n-        self.name = (\n-            self.name or\n-            (self.remote_field.model._meta.model_name + '_' + self.remote_field.model._meta.pk.name)\n+        self.name = self.name or (\n+            self.remote_field.model._meta.model_name\n+            + \"_\"\n+            + self.remote_field.model._meta.pk.name\n         )\n         if self.verbose_name is None:\n             self.verbose_name = self.remote_field.model._meta.verbose_name\n@@ -419,14 +467,16 @@ class RelatedField(FieldCacheMixin, Field):\n         being constructed.\n         \"\"\"\n         defaults = {}\n-        if hasattr(self.remote_field, 'get_related_field'):\n+        if hasattr(self.remote_field, \"get_related_field\"):\n             # If this is a callable, do not invoke it here. Just pass\n             # it in the defaults for when the form class will later be\n             # instantiated.\n             limit_choices_to = self.remote_field.limit_choices_to\n-            defaults.update({\n-                'limit_choices_to': limit_choices_to,\n-            })\n+            defaults.update(\n+                {\n+                    \"limit_choices_to\": limit_choices_to,\n+                }\n+            )\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n@@ -435,7 +485,11 @@ class RelatedField(FieldCacheMixin, Field):\n         Define the name that can be used to identify this related object in a\n         table-spanning query.\n         \"\"\"\n-        return self.remote_field.related_query_name or self.remote_field.related_name or self.opts.model_name\n+        return (\n+            self.remote_field.related_query_name\n+            or self.remote_field.related_name\n+            or self.opts.model_name\n+        )\n \n     @property\n     def target_field(self):\n@@ -446,7 +500,8 @@ class RelatedField(FieldCacheMixin, Field):\n         target_fields = self.get_path_info()[-1].target_fields\n         if len(target_fields) > 1:\n             raise exceptions.FieldError(\n-                \"The relation has multiple target fields, but only single target field was asked for\")\n+                \"The relation has multiple target fields, but only single target field was asked for\"\n+            )\n         return target_fields[0]\n \n     def get_cache_name(self):\n@@ -469,13 +524,24 @@ class ForeignObject(RelatedField):\n     forward_related_accessor_class = ForwardManyToOneDescriptor\n     rel_class = ForeignObjectRel\n \n-    def __init__(self, to, on_delete, from_fields, to_fields, rel=None, related_name=None,\n-                 related_query_name=None, limit_choices_to=None, parent_link=False,\n-                 swappable=True, **kwargs):\n-\n+    def __init__(\n+        self,\n+        to,\n+        on_delete,\n+        from_fields,\n+        to_fields,\n+        rel=None,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        swappable=True,\n+        **kwargs,\n+    ):\n         if rel is None:\n             rel = self.rel_class(\n-                self, to,\n+                self,\n+                to,\n                 related_name=related_name,\n                 related_query_name=related_query_name,\n                 limit_choices_to=limit_choices_to,\n@@ -519,7 +585,7 @@ class ForeignObject(RelatedField):\n                             \"model '%s'.\"\n                             % (to_field, self.remote_field.model._meta.label),\n                             obj=self,\n-                            id='fields.E312',\n+                            id=\"fields.E312\",\n                         )\n                     )\n         return errors\n@@ -540,21 +606,22 @@ class ForeignObject(RelatedField):\n         unique_foreign_fields = {\n             frozenset([f.name])\n             for f in self.remote_field.model._meta.get_fields()\n-            if getattr(f, 'unique', False)\n+            if getattr(f, \"unique\", False)\n         }\n-        unique_foreign_fields.update({\n-            frozenset(ut)\n-            for ut in self.remote_field.model._meta.unique_together\n-        })\n-        unique_foreign_fields.update({\n-            frozenset(uc.fields)\n-            for uc in self.remote_field.model._meta.total_unique_constraints\n-        })\n+        unique_foreign_fields.update(\n+            {frozenset(ut) for ut in self.remote_field.model._meta.unique_together}\n+        )\n+        unique_foreign_fields.update(\n+            {\n+                frozenset(uc.fields)\n+                for uc in self.remote_field.model._meta.total_unique_constraints\n+            }\n+        )\n         foreign_fields = {f.name for f in self.foreign_related_fields}\n         has_unique_constraint = any(u <= foreign_fields for u in unique_foreign_fields)\n \n         if not has_unique_constraint and len(self.foreign_related_fields) > 1:\n-            field_combination = ', '.join(\n+            field_combination = \", \".join(\n                 \"'%s'\" % rel_field.name for rel_field in self.foreign_related_fields\n             )\n             model_name = self.remote_field.model.__name__\n@@ -563,13 +630,13 @@ class ForeignObject(RelatedField):\n                     \"No subset of the fields %s on model '%s' is unique.\"\n                     % (field_combination, model_name),\n                     hint=(\n-                        'Mark a single field as unique=True or add a set of '\n-                        'fields to a unique constraint (via unique_together '\n-                        'or a UniqueConstraint (without condition) in the '\n-                        'model Meta.constraints).'\n+                        \"Mark a single field as unique=True or add a set of \"\n+                        \"fields to a unique constraint (via unique_together \"\n+                        \"or a UniqueConstraint (without condition) in the \"\n+                        \"model Meta.constraints).\"\n                     ),\n                     obj=self,\n-                    id='fields.E310',\n+                    id=\"fields.E310\",\n                 )\n             ]\n         elif not has_unique_constraint:\n@@ -580,12 +647,12 @@ class ForeignObject(RelatedField):\n                     \"'%s.%s' must be unique because it is referenced by \"\n                     \"a foreign key.\" % (model_name, field_name),\n                     hint=(\n-                        'Add unique=True to this field or add a '\n-                        'UniqueConstraint (without condition) in the model '\n-                        'Meta.constraints.'\n+                        \"Add unique=True to this field or add a \"\n+                        \"UniqueConstraint (without condition) in the model \"\n+                        \"Meta.constraints.\"\n                     ),\n                     obj=self,\n-                    id='fields.E311',\n+                    id=\"fields.E311\",\n                 )\n             ]\n         else:\n@@ -593,44 +660,48 @@ class ForeignObject(RelatedField):\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        kwargs['on_delete'] = self.remote_field.on_delete\n-        kwargs['from_fields'] = self.from_fields\n-        kwargs['to_fields'] = self.to_fields\n+        kwargs[\"on_delete\"] = self.remote_field.on_delete\n+        kwargs[\"from_fields\"] = self.from_fields\n+        kwargs[\"to_fields\"] = self.to_fields\n \n         if self.remote_field.parent_link:\n-            kwargs['parent_link'] = self.remote_field.parent_link\n+            kwargs[\"parent_link\"] = self.remote_field.parent_link\n         if isinstance(self.remote_field.model, str):\n-            if '.' in self.remote_field.model:\n-                app_label, model_name = self.remote_field.model.split('.')\n-                kwargs['to'] = '%s.%s' % (app_label, model_name.lower())\n+            if \".\" in self.remote_field.model:\n+                app_label, model_name = self.remote_field.model.split(\".\")\n+                kwargs[\"to\"] = \"%s.%s\" % (app_label, model_name.lower())\n             else:\n-                kwargs['to'] = self.remote_field.model.lower()\n+                kwargs[\"to\"] = self.remote_field.model.lower()\n         else:\n-            kwargs['to'] = self.remote_field.model._meta.label_lower\n+            kwargs[\"to\"] = self.remote_field.model._meta.label_lower\n         # If swappable is True, then see if we're actually pointing to the target\n         # of a swap.\n         swappable_setting = self.swappable_setting\n         if swappable_setting is not None:\n             # If it's already a settings reference, error\n-            if hasattr(kwargs['to'], \"setting_name\"):\n-                if kwargs['to'].setting_name != swappable_setting:\n+            if hasattr(kwargs[\"to\"], \"setting_name\"):\n+                if kwargs[\"to\"].setting_name != swappable_setting:\n                     raise ValueError(\n                         \"Cannot deconstruct a ForeignKey pointing to a model \"\n                         \"that is swapped in place of more than one model (%s and %s)\"\n-                        % (kwargs['to'].setting_name, swappable_setting)\n+                        % (kwargs[\"to\"].setting_name, swappable_setting)\n                     )\n             # Set it\n-            kwargs['to'] = SettingsReference(\n-                kwargs['to'],\n+            kwargs[\"to\"] = SettingsReference(\n+                kwargs[\"to\"],\n                 swappable_setting,\n             )\n         return name, path, args, kwargs\n \n     def resolve_related_fields(self):\n         if not self.from_fields or len(self.from_fields) != len(self.to_fields):\n-            raise ValueError('Foreign Object from and to fields must be the same non-zero length')\n+            raise ValueError(\n+                \"Foreign Object from and to fields must be the same non-zero length\"\n+            )\n         if isinstance(self.remote_field.model, str):\n-            raise ValueError('Related model %r cannot be resolved' % self.remote_field.model)\n+            raise ValueError(\n+                \"Related model %r cannot be resolved\" % self.remote_field.model\n+            )\n         related_fields = []\n         for index in range(len(self.from_fields)):\n             from_field_name = self.from_fields[index]\n@@ -640,8 +711,11 @@ class ForeignObject(RelatedField):\n                 if from_field_name == RECURSIVE_RELATIONSHIP_CONSTANT\n                 else self.opts.get_field(from_field_name)\n             )\n-            to_field = (self.remote_field.model._meta.pk if to_field_name is None\n-                        else self.remote_field.model._meta.get_field(to_field_name))\n+            to_field = (\n+                self.remote_field.model._meta.pk\n+                if to_field_name is None\n+                else self.remote_field.model._meta.get_field(to_field_name)\n+            )\n             related_fields.append((from_field, to_field))\n         return related_fields\n \n@@ -659,7 +733,9 @@ class ForeignObject(RelatedField):\n \n     @cached_property\n     def foreign_related_fields(self):\n-        return tuple(rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field)\n+        return tuple(\n+            rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field\n+        )\n \n     def get_local_related_value(self, instance):\n         return self.get_instance_value_for_fields(instance, self.local_related_fields)\n@@ -677,9 +753,11 @@ class ForeignObject(RelatedField):\n             # instance.pk (that is, parent_ptr_id) when asked for instance.id.\n             if field.primary_key:\n                 possible_parent_link = opts.get_ancestor_link(field.model)\n-                if (not possible_parent_link or\n-                        possible_parent_link.primary_key or\n-                        possible_parent_link.model._meta.abstract):\n+                if (\n+                    not possible_parent_link\n+                    or possible_parent_link.primary_key\n+                    or possible_parent_link.model._meta.abstract\n+                ):\n                     ret.append(instance.pk)\n                     continue\n             ret.append(getattr(instance, field.attname))\n@@ -691,7 +769,9 @@ class ForeignObject(RelatedField):\n \n     def get_joining_columns(self, reverse_join=False):\n         source = self.reverse_related_fields if reverse_join else self.related_fields\n-        return tuple((lhs_field.column, rhs_field.column) for lhs_field, rhs_field in source)\n+        return tuple(\n+            (lhs_field.column, rhs_field.column) for lhs_field, rhs_field in source\n+        )\n \n     def get_reverse_joining_columns(self):\n         return self.get_joining_columns(reverse_join=True)\n@@ -729,36 +809,40 @@ class ForeignObject(RelatedField):\n         \"\"\"Get path from this field to the related model.\"\"\"\n         opts = self.remote_field.model._meta\n         from_opts = self.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=self.foreign_related_fields,\n-            join_field=self,\n-            m2m=False,\n-            direct=True,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=self.foreign_related_fields,\n+                join_field=self,\n+                m2m=False,\n+                direct=True,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     def get_reverse_path_info(self, filtered_relation=None):\n         \"\"\"Get path from the related model to this field's model.\"\"\"\n         opts = self.model._meta\n         from_opts = self.remote_field.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=(opts.pk,),\n-            join_field=self.remote_field,\n-            m2m=not self.unique,\n-            direct=False,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=(opts.pk,),\n+                join_field=self.remote_field,\n+                m2m=not self.unique,\n+                direct=False,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     @classmethod\n     @functools.lru_cache(maxsize=None)\n     def get_lookups(cls):\n         bases = inspect.getmro(cls)\n-        bases = bases[:bases.index(ForeignObject) + 1]\n-        class_lookups = [parent.__dict__.get('class_lookups', {}) for parent in bases]\n+        bases = bases[: bases.index(ForeignObject) + 1]\n+        class_lookups = [parent.__dict__.get(\"class_lookups\", {}) for parent in bases]\n         return cls.merge_dicts(class_lookups)\n \n     def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n@@ -768,13 +852,22 @@ class ForeignObject(RelatedField):\n     def contribute_to_related_class(self, cls, related):\n         # Internal FK's - i.e., those with a related name ending with '+' -\n         # and swapped models don't get a related descriptor.\n-        if not self.remote_field.is_hidden() and not related.related_model._meta.swapped:\n-            setattr(cls._meta.concrete_model, related.get_accessor_name(), self.related_accessor_class(related))\n+        if (\n+            not self.remote_field.is_hidden()\n+            and not related.related_model._meta.swapped\n+        ):\n+            setattr(\n+                cls._meta.concrete_model,\n+                related.get_accessor_name(),\n+                self.related_accessor_class(related),\n+            )\n             # While 'limit_choices_to' might be a callable, simply pass\n             # it along for later - this is too early because it's still\n             # model load time.\n             if self.remote_field.limit_choices_to:\n-                cls._meta.related_fkey_lookups.append(self.remote_field.limit_choices_to)\n+                cls._meta.related_fkey_lookups.append(\n+                    self.remote_field.limit_choices_to\n+                )\n \n \n ForeignObject.register_lookup(RelatedIn)\n@@ -794,6 +887,7 @@ class ForeignKey(ForeignObject):\n     By default ForeignKey will target the pk of the remote model but this\n     behavior can be changed by using the ``to_field`` argument.\n     \"\"\"\n+\n     descriptor_class = ForeignKeyDeferredAttribute\n     # Field flags\n     many_to_many = False\n@@ -805,21 +899,33 @@ class ForeignKey(ForeignObject):\n \n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _('%(model)s instance with %(field)s %(value)r does not exist.')\n+        \"invalid\": _(\"%(model)s instance with %(field)s %(value)r does not exist.\")\n     }\n     description = _(\"Foreign Key (type determined by related field)\")\n \n-    def __init__(self, to, on_delete, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, parent_link=False, to_field=None,\n-                 db_constraint=True, **kwargs):\n+    def __init__(\n+        self,\n+        to,\n+        on_delete,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        parent_link=False,\n+        to_field=None,\n+        db_constraint=True,\n+        **kwargs,\n+    ):\n         try:\n             to._meta.model_name\n         except AttributeError:\n             if not isinstance(to, str):\n                 raise TypeError(\n-                    '%s(%r) is invalid. First parameter to ForeignKey must be '\n-                    'either a model, a model name, or the string %r' % (\n-                        self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT,\n+                    \"%s(%r) is invalid. First parameter to ForeignKey must be \"\n+                    \"either a model, a model name, or the string %r\"\n+                    % (\n+                        self.__class__.__name__,\n+                        to,\n+                        RECURSIVE_RELATIONSHIP_CONSTANT,\n                     )\n                 )\n         else:\n@@ -828,17 +934,19 @@ class ForeignKey(ForeignObject):\n             # be correct until contribute_to_class is called. Refs #12190.\n             to_field = to_field or (to._meta.pk and to._meta.pk.name)\n         if not callable(on_delete):\n-            raise TypeError('on_delete must be callable.')\n+            raise TypeError(\"on_delete must be callable.\")\n \n-        kwargs['rel'] = self.rel_class(\n-            self, to, to_field,\n+        kwargs[\"rel\"] = self.rel_class(\n+            self,\n+            to,\n+            to_field,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n             parent_link=parent_link,\n             on_delete=on_delete,\n         )\n-        kwargs.setdefault('db_index', True)\n+        kwargs.setdefault(\"db_index\", True)\n \n         super().__init__(\n             to,\n@@ -860,54 +968,60 @@ class ForeignKey(ForeignObject):\n         ]\n \n     def _check_on_delete(self):\n-        on_delete = getattr(self.remote_field, 'on_delete', None)\n+        on_delete = getattr(self.remote_field, \"on_delete\", None)\n         if on_delete == SET_NULL and not self.null:\n             return [\n                 checks.Error(\n-                    'Field specifies on_delete=SET_NULL, but cannot be null.',\n-                    hint='Set null=True argument on the field, or change the on_delete rule.',\n+                    \"Field specifies on_delete=SET_NULL, but cannot be null.\",\n+                    hint=\"Set null=True argument on the field, or change the on_delete rule.\",\n                     obj=self,\n-                    id='fields.E320',\n+                    id=\"fields.E320\",\n                 )\n             ]\n         elif on_delete == SET_DEFAULT and not self.has_default():\n             return [\n                 checks.Error(\n-                    'Field specifies on_delete=SET_DEFAULT, but has no default value.',\n-                    hint='Set a default value, or change the on_delete rule.',\n+                    \"Field specifies on_delete=SET_DEFAULT, but has no default value.\",\n+                    hint=\"Set a default value, or change the on_delete rule.\",\n                     obj=self,\n-                    id='fields.E321',\n+                    id=\"fields.E321\",\n                 )\n             ]\n         else:\n             return []\n \n     def _check_unique(self, **kwargs):\n-        return [\n-            checks.Warning(\n-                'Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.',\n-                hint='ForeignKey(unique=True) is usually better served by a OneToOneField.',\n-                obj=self,\n-                id='fields.W342',\n-            )\n-        ] if self.unique else []\n+        return (\n+            [\n+                checks.Warning(\n+                    \"Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.\",\n+                    hint=\"ForeignKey(unique=True) is usually better served by a OneToOneField.\",\n+                    obj=self,\n+                    id=\"fields.W342\",\n+                )\n+            ]\n+            if self.unique\n+            else []\n+        )\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        del kwargs['to_fields']\n-        del kwargs['from_fields']\n+        del kwargs[\"to_fields\"]\n+        del kwargs[\"from_fields\"]\n         # Handle the simpler arguments\n         if self.db_index:\n-            del kwargs['db_index']\n+            del kwargs[\"db_index\"]\n         else:\n-            kwargs['db_index'] = False\n+            kwargs[\"db_index\"] = False\n         if self.db_constraint is not True:\n-            kwargs['db_constraint'] = self.db_constraint\n+            kwargs[\"db_constraint\"] = self.db_constraint\n         # Rel needs more work.\n         to_meta = getattr(self.remote_field.model, \"_meta\", None)\n         if self.remote_field.field_name and (\n-                not to_meta or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)):\n-            kwargs['to_field'] = self.remote_field.field_name\n+            not to_meta\n+            or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)\n+        ):\n+            kwargs[\"to_field\"] = self.remote_field.field_name\n         return name, path, args, kwargs\n \n     def to_python(self, value):\n@@ -921,15 +1035,17 @@ class ForeignKey(ForeignObject):\n         \"\"\"Get path from the related model to this field's model.\"\"\"\n         opts = self.model._meta\n         from_opts = self.remote_field.model._meta\n-        return [PathInfo(\n-            from_opts=from_opts,\n-            to_opts=opts,\n-            target_fields=(opts.pk,),\n-            join_field=self.remote_field,\n-            m2m=not self.unique,\n-            direct=False,\n-            filtered_relation=filtered_relation,\n-        )]\n+        return [\n+            PathInfo(\n+                from_opts=from_opts,\n+                to_opts=opts,\n+                target_fields=(opts.pk,),\n+                join_field=self.remote_field,\n+                m2m=not self.unique,\n+                direct=False,\n+                filtered_relation=filtered_relation,\n+            )\n+        ]\n \n     def validate(self, value, model_instance):\n         if self.remote_field.parent_link:\n@@ -945,21 +1061,27 @@ class ForeignKey(ForeignObject):\n         qs = qs.complex_filter(self.get_limit_choices_to())\n         if not qs.exists():\n             raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n+                self.error_messages[\"invalid\"],\n+                code=\"invalid\",\n                 params={\n-                    'model': self.remote_field.model._meta.verbose_name, 'pk': value,\n-                    'field': self.remote_field.field_name, 'value': value,\n+                    \"model\": self.remote_field.model._meta.verbose_name,\n+                    \"pk\": value,\n+                    \"field\": self.remote_field.field_name,\n+                    \"value\": value,\n                 },  # 'pk' is included for backwards compatibility\n             )\n \n     def resolve_related_fields(self):\n         related_fields = super().resolve_related_fields()\n         for from_field, to_field in related_fields:\n-            if to_field and to_field.model != self.remote_field.model._meta.concrete_model:\n+            if (\n+                to_field\n+                and to_field.model != self.remote_field.model._meta.concrete_model\n+            ):\n                 raise exceptions.FieldError(\n                     \"'%s.%s' refers to field '%s' which is not local to model \"\n-                    \"'%s'.\" % (\n+                    \"'%s'.\"\n+                    % (\n                         self.model._meta.label,\n                         self.name,\n                         to_field.name,\n@@ -969,7 +1091,7 @@ class ForeignKey(ForeignObject):\n         return related_fields\n \n     def get_attname(self):\n-        return '%s_id' % self.name\n+        return \"%s_id\" % self.name\n \n     def get_attname_column(self):\n         attname = self.get_attname()\n@@ -984,9 +1106,13 @@ class ForeignKey(ForeignObject):\n         return field_default\n \n     def get_db_prep_save(self, value, connection):\n-        if value is None or (value == '' and\n-                             (not self.target_field.empty_strings_allowed or\n-                              connection.features.interprets_empty_strings_as_nulls)):\n+        if value is None or (\n+            value == \"\"\n+            and (\n+                not self.target_field.empty_strings_allowed\n+                or connection.features.interprets_empty_strings_as_nulls\n+            )\n+        ):\n             return None\n         else:\n             return self.target_field.get_db_prep_save(value, connection=connection)\n@@ -1004,16 +1130,20 @@ class ForeignKey(ForeignObject):\n \n     def formfield(self, *, using=None, **kwargs):\n         if isinstance(self.remote_field.model, str):\n-            raise ValueError(\"Cannot create form field for %r yet, because \"\n-                             \"its related model %r has not been loaded yet\" %\n-                             (self.name, self.remote_field.model))\n-        return super().formfield(**{\n-            'form_class': forms.ModelChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n-            'to_field_name': self.remote_field.field_name,\n-            **kwargs,\n-            'blank': self.blank,\n-        })\n+            raise ValueError(\n+                \"Cannot create form field for %r yet, because \"\n+                \"its related model %r has not been loaded yet\"\n+                % (self.name, self.remote_field.model)\n+            )\n+        return super().formfield(\n+            **{\n+                \"form_class\": forms.ModelChoiceField,\n+                \"queryset\": self.remote_field.model._default_manager.using(using),\n+                \"to_field_name\": self.remote_field.field_name,\n+                **kwargs,\n+                \"blank\": self.blank,\n+            }\n+        )\n \n     def db_check(self, connection):\n         return []\n@@ -1041,7 +1171,7 @@ class ForeignKey(ForeignObject):\n             while isinstance(output_field, ForeignKey):\n                 output_field = output_field.target_field\n                 if output_field is self:\n-                    raise ValueError('Cannot resolve output_field.')\n+                    raise ValueError(\"Cannot resolve output_field.\")\n         return super().get_col(alias, output_field)\n \n \n@@ -1066,13 +1196,13 @@ class OneToOneField(ForeignKey):\n     description = _(\"One-to-one relationship\")\n \n     def __init__(self, to, on_delete, to_field=None, **kwargs):\n-        kwargs['unique'] = True\n+        kwargs[\"unique\"] = True\n         super().__init__(to, on_delete, to_field=to_field, **kwargs)\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n         if \"unique\" in kwargs:\n-            del kwargs['unique']\n+            del kwargs[\"unique\"]\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n@@ -1102,44 +1232,54 @@ def create_many_to_many_intermediary_model(field, klass):\n         through._meta.managed = model._meta.managed or related._meta.managed\n \n     to_model = resolve_relation(klass, field.remote_field.model)\n-    name = '%s_%s' % (klass._meta.object_name, field.name)\n+    name = \"%s_%s\" % (klass._meta.object_name, field.name)\n     lazy_related_operation(set_managed, klass, to_model, name)\n \n     to = make_model_tuple(to_model)[1]\n     from_ = klass._meta.model_name\n     if to == from_:\n-        to = 'to_%s' % to\n-        from_ = 'from_%s' % from_\n-\n-    meta = type('Meta', (), {\n-        'db_table': field._get_m2m_db_table(klass._meta),\n-        'auto_created': klass,\n-        'app_label': klass._meta.app_label,\n-        'db_tablespace': klass._meta.db_tablespace,\n-        'unique_together': (from_, to),\n-        'verbose_name': _('%(from)s-%(to)s relationship') % {'from': from_, 'to': to},\n-        'verbose_name_plural': _('%(from)s-%(to)s relationships') % {'from': from_, 'to': to},\n-        'apps': field.model._meta.apps,\n-    })\n+        to = \"to_%s\" % to\n+        from_ = \"from_%s\" % from_\n+\n+    meta = type(\n+        \"Meta\",\n+        (),\n+        {\n+            \"db_table\": field._get_m2m_db_table(klass._meta),\n+            \"auto_created\": klass,\n+            \"app_label\": klass._meta.app_label,\n+            \"db_tablespace\": klass._meta.db_tablespace,\n+            \"unique_together\": (from_, to),\n+            \"verbose_name\": _(\"%(from)s-%(to)s relationship\")\n+            % {\"from\": from_, \"to\": to},\n+            \"verbose_name_plural\": _(\"%(from)s-%(to)s relationships\")\n+            % {\"from\": from_, \"to\": to},\n+            \"apps\": field.model._meta.apps,\n+        },\n+    )\n     # Construct and return the new class.\n-    return type(name, (models.Model,), {\n-        'Meta': meta,\n-        '__module__': klass.__module__,\n-        from_: models.ForeignKey(\n-            klass,\n-            related_name='%s+' % name,\n-            db_tablespace=field.db_tablespace,\n-            db_constraint=field.remote_field.db_constraint,\n-            on_delete=CASCADE,\n-        ),\n-        to: models.ForeignKey(\n-            to_model,\n-            related_name='%s+' % name,\n-            db_tablespace=field.db_tablespace,\n-            db_constraint=field.remote_field.db_constraint,\n-            on_delete=CASCADE,\n-        )\n-    })\n+    return type(\n+        name,\n+        (models.Model,),\n+        {\n+            \"Meta\": meta,\n+            \"__module__\": klass.__module__,\n+            from_: models.ForeignKey(\n+                klass,\n+                related_name=\"%s+\" % name,\n+                db_tablespace=field.db_tablespace,\n+                db_constraint=field.remote_field.db_constraint,\n+                on_delete=CASCADE,\n+            ),\n+            to: models.ForeignKey(\n+                to_model,\n+                related_name=\"%s+\" % name,\n+                db_tablespace=field.db_tablespace,\n+                db_constraint=field.remote_field.db_constraint,\n+                on_delete=CASCADE,\n+            ),\n+        },\n+    )\n \n \n class ManyToManyField(RelatedField):\n@@ -1162,31 +1302,45 @@ class ManyToManyField(RelatedField):\n \n     description = _(\"Many-to-many relationship\")\n \n-    def __init__(self, to, related_name=None, related_query_name=None,\n-                 limit_choices_to=None, symmetrical=None, through=None,\n-                 through_fields=None, db_constraint=True, db_table=None,\n-                 swappable=True, **kwargs):\n+    def __init__(\n+        self,\n+        to,\n+        related_name=None,\n+        related_query_name=None,\n+        limit_choices_to=None,\n+        symmetrical=None,\n+        through=None,\n+        through_fields=None,\n+        db_constraint=True,\n+        db_table=None,\n+        swappable=True,\n+        **kwargs,\n+    ):\n         try:\n             to._meta\n         except AttributeError:\n             if not isinstance(to, str):\n                 raise TypeError(\n-                    '%s(%r) is invalid. First parameter to ManyToManyField '\n-                    'must be either a model, a model name, or the string %r' % (\n-                        self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT,\n+                    \"%s(%r) is invalid. First parameter to ManyToManyField \"\n+                    \"must be either a model, a model name, or the string %r\"\n+                    % (\n+                        self.__class__.__name__,\n+                        to,\n+                        RECURSIVE_RELATIONSHIP_CONSTANT,\n                     )\n                 )\n \n         if symmetrical is None:\n-            symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n+            symmetrical = to == RECURSIVE_RELATIONSHIP_CONSTANT\n \n         if through is not None and db_table is not None:\n             raise ValueError(\n-                'Cannot specify a db_table if an intermediary model is used.'\n+                \"Cannot specify a db_table if an intermediary model is used.\"\n             )\n \n-        kwargs['rel'] = self.rel_class(\n-            self, to,\n+        kwargs[\"rel\"] = self.rel_class(\n+            self,\n+            to,\n             related_name=related_name,\n             related_query_name=related_query_name,\n             limit_choices_to=limit_choices_to,\n@@ -1195,7 +1349,7 @@ class ManyToManyField(RelatedField):\n             through_fields=through_fields,\n             db_constraint=db_constraint,\n         )\n-        self.has_null_arg = 'null' in kwargs\n+        self.has_null_arg = \"null\" in kwargs\n \n         super().__init__(\n             related_name=related_name,\n@@ -1213,6 +1367,7 @@ class ManyToManyField(RelatedField):\n             *self._check_unique(**kwargs),\n             *self._check_relationship_model(**kwargs),\n             *self._check_ignored_options(**kwargs),\n+            *self._check_symmetrical(**kwargs),\n             *self._check_table_uniqueness(**kwargs),\n         ]\n \n@@ -1220,9 +1375,9 @@ class ManyToManyField(RelatedField):\n         if self.unique:\n             return [\n                 checks.Error(\n-                    'ManyToManyFields cannot be unique.',\n+                    \"ManyToManyFields cannot be unique.\",\n                     obj=self,\n-                    id='fields.E330',\n+                    id=\"fields.E330\",\n                 )\n             ]\n         return []\n@@ -1233,50 +1388,88 @@ class ManyToManyField(RelatedField):\n         if self.has_null_arg:\n             warnings.append(\n                 checks.Warning(\n-                    'null has no effect on ManyToManyField.',\n+                    \"null has no effect on ManyToManyField.\",\n                     obj=self,\n-                    id='fields.W340',\n+                    id=\"fields.W340\",\n                 )\n             )\n \n         if self._validators:\n             warnings.append(\n                 checks.Warning(\n-                    'ManyToManyField does not support validators.',\n+                    \"ManyToManyField does not support validators.\",\n                     obj=self,\n-                    id='fields.W341',\n+                    id=\"fields.W341\",\n                 )\n             )\n-        if (self.remote_field.limit_choices_to and self.remote_field.through and\n-                not self.remote_field.through._meta.auto_created):\n+        if (\n+            self.remote_field.limit_choices_to\n+            and self.remote_field.through\n+            and not self.remote_field.through._meta.auto_created\n+        ):\n             warnings.append(\n                 checks.Warning(\n-                    'limit_choices_to has no effect on ManyToManyField '\n-                    'with a through model.',\n+                    \"limit_choices_to has no effect on ManyToManyField \"\n+                    \"with a through model.\",\n                     obj=self,\n-                    id='fields.W343',\n+                    id=\"fields.W343\",\n                 )\n             )\n \n         return warnings\n \n+    def _check_symmetrical(self, from_model=None, **kwargs):\n+        errors = []\n+        if from_model is not None:\n+            # Check if the relationship is self-referential\n+            is_self_referential = (\n+                self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT\n+                or (\n+                    isinstance(self.remote_field.model, str)\n+                    and self.remote_field.model == from_model._meta.object_name\n+                )\n+                or (\n+                    not isinstance(self.remote_field.model, str)\n+                    and hasattr(self.remote_field.model, \"_meta\")\n+                    and self.remote_field.model._meta.object_name\n+                    == from_model._meta.object_name\n+                )\n+            )\n+            if (\n+                self.remote_field.symmetrical\n+                and self.remote_field.related_name\n+                and is_self_referential\n+            ):\n+                errors.append(\n+                    checks.Error(\n+                        \"ManyToManyField cannot set related_name on a symmetrical relationship.\",\n+                        obj=self,\n+                        id=\"fields.E342\",\n+                    )\n+                )\n+        return errors\n+\n     def _check_relationship_model(self, from_model=None, **kwargs):\n-        if hasattr(self.remote_field.through, '_meta'):\n+        if hasattr(self.remote_field.through, \"_meta\"):\n             qualified_model_name = \"%s.%s\" % (\n-                self.remote_field.through._meta.app_label, self.remote_field.through.__name__)\n+                self.remote_field.through._meta.app_label,\n+                self.remote_field.through.__name__,\n+            )\n         else:\n             qualified_model_name = self.remote_field.through\n \n         errors = []\n \n-        if self.remote_field.through not in self.opts.apps.get_models(include_auto_created=True):\n+        if self.remote_field.through not in self.opts.apps.get_models(\n+            include_auto_created=True\n+        ):\n             # The relationship model is not installed.\n             errors.append(\n                 checks.Error(\n                     \"Field specifies a many-to-many relation through model \"\n                     \"'%s', which has not been installed.\" % qualified_model_name,\n                     obj=self,\n-                    id='fields.E331',\n+                    id=\"fields.E331\",\n                 )\n             )\n \n@@ -1298,7 +1491,7 @@ class ManyToManyField(RelatedField):\n             # Count foreign keys in intermediate model\n             if self_referential:\n                 seen_self = sum(\n-                    from_model == getattr(field.remote_field, 'model', None)\n+                    from_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n \n@@ -1309,41 +1502,46 @@ class ManyToManyField(RelatedField):\n                             \"'%s', but it has more than two foreign keys \"\n                             \"to '%s', which is ambiguous. You must specify \"\n                             \"which two foreign keys Django should use via the \"\n-                            \"through_fields keyword argument.\" % (self, from_model_name),\n+                            \"through_fields keyword argument.\"\n+                            % (self, from_model_name),\n                             hint=\"Use through_fields to specify which two foreign keys Django should use.\",\n                             obj=self.remote_field.through,\n-                            id='fields.E333',\n+                            id=\"fields.E333\",\n                         )\n                     )\n \n             else:\n                 # Count foreign keys in relationship model\n                 seen_from = sum(\n-                    from_model == getattr(field.remote_field, 'model', None)\n+                    from_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n                 seen_to = sum(\n-                    to_model == getattr(field.remote_field, 'model', None)\n+                    to_model == getattr(field.remote_field, \"model\", None)\n                     for field in self.remote_field.through._meta.fields\n                 )\n \n                 if seen_from > 1 and not self.remote_field.through_fields:\n                     errors.append(\n                         checks.Error(\n-                            (\"The model is used as an intermediate model by \"\n-                             \"'%s', but it has more than one foreign key \"\n-                             \"from '%s', which is ambiguous. You must specify \"\n-                             \"which foreign key Django should use via the \"\n-                             \"through_fields keyword argument.\") % (self, from_model_name),\n+                            (\n+                                \"The model is used as an intermediate model by \"\n+                                \"'%s', but it has more than one foreign key \"\n+                                \"from '%s', which is ambiguous. You must specify \"\n+                                \"which foreign key Django should use via the \"\n+                                \"through_fields keyword argument.\"\n+                            )\n+                            % (self, from_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n+                                \"If you want to create a recursive relationship, \"\n                                 'use ManyToManyField(\"%s\", through=\"%s\").'\n-                            ) % (\n+                            )\n+                            % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n                             ),\n                             obj=self,\n-                            id='fields.E334',\n+                            id=\"fields.E334\",\n                         )\n                     )\n \n@@ -1356,14 +1554,15 @@ class ManyToManyField(RelatedField):\n                             \"which foreign key Django should use via the \"\n                             \"through_fields keyword argument.\" % (self, to_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n+                                \"If you want to create a recursive relationship, \"\n                                 'use ManyToManyField(\"%s\", through=\"%s\").'\n-                            ) % (\n+                            )\n+                            % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n                             ),\n                             obj=self,\n-                            id='fields.E335',\n+                            id=\"fields.E335\",\n                         )\n                     )\n \n@@ -1371,11 +1570,10 @@ class ManyToManyField(RelatedField):\n                     errors.append(\n                         checks.Error(\n                             \"The model is used as an intermediate model by \"\n-                            \"'%s', but it does not have a foreign key to '%s' or '%s'.\" % (\n-                                self, from_model_name, to_model_name\n-                            ),\n+                            \"'%s', but it does not have a foreign key to '%s' or '%s'.\"\n+                            % (self, from_model_name, to_model_name),\n                             obj=self.remote_field.through,\n-                            id='fields.E336',\n+                            id=\"fields.E336\",\n                         )\n                     )\n \n@@ -1383,8 +1581,11 @@ class ManyToManyField(RelatedField):\n         if self.remote_field.through_fields is not None:\n             # Validate that we're given an iterable of at least two items\n             # and that none of them is \"falsy\".\n-            if not (len(self.remote_field.through_fields) >= 2 and\n-                    self.remote_field.through_fields[0] and self.remote_field.through_fields[1]):\n+            if not (\n+                len(self.remote_field.through_fields) >= 2\n+                and self.remote_field.through_fields[0]\n+                and self.remote_field.through_fields[1]\n+            ):\n                 errors.append(\n                     checks.Error(\n                         \"Field specifies 'through_fields' but does not provide \"\n@@ -1392,7 +1593,7 @@ class ManyToManyField(RelatedField):\n                         \"for the relation through model '%s'.\" % qualified_model_name,\n                         hint=\"Make sure you specify 'through_fields' as through_fields=('field1', 'field2')\",\n                         obj=self,\n-                        id='fields.E337',\n+                        id=\"fields.E337\",\n                     )\n                 )\n \n@@ -1406,20 +1607,33 @@ class ManyToManyField(RelatedField):\n                     \"where the field is attached to.\"\n                 )\n \n-                source, through, target = from_model, self.remote_field.through, self.remote_field.model\n-                source_field_name, target_field_name = self.remote_field.through_fields[:2]\n-\n-                for field_name, related_model in ((source_field_name, source),\n-                                                  (target_field_name, target)):\n-\n+                source, through, target = (\n+                    from_model,\n+                    self.remote_field.through,\n+                    self.remote_field.model,\n+                )\n+                source_field_name, target_field_name = self.remote_field.through_fields[\n+                    :2\n+                ]\n+\n+                for field_name, related_model in (\n+                    (source_field_name, source),\n+                    (target_field_name, target),\n+                ):\n                     possible_field_names = []\n                     for f in through._meta.fields:\n-                        if hasattr(f, 'remote_field') and getattr(f.remote_field, 'model', None) == related_model:\n+                        if (\n+                            hasattr(f, \"remote_field\")\n+                            and getattr(f.remote_field, \"model\", None) == related_model\n+                        ):\n                             possible_field_names.append(f.name)\n                     if possible_field_names:\n-                        hint = \"Did you mean one of the following foreign keys to '%s': %s?\" % (\n-                            related_model._meta.object_name,\n-                            ', '.join(possible_field_names),\n+                        hint = (\n+                            \"Did you mean one of the following foreign keys to '%s': %s?\"\n+                            % (\n+                                related_model._meta.object_name,\n+                                \", \".join(possible_field_names),\n+                            )\n                         )\n                     else:\n                         hint = None\n@@ -1433,28 +1647,36 @@ class ManyToManyField(RelatedField):\n                                 % (qualified_model_name, field_name),\n                                 hint=hint,\n                                 obj=self,\n-                                id='fields.E338',\n+                                id=\"fields.E338\",\n                             )\n                         )\n                     else:\n-                        if not (hasattr(field, 'remote_field') and\n-                                getattr(field.remote_field, 'model', None) == related_model):\n+                        if not (\n+                            hasattr(field, \"remote_field\")\n+                            and getattr(field.remote_field, \"model\", None)\n+                            == related_model\n+                        ):\n                             errors.append(\n                                 checks.Error(\n-                                    \"'%s.%s' is not a foreign key to '%s'.\" % (\n-                                        through._meta.object_name, field_name,\n+                                    \"'%s.%s' is not a foreign key to '%s'.\"\n+                                    % (\n+                                        through._meta.object_name,\n+                                        field_name,\n                                         related_model._meta.object_name,\n                                     ),\n                                     hint=hint,\n                                     obj=self,\n-                                    id='fields.E339',\n+                                    id=\"fields.E339\",\n                                 )\n                             )\n \n         return errors\n \n     def _check_table_uniqueness(self, **kwargs):\n-        if isinstance(self.remote_field.through, str) or not self.remote_field.through._meta.managed:\n+        if (\n+            isinstance(self.remote_field.through, str)\n+            or not self.remote_field.through._meta.managed\n+        ):\n             return []\n         registered_tables = {\n             model._meta.db_table: model\n@@ -1465,25 +1687,31 @@ class ManyToManyField(RelatedField):\n         model = registered_tables.get(m2m_db_table)\n         # The second condition allows multiple m2m relations on a model if\n         # some point to a through model that proxies another through model.\n-        if model and model._meta.concrete_model != self.remote_field.through._meta.concrete_model:\n+        if (\n+            model\n+            and model._meta.concrete_model\n+            != self.remote_field.through._meta.concrete_model\n+        ):\n             if model._meta.auto_created:\n+\n                 def _get_field_name(model):\n                     for field in model._meta.auto_created._meta.many_to_many:\n                         if field.remote_field.through is model:\n                             return field.name\n+\n                 opts = model._meta.auto_created._meta\n-                clashing_obj = '%s.%s' % (opts.label, _get_field_name(model))\n+                clashing_obj = \"%s.%s\" % (opts.label, _get_field_name(model))\n             else:\n                 clashing_obj = model._meta.label\n             if settings.DATABASE_ROUTERS:\n-                error_class, error_id = checks.Warning, 'fields.W344'\n+                error_class, error_id = checks.Warning, \"fields.W344\"\n                 error_hint = (\n-                    'You have configured settings.DATABASE_ROUTERS. Verify '\n-                    'that the table of %r is correctly routed to a separate '\n-                    'database.' % clashing_obj\n+                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n+                    \"that the table of %r is correctly routed to a separate \"\n+                    \"database.\" % clashing_obj\n                 )\n             else:\n-                error_class, error_id = checks.Error, 'fields.E340'\n+                error_class, error_id = checks.Error, \"fields.E340\"\n                 error_hint = None\n             return [\n                 error_class(\n@@ -1500,34 +1728,34 @@ class ManyToManyField(RelatedField):\n         name, path, args, kwargs = super().deconstruct()\n         # Handle the simpler arguments.\n         if self.db_table is not None:\n-            kwargs['db_table'] = self.db_table\n+            kwargs[\"db_table\"] = self.db_table\n         if self.remote_field.db_constraint is not True:\n-            kwargs['db_constraint'] = self.remote_field.db_constraint\n+            kwargs[\"db_constraint\"] = self.remote_field.db_constraint\n         # Rel needs more work.\n         if isinstance(self.remote_field.model, str):\n-            kwargs['to'] = self.remote_field.model\n+            kwargs[\"to\"] = self.remote_field.model\n         else:\n-            kwargs['to'] = self.remote_field.model._meta.label\n-        if getattr(self.remote_field, 'through', None) is not None:\n+            kwargs[\"to\"] = self.remote_field.model._meta.label\n+        if getattr(self.remote_field, \"through\", None) is not None:\n             if isinstance(self.remote_field.through, str):\n-                kwargs['through'] = self.remote_field.through\n+                kwargs[\"through\"] = self.remote_field.through\n             elif not self.remote_field.through._meta.auto_created:\n-                kwargs['through'] = self.remote_field.through._meta.label\n+                kwargs[\"through\"] = self.remote_field.through._meta.label\n         # If swappable is True, then see if we're actually pointing to the target\n         # of a swap.\n         swappable_setting = self.swappable_setting\n         if swappable_setting is not None:\n             # If it's already a settings reference, error.\n-            if hasattr(kwargs['to'], \"setting_name\"):\n-                if kwargs['to'].setting_name != swappable_setting:\n+            if hasattr(kwargs[\"to\"], \"setting_name\"):\n+                if kwargs[\"to\"].setting_name != swappable_setting:\n                     raise ValueError(\n                         \"Cannot deconstruct a ManyToManyField pointing to a \"\n                         \"model that is swapped in place of more than one model \"\n-                        \"(%s and %s)\" % (kwargs['to'].setting_name, swappable_setting)\n+                        \"(%s and %s)\" % (kwargs[\"to\"].setting_name, swappable_setting)\n                     )\n \n-            kwargs['to'] = SettingsReference(\n-                kwargs['to'],\n+            kwargs[\"to\"] = SettingsReference(\n+                kwargs[\"to\"],\n                 swappable_setting,\n             )\n         return name, path, args, kwargs\n@@ -1574,7 +1802,7 @@ class ManyToManyField(RelatedField):\n         elif self.db_table:\n             return self.db_table\n         else:\n-            m2m_table_name = '%s_%s' % (utils.strip_quotes(opts.db_table), self.name)\n+            m2m_table_name = \"%s_%s\" % (utils.strip_quotes(opts.db_table), self.name)\n             return utils.truncate_name(m2m_table_name, connection.ops.max_name_length())\n \n     def _get_m2m_attr(self, related, attr):\n@@ -1582,7 +1810,7 @@ class ManyToManyField(RelatedField):\n         Function that can be curried to provide the source accessor or DB\n         column name for the m2m table.\n         \"\"\"\n-        cache_attr = '_m2m_%s_cache' % attr\n+        cache_attr = \"_m2m_%s_cache\" % attr\n         if hasattr(self, cache_attr):\n             return getattr(self, cache_attr)\n         if self.remote_field.through_fields is not None:\n@@ -1590,8 +1818,11 @@ class ManyToManyField(RelatedField):\n         else:\n             link_field_name = None\n         for f in self.remote_field.through._meta.fields:\n-            if (f.is_relation and f.remote_field.model == related.related_model and\n-                    (link_field_name is None or link_field_name == f.name)):\n+            if (\n+                f.is_relation\n+                and f.remote_field.model == related.related_model\n+                and (link_field_name is None or link_field_name == f.name)\n+            ):\n                 setattr(self, cache_attr, getattr(f, attr))\n                 return getattr(self, cache_attr)\n \n@@ -1600,7 +1831,7 @@ class ManyToManyField(RelatedField):\n         Function that can be curried to provide the related accessor or DB\n         column name for the m2m table.\n         \"\"\"\n-        cache_attr = '_m2m_reverse_%s_cache' % attr\n+        cache_attr = \"_m2m_reverse_%s_cache\" % attr\n         if hasattr(self, cache_attr):\n             return getattr(self, cache_attr)\n         found = False\n@@ -1633,8 +1864,8 @@ class ManyToManyField(RelatedField):\n         # automatically. The funky name reduces the chance of an accidental\n         # clash.\n         if self.remote_field.symmetrical and (\n-            self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT or\n-            self.remote_field.model == cls._meta.object_name\n+            self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT\n+            or self.remote_field.model == cls._meta.object_name\n         ):\n             self.remote_field.related_name = \"%s_rel_+\" % name\n         elif self.remote_field.is_hidden():\n@@ -1642,7 +1873,7 @@ class ManyToManyField(RelatedField):\n             # related_name with one generated from the m2m field name. Django\n             # still uses backwards relations internally and we need to avoid\n             # clashes between multiple m2m fields with related_name == '+'.\n-            self.remote_field.related_name = '_%s_%s_%s_+' % (\n+            self.remote_field.related_name = \"_%s_%s_%s_+\" % (\n                 cls._meta.app_label,\n                 cls.__name__.lower(),\n                 name,\n@@ -1656,11 +1887,17 @@ class ManyToManyField(RelatedField):\n         #  3) The class owning the m2m field has been swapped out.\n         if not cls._meta.abstract:\n             if self.remote_field.through:\n+\n                 def resolve_through_model(_, model, field):\n                     field.remote_field.through = model\n-                lazy_related_operation(resolve_through_model, cls, self.remote_field.through, field=self)\n+\n+                lazy_related_operation(\n+                    resolve_through_model, cls, self.remote_field.through, field=self\n+                )\n             elif not cls._meta.swapped:\n-                self.remote_field.through = create_many_to_many_intermediary_model(self, cls)\n+                self.remote_field.through = create_many_to_many_intermediary_model(\n+                    self, cls\n+                )\n \n         # Add the descriptor for the m2m relation.\n         setattr(cls, self.name, ManyToManyDescriptor(self.remote_field, reverse=False))\n@@ -1671,19 +1908,30 @@ class ManyToManyField(RelatedField):\n     def contribute_to_related_class(self, cls, related):\n         # Internal M2Ms (i.e., those with a related name ending with '+')\n         # and swapped models don't get a related descriptor.\n-        if not self.remote_field.is_hidden() and not related.related_model._meta.swapped:\n-            setattr(cls, related.get_accessor_name(), ManyToManyDescriptor(self.remote_field, reverse=True))\n+        if (\n+            not self.remote_field.is_hidden()\n+            and not related.related_model._meta.swapped\n+        ):\n+            setattr(\n+                cls,\n+                related.get_accessor_name(),\n+                ManyToManyDescriptor(self.remote_field, reverse=True),\n+            )\n \n         # Set up the accessors for the column names on the m2m table.\n-        self.m2m_column_name = partial(self._get_m2m_attr, related, 'column')\n-        self.m2m_reverse_name = partial(self._get_m2m_reverse_attr, related, 'column')\n+        self.m2m_column_name = partial(self._get_m2m_attr, related, \"column\")\n+        self.m2m_reverse_name = partial(self._get_m2m_reverse_attr, related, \"column\")\n \n-        self.m2m_field_name = partial(self._get_m2m_attr, related, 'name')\n-        self.m2m_reverse_field_name = partial(self._get_m2m_reverse_attr, related, 'name')\n+        self.m2m_field_name = partial(self._get_m2m_attr, related, \"name\")\n+        self.m2m_reverse_field_name = partial(\n+            self._get_m2m_reverse_attr, related, \"name\"\n+        )\n \n-        get_m2m_rel = partial(self._get_m2m_attr, related, 'remote_field')\n+        get_m2m_rel = partial(self._get_m2m_attr, related, \"remote_field\")\n         self.m2m_target_field_name = lambda: get_m2m_rel().field_name\n-        get_m2m_reverse_rel = partial(self._get_m2m_reverse_attr, related, 'remote_field')\n+        get_m2m_reverse_rel = partial(\n+            self._get_m2m_reverse_attr, related, \"remote_field\"\n+        )\n         self.m2m_reverse_target_field_name = lambda: get_m2m_reverse_rel().field_name\n \n     def set_attributes_from_rel(self):\n@@ -1697,17 +1945,17 @@ class ManyToManyField(RelatedField):\n \n     def formfield(self, *, using=None, **kwargs):\n         defaults = {\n-            'form_class': forms.ModelMultipleChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n+            \"form_class\": forms.ModelMultipleChoiceField,\n+            \"queryset\": self.remote_field.model._default_manager.using(using),\n             **kwargs,\n         }\n         # If initial is passed in, it's a list of related objects, but the\n         # MultipleChoiceField takes a list of IDs.\n-        if defaults.get('initial') is not None:\n-            initial = defaults['initial']\n+        if defaults.get(\"initial\") is not None:\n+            initial = defaults[\"initial\"]\n             if callable(initial):\n                 initial = initial()\n-            defaults['initial'] = [i.pk for i in initial]\n+            defaults[\"initial\"] = [i.pk for i in initial]\n         return super().formfield(**defaults)\n \n     def db_check(self, connection):\n"}
{"instance_id": "django__django-14752", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..b457b160dc 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -6,6 +6,7 @@ from django.views.generic.list import BaseListView\n \n class AutocompleteJsonView(BaseListView):\n     \"\"\"Handle AutocompleteWidget's AJAX requests for data.\"\"\"\n+\n     paginate_by = 20\n     admin_site = None\n \n@@ -17,20 +18,31 @@ class AutocompleteJsonView(BaseListView):\n             pagination: {more: true}\n         }\n         \"\"\"\n-        self.term, self.model_admin, self.source_field, to_field_name = self.process_request(request)\n+        self.term, self.model_admin, self.source_field, to_field_name = (\n+            self.process_request(request)\n+        )\n \n         if not self.has_perm(request):\n             raise PermissionDenied\n \n         self.object_list = self.get_queryset()\n         context = self.get_context_data()\n-        return JsonResponse({\n-            'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n-            ],\n-            'pagination': {'more': context['page_obj'].has_next()},\n-        })\n+        return JsonResponse(\n+            {\n+                \"results\": [\n+                    self.serialize_result(obj, to_field_name)\n+                    for obj in context[\"object_list\"]\n+                ],\n+                \"pagination\": {\"more\": context[\"page_obj\"].has_next()},\n+            }\n+        )\n+\n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"\n+        Convert the provided model object to a dictionary that is added to the\n+        results list.\n+        \"\"\"\n+        return {\"id\": str(getattr(obj, to_field_name)), \"text\": str(obj)}\n \n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n@@ -40,7 +52,9 @@ class AutocompleteJsonView(BaseListView):\n         \"\"\"Return queryset based on ModelAdmin.get_search_results().\"\"\"\n         qs = self.model_admin.get_queryset(self.request)\n         qs = qs.complex_filter(self.source_field.get_limit_choices_to())\n-        qs, search_use_distinct = self.model_admin.get_search_results(self.request, qs, self.term)\n+        qs, search_use_distinct = self.model_admin.get_search_results(\n+            self.request, qs, self.term\n+        )\n         if search_use_distinct:\n             qs = qs.distinct()\n         return qs\n@@ -56,11 +70,11 @@ class AutocompleteJsonView(BaseListView):\n         Raise Http404 if the target model admin is not configured properly with\n         search_fields.\n         \"\"\"\n-        term = request.GET.get('term', '')\n+        term = request.GET.get(\"term\", \"\")\n         try:\n-            app_label = request.GET['app_label']\n-            model_name = request.GET['model_name']\n-            field_name = request.GET['field_name']\n+            app_label = request.GET[\"app_label\"]\n+            model_name = request.GET[\"model_name\"]\n+            field_name = request.GET[\"field_name\"]\n         except KeyError as e:\n             raise PermissionDenied from e\n \n@@ -86,11 +100,13 @@ class AutocompleteJsonView(BaseListView):\n         # Validate suitability of objects.\n         if not model_admin.get_search_fields(request):\n             raise Http404(\n-                '%s must have search_fields for the autocomplete_view.' %\n-                type(model_admin).__qualname__\n+                \"%s must have search_fields for the autocomplete_view.\"\n+                % type(model_admin).__qualname__\n             )\n \n-        to_field_name = getattr(source_field.remote_field, 'field_name', remote_model._meta.pk.attname)\n+        to_field_name = getattr(\n+            source_field.remote_field, \"field_name\", remote_model._meta.pk.attname\n+        )\n         to_field_name = remote_model._meta.get_field(to_field_name).attname\n         if not model_admin.to_field_allowed(request, to_field_name):\n             raise PermissionDenied\n"}
{"instance_id": "django__django-14787", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..aa15c21d8d 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -6,7 +6,9 @@ from functools import partial, update_wrapper, wraps\n class classonlymethod(classmethod):\n     def __get__(self, instance, cls=None):\n         if instance is not None:\n-            raise AttributeError(\"This method is available only on the class, not on instances.\")\n+            raise AttributeError(\n+                \"This method is available only on the class, not on instances.\"\n+            )\n         return super().__get__(instance, cls)\n \n \n@@ -16,6 +18,7 @@ def _update_method_wrapper(_wrapper, decorator):\n     @decorator\n     def dummy(*args, **kwargs):\n         pass\n+\n     update_wrapper(_wrapper, dummy)\n \n \n@@ -24,7 +27,7 @@ def _multi_decorate(decorators, method):\n     Decorate `method` with one or more function decorators. `decorators` can be\n     a single decorator or an iterable of decorators.\n     \"\"\"\n-    if hasattr(decorators, '__iter__'):\n+    if hasattr(decorators, \"__iter__\"):\n         # Apply a list/tuple of decorators if 'decorators' is one. Decorator\n         # functions are applied so that the call order is the same as the\n         # order in which they appear in the iterable.\n@@ -38,6 +41,7 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n@@ -50,10 +54,11 @@ def _multi_decorate(decorators, method):\n     return _wrapper\n \n \n-def method_decorator(decorator, name=''):\n+def method_decorator(decorator, name=\"\"):\n     \"\"\"\n     Convert a function decorator into a method decorator\n     \"\"\"\n+\n     # 'obj' can be a class or a function. If 'obj' is a function at the time it\n     # is passed to _dec,  it will eventually be a method of the class it is\n     # defined on. If 'obj' is a class, the 'name' is required to be the name\n@@ -78,11 +83,11 @@ def method_decorator(decorator, name=''):\n \n     # Don't worry about making _dec look similar to a list/tuple as it's rather\n     # meaningless.\n-    if not hasattr(decorator, '__iter__'):\n+    if not hasattr(decorator, \"__iter__\"):\n         update_wrapper(_dec, decorator)\n     # Change the name to aid debugging.\n-    obj = decorator if hasattr(decorator, '__name__') else decorator.__class__\n-    _dec.__name__ = 'method_decorator(%s)' % obj.__name__\n+    obj = decorator if hasattr(decorator, \"__name__\") else decorator.__class__\n+    _dec.__name__ = \"method_decorator(%s)\" % obj.__name__\n     return _dec\n \n \n@@ -118,37 +123,44 @@ def make_middleware_decorator(middleware_class):\n \n             @wraps(view_func)\n             def _wrapped_view(request, *args, **kwargs):\n-                if hasattr(middleware, 'process_request'):\n+                if hasattr(middleware, \"process_request\"):\n                     result = middleware.process_request(request)\n                     if result is not None:\n                         return result\n-                if hasattr(middleware, 'process_view'):\n+                if hasattr(middleware, \"process_view\"):\n                     result = middleware.process_view(request, view_func, args, kwargs)\n                     if result is not None:\n                         return result\n                 try:\n                     response = view_func(request, *args, **kwargs)\n                 except Exception as e:\n-                    if hasattr(middleware, 'process_exception'):\n+                    if hasattr(middleware, \"process_exception\"):\n                         result = middleware.process_exception(request, e)\n                         if result is not None:\n                             return result\n                     raise\n-                if hasattr(response, 'render') and callable(response.render):\n-                    if hasattr(middleware, 'process_template_response'):\n-                        response = middleware.process_template_response(request, response)\n+                if hasattr(response, \"render\") and callable(response.render):\n+                    if hasattr(middleware, \"process_template_response\"):\n+                        response = middleware.process_template_response(\n+                            request, response\n+                        )\n                     # Defer running of process_response until after the template\n                     # has been rendered:\n-                    if hasattr(middleware, 'process_response'):\n+                    if hasattr(middleware, \"process_response\"):\n+\n                         def callback(response):\n                             return middleware.process_response(request, response)\n+\n                         response.add_post_render_callback(callback)\n                 else:\n-                    if hasattr(middleware, 'process_response'):\n+                    if hasattr(middleware, \"process_response\"):\n                         return middleware.process_response(request, response)\n                 return response\n+\n             return _wrapped_view\n+\n         return _decorator\n+\n     return _make_decorator\n \n \n"}
{"instance_id": "django__django-14855", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..8a89c55644 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -2,12 +2,18 @@ import json\n \n from django import forms\n from django.contrib.admin.utils import (\n-    display_for_field, flatten_fieldsets, help_text_for_field, label_for_field,\n-    lookup_field, quote,\n+    display_for_field,\n+    flatten_fieldsets,\n+    help_text_for_field,\n+    label_for_field,\n+    lookup_field,\n+    quote,\n )\n from django.core.exceptions import ObjectDoesNotExist\n from django.db.models.fields.related import (\n-    ForeignObjectRel, ManyToManyRel, OneToOneField,\n+    ForeignObjectRel,\n+    ManyToManyRel,\n+    OneToOneField,\n )\n from django.forms.utils import flatatt\n from django.template.defaultfilters import capfirst, linebreaksbr\n@@ -16,29 +22,36 @@ from django.utils.html import conditional_escape, format_html\n from django.utils.safestring import mark_safe\n from django.utils.translation import gettext, gettext_lazy as _\n \n-ACTION_CHECKBOX_NAME = '_selected_action'\n+ACTION_CHECKBOX_NAME = \"_selected_action\"\n \n \n class ActionForm(forms.Form):\n-    action = forms.ChoiceField(label=_('Action:'))\n+    action = forms.ChoiceField(label=_(\"Action:\"))\n     select_across = forms.BooleanField(\n-        label='',\n+        label=\"\",\n         required=False,\n         initial=0,\n-        widget=forms.HiddenInput({'class': 'select-across'}),\n+        widget=forms.HiddenInput({\"class\": \"select-across\"}),\n     )\n \n \n-checkbox = forms.CheckboxInput({'class': 'action-select'}, lambda value: False)\n+checkbox = forms.CheckboxInput({\"class\": \"action-select\"}, lambda value: False)\n \n \n class AdminForm:\n-    def __init__(self, form, fieldsets, prepopulated_fields, readonly_fields=None, model_admin=None):\n+    def __init__(\n+        self,\n+        form,\n+        fieldsets,\n+        prepopulated_fields,\n+        readonly_fields=None,\n+        model_admin=None,\n+    ):\n         self.form, self.fieldsets = form, fieldsets\n-        self.prepopulated_fields = [{\n-            'field': form[field_name],\n-            'dependencies': [form[f] for f in dependencies]\n-        } for field_name, dependencies in prepopulated_fields.items()]\n+        self.prepopulated_fields = [\n+            {\"field\": form[field_name], \"dependencies\": [form[f] for f in dependencies]}\n+            for field_name, dependencies in prepopulated_fields.items()\n+        ]\n         self.model_admin = model_admin\n         if readonly_fields is None:\n             readonly_fields = ()\n@@ -46,18 +59,19 @@ class AdminForm:\n \n     def __repr__(self):\n         return (\n-            f'<{self.__class__.__qualname__}: '\n-            f'form={self.form.__class__.__qualname__} '\n-            f'fieldsets={self.fieldsets!r}>'\n+            f\"<{self.__class__.__qualname__}: \"\n+            f\"form={self.form.__class__.__qualname__} \"\n+            f\"fieldsets={self.fieldsets!r}>\"\n         )\n \n     def __iter__(self):\n         for name, options in self.fieldsets:\n             yield Fieldset(\n-                self.form, name,\n+                self.form,\n+                name,\n                 readonly_fields=self.readonly_fields,\n                 model_admin=self.model_admin,\n-                **options\n+                **options,\n             )\n \n     @property\n@@ -77,24 +91,34 @@ class AdminForm:\n \n \n class Fieldset:\n-    def __init__(self, form, name=None, readonly_fields=(), fields=(), classes=(),\n-                 description=None, model_admin=None):\n+    def __init__(\n+        self,\n+        form,\n+        name=None,\n+        readonly_fields=(),\n+        fields=(),\n+        classes=(),\n+        description=None,\n+        model_admin=None,\n+    ):\n         self.form = form\n         self.name, self.fields = name, fields\n-        self.classes = ' '.join(classes)\n+        self.classes = \" \".join(classes)\n         self.description = description\n         self.model_admin = model_admin\n         self.readonly_fields = readonly_fields\n \n     @property\n     def media(self):\n-        if 'collapse' in self.classes:\n-            return forms.Media(js=['admin/js/collapse.js'])\n+        if \"collapse\" in self.classes:\n+            return forms.Media(js=[\"admin/js/collapse.js\"])\n         return forms.Media()\n \n     def __iter__(self):\n         for field in self.fields:\n-            yield Fieldline(self.form, field, self.readonly_fields, model_admin=self.model_admin)\n+            yield Fieldline(\n+                self.form, field, self.readonly_fields, model_admin=self.model_admin\n+            )\n \n \n class Fieldline:\n@@ -116,15 +140,19 @@ class Fieldline:\n     def __iter__(self):\n         for i, field in enumerate(self.fields):\n             if field in self.readonly_fields:\n-                yield AdminReadonlyField(self.form, field, is_first=(i == 0), model_admin=self.model_admin)\n+                yield AdminReadonlyField(\n+                    self.form, field, is_first=(i == 0), model_admin=self.model_admin\n+                )\n             else:\n                 yield AdminField(self.form, field, is_first=(i == 0))\n \n     def errors(self):\n         return mark_safe(\n-            '\\n'.join(\n-                self.form[f].errors.as_ul() for f in self.fields if f not in self.readonly_fields\n-            ).strip('\\n')\n+            \"\\n\".join(\n+                self.form[f].errors.as_ul()\n+                for f in self.fields\n+                if f not in self.readonly_fields\n+            ).strip(\"\\n\")\n         )\n \n \n@@ -139,18 +167,19 @@ class AdminField:\n         classes = []\n         contents = conditional_escape(self.field.label)\n         if self.is_checkbox:\n-            classes.append('vCheckboxLabel')\n+            classes.append(\"vCheckboxLabel\")\n \n         if self.field.field.required:\n-            classes.append('required')\n+            classes.append(\"required\")\n         if not self.is_first:\n-            classes.append('inline')\n-        attrs = {'class': ' '.join(classes)} if classes else {}\n+            classes.append(\"inline\")\n+        attrs = {\"class\": \" \".join(classes)} if classes else {}\n         # checkboxes should not have a label suffix as the checkbox appears\n         # to the left of the label.\n         return self.field.label_tag(\n-            contents=mark_safe(contents), attrs=attrs,\n-            label_suffix='' if self.is_checkbox else None,\n+            contents=mark_safe(contents),\n+            attrs=attrs,\n+            label_suffix=\"\" if self.is_checkbox else None,\n         )\n \n     def errors(self):\n@@ -163,7 +192,7 @@ class AdminReadonlyField:\n         # {{ field.name }} must be a useful class name to identify the field.\n         # For convenience, store other field-related data here too.\n         if callable(field):\n-            class_name = field.__name__ if field.__name__ != '<lambda>' else ''\n+            class_name = field.__name__ if field.__name__ != \"<lambda>\" else \"\"\n         else:\n             class_name = field\n \n@@ -183,11 +212,11 @@ class AdminReadonlyField:\n             is_hidden = False\n \n         self.field = {\n-            'name': class_name,\n-            'label': label,\n-            'help_text': help_text,\n-            'field': field,\n-            'is_hidden': is_hidden,\n+            \"name\": class_name,\n+            \"label\": label,\n+            \"help_text\": help_text,\n+            \"field\": field,\n+            \"is_hidden\": is_hidden,\n         }\n         self.form = form\n         self.model_admin = model_admin\n@@ -200,23 +229,37 @@ class AdminReadonlyField:\n         attrs = {}\n         if not self.is_first:\n             attrs[\"class\"] = \"inline\"\n-        label = self.field['label']\n-        return format_html('<label{}>{}{}</label>', flatatt(attrs), capfirst(label), self.form.label_suffix)\n+        label = self.field[\"label\"]\n+        return format_html(\n+            \"<label{}>{}{}</label>\",\n+            flatatt(attrs),\n+            capfirst(label),\n+            self.form.label_suffix,\n+        )\n \n     def get_admin_url(self, remote_field, remote_obj):\n-        url_name = 'admin:%s_%s_change' % (\n+        url_name = \"admin:%s_%s_change\" % (\n             remote_field.model._meta.app_label,\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name,\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n \n     def contents(self):\n         from django.contrib.admin.templatetags.admin_list import _boolean_icon\n-        field, obj, model_admin = self.field['field'], self.form.instance, self.model_admin\n+\n+        field, obj, model_admin = (\n+            self.field[\"field\"],\n+            self.form.instance,\n+            self.model_admin,\n+        )\n         try:\n             f, attr, value = lookup_field(field, obj, model_admin)\n         except (AttributeError, ValueError, ObjectDoesNotExist):\n@@ -226,10 +269,10 @@ class AdminReadonlyField:\n                 widget = self.form[field].field.widget\n                 # This isn't elegant but suffices for contrib.auth's\n                 # ReadOnlyPasswordHashWidget.\n-                if getattr(widget, 'read_only', False):\n+                if getattr(widget, \"read_only\", False):\n                     return widget.render(field, value)\n             if f is None:\n-                if getattr(attr, 'boolean', False):\n+                if getattr(attr, \"boolean\", False):\n                     result_repr = _boolean_icon(value)\n                 else:\n                     if hasattr(value, \"__html__\"):\n@@ -240,8 +283,8 @@ class AdminReadonlyField:\n                 if isinstance(f.remote_field, ManyToManyRel) and value is not None:\n                     result_repr = \", \".join(map(str, value.all()))\n                 elif (\n-                    isinstance(f.remote_field, (ForeignObjectRel, OneToOneField)) and\n-                    value is not None\n+                    isinstance(f.remote_field, (ForeignObjectRel, OneToOneField))\n+                    and value is not None\n                 ):\n                     result_repr = self.get_admin_url(f.remote_field, value)\n                 else:\n@@ -254,10 +297,20 @@ class InlineAdminFormSet:\n     \"\"\"\n     A wrapper around an inline formset for use in the admin system.\n     \"\"\"\n-    def __init__(self, inline, formset, fieldsets, prepopulated_fields=None,\n-                 readonly_fields=None, model_admin=None, has_add_permission=True,\n-                 has_change_permission=True, has_delete_permission=True,\n-                 has_view_permission=True):\n+\n+    def __init__(\n+        self,\n+        inline,\n+        formset,\n+        fieldsets,\n+        prepopulated_fields=None,\n+        readonly_fields=None,\n+        model_admin=None,\n+        has_add_permission=True,\n+        has_change_permission=True,\n+        has_delete_permission=True,\n+        has_view_permission=True,\n+    ):\n         self.opts = inline\n         self.formset = formset\n         self.fieldsets = fieldsets\n@@ -268,7 +321,7 @@ class InlineAdminFormSet:\n         if prepopulated_fields is None:\n             prepopulated_fields = {}\n         self.prepopulated_fields = prepopulated_fields\n-        self.classes = ' '.join(inline.classes) if inline.classes else ''\n+        self.classes = \" \".join(inline.classes) if inline.classes else \"\"\n         self.has_add_permission = has_add_permission\n         self.has_change_permission = has_change_permission\n         self.has_delete_permission = has_delete_permission\n@@ -278,25 +331,43 @@ class InlineAdminFormSet:\n         if self.has_change_permission:\n             readonly_fields_for_editing = self.readonly_fields\n         else:\n-            readonly_fields_for_editing = self.readonly_fields + flatten_fieldsets(self.fieldsets)\n+            readonly_fields_for_editing = self.readonly_fields + flatten_fieldsets(\n+                self.fieldsets\n+            )\n \n-        for form, original in zip(self.formset.initial_forms, self.formset.get_queryset()):\n+        for form, original in zip(\n+            self.formset.initial_forms, self.formset.get_queryset()\n+        ):\n             view_on_site_url = self.opts.get_view_on_site_url(original)\n             yield InlineAdminForm(\n-                self.formset, form, self.fieldsets, self.prepopulated_fields,\n-                original, readonly_fields_for_editing, model_admin=self.opts,\n+                self.formset,\n+                form,\n+                self.fieldsets,\n+                self.prepopulated_fields,\n+                original,\n+                readonly_fields_for_editing,\n+                model_admin=self.opts,\n                 view_on_site_url=view_on_site_url,\n             )\n         for form in self.formset.extra_forms:\n             yield InlineAdminForm(\n-                self.formset, form, self.fieldsets, self.prepopulated_fields,\n-                None, self.readonly_fields, model_admin=self.opts,\n+                self.formset,\n+                form,\n+                self.fieldsets,\n+                self.prepopulated_fields,\n+                None,\n+                self.readonly_fields,\n+                model_admin=self.opts,\n             )\n         if self.has_add_permission:\n             yield InlineAdminForm(\n-                self.formset, self.formset.empty_form,\n-                self.fieldsets, self.prepopulated_fields, None,\n-                self.readonly_fields, model_admin=self.opts,\n+                self.formset,\n+                self.formset.empty_form,\n+                self.fieldsets,\n+                self.prepopulated_fields,\n+                None,\n+                self.readonly_fields,\n+                model_admin=self.opts,\n             )\n \n     def fields(self):\n@@ -313,42 +384,49 @@ class InlineAdminFormSet:\n                 if form_field is not None:\n                     widget_is_hidden = form_field.widget.is_hidden\n                 yield {\n-                    'name': field_name,\n-                    'label': meta_labels.get(field_name) or label_for_field(\n+                    \"name\": field_name,\n+                    \"label\": meta_labels.get(field_name)\n+                    or label_for_field(\n                         field_name,\n                         self.opts.model,\n                         self.opts,\n                         form=empty_form,\n                     ),\n-                    'widget': {'is_hidden': widget_is_hidden},\n-                    'required': False,\n-                    'help_text': meta_help_texts.get(field_name) or help_text_for_field(field_name, self.opts.model),\n+                    \"widget\": {\"is_hidden\": widget_is_hidden},\n+                    \"required\": False,\n+                    \"help_text\": meta_help_texts.get(field_name)\n+                    or help_text_for_field(field_name, self.opts.model),\n                 }\n             else:\n                 form_field = empty_form.fields[field_name]\n                 label = form_field.label\n                 if label is None:\n-                    label = label_for_field(field_name, self.opts.model, self.opts, form=empty_form)\n+                    label = label_for_field(\n+                        field_name, self.opts.model, self.opts, form=empty_form\n+                    )\n                 yield {\n-                    'name': field_name,\n-                    'label': label,\n-                    'widget': form_field.widget,\n-                    'required': form_field.required,\n-                    'help_text': form_field.help_text,\n+                    \"name\": field_name,\n+                    \"label\": label,\n+                    \"widget\": form_field.widget,\n+                    \"required\": form_field.required,\n+                    \"help_text\": form_field.help_text,\n                 }\n \n     def inline_formset_data(self):\n         verbose_name = self.opts.verbose_name\n-        return json.dumps({\n-            'name': '#%s' % self.formset.prefix,\n-            'options': {\n-                'prefix': self.formset.prefix,\n-                'addText': gettext('Add another %(verbose_name)s') % {\n-                    'verbose_name': capfirst(verbose_name),\n+        return json.dumps(\n+            {\n+                \"name\": \"#%s\" % self.formset.prefix,\n+                \"options\": {\n+                    \"prefix\": self.formset.prefix,\n+                    \"addText\": gettext(\"Add another %(verbose_name)s\")\n+                    % {\n+                        \"verbose_name\": capfirst(verbose_name),\n+                    },\n+                    \"deleteText\": gettext(\"Remove\"),\n                 },\n-                'deleteText': gettext('Remove'),\n             }\n-        })\n+        )\n \n     @property\n     def forms(self):\n@@ -370,31 +448,51 @@ class InlineAdminForm(AdminForm):\n     \"\"\"\n     A wrapper around an inline form for use in the admin system.\n     \"\"\"\n-    def __init__(self, formset, form, fieldsets, prepopulated_fields, original,\n-                 readonly_fields=None, model_admin=None, view_on_site_url=None):\n+\n+    def __init__(\n+        self,\n+        formset,\n+        form,\n+        fieldsets,\n+        prepopulated_fields,\n+        original,\n+        readonly_fields=None,\n+        model_admin=None,\n+        view_on_site_url=None,\n+    ):\n         self.formset = formset\n         self.model_admin = model_admin\n         self.original = original\n         self.show_url = original and view_on_site_url is not None\n         self.absolute_url = view_on_site_url\n-        super().__init__(form, fieldsets, prepopulated_fields, readonly_fields, model_admin)\n+        super().__init__(\n+            form, fieldsets, prepopulated_fields, readonly_fields, model_admin\n+        )\n \n     def __iter__(self):\n         for name, options in self.fieldsets:\n             yield InlineFieldset(\n-                self.formset, self.form, name, self.readonly_fields,\n-                model_admin=self.model_admin, **options\n+                self.formset,\n+                self.form,\n+                name,\n+                self.readonly_fields,\n+                model_admin=self.model_admin,\n+                **options,\n             )\n \n     def needs_explicit_pk_field(self):\n         return (\n             # Auto fields are editable, so check for auto or non-editable pk.\n-            self.form._meta.model._meta.auto_field or not self.form._meta.model._meta.pk.editable or\n+            self.form._meta.model._meta.auto_field\n+            or not self.form._meta.model._meta.pk.editable\n+            or\n             # Also search any parents for an auto field. (The pk info is\n             # propagated to child models so that does not need to be checked\n             # in parents.)\n-            any(parent._meta.auto_field or not parent._meta.model._meta.pk.editable\n-                for parent in self.form._meta.model._meta.get_parent_list())\n+            any(\n+                parent._meta.auto_field or not parent._meta.model._meta.pk.editable\n+                for parent in self.form._meta.model._meta.get_parent_list()\n+            )\n         )\n \n     def pk_field(self):\n@@ -409,10 +507,12 @@ class InlineAdminForm(AdminForm):\n \n     def deletion_field(self):\n         from django.forms.formsets import DELETION_FIELD_NAME\n+\n         return AdminField(self.form, DELETION_FIELD_NAME, False)\n \n     def ordering_field(self):\n         from django.forms.formsets import ORDERING_FIELD_NAME\n+\n         return AdminField(self.form, ORDERING_FIELD_NAME, False)\n \n \n@@ -425,11 +525,14 @@ class InlineFieldset(Fieldset):\n         fk = getattr(self.formset, \"fk\", None)\n         for field in self.fields:\n             if not fk or fk.name != field:\n-                yield Fieldline(self.form, field, self.readonly_fields, model_admin=self.model_admin)\n+                yield Fieldline(\n+                    self.form, field, self.readonly_fields, model_admin=self.model_admin\n+                )\n \n \n class AdminErrorList(forms.utils.ErrorList):\n     \"\"\"Store errors for the form/formsets in an add/change view.\"\"\"\n+\n     def __init__(self, form, inline_formsets):\n         super().__init__()\n \n"}
{"instance_id": "django__django-14915", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..ceb348896e 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -2,29 +2,44 @@\n Helper functions for creating Form classes from Django models\n and database field objects.\n \"\"\"\n+\n from itertools import chain\n \n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldError, ImproperlyConfigured, ValidationError,\n+    NON_FIELD_ERRORS,\n+    FieldError,\n+    ImproperlyConfigured,\n+    ValidationError,\n )\n from django.forms.fields import ChoiceField, Field\n from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, RadioSelect, SelectMultiple,\n+    HiddenInput,\n+    MultipleHiddenInput,\n+    RadioSelect,\n+    SelectMultiple,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n __all__ = (\n-    'ModelForm', 'BaseModelForm', 'model_to_dict', 'fields_for_model',\n-    'ModelChoiceField', 'ModelMultipleChoiceField', 'ALL_FIELDS',\n-    'BaseModelFormSet', 'modelformset_factory', 'BaseInlineFormSet',\n-    'inlineformset_factory', 'modelform_factory',\n+    \"ModelForm\",\n+    \"BaseModelForm\",\n+    \"model_to_dict\",\n+    \"fields_for_model\",\n+    \"ModelChoiceField\",\n+    \"ModelMultipleChoiceField\",\n+    \"ALL_FIELDS\",\n+    \"BaseModelFormSet\",\n+    \"modelformset_factory\",\n+    \"BaseInlineFormSet\",\n+    \"inlineformset_factory\",\n+    \"modelform_factory\",\n )\n \n-ALL_FIELDS = '__all__'\n+ALL_FIELDS = \"__all__\"\n \n \n def construct_instance(form, instance, fields=None, exclude=None):\n@@ -33,13 +48,17 @@ def construct_instance(form, instance, fields=None, exclude=None):\n     ``cleaned_data``, but do not save the returned instance to the database.\n     \"\"\"\n     from django.db import models\n+\n     opts = instance._meta\n \n     cleaned_data = form.cleaned_data\n     file_field_list = []\n     for f in opts.fields:\n-        if not f.editable or isinstance(f, models.AutoField) \\\n-                or f.name not in cleaned_data:\n+        if (\n+            not f.editable\n+            or isinstance(f, models.AutoField)\n+            or f.name not in cleaned_data\n+        ):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -48,9 +67,11 @@ def construct_instance(form, instance, fields=None, exclude=None):\n         # Leave defaults for fields that aren't in POST data, except for\n         # checkbox inputs because they don't appear in POST data if not checked.\n         if (\n-            f.has_default() and\n-            form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name)) and\n-            cleaned_data.get(f.name) in form[f.name].field.empty_values\n+            f.has_default()\n+            and form[f.name].field.widget.value_omitted_from_data(\n+                form.data, form.files, form.add_prefix(f.name)\n+            )\n+            and cleaned_data.get(f.name) in form[f.name].field.empty_values\n         ):\n             continue\n         # Defer saving file-type fields until after the other fields, so a\n@@ -68,6 +89,7 @@ def construct_instance(form, instance, fields=None, exclude=None):\n \n # ModelForms #################################################################\n \n+\n def model_to_dict(instance, fields=None, exclude=None):\n     \"\"\"\n     Return a dict containing the data in ``instance`` suitable for passing as\n@@ -83,7 +105,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     opts = instance._meta\n     data = {}\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n-        if not getattr(f, 'editable', False):\n+        if not getattr(f, \"editable\", False):\n             continue\n         if fields is not None and f.name not in fields:\n             continue\n@@ -96,23 +118,34 @@ def model_to_dict(instance, fields=None, exclude=None):\n def apply_limit_choices_to_to_formfield(formfield):\n     \"\"\"Apply limit_choices_to to the formfield's queryset if needed.\"\"\"\n     from django.db.models import Exists, OuterRef, Q\n-    if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n+\n+    if hasattr(formfield, \"queryset\") and hasattr(formfield, \"get_limit_choices_to\"):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to:\n             complex_filter = limit_choices_to\n             if not isinstance(complex_filter, Q):\n                 complex_filter = Q(**limit_choices_to)\n-            complex_filter &= Q(pk=OuterRef('pk'))\n+            complex_filter &= Q(pk=OuterRef(\"pk\"))\n             # Use Exists() to avoid potential duplicates.\n             formfield.queryset = formfield.queryset.filter(\n                 Exists(formfield.queryset.model._base_manager.filter(complex_filter)),\n             )\n \n \n-def fields_for_model(model, fields=None, exclude=None, widgets=None,\n-                     formfield_callback=None, localized_fields=None,\n-                     labels=None, help_texts=None, error_messages=None,\n-                     field_classes=None, *, apply_limit_choices_to=True):\n+def fields_for_model(\n+    model,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    formfield_callback=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+    *,\n+    apply_limit_choices_to=True,\n+):\n     \"\"\"\n     Return a dictionary containing form fields for the given model.\n \n@@ -148,14 +181,22 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n     opts = model._meta\n     # Avoid circular import\n     from django.db.models import Field as ModelField\n-    sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)]\n-    for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)):\n-        if not getattr(f, 'editable', False):\n-            if (fields is not None and f.name in fields and\n-                    (exclude is None or f.name not in exclude)):\n+\n+    sortable_private_fields = [\n+        f for f in opts.private_fields if isinstance(f, ModelField)\n+    ]\n+    for f in sorted(\n+        chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)\n+    ):\n+        if not getattr(f, \"editable\", False):\n+            if (\n+                fields is not None\n+                and f.name in fields\n+                and (exclude is None or f.name not in exclude)\n+            ):\n                 raise FieldError(\n-                    \"'%s' cannot be specified for %s model form as it is a non-editable field\" % (\n-                        f.name, model.__name__)\n+                    \"'%s' cannot be specified for %s model form as it is a non-editable field\"\n+                    % (f.name, model.__name__)\n                 )\n             continue\n         if fields is not None and f.name not in fields:\n@@ -165,22 +206,24 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n         kwargs = {}\n         if widgets and f.name in widgets:\n-            kwargs['widget'] = widgets[f.name]\n-        if localized_fields == ALL_FIELDS or (localized_fields and f.name in localized_fields):\n-            kwargs['localize'] = True\n+            kwargs[\"widget\"] = widgets[f.name]\n+        if localized_fields == ALL_FIELDS or (\n+            localized_fields and f.name in localized_fields\n+        ):\n+            kwargs[\"localize\"] = True\n         if labels and f.name in labels:\n-            kwargs['label'] = labels[f.name]\n+            kwargs[\"label\"] = labels[f.name]\n         if help_texts and f.name in help_texts:\n-            kwargs['help_text'] = help_texts[f.name]\n+            kwargs[\"help_text\"] = help_texts[f.name]\n         if error_messages and f.name in error_messages:\n-            kwargs['error_messages'] = error_messages[f.name]\n+            kwargs[\"error_messages\"] = error_messages[f.name]\n         if field_classes and f.name in field_classes:\n-            kwargs['form_class'] = field_classes[f.name]\n+            kwargs[\"form_class\"] = field_classes[f.name]\n \n         if formfield_callback is None:\n             formfield = f.formfield(**kwargs)\n         elif not callable(formfield_callback):\n-            raise TypeError('formfield_callback must be a function or callable')\n+            raise TypeError(\"formfield_callback must be a function or callable\")\n         else:\n             formfield = formfield_callback(f, **kwargs)\n \n@@ -192,7 +235,8 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n             ignored.append(f.name)\n     if fields:\n         field_dict = {\n-            f: field_dict.get(f) for f in fields\n+            f: field_dict.get(f)\n+            for f in fields\n             if (not exclude or f not in exclude) and f not in ignored\n         }\n     return field_dict\n@@ -200,46 +244,49 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n \n class ModelFormOptions:\n     def __init__(self, options=None):\n-        self.model = getattr(options, 'model', None)\n-        self.fields = getattr(options, 'fields', None)\n-        self.exclude = getattr(options, 'exclude', None)\n-        self.widgets = getattr(options, 'widgets', None)\n-        self.localized_fields = getattr(options, 'localized_fields', None)\n-        self.labels = getattr(options, 'labels', None)\n-        self.help_texts = getattr(options, 'help_texts', None)\n-        self.error_messages = getattr(options, 'error_messages', None)\n-        self.field_classes = getattr(options, 'field_classes', None)\n+        self.model = getattr(options, \"model\", None)\n+        self.fields = getattr(options, \"fields\", None)\n+        self.exclude = getattr(options, \"exclude\", None)\n+        self.widgets = getattr(options, \"widgets\", None)\n+        self.localized_fields = getattr(options, \"localized_fields\", None)\n+        self.labels = getattr(options, \"labels\", None)\n+        self.help_texts = getattr(options, \"help_texts\", None)\n+        self.error_messages = getattr(options, \"error_messages\", None)\n+        self.field_classes = getattr(options, \"field_classes\", None)\n \n \n class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n     def __new__(mcs, name, bases, attrs):\n         base_formfield_callback = None\n         for b in bases:\n-            if hasattr(b, 'Meta') and hasattr(b.Meta, 'formfield_callback'):\n+            if hasattr(b, \"Meta\") and hasattr(b.Meta, \"formfield_callback\"):\n                 base_formfield_callback = b.Meta.formfield_callback\n                 break\n \n-        formfield_callback = attrs.pop('formfield_callback', base_formfield_callback)\n+        formfield_callback = attrs.pop(\"formfield_callback\", base_formfield_callback)\n \n         new_class = super().__new__(mcs, name, bases, attrs)\n \n         if bases == (BaseModelForm,):\n             return new_class\n \n-        opts = new_class._meta = ModelFormOptions(getattr(new_class, 'Meta', None))\n+        opts = new_class._meta = ModelFormOptions(getattr(new_class, \"Meta\", None))\n \n         # We check if a string was passed to `fields` or `exclude`,\n         # which is likely to be a mistake where the user typed ('foo') instead\n         # of ('foo',)\n-        for opt in ['fields', 'exclude', 'localized_fields']:\n+        for opt in [\"fields\", \"exclude\", \"localized_fields\"]:\n             value = getattr(opts, opt)\n             if isinstance(value, str) and value != ALL_FIELDS:\n-                msg = (\"%(model)s.Meta.%(opt)s cannot be a string. \"\n-                       \"Did you mean to type: ('%(value)s',)?\" % {\n-                           'model': new_class.__name__,\n-                           'opt': opt,\n-                           'value': value,\n-                       })\n+                msg = (\n+                    \"%(model)s.Meta.%(opt)s cannot be a string. \"\n+                    \"Did you mean to type: ('%(value)s',)?\"\n+                    % {\n+                        \"model\": new_class.__name__,\n+                        \"opt\": opt,\n+                        \"value\": value,\n+                    }\n+                )\n                 raise TypeError(msg)\n \n         if opts.model:\n@@ -257,9 +304,16 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n                 opts.fields = None\n \n             fields = fields_for_model(\n-                opts.model, opts.fields, opts.exclude, opts.widgets,\n-                formfield_callback, opts.localized_fields, opts.labels,\n-                opts.help_texts, opts.error_messages, opts.field_classes,\n+                opts.model,\n+                opts.fields,\n+                opts.exclude,\n+                opts.widgets,\n+                formfield_callback,\n+                opts.localized_fields,\n+                opts.labels,\n+                opts.help_texts,\n+                opts.error_messages,\n+                opts.field_classes,\n                 # limit_choices_to will be applied during ModelForm.__init__().\n                 apply_limit_choices_to=False,\n             )\n@@ -268,9 +322,8 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n             none_model_fields = {k for k, v in fields.items() if not v}\n             missing_fields = none_model_fields.difference(new_class.declared_fields)\n             if missing_fields:\n-                message = 'Unknown field(s) (%s) specified for %s'\n-                message = message % (', '.join(missing_fields),\n-                                     opts.model.__name__)\n+                message = \"Unknown field(s) (%s) specified for %s\"\n+                message = message % (\", \".join(missing_fields), opts.model.__name__)\n                 raise FieldError(message)\n             # Override default model fields with any custom declared ones\n             # (plus, include all the other declared fields).\n@@ -284,13 +337,23 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n \n \n class BaseModelForm(BaseForm):\n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 initial=None, error_class=ErrorList, label_suffix=None,\n-                 empty_permitted=False, instance=None, use_required_attribute=None,\n-                 renderer=None):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        initial=None,\n+        error_class=ErrorList,\n+        label_suffix=None,\n+        empty_permitted=False,\n+        instance=None,\n+        use_required_attribute=None,\n+        renderer=None,\n+    ):\n         opts = self._meta\n         if opts.model is None:\n-            raise ValueError('ModelForm has no model class specified.')\n+            raise ValueError(\"ModelForm has no model class specified.\")\n         if instance is None:\n             # if we didn't get an instance, instantiate a new one\n             self.instance = opts.model()\n@@ -306,8 +369,15 @@ class BaseModelForm(BaseForm):\n         # super will stop validate_unique from being called.\n         self._validate_unique = False\n         super().__init__(\n-            data, files, auto_id, prefix, object_data, error_class,\n-            label_suffix, empty_permitted, use_required_attribute=use_required_attribute,\n+            data,\n+            files,\n+            auto_id,\n+            prefix,\n+            object_data,\n+            error_class,\n+            label_suffix,\n+            empty_permitted,\n+            use_required_attribute=use_required_attribute,\n             renderer=renderer,\n         )\n         for formfield in self.fields.values():\n@@ -350,7 +420,11 @@ class BaseModelForm(BaseForm):\n             else:\n                 form_field = self.fields[field]\n                 field_value = self.cleaned_data.get(field)\n-                if not f.blank and not form_field.required and field_value in form_field.empty_values:\n+                if (\n+                    not f.blank\n+                    and not form_field.required\n+                    and field_value in form_field.empty_values\n+                ):\n                     exclude.append(f.name)\n         return exclude\n \n@@ -365,14 +439,17 @@ class BaseModelForm(BaseForm):\n \n         # Allow the model generated by construct_instance() to raise\n         # ValidationError and have them handled in the same way as others.\n-        if hasattr(errors, 'error_dict'):\n+        if hasattr(errors, \"error_dict\"):\n             error_dict = errors.error_dict\n         else:\n             error_dict = {NON_FIELD_ERRORS: errors}\n \n         for field, messages in error_dict.items():\n-            if (field == NON_FIELD_ERRORS and opts.error_messages and\n-                    NON_FIELD_ERRORS in opts.error_messages):\n+            if (\n+                field == NON_FIELD_ERRORS\n+                and opts.error_messages\n+                and NON_FIELD_ERRORS in opts.error_messages\n+            ):\n                 error_messages = opts.error_messages[NON_FIELD_ERRORS]\n             elif field in self.fields:\n                 error_messages = self.fields[field].error_messages\n@@ -380,8 +457,10 @@ class BaseModelForm(BaseForm):\n                 continue\n \n             for message in messages:\n-                if (isinstance(message, ValidationError) and\n-                        message.code in error_messages):\n+                if (\n+                    isinstance(message, ValidationError)\n+                    and message.code in error_messages\n+                ):\n                     message.message = error_messages[message.code]\n \n         self.add_error(None, errors)\n@@ -403,7 +482,9 @@ class BaseModelForm(BaseForm):\n                 exclude.append(name)\n \n         try:\n-            self.instance = construct_instance(self, self.instance, opts.fields, opts.exclude)\n+            self.instance = construct_instance(\n+                self, self.instance, opts.fields, opts.exclude\n+            )\n         except ValidationError as e:\n             self._update_errors(e)\n \n@@ -439,7 +520,7 @@ class BaseModelForm(BaseForm):\n         # private_fields here. (GenericRelation was previously a fake\n         # m2m field).\n         for f in chain(opts.many_to_many, opts.private_fields):\n-            if not hasattr(f, 'save_form_data'):\n+            if not hasattr(f, \"save_form_data\"):\n                 continue\n             if fields and f.name not in fields:\n                 continue\n@@ -456,9 +537,10 @@ class BaseModelForm(BaseForm):\n         \"\"\"\n         if self.errors:\n             raise ValueError(\n-                \"The %s could not be %s because the data didn't validate.\" % (\n+                \"The %s could not be %s because the data didn't validate.\"\n+                % (\n                     self.instance._meta.object_name,\n-                    'created' if self.instance._state.adding else 'changed',\n+                    \"created\" if self.instance._state.adding else \"changed\",\n                 )\n             )\n         if commit:\n@@ -478,10 +560,19 @@ class ModelForm(BaseModelForm, metaclass=ModelFormMetaclass):\n     pass\n \n \n-def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n-                      formfield_callback=None, widgets=None, localized_fields=None,\n-                      labels=None, help_texts=None, error_messages=None,\n-                      field_classes=None):\n+def modelform_factory(\n+    model,\n+    form=ModelForm,\n+    fields=None,\n+    exclude=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    field_classes=None,\n+):\n     \"\"\"\n     Return a ModelForm containing form fields for the given model. You can\n     optionally pass a `form` argument to use as a starting point for\n@@ -517,41 +608,37 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n     # inner class.\n \n     # Build up a list of attributes that the Meta object will have.\n-    attrs = {'model': model}\n+    attrs = {\"model\": model}\n     if fields is not None:\n-        attrs['fields'] = fields\n+        attrs[\"fields\"] = fields\n     if exclude is not None:\n-        attrs['exclude'] = exclude\n+        attrs[\"exclude\"] = exclude\n     if widgets is not None:\n-        attrs['widgets'] = widgets\n+        attrs[\"widgets\"] = widgets\n     if localized_fields is not None:\n-        attrs['localized_fields'] = localized_fields\n+        attrs[\"localized_fields\"] = localized_fields\n     if labels is not None:\n-        attrs['labels'] = labels\n+        attrs[\"labels\"] = labels\n     if help_texts is not None:\n-        attrs['help_texts'] = help_texts\n+        attrs[\"help_texts\"] = help_texts\n     if error_messages is not None:\n-        attrs['error_messages'] = error_messages\n+        attrs[\"error_messages\"] = error_messages\n     if field_classes is not None:\n-        attrs['field_classes'] = field_classes\n+        attrs[\"field_classes\"] = field_classes\n \n     # If parent form class already has an inner Meta, the Meta we're\n     # creating needs to inherit from the parent's inner meta.\n-    bases = (form.Meta,) if hasattr(form, 'Meta') else ()\n-    Meta = type('Meta', bases, attrs)\n+    bases = (form.Meta,) if hasattr(form, \"Meta\") else ()\n+    Meta = type(\"Meta\", bases, attrs)\n     if formfield_callback:\n         Meta.formfield_callback = staticmethod(formfield_callback)\n     # Give this new form class a reasonable name.\n-    class_name = model.__name__ + 'Form'\n+    class_name = model.__name__ + \"Form\"\n \n     # Class attributes for the new form class.\n-    form_class_attrs = {\n-        'Meta': Meta,\n-        'formfield_callback': formfield_callback\n-    }\n+    form_class_attrs = {\"Meta\": Meta, \"formfield_callback\": formfield_callback}\n \n-    if (getattr(Meta, 'fields', None) is None and\n-            getattr(Meta, 'exclude', None) is None):\n+    if getattr(Meta, \"fields\", None) is None and getattr(Meta, \"exclude\", None) is None:\n         raise ImproperlyConfigured(\n             \"Calling modelform_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n@@ -563,20 +650,39 @@ def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n \n # ModelFormSets ##############################################################\n \n+\n class BaseModelFormSet(BaseFormSet):\n     \"\"\"\n     A ``FormSet`` for editing a queryset and/or adding new objects to it.\n     \"\"\"\n+\n     model = None\n \n     # Set of fields that must be unique among forms of this set.\n     unique_fields = set()\n \n-    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,\n-                 queryset=None, *, initial=None, **kwargs):\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        auto_id=\"id_%s\",\n+        prefix=None,\n+        queryset=None,\n+        *,\n+        initial=None,\n+        **kwargs,\n+    ):\n         self.queryset = queryset\n         self.initial_extra = initial\n-        super().__init__(**{'data': data, 'files': files, 'auto_id': auto_id, 'prefix': prefix, **kwargs})\n+        super().__init__(\n+            **{\n+                \"data\": data,\n+                \"files\": files,\n+                \"auto_id\": auto_id,\n+                \"prefix\": prefix,\n+                **kwargs,\n+            }\n+        )\n \n     def initial_form_count(self):\n         \"\"\"Return the number of forms that are required in this FormSet.\"\"\"\n@@ -585,7 +691,7 @@ class BaseModelFormSet(BaseFormSet):\n         return super().initial_form_count()\n \n     def _existing_object(self, pk):\n-        if not hasattr(self, '_object_dict'):\n+        if not hasattr(self, \"_object_dict\"):\n             self._object_dict = {o.pk: o for o in self.get_queryset()}\n         return self._object_dict.get(pk)\n \n@@ -602,7 +708,7 @@ class BaseModelFormSet(BaseFormSet):\n         pk_required = i < self.initial_form_count()\n         if pk_required:\n             if self.is_bound:\n-                pk_key = '%s-%s' % (self.add_prefix(i), self.model._meta.pk.name)\n+                pk_key = \"%s-%s\" % (self.add_prefix(i), self.model._meta.pk.name)\n                 try:\n                     pk = self.data[pk_key]\n                 except KeyError:\n@@ -618,13 +724,13 @@ class BaseModelFormSet(BaseFormSet):\n                         # user may have tampered with POST data.\n                         pass\n                     else:\n-                        kwargs['instance'] = self._existing_object(pk)\n+                        kwargs[\"instance\"] = self._existing_object(pk)\n             else:\n-                kwargs['instance'] = self.get_queryset()[i]\n+                kwargs[\"instance\"] = self.get_queryset()[i]\n         elif self.initial_extra:\n             # Set initial values for extra forms\n             try:\n-                kwargs['initial'] = self.initial_extra[i - self.initial_form_count()]\n+                kwargs[\"initial\"] = self.initial_extra[i - self.initial_form_count()]\n             except IndexError:\n                 pass\n         form = super()._construct_form(i, **kwargs)\n@@ -633,7 +739,7 @@ class BaseModelFormSet(BaseFormSet):\n         return form\n \n     def get_queryset(self):\n-        if not hasattr(self, '_queryset'):\n+        if not hasattr(self, \"_queryset\"):\n             if self.queryset is not None:\n                 qs = self.queryset\n             else:\n@@ -675,6 +781,7 @@ class BaseModelFormSet(BaseFormSet):\n             def save_m2m():\n                 for form in self.saved_forms:\n                     form.save_m2m()\n+\n             self.save_m2m = save_m2m\n         return self.save_existing_objects(commit) + self.save_new_objects(commit)\n \n@@ -688,10 +795,16 @@ class BaseModelFormSet(BaseFormSet):\n         all_unique_checks = set()\n         all_date_checks = set()\n         forms_to_delete = self.deleted_forms\n-        valid_forms = [form for form in self.forms if form.is_valid() and form not in forms_to_delete]\n+        valid_forms = [\n+            form\n+            for form in self.forms\n+            if form.is_valid() and form not in forms_to_delete\n+        ]\n         for form in valid_forms:\n             exclude = form._get_validation_exclusions()\n-            unique_checks, date_checks = form.instance._get_unique_checks(exclude=exclude)\n+            unique_checks, date_checks = form.instance._get_unique_checks(\n+                exclude=exclude\n+            )\n             all_unique_checks.update(unique_checks)\n             all_date_checks.update(date_checks)\n \n@@ -703,14 +816,18 @@ class BaseModelFormSet(BaseFormSet):\n                 # Get the data for the set of fields that must be unique among the forms.\n                 row_data = (\n                     field if field in self.unique_fields else form.cleaned_data[field]\n-                    for field in unique_check if field in form.cleaned_data\n+                    for field in unique_check\n+                    if field in form.cleaned_data\n                 )\n                 # Reduce Model instances to their primary key values\n                 row_data = tuple(\n-                    d._get_pk_val() if hasattr(d, '_get_pk_val')\n+                    d._get_pk_val()\n+                    if hasattr(d, \"_get_pk_val\")\n                     # Prevent \"unhashable type: list\" errors later on.\n-                    else tuple(d) if isinstance(d, list)\n-                    else d for d in row_data\n+                    else tuple(d)\n+                    if isinstance(d, list)\n+                    else d\n+                    for d in row_data\n                 )\n                 if row_data and None not in row_data:\n                     # if we've already seen it then we have a uniqueness failure\n@@ -734,10 +851,13 @@ class BaseModelFormSet(BaseFormSet):\n             uclass, lookup, field, unique_for = date_check\n             for form in valid_forms:\n                 # see if we have data for both fields\n-                if (form.cleaned_data and form.cleaned_data[field] is not None and\n-                        form.cleaned_data[unique_for] is not None):\n+                if (\n+                    form.cleaned_data\n+                    and form.cleaned_data[field] is not None\n+                    and form.cleaned_data[unique_for] is not None\n+                ):\n                     # if it's a date lookup we need to get the data for all the fields\n-                    if lookup == 'date':\n+                    if lookup == \"date\":\n                         date = form.cleaned_data[unique_for]\n                         date_data = (date.year, date.month, date.day)\n                     # otherwise it's just the attribute on the date/datetime\n@@ -768,7 +888,9 @@ class BaseModelFormSet(BaseFormSet):\n                 \"field\": unique_check[0],\n             }\n         else:\n-            return gettext(\"Please correct the duplicate data for %(field)s, which must be unique.\") % {\n+            return gettext(\n+                \"Please correct the duplicate data for %(field)s, which must be unique.\"\n+            ) % {\n                 \"field\": get_text_list(unique_check, _(\"and\")),\n             }\n \n@@ -777,9 +899,9 @@ class BaseModelFormSet(BaseFormSet):\n             \"Please correct the duplicate data for %(field_name)s \"\n             \"which must be unique for the %(lookup)s in %(date_field)s.\"\n         ) % {\n-            'field_name': date_check[2],\n-            'date_field': date_check[3],\n-            'lookup': str(date_check[1]),\n+            \"field_name\": date_check[2],\n+            \"date_field\": date_check[3],\n+            \"lookup\": str(date_check[1]),\n         }\n \n     def get_form_error(self):\n@@ -828,6 +950,7 @@ class BaseModelFormSet(BaseFormSet):\n     def add_fields(self, form, index):\n         \"\"\"Add a hidden field for the object's primary key.\"\"\"\n         from django.db.models import AutoField, ForeignKey, OneToOneField\n+\n         self._pk_field = pk = self.model._meta.pk\n         # If a pk isn't editable, then it won't be on the form, so we need to\n         # add it here so we can tell which object is which when we get the\n@@ -837,11 +960,15 @@ class BaseModelFormSet(BaseFormSet):\n \n         def pk_is_not_editable(pk):\n             return (\n-                (not pk.editable) or (pk.auto_created or isinstance(pk, AutoField)) or (\n-                    pk.remote_field and pk.remote_field.parent_link and\n-                    pk_is_not_editable(pk.remote_field.model._meta.pk)\n+                (not pk.editable)\n+                or (pk.auto_created or isinstance(pk, AutoField))\n+                or (\n+                    pk.remote_field\n+                    and pk.remote_field.parent_link\n+                    and pk_is_not_editable(pk.remote_field.model._meta.pk)\n                 )\n             )\n+\n         if pk_is_not_editable(pk) or pk.name not in form.fields:\n             if form.is_bound:\n                 # If we're adding the related instance, ignore its primary key\n@@ -865,46 +992,94 @@ class BaseModelFormSet(BaseFormSet):\n                 widget = form._meta.widgets.get(self._pk_field.name, HiddenInput)\n             else:\n                 widget = HiddenInput\n-            form.fields[self._pk_field.name] = ModelChoiceField(qs, initial=pk_value, required=False, widget=widget)\n+            form.fields[self._pk_field.name] = ModelChoiceField(\n+                qs, initial=pk_value, required=False, widget=widget\n+            )\n         super().add_fields(form, index)\n \n \n-def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n-                         formset=BaseModelFormSet, extra=1, can_delete=False,\n-                         can_order=False, max_num=None, fields=None, exclude=None,\n-                         widgets=None, validate_max=False, localized_fields=None,\n-                         labels=None, help_texts=None, error_messages=None,\n-                         min_num=None, validate_min=False, field_classes=None,\n-                         absolute_max=None, can_delete_extra=True, renderer=None):\n+def modelformset_factory(\n+    model,\n+    form=ModelForm,\n+    formfield_callback=None,\n+    formset=BaseModelFormSet,\n+    extra=1,\n+    can_delete=False,\n+    can_order=False,\n+    max_num=None,\n+    fields=None,\n+    exclude=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+    renderer=None,\n+):\n     \"\"\"Return a FormSet class for the given Django model class.\"\"\"\n-    meta = getattr(form, 'Meta', None)\n-    if (getattr(meta, 'fields', fields) is None and\n-            getattr(meta, 'exclude', exclude) is None):\n+    meta = getattr(form, \"Meta\", None)\n+    if (\n+        getattr(meta, \"fields\", fields) is None\n+        and getattr(meta, \"exclude\", exclude) is None\n+    ):\n         raise ImproperlyConfigured(\n             \"Calling modelformset_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n         )\n \n-    form = modelform_factory(model, form=form, fields=fields, exclude=exclude,\n-                             formfield_callback=formfield_callback,\n-                             widgets=widgets, localized_fields=localized_fields,\n-                             labels=labels, help_texts=help_texts,\n-                             error_messages=error_messages, field_classes=field_classes)\n-    FormSet = formset_factory(form, formset, extra=extra, min_num=min_num, max_num=max_num,\n-                              can_order=can_order, can_delete=can_delete,\n-                              validate_min=validate_min, validate_max=validate_max,\n-                              absolute_max=absolute_max, can_delete_extra=can_delete_extra,\n-                              renderer=renderer)\n+    form = modelform_factory(\n+        model,\n+        form=form,\n+        fields=fields,\n+        exclude=exclude,\n+        formfield_callback=formfield_callback,\n+        widgets=widgets,\n+        localized_fields=localized_fields,\n+        labels=labels,\n+        help_texts=help_texts,\n+        error_messages=error_messages,\n+        field_classes=field_classes,\n+    )\n+    FormSet = formset_factory(\n+        form,\n+        formset,\n+        extra=extra,\n+        min_num=min_num,\n+        max_num=max_num,\n+        can_order=can_order,\n+        can_delete=can_delete,\n+        validate_min=validate_min,\n+        validate_max=validate_max,\n+        absolute_max=absolute_max,\n+        can_delete_extra=can_delete_extra,\n+        renderer=renderer,\n+    )\n     FormSet.model = model\n     return FormSet\n \n \n # InlineFormSets #############################################################\n \n+\n class BaseInlineFormSet(BaseModelFormSet):\n     \"\"\"A formset for child objects related to a parent.\"\"\"\n-    def __init__(self, data=None, files=None, instance=None,\n-                 save_as_new=False, prefix=None, queryset=None, **kwargs):\n+\n+    def __init__(\n+        self,\n+        data=None,\n+        files=None,\n+        instance=None,\n+        save_as_new=False,\n+        prefix=None,\n+        queryset=None,\n+        **kwargs,\n+    ):\n         if instance is None:\n             self.instance = self.fk.remote_field.model()\n         else:\n@@ -934,7 +1109,7 @@ class BaseInlineFormSet(BaseModelFormSet):\n     def _construct_form(self, i, **kwargs):\n         form = super()._construct_form(i, **kwargs)\n         if self.save_as_new:\n-            mutable = getattr(form.data, '_mutable', None)\n+            mutable = getattr(form.data, \"_mutable\", None)\n             # Allow modifying an immutable QueryDict.\n             if mutable is not None:\n                 form.data._mutable = True\n@@ -950,13 +1125,13 @@ class BaseInlineFormSet(BaseModelFormSet):\n         fk_value = self.instance.pk\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n             fk_value = getattr(self.instance, self.fk.remote_field.field_name)\n-            fk_value = getattr(fk_value, 'pk', fk_value)\n+            fk_value = getattr(fk_value, \"pk\", fk_value)\n         setattr(form.instance, self.fk.get_attname(), fk_value)\n         return form\n \n     @classmethod\n     def get_default_prefix(cls):\n-        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace('+', '')\n+        return cls.fk.remote_field.get_accessor_name(model=cls.model).replace(\"+\", \"\")\n \n     def save_new(self, form, commit=True):\n         # Ensure the latest copy of the related instance is present on each\n@@ -969,26 +1144,28 @@ class BaseInlineFormSet(BaseModelFormSet):\n         super().add_fields(form, index)\n         if self._pk_field == self.fk:\n             name = self._pk_field.name\n-            kwargs = {'pk_field': True}\n+            kwargs = {\"pk_field\": True}\n         else:\n             # The foreign key field might not be on the form, so we poke at the\n             # Model field to get the label, since we need that for error messages.\n             name = self.fk.name\n             kwargs = {\n-                'label': getattr(form.fields.get(name), 'label', capfirst(self.fk.verbose_name))\n+                \"label\": getattr(\n+                    form.fields.get(name), \"label\", capfirst(self.fk.verbose_name)\n+                )\n             }\n \n         # The InlineForeignKeyField assumes that the foreign key relation is\n         # based on the parent model's pk. If this isn't the case, set to_field\n         # to correctly resolve the initial form value.\n         if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name:\n-            kwargs['to_field'] = self.fk.remote_field.field_name\n+            kwargs[\"to_field\"] = self.fk.remote_field.field_name\n \n         # If we're adding a new object, ignore a parent's auto-generated key\n         # as it will be regenerated on the save request.\n         if self.instance._state.adding:\n-            if kwargs.get('to_field') is not None:\n-                to_field = self.instance._meta.get_field(kwargs['to_field'])\n+            if kwargs.get(\"to_field\") is not None:\n+                to_field = self.instance._meta.get_field(kwargs[\"to_field\"])\n             else:\n                 to_field = self.instance._meta.pk\n             if to_field.has_default():\n@@ -1011,24 +1188,30 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     \"\"\"\n     # avoid circular import\n     from django.db.models import ForeignKey\n+\n     opts = model._meta\n     if fk_name:\n         fks_to_parent = [f for f in opts.fields if f.name == fk_name]\n         if len(fks_to_parent) == 1:\n             fk = fks_to_parent[0]\n             parent_list = parent_model._meta.get_parent_list()\n-            if not isinstance(fk, ForeignKey) or (\n-                # ForeignKey to proxy models.\n-                fk.remote_field.model._meta.proxy and\n-                fk.remote_field.model._meta.proxy_for_model not in parent_list\n-            ) or (\n-                # ForeignKey to concrete models.\n-                not fk.remote_field.model._meta.proxy and\n-                fk.remote_field.model != parent_model and\n-                fk.remote_field.model not in parent_list\n+            if (\n+                not isinstance(fk, ForeignKey)\n+                or (\n+                    # ForeignKey to proxy models.\n+                    fk.remote_field.model._meta.proxy\n+                    and fk.remote_field.model._meta.proxy_for_model not in parent_list\n+                )\n+                or (\n+                    # ForeignKey to concrete models.\n+                    not fk.remote_field.model._meta.proxy\n+                    and fk.remote_field.model != parent_model\n+                    and fk.remote_field.model not in parent_list\n+                )\n             ):\n                 raise ValueError(\n-                    \"fk_name '%s' is not a ForeignKey to '%s'.\" % (fk_name, parent_model._meta.label)\n+                    \"fk_name '%s' is not a ForeignKey to '%s'.\"\n+                    % (fk_name, parent_model._meta.label)\n                 )\n         elif not fks_to_parent:\n             raise ValueError(\n@@ -1038,12 +1221,15 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n         # Try to discover what the ForeignKey from model to parent_model is\n         parent_list = parent_model._meta.get_parent_list()\n         fks_to_parent = [\n-            f for f in opts.fields\n-            if isinstance(f, ForeignKey) and (\n-                f.remote_field.model == parent_model or\n-                f.remote_field.model in parent_list or (\n-                    f.remote_field.model._meta.proxy and\n-                    f.remote_field.model._meta.proxy_for_model in parent_list\n+            f\n+            for f in opts.fields\n+            if isinstance(f, ForeignKey)\n+            and (\n+                f.remote_field.model == parent_model\n+                or f.remote_field.model in parent_list\n+                or (\n+                    f.remote_field.model._meta.proxy\n+                    and f.remote_field.model._meta.proxy_for_model in parent_list\n                 )\n             )\n         ]\n@@ -1053,7 +1239,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n             if can_fail:\n                 return\n             raise ValueError(\n-                \"'%s' has no ForeignKey to '%s'.\" % (\n+                \"'%s' has no ForeignKey to '%s'.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1061,7 +1248,8 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n         else:\n             raise ValueError(\n                 \"'%s' has more than one ForeignKey to '%s'. You must specify \"\n-                \"a 'fk_name' attribute.\" % (\n+                \"a 'fk_name' attribute.\"\n+                % (\n                     model._meta.label,\n                     parent_model._meta.label,\n                 )\n@@ -1069,14 +1257,32 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n     return fk\n \n \n-def inlineformset_factory(parent_model, model, form=ModelForm,\n-                          formset=BaseInlineFormSet, fk_name=None,\n-                          fields=None, exclude=None, extra=3, can_order=False,\n-                          can_delete=True, max_num=None, formfield_callback=None,\n-                          widgets=None, validate_max=False, localized_fields=None,\n-                          labels=None, help_texts=None, error_messages=None,\n-                          min_num=None, validate_min=False, field_classes=None,\n-                          absolute_max=None, can_delete_extra=True, renderer=None):\n+def inlineformset_factory(\n+    parent_model,\n+    model,\n+    form=ModelForm,\n+    formset=BaseInlineFormSet,\n+    fk_name=None,\n+    fields=None,\n+    exclude=None,\n+    extra=3,\n+    can_order=False,\n+    can_delete=True,\n+    max_num=None,\n+    formfield_callback=None,\n+    widgets=None,\n+    validate_max=False,\n+    localized_fields=None,\n+    labels=None,\n+    help_texts=None,\n+    error_messages=None,\n+    min_num=None,\n+    validate_min=False,\n+    field_classes=None,\n+    absolute_max=None,\n+    can_delete_extra=True,\n+    renderer=None,\n+):\n     \"\"\"\n     Return an ``InlineFormSet`` for the given kwargs.\n \n@@ -1088,27 +1294,27 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n     if fk.unique:\n         max_num = 1\n     kwargs = {\n-        'form': form,\n-        'formfield_callback': formfield_callback,\n-        'formset': formset,\n-        'extra': extra,\n-        'can_delete': can_delete,\n-        'can_order': can_order,\n-        'fields': fields,\n-        'exclude': exclude,\n-        'min_num': min_num,\n-        'max_num': max_num,\n-        'widgets': widgets,\n-        'validate_min': validate_min,\n-        'validate_max': validate_max,\n-        'localized_fields': localized_fields,\n-        'labels': labels,\n-        'help_texts': help_texts,\n-        'error_messages': error_messages,\n-        'field_classes': field_classes,\n-        'absolute_max': absolute_max,\n-        'can_delete_extra': can_delete_extra,\n-        'renderer': renderer,\n+        \"form\": form,\n+        \"formfield_callback\": formfield_callback,\n+        \"formset\": formset,\n+        \"extra\": extra,\n+        \"can_delete\": can_delete,\n+        \"can_order\": can_order,\n+        \"fields\": fields,\n+        \"exclude\": exclude,\n+        \"min_num\": min_num,\n+        \"max_num\": max_num,\n+        \"widgets\": widgets,\n+        \"validate_min\": validate_min,\n+        \"validate_max\": validate_max,\n+        \"localized_fields\": localized_fields,\n+        \"labels\": labels,\n+        \"help_texts\": help_texts,\n+        \"error_messages\": error_messages,\n+        \"field_classes\": field_classes,\n+        \"absolute_max\": absolute_max,\n+        \"can_delete_extra\": can_delete_extra,\n+        \"renderer\": renderer,\n     }\n     FormSet = modelformset_factory(model, **kwargs)\n     FormSet.fk = fk\n@@ -1117,14 +1323,16 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n \n # Fields #####################################################################\n \n+\n class InlineForeignKeyField(Field):\n     \"\"\"\n     A basic integer field that deals with validating the given value to a\n     given parent instance in an inline.\n     \"\"\"\n+\n     widget = HiddenInput\n     default_error_messages = {\n-        'invalid_choice': _('The inline value did not match the parent instance.'),\n+        \"invalid_choice\": _(\"The inline value did not match the parent instance.\"),\n     }\n \n     def __init__(self, parent_instance, *args, pk_field=False, to_field=None, **kwargs):\n@@ -1151,7 +1359,9 @@ class InlineForeignKeyField(Field):\n         else:\n             orig = self.parent_instance.pk\n         if str(value) != str(orig):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages[\"invalid_choice\"], code=\"invalid_choice\"\n+            )\n         return self.parent_instance\n \n     def has_changed(self, initial, data):\n@@ -1171,6 +1381,9 @@ class ModelChoiceIteratorValue:\n             other = other.value\n         return self.value == other\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):\n@@ -1205,33 +1418,50 @@ class ModelChoiceIterator:\n \n class ModelChoiceField(ChoiceField):\n     \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n-                            ' the available choices.'),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. That choice is not one of the available choices.\"\n+        ),\n     }\n     iterator = ModelChoiceIterator\n \n-    def __init__(self, queryset, *, empty_label=\"---------\",\n-                 required=True, widget=None, label=None, initial=None,\n-                 help_text='', to_field_name=None, limit_choices_to=None,\n-                 blank=False, **kwargs):\n+    def __init__(\n+        self,\n+        queryset,\n+        *,\n+        empty_label=\"---------\",\n+        required=True,\n+        widget=None,\n+        label=None,\n+        initial=None,\n+        help_text=\"\",\n+        to_field_name=None,\n+        limit_choices_to=None,\n+        blank=False,\n+        **kwargs,\n+    ):\n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n         Field.__init__(\n-            self, required=required, widget=widget, label=label,\n-            initial=initial, help_text=help_text, **kwargs\n+            self,\n+            required=required,\n+            widget=widget,\n+            label=label,\n+            initial=initial,\n+            help_text=help_text,\n+            **kwargs,\n         )\n-        if (\n-            (required and initial is not None) or\n-            (isinstance(self.widget, RadioSelect) and not blank)\n+        if (required and initial is not None) or (\n+            isinstance(self.widget, RadioSelect) and not blank\n         ):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n         self.queryset = queryset\n-        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.limit_choices_to = limit_choices_to  # limit the queryset later.\n         self.to_field_name = to_field_name\n \n     def get_limit_choices_to(self):\n@@ -1273,7 +1503,7 @@ class ModelChoiceField(ChoiceField):\n     def _get_choices(self):\n         # If self._choices is set, then somebody must have manually set\n         # the property self.choices. In this case, just return self._choices.\n-        if hasattr(self, '_choices'):\n+        if hasattr(self, \"_choices\"):\n             return self._choices\n \n         # Otherwise, execute the QuerySet in self.queryset to determine the\n@@ -1288,7 +1518,7 @@ class ModelChoiceField(ChoiceField):\n     choices = property(_get_choices, ChoiceField._set_choices)\n \n     def prepare_value(self, value):\n-        if hasattr(value, '_meta'):\n+        if hasattr(value, \"_meta\"):\n             if self.to_field_name:\n                 return value.serializable_value(self.to_field_name)\n             else:\n@@ -1299,15 +1529,15 @@ class ModelChoiceField(ChoiceField):\n         if value in self.empty_values:\n             return None\n         try:\n-            key = self.to_field_name or 'pk'\n+            key = self.to_field_name or \"pk\"\n             if isinstance(value, self.queryset.model):\n                 value = getattr(value, key)\n             value = self.queryset.get(**{key: value})\n         except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n             raise ValidationError(\n-                self.error_messages['invalid_choice'],\n-                code='invalid_choice',\n-                params={'value': value},\n+                self.error_messages[\"invalid_choice\"],\n+                code=\"invalid_choice\",\n+                params={\"value\": value},\n             )\n         return value\n \n@@ -1317,20 +1547,22 @@ class ModelChoiceField(ChoiceField):\n     def has_changed(self, initial, data):\n         if self.disabled:\n             return False\n-        initial_value = initial if initial is not None else ''\n-        data_value = data if data is not None else ''\n+        initial_value = initial if initial is not None else \"\"\n+        data_value = data if data is not None else \"\"\n         return str(self.prepare_value(initial_value)) != str(data_value)\n \n \n class ModelMultipleChoiceField(ModelChoiceField):\n     \"\"\"A MultipleChoiceField whose choices are a model QuerySet.\"\"\"\n+\n     widget = SelectMultiple\n     hidden_widget = MultipleHiddenInput\n     default_error_messages = {\n-        'invalid_list': _('Enter a list of values.'),\n-        'invalid_choice': _('Select a valid choice. %(value)s is not one of the'\n-                            ' available choices.'),\n-        'invalid_pk_value': _('\u201c%(pk)s\u201d is not a valid value.')\n+        \"invalid_list\": _(\"Enter a list of values.\"),\n+        \"invalid_choice\": _(\n+            \"Select a valid choice. %(value)s is not one of the available choices.\"\n+        ),\n+        \"invalid_pk_value\": _(\"\u201c%(pk)s\u201d is not a valid value.\"),\n     }\n \n     def __init__(self, queryset, **kwargs):\n@@ -1344,13 +1576,13 @@ class ModelMultipleChoiceField(ModelChoiceField):\n     def clean(self, value):\n         value = self.prepare_value(value)\n         if self.required and not value:\n-            raise ValidationError(self.error_messages['required'], code='required')\n+            raise ValidationError(self.error_messages[\"required\"], code=\"required\")\n         elif not self.required and not value:\n             return self.queryset.none()\n         if not isinstance(value, (list, tuple)):\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         qs = self._check_values(value)\n         # Since this overrides the inherited ModelChoiceField.clean\n@@ -1364,7 +1596,7 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         corresponding objects. Raise a ValidationError if a given value is\n         invalid (not a valid PK, not in the queryset, etc.)\n         \"\"\"\n-        key = self.to_field_name or 'pk'\n+        key = self.to_field_name or \"pk\"\n         # deduplicate given values to avoid creating many querysets or\n         # requiring the database backend deduplicate efficiently.\n         try:\n@@ -1372,33 +1604,35 @@ class ModelMultipleChoiceField(ModelChoiceField):\n         except TypeError:\n             # list of lists isn't hashable, for example\n             raise ValidationError(\n-                self.error_messages['invalid_list'],\n-                code='invalid_list',\n+                self.error_messages[\"invalid_list\"],\n+                code=\"invalid_list\",\n             )\n         for pk in value:\n             try:\n                 self.queryset.filter(**{key: pk})\n             except (ValueError, TypeError):\n                 raise ValidationError(\n-                    self.error_messages['invalid_pk_value'],\n-                    code='invalid_pk_value',\n-                    params={'pk': pk},\n+                    self.error_messages[\"invalid_pk_value\"],\n+                    code=\"invalid_pk_value\",\n+                    params={\"pk\": pk},\n                 )\n-        qs = self.queryset.filter(**{'%s__in' % key: value})\n+        qs = self.queryset.filter(**{\"%s__in\" % key: value})\n         pks = {str(getattr(o, key)) for o in qs}\n         for val in value:\n             if str(val) not in pks:\n                 raise ValidationError(\n-                    self.error_messages['invalid_choice'],\n-                    code='invalid_choice',\n-                    params={'value': val},\n+                    self.error_messages[\"invalid_choice\"],\n+                    code=\"invalid_choice\",\n+                    params={\"value\": val},\n                 )\n         return qs\n \n     def prepare_value(self, value):\n-        if (hasattr(value, '__iter__') and\n-                not isinstance(value, str) and\n-                not hasattr(value, '_meta')):\n+        if (\n+            hasattr(value, \"__iter__\")\n+            and not isinstance(value, str)\n+            and not hasattr(value, \"_meta\")\n+        ):\n             prepare_value = super().prepare_value\n             return [prepare_value(v) for v in value]\n         return super().prepare_value(value)\n@@ -1418,7 +1652,6 @@ class ModelMultipleChoiceField(ModelChoiceField):\n \n \n def modelform_defines_fields(form_class):\n-    return hasattr(form_class, '_meta') and (\n-        form_class._meta.fields is not None or\n-        form_class._meta.exclude is not None\n+    return hasattr(form_class, \"_meta\") and (\n+        form_class._meta.fields is not None or form_class._meta.exclude is not None\n     )\n"}
{"instance_id": "django__django-14997", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex f0c81c123b..526eb4f26d 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -11,10 +11,11 @@ from django.db.transaction import atomic\n \n \n class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n-\n     sql_delete_table = \"DROP TABLE %(table)s\"\n     sql_create_fk = None\n-    sql_create_inline_fk = \"REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED\"\n+    sql_create_inline_fk = (\n+        \"REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED\"\n+    )\n     sql_create_unique = \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)\"\n     sql_delete_unique = \"DROP INDEX %(name)s\"\n \n@@ -23,11 +24,11 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # disabled. Enforce it here for the duration of the schema edition.\n         if not self.connection.disable_constraint_checking():\n             raise NotSupportedError(\n-                'SQLite schema editor cannot be used while foreign key '\n-                'constraint checks are enabled. Make sure to disable them '\n-                'before entering a transaction.atomic() context because '\n-                'SQLite does not support disabling them in the middle of '\n-                'a multi-statement transaction.'\n+                \"SQLite schema editor cannot be used while foreign key \"\n+                \"constraint checks are enabled. Make sure to disable them \"\n+                \"before entering a transaction.atomic() context because \"\n+                \"SQLite does not support disabling them in the middle of \"\n+                \"a multi-statement transaction.\"\n             )\n         return super().__enter__()\n \n@@ -42,6 +43,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # security hardening).\n         try:\n             import sqlite3\n+\n             value = sqlite3.adapt(value)\n         except ImportError:\n             pass\n@@ -53,7 +55,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         elif isinstance(value, (Decimal, float, int)):\n             return str(value)\n         elif isinstance(value, str):\n-            return \"'%s'\" % value.replace(\"\\'\", \"\\'\\'\")\n+            return \"'%s'\" % value.replace(\"'\", \"''\")\n         elif value is None:\n             return \"NULL\"\n         elif isinstance(value, (bytes, bytearray, memoryview)):\n@@ -62,9 +64,13 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             # character.\n             return \"X'%s'\" % value.hex()\n         else:\n-            raise ValueError(\"Cannot quote parameter value %r of type %s\" % (value, type(value)))\n+            raise ValueError(\n+                \"Cannot quote parameter value %r of type %s\" % (value, type(value))\n+            )\n \n-    def _is_referenced_by_fk_constraint(self, table_name, column_name=None, ignore_self=False):\n+    def _is_referenced_by_fk_constraint(\n+        self, table_name, column_name=None, ignore_self=False\n+    ):\n         \"\"\"\n         Return whether or not the provided table name is referenced by another\n         one. If `column_name` is specified, only references pointing to that\n@@ -75,23 +81,36 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             for other_table in self.connection.introspection.get_table_list(cursor):\n                 if ignore_self and other_table.name == table_name:\n                     continue\n-                constraints = self.connection.introspection._get_foreign_key_constraints(cursor, other_table.name)\n+                constraints = (\n+                    self.connection.introspection._get_foreign_key_constraints(\n+                        cursor, other_table.name\n+                    )\n+                )\n                 for constraint in constraints.values():\n-                    constraint_table, constraint_column = constraint['foreign_key']\n-                    if (constraint_table == table_name and\n-                            (column_name is None or constraint_column == column_name)):\n+                    constraint_table, constraint_column = constraint[\"foreign_key\"]\n+                    if constraint_table == table_name and (\n+                        column_name is None or constraint_column == column_name\n+                    ):\n                         return True\n         return False\n \n-    def alter_db_table(self, model, old_db_table, new_db_table, disable_constraints=True):\n-        if (not self.connection.features.supports_atomic_references_rename and\n-                disable_constraints and self._is_referenced_by_fk_constraint(old_db_table)):\n+    def alter_db_table(\n+        self, model, old_db_table, new_db_table, disable_constraints=True\n+    ):\n+        if (\n+            not self.connection.features.supports_atomic_references_rename\n+            and disable_constraints\n+            and self._is_referenced_by_fk_constraint(old_db_table)\n+        ):\n             if self.connection.in_atomic_block:\n-                raise NotSupportedError((\n-                    'Renaming the %r table while in a transaction is not '\n-                    'supported on SQLite < 3.26 because it would break referential '\n-                    'integrity. Try adding `atomic = False` to the Migration class.'\n-                ) % old_db_table)\n+                raise NotSupportedError(\n+                    (\n+                        \"Renaming the %r table while in a transaction is not \"\n+                        \"supported on SQLite < 3.26 because it would break referential \"\n+                        \"integrity. Try adding `atomic = False` to the Migration class.\"\n+                    )\n+                    % old_db_table\n+                )\n             self.connection.enable_constraint_checking()\n             super().alter_db_table(model, old_db_table, new_db_table)\n             self.connection.disable_constraint_checking()\n@@ -104,42 +123,56 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         old_field_name = old_field.name\n         table_name = model._meta.db_table\n         _, old_column_name = old_field.get_attname_column()\n-        if (new_field.name != old_field_name and\n-                not self.connection.features.supports_atomic_references_rename and\n-                self._is_referenced_by_fk_constraint(table_name, old_column_name, ignore_self=True)):\n+        if (\n+            new_field.name != old_field_name\n+            and not self.connection.features.supports_atomic_references_rename\n+            and self._is_referenced_by_fk_constraint(\n+                table_name, old_column_name, ignore_self=True\n+            )\n+        ):\n             if self.connection.in_atomic_block:\n-                raise NotSupportedError((\n-                    'Renaming the %r.%r column while in a transaction is not '\n-                    'supported on SQLite < 3.26 because it would break referential '\n-                    'integrity. Try adding `atomic = False` to the Migration class.'\n-                ) % (model._meta.db_table, old_field_name))\n+                raise NotSupportedError(\n+                    (\n+                        \"Renaming the %r.%r column while in a transaction is not \"\n+                        \"supported on SQLite < 3.26 because it would break referential \"\n+                        \"integrity. Try adding `atomic = False` to the Migration class.\"\n+                    )\n+                    % (model._meta.db_table, old_field_name)\n+                )\n             with atomic(self.connection.alias):\n                 super().alter_field(model, old_field, new_field, strict=strict)\n                 # Follow SQLite's documented procedure for performing changes\n                 # that don't affect the on-disk content.\n                 # https://sqlite.org/lang_altertable.html#otheralter\n                 with self.connection.cursor() as cursor:\n-                    schema_version = cursor.execute('PRAGMA schema_version').fetchone()[0]\n-                    cursor.execute('PRAGMA writable_schema = 1')\n+                    schema_version = cursor.execute(\"PRAGMA schema_version\").fetchone()[\n+                        0\n+                    ]\n+                    cursor.execute(\"PRAGMA writable_schema = 1\")\n                     references_template = ' REFERENCES \"%s\" (\"%%s\") ' % table_name\n                     new_column_name = new_field.get_attname_column()[1]\n                     search = references_template % old_column_name\n                     replacement = references_template % new_column_name\n-                    cursor.execute('UPDATE sqlite_master SET sql = replace(sql, %s, %s)', (search, replacement))\n-                    cursor.execute('PRAGMA schema_version = %d' % (schema_version + 1))\n-                    cursor.execute('PRAGMA writable_schema = 0')\n+                    cursor.execute(\n+                        \"UPDATE sqlite_master SET sql = replace(sql, %s, %s)\",\n+                        (search, replacement),\n+                    )\n+                    cursor.execute(\"PRAGMA schema_version = %d\" % (schema_version + 1))\n+                    cursor.execute(\"PRAGMA writable_schema = 0\")\n                     # The integrity check will raise an exception and rollback\n                     # the transaction if the sqlite_master updates corrupt the\n                     # database.\n-                    cursor.execute('PRAGMA integrity_check')\n+                    cursor.execute(\"PRAGMA integrity_check\")\n             # Perform a VACUUM to refresh the database representation from\n             # the sqlite_master table.\n             with self.connection.cursor() as cursor:\n-                cursor.execute('VACUUM')\n+                cursor.execute(\"VACUUM\")\n         else:\n             super().alter_field(model, old_field, new_field, strict=strict)\n \n-    def _remake_table(self, model, create_field=None, delete_field=None, alter_field=None):\n+    def _remake_table(\n+        self, model, create_field=None, delete_field=None, alter_field=None\n+    ):\n         \"\"\"\n         Shortcut to transform a model from old_model into new_model\n \n@@ -155,11 +188,13 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n           4. Rename the \"new__app_model\" table to \"app_model\"\n           5. Restore any index of the previous \"app_model\" table.\n         \"\"\"\n+\n         # Self-referential fields must be recreated rather than copied from\n         # the old model to ensure their remote_field.field_name doesn't refer\n         # to an altered field.\n         def is_self_referential(f):\n             return f.is_relation and f.remote_field.model is model\n+\n         # Work out the new fields dict / mapping\n         body = {\n             f.name: f.clone() if is_self_referential(f) else f\n@@ -167,14 +202,18 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         }\n         # Since mapping might mix column names and default values,\n         # its values must be already quoted.\n-        mapping = {f.column: self.quote_name(f.column) for f in model._meta.local_concrete_fields}\n+        mapping = {\n+            f.column: self.quote_name(f.column)\n+            for f in model._meta.local_concrete_fields\n+        }\n         # This maps field names (not columns) for things like unique_together\n         rename_mapping = {}\n         # If any of the new or altered fields is introducing a new PK,\n         # remove the old one\n         restore_pk_field = None\n-        if getattr(create_field, 'primary_key', False) or (\n-                alter_field and getattr(alter_field[1], 'primary_key', False)):\n+        if getattr(create_field, \"primary_key\", False) or (\n+            alter_field and getattr(alter_field[1], \"primary_key\", False)\n+        ):\n             for name, field in list(body.items()):\n                 if field.primary_key:\n                     field.primary_key = False\n@@ -198,8 +237,8 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             body[new_field.name] = new_field\n             if old_field.null and not new_field.null:\n                 case_sql = \"coalesce(%(col)s, %(default)s)\" % {\n-                    'col': self.quote_name(old_field.column),\n-                    'default': self.quote_value(self.effective_default(new_field))\n+                    \"col\": self.quote_name(old_field.column),\n+                    \"default\": self.quote_value(self.effective_default(new_field)),\n                 }\n                 mapping[new_field.column] = case_sql\n             else:\n@@ -210,7 +249,10 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             del body[delete_field.name]\n             del mapping[delete_field.column]\n             # Remove any implicit M2M tables\n-            if delete_field.many_to_many and delete_field.remote_field.through._meta.auto_created:\n+            if (\n+                delete_field.many_to_many\n+                and delete_field.remote_field.through._meta.auto_created\n+            ):\n                 return self.delete_model(delete_field.remote_field.through)\n         # Work inside a new app registry\n         apps = Apps()\n@@ -232,11 +274,14 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         indexes = model._meta.indexes\n         if delete_field:\n             indexes = [\n-                index for index in indexes\n-                if delete_field.name not in index.fields\n+                index for index in indexes if delete_field.name not in index.fields\n             ]\n \n-        constraints = list(model._meta.constraints)\n+        constraints = [\n+            constraint\n+            for constraint in model._meta.constraints\n+            if not constraint.contains_expressions\n+        ]\n \n         # Provide isolated instances of the fields to the new model body so\n         # that the existing model's internals aren't interfered with when\n@@ -249,52 +294,57 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # This wouldn't be required if the schema editor was operating on model\n         # states instead of rendered models.\n         meta_contents = {\n-            'app_label': model._meta.app_label,\n-            'db_table': model._meta.db_table,\n-            'unique_together': unique_together,\n-            'index_together': index_together,\n-            'indexes': indexes,\n-            'constraints': constraints,\n-            'apps': apps,\n+            \"app_label\": model._meta.app_label,\n+            \"db_table\": model._meta.db_table,\n+            \"unique_together\": unique_together,\n+            \"index_together\": index_together,\n+            \"indexes\": indexes,\n+            \"constraints\": constraints,\n+            \"apps\": apps,\n         }\n         meta = type(\"Meta\", (), meta_contents)\n-        body_copy['Meta'] = meta\n-        body_copy['__module__'] = model.__module__\n+        body_copy[\"Meta\"] = meta\n+        body_copy[\"__module__\"] = model.__module__\n         type(model._meta.object_name, model.__bases__, body_copy)\n \n         # Construct a model with a renamed table name.\n         body_copy = copy.deepcopy(body)\n         meta_contents = {\n-            'app_label': model._meta.app_label,\n-            'db_table': 'new__%s' % strip_quotes(model._meta.db_table),\n-            'unique_together': unique_together,\n-            'index_together': index_together,\n-            'indexes': indexes,\n-            'constraints': constraints,\n-            'apps': apps,\n+            \"app_label\": model._meta.app_label,\n+            \"db_table\": \"new__%s\" % strip_quotes(model._meta.db_table),\n+            \"unique_together\": unique_together,\n+            \"index_together\": index_together,\n+            \"indexes\": indexes,\n+            \"constraints\": constraints,\n+            \"apps\": apps,\n         }\n         meta = type(\"Meta\", (), meta_contents)\n-        body_copy['Meta'] = meta\n-        body_copy['__module__'] = model.__module__\n-        new_model = type('New%s' % model._meta.object_name, model.__bases__, body_copy)\n+        body_copy[\"Meta\"] = meta\n+        body_copy[\"__module__\"] = model.__module__\n+        new_model = type(\"New%s\" % model._meta.object_name, model.__bases__, body_copy)\n \n         # Create a new table with the updated schema.\n         self.create_model(new_model)\n \n         # Copy data from the old table into the new table\n-        self.execute(\"INSERT INTO %s (%s) SELECT %s FROM %s\" % (\n-            self.quote_name(new_model._meta.db_table),\n-            ', '.join(self.quote_name(x) for x in mapping),\n-            ', '.join(mapping.values()),\n-            self.quote_name(model._meta.db_table),\n-        ))\n+        self.execute(\n+            \"INSERT INTO %s (%s) SELECT %s FROM %s\"\n+            % (\n+                self.quote_name(new_model._meta.db_table),\n+                \", \".join(self.quote_name(x) for x in mapping),\n+                \", \".join(mapping.values()),\n+                self.quote_name(model._meta.db_table),\n+            )\n+        )\n \n         # Delete the old table to make way for the new\n         self.delete_model(model, handle_autom2m=False)\n \n         # Rename the new table to take way for the old\n         self.alter_db_table(\n-            new_model, new_model._meta.db_table, model._meta.db_table,\n+            new_model,\n+            new_model._meta.db_table,\n+            model._meta.db_table,\n             disable_constraints=False,\n         )\n \n@@ -311,12 +361,17 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             super().delete_model(model)\n         else:\n             # Delete the table (and only that)\n-            self.execute(self.sql_delete_table % {\n-                \"table\": self.quote_name(model._meta.db_table),\n-            })\n+            self.execute(\n+                self.sql_delete_table\n+                % {\n+                    \"table\": self.quote_name(model._meta.db_table),\n+                }\n+            )\n             # Remove all deferred statements referencing the deleted table.\n             for sql in list(self.deferred_sql):\n-                if isinstance(sql, Statement) and sql.references_table(model._meta.db_table):\n+                if isinstance(sql, Statement) and sql.references_table(\n+                    model._meta.db_table\n+                ):\n                     self.deferred_sql.remove(sql)\n \n     def add_field(self, model, field):\n@@ -343,21 +398,40 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # For everything else, remake.\n         else:\n             # It might not actually have a column behind it\n-            if field.db_parameters(connection=self.connection)['type'] is None:\n+            if field.db_parameters(connection=self.connection)[\"type\"] is None:\n                 return\n             self._remake_table(model, delete_field=field)\n \n-    def _alter_field(self, model, old_field, new_field, old_type, new_type,\n-                     old_db_params, new_db_params, strict=False):\n+    def _alter_field(\n+        self,\n+        model,\n+        old_field,\n+        new_field,\n+        old_type,\n+        new_type,\n+        old_db_params,\n+        new_db_params,\n+        strict=False,\n+    ):\n         \"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"\n         # Use \"ALTER TABLE ... RENAME COLUMN\" if only the column name\n         # changed and there aren't any constraints.\n-        if (self.connection.features.can_alter_table_rename_column and\n-            old_field.column != new_field.column and\n-            self.column_sql(model, old_field) == self.column_sql(model, new_field) and\n-            not (old_field.remote_field and old_field.db_constraint or\n-                 new_field.remote_field and new_field.db_constraint)):\n-            return self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type))\n+        if (\n+            self.connection.features.can_alter_table_rename_column\n+            and old_field.column != new_field.column\n+            and self.column_sql(model, old_field) == self.column_sql(model, new_field)\n+            and not (\n+                old_field.remote_field\n+                and old_field.db_constraint\n+                or new_field.remote_field\n+                and new_field.db_constraint\n+            )\n+        ):\n+            return self.execute(\n+                self._rename_field_sql(\n+                    model._meta.db_table, old_field, new_field, new_type\n+                )\n+            )\n         # Alter by remaking table\n         self._remake_table(model, alter_field=(old_field, new_field))\n         # Rebuild tables with FKs pointing to this field.\n@@ -385,15 +459,22 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n \n     def _alter_many_to_many(self, model, old_field, new_field, strict):\n         \"\"\"Alter M2Ms to repoint their to= endpoints.\"\"\"\n-        if old_field.remote_field.through._meta.db_table == new_field.remote_field.through._meta.db_table:\n+        if (\n+            old_field.remote_field.through._meta.db_table\n+            == new_field.remote_field.through._meta.db_table\n+        ):\n             # The field name didn't change, but some options did; we have to propagate this altering.\n             self._remake_table(\n                 old_field.remote_field.through,\n                 alter_field=(\n                     # We need the field that points to the target model, so we can tell alter_field to change it -\n                     # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)\n-                    old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()),\n-                    new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()),\n+                    old_field.remote_field.through._meta.get_field(\n+                        old_field.m2m_reverse_field_name()\n+                    ),\n+                    new_field.remote_field.through._meta.get_field(\n+                        new_field.m2m_reverse_field_name()\n+                    ),\n                 ),\n             )\n             return\n@@ -401,29 +482,36 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # Make a new through table\n         self.create_model(new_field.remote_field.through)\n         # Copy the data across\n-        self.execute(\"INSERT INTO %s (%s) SELECT %s FROM %s\" % (\n-            self.quote_name(new_field.remote_field.through._meta.db_table),\n-            ', '.join([\n-                \"id\",\n-                new_field.m2m_column_name(),\n-                new_field.m2m_reverse_name(),\n-            ]),\n-            ', '.join([\n-                \"id\",\n-                old_field.m2m_column_name(),\n-                old_field.m2m_reverse_name(),\n-            ]),\n-            self.quote_name(old_field.remote_field.through._meta.db_table),\n-        ))\n+        self.execute(\n+            \"INSERT INTO %s (%s) SELECT %s FROM %s\"\n+            % (\n+                self.quote_name(new_field.remote_field.through._meta.db_table),\n+                \", \".join(\n+                    [\n+                        \"id\",\n+                        new_field.m2m_column_name(),\n+                        new_field.m2m_reverse_name(),\n+                    ]\n+                ),\n+                \", \".join(\n+                    [\n+                        \"id\",\n+                        old_field.m2m_column_name(),\n+                        old_field.m2m_reverse_name(),\n+                    ]\n+                ),\n+                self.quote_name(old_field.remote_field.through._meta.db_table),\n+            )\n+        )\n         # Delete the old through table\n         self.delete_model(old_field.remote_field.through)\n \n     def add_constraint(self, model, constraint):\n         if isinstance(constraint, UniqueConstraint) and (\n-            constraint.condition or\n-            constraint.contains_expressions or\n-            constraint.include or\n-            constraint.deferrable\n+            constraint.condition\n+            or constraint.contains_expressions\n+            or constraint.include\n+            or constraint.deferrable\n         ):\n             super().add_constraint(model, constraint)\n         else:\n@@ -431,14 +519,14 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n \n     def remove_constraint(self, model, constraint):\n         if isinstance(constraint, UniqueConstraint) and (\n-            constraint.condition or\n-            constraint.contains_expressions or\n-            constraint.include or\n-            constraint.deferrable\n+            constraint.condition\n+            or constraint.contains_expressions\n+            or constraint.include\n+            or constraint.deferrable\n         ):\n             super().remove_constraint(model, constraint)\n         else:\n             self._remake_table(model)\n \n     def _collate_sql(self, collation):\n-        return 'COLLATE ' + collation\n+        return \"COLLATE \" + collation\n"}
{"instance_id": "django__django-14999", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..7c18f2adf3 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -6,7 +6,11 @@ from django.db.models.options import normalize_together\n from django.utils.functional import cached_property\n \n from .fields import (\n-    AddField, AlterField, FieldOperation, RemoveField, RenameField,\n+    AddField,\n+    AlterField,\n+    FieldOperation,\n+    RemoveField,\n+    RenameField,\n )\n \n \n@@ -32,16 +36,15 @@ class ModelOperation(Operation):\n         return name.lower() == self.name_lower\n \n     def reduce(self, operation, app_label):\n-        return (\n-            super().reduce(operation, app_label) or\n-            not operation.references_model(self.name, app_label)\n+        return super().reduce(operation, app_label) or not operation.references_model(\n+            self.name, app_label\n         )\n \n \n class CreateModel(ModelOperation):\n     \"\"\"Create a model's table.\"\"\"\n \n-    serialization_expand_args = ['fields', 'options', 'managers']\n+    serialization_expand_args = [\"fields\", \"options\", \"managers\"]\n \n     def __init__(self, name, fields, options=None, bases=None, managers=None):\n         self.fields = fields\n@@ -51,40 +54,44 @@ class CreateModel(ModelOperation):\n         super().__init__(name)\n         # Sanity-check that there are no duplicated field names, bases, or\n         # manager names\n-        _check_for_duplicates('fields', (name for name, _ in self.fields))\n-        _check_for_duplicates('bases', (\n-            base._meta.label_lower if hasattr(base, '_meta') else\n-            base.lower() if isinstance(base, str) else base\n-            for base in self.bases\n-        ))\n-        _check_for_duplicates('managers', (name for name, _ in self.managers))\n+        _check_for_duplicates(\"fields\", (name for name, _ in self.fields))\n+        _check_for_duplicates(\n+            \"bases\",\n+            (\n+                base._meta.label_lower\n+                if hasattr(base, \"_meta\")\n+                else base.lower()\n+                if isinstance(base, str)\n+                else base\n+                for base in self.bases\n+            ),\n+        )\n+        _check_for_duplicates(\"managers\", (name for name, _ in self.managers))\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n-            'fields': self.fields,\n+            \"name\": self.name,\n+            \"fields\": self.fields,\n         }\n         if self.options:\n-            kwargs['options'] = self.options\n+            kwargs[\"options\"] = self.options\n         if self.bases and self.bases != (models.Model,):\n-            kwargs['bases'] = self.bases\n-        if self.managers and self.managers != [('objects', models.Manager())]:\n-            kwargs['managers'] = self.managers\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+            kwargs[\"bases\"] = self.bases\n+        if self.managers and self.managers != [(\"objects\", models.Manager())]:\n+            kwargs[\"managers\"] = self.managers\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n-        state.add_model(ModelState(\n-            app_label,\n-            self.name,\n-            list(self.fields),\n-            dict(self.options),\n-            tuple(self.bases),\n-            list(self.managers),\n-        ))\n+        state.add_model(\n+            ModelState(\n+                app_label,\n+                self.name,\n+                list(self.fields),\n+                dict(self.options),\n+                tuple(self.bases),\n+                list(self.managers),\n+            )\n+        )\n \n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         model = to_state.apps.get_model(app_label, self.name)\n@@ -97,7 +104,10 @@ class CreateModel(ModelOperation):\n             schema_editor.delete_model(model)\n \n     def describe(self):\n-        return \"Create %smodel %s\" % (\"proxy \" if self.options.get(\"proxy\", False) else \"\", self.name)\n+        return \"Create %smodel %s\" % (\n+            \"proxy \" if self.options.get(\"proxy\", False) else \"\",\n+            self.name,\n+        )\n \n     @property\n     def migration_name_fragment(self):\n@@ -111,22 +121,32 @@ class CreateModel(ModelOperation):\n         # Check we didn't inherit from the model\n         reference_model_tuple = (app_label, name_lower)\n         for base in self.bases:\n-            if (base is not models.Model and isinstance(base, (models.base.ModelBase, str)) and\n-                    resolve_relation(base, app_label) == reference_model_tuple):\n+            if (\n+                base is not models.Model\n+                and isinstance(base, (models.base.ModelBase, str))\n+                and resolve_relation(base, app_label) == reference_model_tuple\n+            ):\n                 return True\n \n         # Check we have no FKs/M2Ms with it\n         for _name, field in self.fields:\n-            if field_references((app_label, self.name_lower), field, reference_model_tuple):\n+            if field_references(\n+                (app_label, self.name_lower), field, reference_model_tuple\n+            ):\n                 return True\n         return False\n \n     def reduce(self, operation, app_label):\n-        if (isinstance(operation, DeleteModel) and\n-                self.name_lower == operation.name_lower and\n-                not self.options.get(\"proxy\", False)):\n+        if (\n+            isinstance(operation, DeleteModel)\n+            and self.name_lower == operation.name_lower\n+            and not self.options.get(\"proxy\", False)\n+        ):\n             return []\n-        elif isinstance(operation, RenameModel) and self.name_lower == operation.old_name_lower:\n+        elif (\n+            isinstance(operation, RenameModel)\n+            and self.name_lower == operation.old_name_lower\n+        ):\n             return [\n                 CreateModel(\n                     operation.new_name,\n@@ -136,7 +156,10 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, AlterModelOptions) and self.name_lower == operation.name_lower:\n+        elif (\n+            isinstance(operation, AlterModelOptions)\n+            and self.name_lower == operation.name_lower\n+        ):\n             options = {**self.options, **operation.options}\n             for key in operation.ALTER_OPTION_KEYS:\n                 if key not in operation.options:\n@@ -150,27 +173,42 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, AlterTogetherOptionOperation) and self.name_lower == operation.name_lower:\n+        elif (\n+            isinstance(operation, AlterTogetherOptionOperation)\n+            and self.name_lower == operation.name_lower\n+        ):\n             return [\n                 CreateModel(\n                     self.name,\n                     fields=self.fields,\n-                    options={**self.options, **{operation.option_name: operation.option_value}},\n+                    options={\n+                        **self.options,\n+                        **{operation.option_name: operation.option_value},\n+                    },\n                     bases=self.bases,\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, AlterOrderWithRespectTo) and self.name_lower == operation.name_lower:\n+        elif (\n+            isinstance(operation, AlterOrderWithRespectTo)\n+            and self.name_lower == operation.name_lower\n+        ):\n             return [\n                 CreateModel(\n                     self.name,\n                     fields=self.fields,\n-                    options={**self.options, 'order_with_respect_to': operation.order_with_respect_to},\n+                    options={\n+                        **self.options,\n+                        \"order_with_respect_to\": operation.order_with_respect_to,\n+                    },\n                     bases=self.bases,\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, FieldOperation) and self.name_lower == operation.model_name_lower:\n+        elif (\n+            isinstance(operation, FieldOperation)\n+            and self.name_lower == operation.model_name_lower\n+        ):\n             if isinstance(operation, AddField):\n                 return [\n                     CreateModel(\n@@ -196,17 +234,25 @@ class CreateModel(ModelOperation):\n                 ]\n             elif isinstance(operation, RemoveField):\n                 options = self.options.copy()\n-                for option_name in ('unique_together', 'index_together'):\n+                for option_name in (\"unique_together\", \"index_together\"):\n                     option = options.pop(option_name, None)\n                     if option:\n-                        option = set(filter(bool, (\n-                            tuple(f for f in fields if f != operation.name_lower) for fields in option\n-                        )))\n+                        option = set(\n+                            filter(\n+                                bool,\n+                                (\n+                                    tuple(\n+                                        f for f in fields if f != operation.name_lower\n+                                    )\n+                                    for fields in option\n+                                ),\n+                            )\n+                        )\n                         if option:\n                             options[option_name] = option\n-                order_with_respect_to = options.get('order_with_respect_to')\n+                order_with_respect_to = options.get(\"order_with_respect_to\")\n                 if order_with_respect_to == operation.name_lower:\n-                    del options['order_with_respect_to']\n+                    del options[\"order_with_respect_to\"]\n                 return [\n                     CreateModel(\n                         self.name,\n@@ -222,16 +268,19 @@ class CreateModel(ModelOperation):\n                 ]\n             elif isinstance(operation, RenameField):\n                 options = self.options.copy()\n-                for option_name in ('unique_together', 'index_together'):\n+                for option_name in (\"unique_together\", \"index_together\"):\n                     option = options.get(option_name)\n                     if option:\n                         options[option_name] = {\n-                            tuple(operation.new_name if f == operation.old_name else f for f in fields)\n+                            tuple(\n+                                operation.new_name if f == operation.old_name else f\n+                                for f in fields\n+                            )\n                             for fields in option\n                         }\n-                order_with_respect_to = options.get('order_with_respect_to')\n+                order_with_respect_to = options.get(\"order_with_respect_to\")\n                 if order_with_respect_to == operation.old_name:\n-                    options['order_with_respect_to'] = operation.new_name\n+                    options[\"order_with_respect_to\"] = operation.new_name\n                 return [\n                     CreateModel(\n                         self.name,\n@@ -252,13 +301,9 @@ class DeleteModel(ModelOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n+            \"name\": self.name,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n         state.remove_model(app_label, self.name_lower)\n@@ -283,7 +328,7 @@ class DeleteModel(ModelOperation):\n \n     @property\n     def migration_name_fragment(self):\n-        return 'delete_%s' % self.name_lower\n+        return \"delete_%s\" % self.name_lower\n \n \n class RenameModel(ModelOperation):\n@@ -304,14 +349,10 @@ class RenameModel(ModelOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'old_name': self.old_name,\n-            'new_name': self.new_name,\n+            \"old_name\": self.old_name,\n+            \"new_name\": self.new_name,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n         state.rename_model(app_label, self.old_name, self.new_name)\n@@ -321,6 +362,8 @@ class RenameModel(ModelOperation):\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n             # Move the main table\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             schema_editor.alter_db_table(\n                 new_model,\n                 old_model._meta.db_table,\n@@ -337,19 +380,24 @@ class RenameModel(ModelOperation):\n                         related_object.related_model._meta.app_label,\n                         related_object.related_model._meta.model_name,\n                     )\n-                to_field = to_state.apps.get_model(\n-                    *related_key\n-                )._meta.get_field(related_object.field.name)\n+                to_field = to_state.apps.get_model(*related_key)._meta.get_field(\n+                    related_object.field.name\n+                )\n                 schema_editor.alter_field(\n                     model,\n                     related_object.field,\n                     to_field,\n                 )\n             # Rename M2M fields whose name is based on this model's name.\n-            fields = zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many)\n-            for (old_field, new_field) in fields:\n+            fields = zip(\n+                old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n+            )\n+            for old_field, new_field in fields:\n                 # Skip self-referential fields as these are renamed above.\n-                if new_field.model == new_field.related_model or not new_field.remote_field.through._meta.auto_created:\n+                if (\n+                    new_field.model == new_field.related_model\n+                    or not new_field.remote_field.through._meta.auto_created\n+                ):\n                     continue\n                 # Rename the M2M table that's based on this model's name.\n                 old_m2m_model = old_field.remote_field.through\n@@ -368,18 +416,23 @@ class RenameModel(ModelOperation):\n                 )\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n-        self.new_name_lower, self.old_name_lower = self.old_name_lower, self.new_name_lower\n+        self.new_name_lower, self.old_name_lower = (\n+            self.old_name_lower,\n+            self.new_name_lower,\n+        )\n         self.new_name, self.old_name = self.old_name, self.new_name\n \n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n-        self.new_name_lower, self.old_name_lower = self.old_name_lower, self.new_name_lower\n+        self.new_name_lower, self.old_name_lower = (\n+            self.old_name_lower,\n+            self.new_name_lower,\n+        )\n         self.new_name, self.old_name = self.old_name, self.new_name\n \n     def references_model(self, name, app_label):\n         return (\n-            name.lower() == self.old_name_lower or\n-            name.lower() == self.new_name_lower\n+            name.lower() == self.old_name_lower or name.lower() == self.new_name_lower\n         )\n \n     def describe(self):\n@@ -387,11 +440,13 @@ class RenameModel(ModelOperation):\n \n     @property\n     def migration_name_fragment(self):\n-        return 'rename_%s_%s' % (self.old_name_lower, self.new_name_lower)\n+        return \"rename_%s_%s\" % (self.old_name_lower, self.new_name_lower)\n \n     def reduce(self, operation, app_label):\n-        if (isinstance(operation, RenameModel) and\n-                self.new_name_lower == operation.old_name_lower):\n+        if (\n+            isinstance(operation, RenameModel)\n+            and self.new_name_lower == operation.old_name_lower\n+        ):\n             return [\n                 RenameModel(\n                     self.old_name,\n@@ -400,15 +455,17 @@ class RenameModel(ModelOperation):\n             ]\n         # Skip `ModelOperation.reduce` as we want to run `references_model`\n         # against self.new_name.\n-        return (\n-            super(ModelOperation, self).reduce(operation, app_label) or\n-            not operation.references_model(self.new_name, app_label)\n-        )\n+        return super(ModelOperation, self).reduce(\n+            operation, app_label\n+        ) or not operation.references_model(self.new_name, app_label)\n \n \n class ModelOptionOperation(ModelOperation):\n     def reduce(self, operation, app_label):\n-        if isinstance(operation, (self.__class__, DeleteModel)) and self.name_lower == operation.name_lower:\n+        if (\n+            isinstance(operation, (self.__class__, DeleteModel))\n+            and self.name_lower == operation.name_lower\n+        ):\n             return [operation]\n         return super().reduce(operation, app_label)\n \n@@ -422,17 +479,13 @@ class AlterModelTable(ModelOptionOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n-            'table': self.table,\n+            \"name\": self.name,\n+            \"table\": self.table,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n-        state.alter_model_options(app_label, self.name_lower, {'db_table': self.table})\n+        state.alter_model_options(app_label, self.name_lower, {\"db_table\": self.table})\n \n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         new_model = to_state.apps.get_model(app_label, self.name)\n@@ -444,7 +497,9 @@ class AlterModelTable(ModelOptionOperation):\n                 new_model._meta.db_table,\n             )\n             # Rename M2M fields whose name is based on this model's db_table\n-            for (old_field, new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many):\n+            for old_field, new_field in zip(\n+                old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n+            ):\n                 if new_field.remote_field.through._meta.auto_created:\n                     schema_editor.alter_db_table(\n                         new_field.remote_field.through,\n@@ -458,12 +513,12 @@ class AlterModelTable(ModelOptionOperation):\n     def describe(self):\n         return \"Rename table for %s to %s\" % (\n             self.name,\n-            self.table if self.table is not None else \"(default)\"\n+            self.table if self.table is not None else \"(default)\",\n         )\n \n     @property\n     def migration_name_fragment(self):\n-        return 'alter_%s_table' % self.name_lower\n+        return \"alter_%s_table\" % self.name_lower\n \n \n class AlterTogetherOptionOperation(ModelOptionOperation):\n@@ -481,14 +536,10 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n+            \"name\": self.name,\n             self.option_name: self.option_value,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n         state.alter_model_options(\n@@ -501,7 +552,7 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n         new_model = to_state.apps.get_model(app_label, self.name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.name)\n-            alter_together = getattr(schema_editor, 'alter_%s' % self.option_name)\n+            alter_together = getattr(schema_editor, \"alter_%s\" % self.option_name)\n             alter_together(\n                 new_model,\n                 getattr(old_model._meta, self.option_name, set()),\n@@ -512,20 +563,21 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n         return self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n     def references_field(self, model_name, name, app_label):\n-        return (\n-            self.references_model(model_name, app_label) and\n-            (\n-                not self.option_value or\n-                any((name in fields) for fields in self.option_value)\n-            )\n+        return self.references_model(model_name, app_label) and (\n+            not self.option_value\n+            or any((name in fields) for fields in self.option_value)\n         )\n \n     def describe(self):\n-        return \"Alter %s for %s (%s constraint(s))\" % (self.option_name, self.name, len(self.option_value or ''))\n+        return \"Alter %s for %s (%s constraint(s))\" % (\n+            self.option_name,\n+            self.name,\n+            len(self.option_value or \"\"),\n+        )\n \n     @property\n     def migration_name_fragment(self):\n-        return 'alter_%s_%s' % (self.name_lower, self.option_name)\n+        return \"alter_%s_%s\" % (self.name_lower, self.option_name)\n \n \n class AlterUniqueTogether(AlterTogetherOptionOperation):\n@@ -533,7 +585,8 @@ class AlterUniqueTogether(AlterTogetherOptionOperation):\n     Change the value of unique_together to the target one.\n     Input value of unique_together must be a set of tuples.\n     \"\"\"\n-    option_name = 'unique_together'\n+\n+    option_name = \"unique_together\"\n \n     def __init__(self, name, unique_together):\n         super().__init__(name, unique_together)\n@@ -544,6 +597,7 @@ class AlterIndexTogether(AlterTogetherOptionOperation):\n     Change the value of index_together to the target one.\n     Input value of index_together must be a set of tuples.\n     \"\"\"\n+\n     option_name = \"index_together\"\n \n     def __init__(self, name, index_together):\n@@ -553,7 +607,7 @@ class AlterIndexTogether(AlterTogetherOptionOperation):\n class AlterOrderWithRespectTo(ModelOptionOperation):\n     \"\"\"Represent a change with the order_with_respect_to option.\"\"\"\n \n-    option_name = 'order_with_respect_to'\n+    option_name = \"order_with_respect_to\"\n \n     def __init__(self, name, order_with_respect_to):\n         self.order_with_respect_to = order_with_respect_to\n@@ -561,14 +615,10 @@ class AlterOrderWithRespectTo(ModelOptionOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n-            'order_with_respect_to': self.order_with_respect_to,\n+            \"name\": self.name,\n+            \"order_with_respect_to\": self.order_with_respect_to,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n         state.alter_model_options(\n@@ -582,11 +632,19 @@ class AlterOrderWithRespectTo(ModelOptionOperation):\n         if self.allow_migrate_model(schema_editor.connection.alias, to_model):\n             from_model = from_state.apps.get_model(app_label, self.name)\n             # Remove a field if we need to\n-            if from_model._meta.order_with_respect_to and not to_model._meta.order_with_respect_to:\n-                schema_editor.remove_field(from_model, from_model._meta.get_field(\"_order\"))\n+            if (\n+                from_model._meta.order_with_respect_to\n+                and not to_model._meta.order_with_respect_to\n+            ):\n+                schema_editor.remove_field(\n+                    from_model, from_model._meta.get_field(\"_order\")\n+                )\n             # Add a field if we need to (altering the column is untouched as\n             # it's likely a rename)\n-            elif to_model._meta.order_with_respect_to and not from_model._meta.order_with_respect_to:\n+            elif (\n+                to_model._meta.order_with_respect_to\n+                and not from_model._meta.order_with_respect_to\n+            ):\n                 field = to_model._meta.get_field(\"_order\")\n                 if not field.has_default():\n                     field.default = 0\n@@ -599,20 +657,19 @@ class AlterOrderWithRespectTo(ModelOptionOperation):\n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n     def references_field(self, model_name, name, app_label):\n-        return (\n-            self.references_model(model_name, app_label) and\n-            (\n-                self.order_with_respect_to is None or\n-                name == self.order_with_respect_to\n-            )\n+        return self.references_model(model_name, app_label) and (\n+            self.order_with_respect_to is None or name == self.order_with_respect_to\n         )\n \n     def describe(self):\n-        return \"Set order_with_respect_to on %s to %s\" % (self.name, self.order_with_respect_to)\n+        return \"Set order_with_respect_to on %s to %s\" % (\n+            self.name,\n+            self.order_with_respect_to,\n+        )\n \n     @property\n     def migration_name_fragment(self):\n-        return 'alter_%s_order_with_respect_to' % self.name_lower\n+        return \"alter_%s_order_with_respect_to\" % self.name_lower\n \n \n class AlterModelOptions(ModelOptionOperation):\n@@ -643,14 +700,10 @@ class AlterModelOptions(ModelOptionOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'name': self.name,\n-            'options': self.options,\n+            \"name\": self.name,\n+            \"options\": self.options,\n         }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n+        return (self.__class__.__qualname__, [], kwargs)\n \n     def state_forwards(self, app_label, state):\n         state.alter_model_options(\n@@ -671,24 +724,20 @@ class AlterModelOptions(ModelOptionOperation):\n \n     @property\n     def migration_name_fragment(self):\n-        return 'alter_%s_options' % self.name_lower\n+        return \"alter_%s_options\" % self.name_lower\n \n \n class AlterModelManagers(ModelOptionOperation):\n     \"\"\"Alter the model's managers.\"\"\"\n \n-    serialization_expand_args = ['managers']\n+    serialization_expand_args = [\"managers\"]\n \n     def __init__(self, name, managers):\n         self.managers = managers\n         super().__init__(name)\n \n     def deconstruct(self):\n-        return (\n-            self.__class__.__qualname__,\n-            [self.name, self.managers],\n-            {}\n-        )\n+        return (self.__class__.__qualname__, [self.name, self.managers], {})\n \n     def state_forwards(self, app_label, state):\n         state.alter_model_managers(app_label, self.name_lower, self.managers)\n@@ -704,11 +753,11 @@ class AlterModelManagers(ModelOptionOperation):\n \n     @property\n     def migration_name_fragment(self):\n-        return 'alter_%s_managers' % self.name_lower\n+        return \"alter_%s_managers\" % self.name_lower\n \n \n class IndexOperation(Operation):\n-    option_name = 'indexes'\n+    option_name = \"indexes\"\n \n     @cached_property\n     def model_name_lower(self):\n@@ -742,8 +791,8 @@ class AddIndex(IndexOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'model_name': self.model_name,\n-            'index': self.index,\n+            \"model_name\": self.model_name,\n+            \"index\": self.index,\n         }\n         return (\n             self.__class__.__qualname__,\n@@ -753,20 +802,20 @@ class AddIndex(IndexOperation):\n \n     def describe(self):\n         if self.index.expressions:\n-            return 'Create index %s on %s on model %s' % (\n+            return \"Create index %s on %s on model %s\" % (\n                 self.index.name,\n-                ', '.join([str(expression) for expression in self.index.expressions]),\n+                \", \".join([str(expression) for expression in self.index.expressions]),\n                 self.model_name,\n             )\n-        return 'Create index %s on field(s) %s of model %s' % (\n+        return \"Create index %s on field(s) %s of model %s\" % (\n             self.index.name,\n-            ', '.join(self.index.fields),\n+            \", \".join(self.index.fields),\n             self.model_name,\n         )\n \n     @property\n     def migration_name_fragment(self):\n-        return '%s_%s' % (self.model_name_lower, self.index.name.lower())\n+        return \"%s_%s\" % (self.model_name_lower, self.index.name.lower())\n \n \n class RemoveIndex(IndexOperation):\n@@ -795,8 +844,8 @@ class RemoveIndex(IndexOperation):\n \n     def deconstruct(self):\n         kwargs = {\n-            'model_name': self.model_name,\n-            'name': self.name,\n+            \"model_name\": self.model_name,\n+            \"name\": self.name,\n         }\n         return (\n             self.__class__.__qualname__,\n@@ -805,15 +854,15 @@ class RemoveIndex(IndexOperation):\n         )\n \n     def describe(self):\n-        return 'Remove index %s from %s' % (self.name, self.model_name)\n+        return \"Remove index %s from %s\" % (self.name, self.model_name)\n \n     @property\n     def migration_name_fragment(self):\n-        return 'remove_%s_%s' % (self.model_name_lower, self.name.lower())\n+        return \"remove_%s_%s\" % (self.model_name_lower, self.name.lower())\n \n \n class AddConstraint(IndexOperation):\n-    option_name = 'constraints'\n+    option_name = \"constraints\"\n \n     def __init__(self, model_name, constraint):\n         self.model_name = model_name\n@@ -833,21 +882,28 @@ class AddConstraint(IndexOperation):\n             schema_editor.remove_constraint(model, self.constraint)\n \n     def deconstruct(self):\n-        return self.__class__.__name__, [], {\n-            'model_name': self.model_name,\n-            'constraint': self.constraint,\n-        }\n+        return (\n+            self.__class__.__name__,\n+            [],\n+            {\n+                \"model_name\": self.model_name,\n+                \"constraint\": self.constraint,\n+            },\n+        )\n \n     def describe(self):\n-        return 'Create constraint %s on model %s' % (self.constraint.name, self.model_name)\n+        return \"Create constraint %s on model %s\" % (\n+            self.constraint.name,\n+            self.model_name,\n+        )\n \n     @property\n     def migration_name_fragment(self):\n-        return '%s_%s' % (self.model_name_lower, self.constraint.name.lower())\n+        return \"%s_%s\" % (self.model_name_lower, self.constraint.name.lower())\n \n \n class RemoveConstraint(IndexOperation):\n-    option_name = 'constraints'\n+    option_name = \"constraints\"\n \n     def __init__(self, model_name, name):\n         self.model_name = model_name\n@@ -871,14 +927,18 @@ class RemoveConstraint(IndexOperation):\n             schema_editor.add_constraint(model, constraint)\n \n     def deconstruct(self):\n-        return self.__class__.__name__, [], {\n-            'model_name': self.model_name,\n-            'name': self.name,\n-        }\n+        return (\n+            self.__class__.__name__,\n+            [],\n+            {\n+                \"model_name\": self.model_name,\n+                \"name\": self.name,\n+            },\n+        )\n \n     def describe(self):\n-        return 'Remove constraint %s from model %s' % (self.name, self.model_name)\n+        return \"Remove constraint %s from model %s\" % (self.name, self.model_name)\n \n     @property\n     def migration_name_fragment(self):\n-        return 'remove_%s_%s' % (self.model_name_lower, self.name.lower())\n+        return \"remove_%s_%s\" % (self.model_name_lower, self.name.lower())\n"}
{"instance_id": "django__django-15061", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..c34e5bf0e6 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -18,23 +18,43 @@ from django.utils.html import format_html, html_safe\n from django.utils.regex_helper import _lazy_re_compile\n from django.utils.safestring import mark_safe\n from django.utils.topological_sort import (\n-    CyclicDependencyError, stable_topological_sort,\n+    CyclicDependencyError,\n+    stable_topological_sort,\n )\n from django.utils.translation import gettext_lazy as _\n \n from .renderers import get_default_renderer\n \n __all__ = (\n-    'Media', 'MediaDefiningClass', 'Widget', 'TextInput', 'NumberInput',\n-    'EmailInput', 'URLInput', 'PasswordInput', 'HiddenInput',\n-    'MultipleHiddenInput', 'FileInput', 'ClearableFileInput', 'Textarea',\n-    'DateInput', 'DateTimeInput', 'TimeInput', 'CheckboxInput', 'Select',\n-    'NullBooleanSelect', 'SelectMultiple', 'RadioSelect',\n-    'CheckboxSelectMultiple', 'MultiWidget', 'SplitDateTimeWidget',\n-    'SplitHiddenDateTimeWidget', 'SelectDateWidget',\n+    \"Media\",\n+    \"MediaDefiningClass\",\n+    \"Widget\",\n+    \"TextInput\",\n+    \"NumberInput\",\n+    \"EmailInput\",\n+    \"URLInput\",\n+    \"PasswordInput\",\n+    \"HiddenInput\",\n+    \"MultipleHiddenInput\",\n+    \"FileInput\",\n+    \"ClearableFileInput\",\n+    \"Textarea\",\n+    \"DateInput\",\n+    \"DateTimeInput\",\n+    \"TimeInput\",\n+    \"CheckboxInput\",\n+    \"Select\",\n+    \"NullBooleanSelect\",\n+    \"SelectMultiple\",\n+    \"RadioSelect\",\n+    \"CheckboxSelectMultiple\",\n+    \"MultiWidget\",\n+    \"SplitDateTimeWidget\",\n+    \"SplitHiddenDateTimeWidget\",\n+    \"SelectDateWidget\",\n )\n \n-MEDIA_TYPES = ('css', 'js')\n+MEDIA_TYPES = (\"css\", \"js\")\n \n \n class MediaOrderConflictWarning(RuntimeWarning):\n@@ -45,8 +65,8 @@ class MediaOrderConflictWarning(RuntimeWarning):\n class Media:\n     def __init__(self, media=None, css=None, js=None):\n         if media is not None:\n-            css = getattr(media, 'css', {})\n-            js = getattr(media, 'js', [])\n+            css = getattr(media, \"css\", {})\n+            js = getattr(media, \"js\", [])\n         else:\n             if css is None:\n                 css = {}\n@@ -56,7 +76,7 @@ class Media:\n         self._js_lists = [js]\n \n     def __repr__(self):\n-        return 'Media(css=%r, js=%r)' % (self._css, self._js)\n+        return \"Media(css=%r, js=%r)\" % (self._css, self._js)\n \n     def __str__(self):\n         return self.render()\n@@ -74,26 +94,35 @@ class Media:\n         return self.merge(*self._js_lists)\n \n     def render(self):\n-        return mark_safe('\\n'.join(chain.from_iterable(getattr(self, 'render_' + name)() for name in MEDIA_TYPES)))\n+        return mark_safe(\n+            \"\\n\".join(\n+                chain.from_iterable(\n+                    getattr(self, \"render_\" + name)() for name in MEDIA_TYPES\n+                )\n+            )\n+        )\n \n     def render_js(self):\n         return [\n-            format_html(\n-                '<script src=\"{}\"></script>',\n-                self.absolute_path(path)\n-            ) for path in self._js\n+            format_html('<script src=\"{}\"></script>', self.absolute_path(path))\n+            for path in self._js\n         ]\n \n     def render_css(self):\n         # To keep rendering order consistent, we can't just iterate over items().\n         # We need to sort the keys, and iterate over the sorted list.\n         media = sorted(self._css)\n-        return chain.from_iterable([\n-            format_html(\n-                '<link href=\"{}\" type=\"text/css\" media=\"{}\" rel=\"stylesheet\">',\n-                self.absolute_path(path), medium\n-            ) for path in self._css[medium]\n-        ] for medium in media)\n+        return chain.from_iterable(\n+            [\n+                format_html(\n+                    '<link href=\"{}\" type=\"text/css\" media=\"{}\" rel=\"stylesheet\">',\n+                    self.absolute_path(path),\n+                    medium,\n+                )\n+                for path in self._css[medium]\n+            ]\n+            for medium in media\n+        )\n \n     def absolute_path(self, path):\n         \"\"\"\n@@ -101,14 +130,14 @@ class Media:\n         path. An absolute path will be returned unchanged while a relative path\n         will be passed to django.templatetags.static.static().\n         \"\"\"\n-        if path.startswith(('http://', 'https://', '/')):\n+        if path.startswith((\"http://\", \"https://\", \"/\")):\n             return path\n         return static(path)\n \n     def __getitem__(self, name):\n         \"\"\"Return a Media object that only contains media of the given type.\"\"\"\n         if name in MEDIA_TYPES:\n-            return Media(**{str(name): getattr(self, '_' + name)})\n+            return Media(**{str(name): getattr(self, \"_\" + name)})\n         raise KeyError('Unknown media type \"%s\"' % name)\n \n     @staticmethod\n@@ -138,9 +167,10 @@ class Media:\n             return stable_topological_sort(all_items, dependency_graph)\n         except CyclicDependencyError:\n             warnings.warn(\n-                'Detected duplicate Media files in an opposite order: {}'.format(\n-                    ', '.join(repr(list_) for list_ in lists)\n-                ), MediaOrderConflictWarning,\n+                \"Detected duplicate Media files in an opposite order: {}\".format(\n+                    \", \".join(repr(list_) for list_ in lists)\n+                ),\n+                MediaOrderConflictWarning,\n             )\n             return list(all_items)\n \n@@ -167,9 +197,9 @@ def media_property(cls):\n             base = Media()\n \n         # Get the media definition for this class\n-        definition = getattr(cls, 'Media', None)\n+        definition = getattr(cls, \"Media\", None)\n         if definition:\n-            extend = getattr(definition, 'extend', True)\n+            extend = getattr(definition, \"extend\", True)\n             if extend:\n                 if extend is True:\n                     m = base\n@@ -180,6 +210,7 @@ def media_property(cls):\n                 return m + Media(definition)\n             return Media(definition)\n         return base\n+\n     return property(_media)\n \n \n@@ -187,10 +218,11 @@ class MediaDefiningClass(type):\n     \"\"\"\n     Metaclass for classes that can have media definitions.\n     \"\"\"\n+\n     def __new__(mcs, name, bases, attrs):\n         new_class = super().__new__(mcs, name, bases, attrs)\n \n-        if 'media' not in attrs:\n+        if \"media\" not in attrs:\n             new_class.media = media_property(new_class)\n \n         return new_class\n@@ -213,17 +245,17 @@ class Widget(metaclass=MediaDefiningClass):\n \n     @property\n     def is_hidden(self):\n-        return self.input_type == 'hidden' if hasattr(self, 'input_type') else False\n+        return self.input_type == \"hidden\" if hasattr(self, \"input_type\") else False\n \n     def subwidgets(self, name, value, attrs=None):\n         context = self.get_context(name, value, attrs)\n-        yield context['widget']\n+        yield context[\"widget\"]\n \n     def format_value(self, value):\n         \"\"\"\n         Return a value as it should appear when rendered in a template.\n         \"\"\"\n-        if value == '' or value is None:\n+        if value == \"\" or value is None:\n             return None\n         if self.is_localized:\n             return formats.localize_input(value)\n@@ -231,13 +263,13 @@ class Widget(metaclass=MediaDefiningClass):\n \n     def get_context(self, name, value, attrs):\n         return {\n-            'widget': {\n-                'name': name,\n-                'is_hidden': self.is_hidden,\n-                'required': self.is_required,\n-                'value': self.format_value(value),\n-                'attrs': self.build_attrs(self.attrs, attrs),\n-                'template_name': self.template_name,\n+            \"widget\": {\n+                \"name\": name,\n+                \"is_hidden\": self.is_hidden,\n+                \"required\": self.is_required,\n+                \"value\": self.format_value(value),\n+                \"attrs\": self.build_attrs(self.attrs, attrs),\n+                \"template_name\": self.template_name,\n             },\n         }\n \n@@ -285,44 +317,45 @@ class Input(Widget):\n     \"\"\"\n     Base class for all <input> widgets.\n     \"\"\"\n+\n     input_type = None  # Subclasses must define this.\n-    template_name = 'django/forms/widgets/input.html'\n+    template_name = \"django/forms/widgets/input.html\"\n \n     def __init__(self, attrs=None):\n         if attrs is not None:\n             attrs = attrs.copy()\n-            self.input_type = attrs.pop('type', self.input_type)\n+            self.input_type = attrs.pop(\"type\", self.input_type)\n         super().__init__(attrs)\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        context['widget']['type'] = self.input_type\n+        context[\"widget\"][\"type\"] = self.input_type\n         return context\n \n \n class TextInput(Input):\n-    input_type = 'text'\n-    template_name = 'django/forms/widgets/text.html'\n+    input_type = \"text\"\n+    template_name = \"django/forms/widgets/text.html\"\n \n \n class NumberInput(Input):\n-    input_type = 'number'\n-    template_name = 'django/forms/widgets/number.html'\n+    input_type = \"number\"\n+    template_name = \"django/forms/widgets/number.html\"\n \n \n class EmailInput(Input):\n-    input_type = 'email'\n-    template_name = 'django/forms/widgets/email.html'\n+    input_type = \"email\"\n+    template_name = \"django/forms/widgets/email.html\"\n \n \n class URLInput(Input):\n-    input_type = 'url'\n-    template_name = 'django/forms/widgets/url.html'\n+    input_type = \"url\"\n+    template_name = \"django/forms/widgets/url.html\"\n \n \n class PasswordInput(Input):\n-    input_type = 'password'\n-    template_name = 'django/forms/widgets/password.html'\n+    input_type = \"password\"\n+    template_name = \"django/forms/widgets/password.html\"\n \n     def __init__(self, attrs=None, render_value=False):\n         super().__init__(attrs)\n@@ -335,8 +368,8 @@ class PasswordInput(Input):\n \n \n class HiddenInput(Input):\n-    input_type = 'hidden'\n-    template_name = 'django/forms/widgets/hidden.html'\n+    input_type = \"hidden\"\n+    template_name = \"django/forms/widgets/hidden.html\"\n \n \n class MultipleHiddenInput(HiddenInput):\n@@ -344,25 +377,26 @@ class MultipleHiddenInput(HiddenInput):\n     Handle <input type=\"hidden\"> for fields that have a list\n     of values.\n     \"\"\"\n-    template_name = 'django/forms/widgets/multiple_hidden.html'\n+\n+    template_name = \"django/forms/widgets/multiple_hidden.html\"\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        final_attrs = context['widget']['attrs']\n-        id_ = context['widget']['attrs'].get('id')\n+        final_attrs = context[\"widget\"][\"attrs\"]\n+        id_ = context[\"widget\"][\"attrs\"].get(\"id\")\n \n         subwidgets = []\n-        for index, value_ in enumerate(context['widget']['value']):\n+        for index, value_ in enumerate(context[\"widget\"][\"value\"]):\n             widget_attrs = final_attrs.copy()\n             if id_:\n                 # An ID attribute was given. Add a numeric index as a suffix\n                 # so that the inputs don't all have the same ID attribute.\n-                widget_attrs['id'] = '%s_%s' % (id_, index)\n+                widget_attrs[\"id\"] = \"%s_%s\" % (id_, index)\n             widget = HiddenInput()\n             widget.is_required = self.is_required\n-            subwidgets.append(widget.get_context(name, value_, widget_attrs)['widget'])\n+            subwidgets.append(widget.get_context(name, value_, widget_attrs)[\"widget\"])\n \n-        context['widget']['subwidgets'] = subwidgets\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n     def value_from_datadict(self, data, files, name):\n@@ -377,9 +411,9 @@ class MultipleHiddenInput(HiddenInput):\n \n \n class FileInput(Input):\n-    input_type = 'file'\n+    input_type = \"file\"\n     needs_multipart_form = True\n-    template_name = 'django/forms/widgets/file.html'\n+    template_name = \"django/forms/widgets/file.html\"\n \n     def format_value(self, value):\n         \"\"\"File input never renders a value.\"\"\"\n@@ -400,29 +434,29 @@ FILE_INPUT_CONTRADICTION = object()\n \n \n class ClearableFileInput(FileInput):\n-    clear_checkbox_label = _('Clear')\n-    initial_text = _('Currently')\n-    input_text = _('Change')\n-    template_name = 'django/forms/widgets/clearable_file_input.html'\n+    clear_checkbox_label = _(\"Clear\")\n+    initial_text = _(\"Currently\")\n+    input_text = _(\"Change\")\n+    template_name = \"django/forms/widgets/clearable_file_input.html\"\n \n     def clear_checkbox_name(self, name):\n         \"\"\"\n         Given the name of the file input, return the name of the clear checkbox\n         input.\n         \"\"\"\n-        return name + '-clear'\n+        return name + \"-clear\"\n \n     def clear_checkbox_id(self, name):\n         \"\"\"\n         Given the name of the clear checkbox input, return the HTML id for it.\n         \"\"\"\n-        return name + '_id'\n+        return name + \"_id\"\n \n     def is_initial(self, value):\n         \"\"\"\n         Return whether value is considered to be initial value.\n         \"\"\"\n-        return bool(value and getattr(value, 'url', False))\n+        return bool(value and getattr(value, \"url\", False))\n \n     def format_value(self, value):\n         \"\"\"\n@@ -435,21 +469,23 @@ class ClearableFileInput(FileInput):\n         context = super().get_context(name, value, attrs)\n         checkbox_name = self.clear_checkbox_name(name)\n         checkbox_id = self.clear_checkbox_id(checkbox_name)\n-        context['widget'].update({\n-            'checkbox_name': checkbox_name,\n-            'checkbox_id': checkbox_id,\n-            'is_initial': self.is_initial(value),\n-            'input_text': self.input_text,\n-            'initial_text': self.initial_text,\n-            'clear_checkbox_label': self.clear_checkbox_label,\n-        })\n+        context[\"widget\"].update(\n+            {\n+                \"checkbox_name\": checkbox_name,\n+                \"checkbox_id\": checkbox_id,\n+                \"is_initial\": self.is_initial(value),\n+                \"input_text\": self.input_text,\n+                \"initial_text\": self.initial_text,\n+                \"clear_checkbox_label\": self.clear_checkbox_label,\n+            }\n+        )\n         return context\n \n     def value_from_datadict(self, data, files, name):\n         upload = super().value_from_datadict(data, files, name)\n         if not self.is_required and CheckboxInput().value_from_datadict(\n-                data, files, self.clear_checkbox_name(name)):\n-\n+            data, files, self.clear_checkbox_name(name)\n+        ):\n             if upload:\n                 # If the user contradicts themselves (uploads a new file AND\n                 # checks the \"clear\" checkbox), we return a unique marker\n@@ -461,24 +497,24 @@ class ClearableFileInput(FileInput):\n \n     def value_omitted_from_data(self, data, files, name):\n         return (\n-            super().value_omitted_from_data(data, files, name) and\n-            self.clear_checkbox_name(name) not in data\n+            super().value_omitted_from_data(data, files, name)\n+            and self.clear_checkbox_name(name) not in data\n         )\n \n \n class Textarea(Widget):\n-    template_name = 'django/forms/widgets/textarea.html'\n+    template_name = \"django/forms/widgets/textarea.html\"\n \n     def __init__(self, attrs=None):\n         # Use slightly better defaults than HTML's 20x2 box\n-        default_attrs = {'cols': '40', 'rows': '10'}\n+        default_attrs = {\"cols\": \"40\", \"rows\": \"10\"}\n         if attrs:\n             default_attrs.update(attrs)\n         super().__init__(default_attrs)\n \n \n class DateTimeBaseInput(TextInput):\n-    format_key = ''\n+    format_key = \"\"\n     supports_microseconds = False\n \n     def __init__(self, attrs=None, format=None):\n@@ -486,32 +522,34 @@ class DateTimeBaseInput(TextInput):\n         self.format = format or None\n \n     def format_value(self, value):\n-        return formats.localize_input(value, self.format or formats.get_format(self.format_key)[0])\n+        return formats.localize_input(\n+            value, self.format or formats.get_format(self.format_key)[0]\n+        )\n \n \n class DateInput(DateTimeBaseInput):\n-    format_key = 'DATE_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/date.html'\n+    format_key = \"DATE_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/date.html\"\n \n \n class DateTimeInput(DateTimeBaseInput):\n-    format_key = 'DATETIME_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/datetime.html'\n+    format_key = \"DATETIME_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/datetime.html\"\n \n \n class TimeInput(DateTimeBaseInput):\n-    format_key = 'TIME_INPUT_FORMATS'\n-    template_name = 'django/forms/widgets/time.html'\n+    format_key = \"TIME_INPUT_FORMATS\"\n+    template_name = \"django/forms/widgets/time.html\"\n \n \n # Defined at module level so that CheckboxInput is picklable (#17976)\n def boolean_check(v):\n-    return not (v is False or v is None or v == '')\n+    return not (v is False or v is None or v == \"\")\n \n \n class CheckboxInput(Input):\n-    input_type = 'checkbox'\n-    template_name = 'django/forms/widgets/checkbox.html'\n+    input_type = \"checkbox\"\n+    template_name = \"django/forms/widgets/checkbox.html\"\n \n     def __init__(self, attrs=None, check_test=None):\n         super().__init__(attrs)\n@@ -521,13 +559,13 @@ class CheckboxInput(Input):\n \n     def format_value(self, value):\n         \"\"\"Only return the 'value' attribute if value isn't empty.\"\"\"\n-        if value is True or value is False or value is None or value == '':\n+        if value is True or value is False or value is None or value == \"\":\n             return\n         return str(value)\n \n     def get_context(self, name, value, attrs):\n         if self.check_test(value):\n-            attrs = {**(attrs or {}), 'checked': True}\n+            attrs = {**(attrs or {}), \"checked\": True}\n         return super().get_context(name, value, attrs)\n \n     def value_from_datadict(self, data, files, name):\n@@ -537,7 +575,7 @@ class CheckboxInput(Input):\n             return False\n         value = data.get(name)\n         # Translate true and false strings to boolean values.\n-        values = {'true': True, 'false': False}\n+        values = {\"true\": True, \"false\": False}\n         if isinstance(value, str):\n             value = values.get(value.lower(), value)\n         return bool(value)\n@@ -554,7 +592,7 @@ class ChoiceWidget(Widget):\n     template_name = None\n     option_template_name = None\n     add_id_index = True\n-    checked_attribute = {'checked': True}\n+    checked_attribute = {\"checked\": True}\n     option_inherits_attrs = True\n \n     def __init__(self, attrs=None, choices=()):\n@@ -591,7 +629,7 @@ class ChoiceWidget(Widget):\n \n         for index, (option_value, option_label) in enumerate(self.choices):\n             if option_value is None:\n-                option_value = ''\n+                option_value = \"\"\n \n             subgroup = []\n             if isinstance(option_label, (list, tuple)):\n@@ -605,50 +643,62 @@ class ChoiceWidget(Widget):\n             groups.append((group_name, subgroup, index))\n \n             for subvalue, sublabel in choices:\n-                selected = (\n-                    (not has_selected or self.allow_multiple_selected) and\n-                    str(subvalue) in value\n-                )\n+                selected = (not has_selected or self.allow_multiple_selected) and str(\n+                    subvalue\n+                ) in value\n                 has_selected |= selected\n-                subgroup.append(self.create_option(\n-                    name, subvalue, sublabel, selected, index,\n-                    subindex=subindex, attrs=attrs,\n-                ))\n+                subgroup.append(\n+                    self.create_option(\n+                        name,\n+                        subvalue,\n+                        sublabel,\n+                        selected,\n+                        index,\n+                        subindex=subindex,\n+                        attrs=attrs,\n+                    )\n+                )\n                 if subindex is not None:\n                     subindex += 1\n         return groups\n \n-    def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n+    def create_option(\n+        self, name, value, label, selected, index, subindex=None, attrs=None\n+    ):\n         index = str(index) if subindex is None else \"%s_%s\" % (index, subindex)\n-        option_attrs = self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n+        option_attrs = (\n+            self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n+        )\n         if selected:\n             option_attrs.update(self.checked_attribute)\n-        if 'id' in option_attrs:\n-            option_attrs['id'] = self.id_for_label(option_attrs['id'], index)\n+        if \"id\" in option_attrs:\n+            option_attrs[\"id\"] = self.id_for_label(option_attrs[\"id\"], index)\n         return {\n-            'name': name,\n-            'value': value,\n-            'label': label,\n-            'selected': selected,\n-            'index': index,\n-            'attrs': option_attrs,\n-            'type': self.input_type,\n-            'template_name': self.option_template_name,\n-            'wrap_label': True,\n+            \"name\": name,\n+            \"value\": value,\n+            \"label\": label,\n+            \"selected\": selected,\n+            \"index\": index,\n+            \"attrs\": option_attrs,\n+            \"type\": self.input_type,\n+            \"template_name\": self.option_template_name,\n+            \"wrap_label\": True,\n         }\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n-        context['widget']['optgroups'] = self.optgroups(name, context['widget']['value'], attrs)\n+        context[\"widget\"][\"optgroups\"] = self.optgroups(\n+            name, context[\"widget\"][\"value\"], attrs\n+        )\n         return context\n \n-    def id_for_label(self, id_, index='0'):\n+    def id_for_label(self, id_, index=\"0\"):\n         \"\"\"\n         Use an incremented id for each option where the main widget\n         references the zero index.\n         \"\"\"\n         if id_ and self.add_id_index:\n-            id_ = '%s_%s' % (id_, index)\n+            id_ = \"%s_%s\" % (id_, index)\n         return id_\n \n     def value_from_datadict(self, data, files, name):\n@@ -666,28 +716,28 @@ class ChoiceWidget(Widget):\n             return []\n         if not isinstance(value, (tuple, list)):\n             value = [value]\n-        return [str(v) if v is not None else '' for v in value]\n+        return [str(v) if v is not None else \"\" for v in value]\n \n \n class Select(ChoiceWidget):\n-    input_type = 'select'\n-    template_name = 'django/forms/widgets/select.html'\n-    option_template_name = 'django/forms/widgets/select_option.html'\n+    input_type = \"select\"\n+    template_name = \"django/forms/widgets/select.html\"\n+    option_template_name = \"django/forms/widgets/select_option.html\"\n     add_id_index = False\n-    checked_attribute = {'selected': True}\n+    checked_attribute = {\"selected\": True}\n     option_inherits_attrs = False\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         if self.allow_multiple_selected:\n-            context['widget']['attrs']['multiple'] = True\n+            context[\"widget\"][\"attrs\"][\"multiple\"] = True\n         return context\n \n     @staticmethod\n     def _choice_has_empty_value(choice):\n         \"\"\"Return True if the choice's value is empty string or None.\"\"\"\n         value, _ = choice\n-        return value is None or value == ''\n+        return value is None or value == \"\"\n \n     def use_required_attribute(self, initial):\n         \"\"\"\n@@ -700,44 +750,52 @@ class Select(ChoiceWidget):\n             return use_required_attribute\n \n         first_choice = next(iter(self.choices), None)\n-        return use_required_attribute and first_choice is not None and self._choice_has_empty_value(first_choice)\n+        return (\n+            use_required_attribute\n+            and first_choice is not None\n+            and self._choice_has_empty_value(first_choice)\n+        )\n \n \n class NullBooleanSelect(Select):\n     \"\"\"\n     A Select Widget intended to be used with NullBooleanField.\n     \"\"\"\n+\n     def __init__(self, attrs=None):\n         choices = (\n-            ('unknown', _('Unknown')),\n-            ('true', _('Yes')),\n-            ('false', _('No')),\n+            (\"unknown\", _(\"Unknown\")),\n+            (\"true\", _(\"Yes\")),\n+            (\"false\", _(\"No\")),\n         )\n         super().__init__(attrs, choices)\n \n     def format_value(self, value):\n         try:\n             return {\n-                True: 'true', False: 'false',\n-                'true': 'true', 'false': 'false',\n+                True: \"true\",\n+                False: \"false\",\n+                \"true\": \"true\",\n+                \"false\": \"false\",\n                 # For backwards compatibility with Django < 2.2.\n-                '2': 'true', '3': 'false',\n+                \"2\": \"true\",\n+                \"3\": \"false\",\n             }[value]\n         except KeyError:\n-            return 'unknown'\n+            return \"unknown\"\n \n     def value_from_datadict(self, data, files, name):\n         value = data.get(name)\n         return {\n             True: True,\n-            'True': True,\n-            'False': False,\n+            \"True\": True,\n+            \"False\": False,\n             False: False,\n-            'true': True,\n-            'false': False,\n+            \"true\": True,\n+            \"false\": False,\n             # For backwards compatibility with Django < 2.2.\n-            '2': True,\n-            '3': False,\n+            \"2\": True,\n+            \"3\": False,\n         }.get(value)\n \n \n@@ -758,9 +816,9 @@ class SelectMultiple(Select):\n \n \n class RadioSelect(ChoiceWidget):\n-    input_type = 'radio'\n-    template_name = 'django/forms/widgets/radio.html'\n-    option_template_name = 'django/forms/widgets/radio_option.html'\n+    input_type = \"radio\"\n+    template_name = \"django/forms/widgets/radio.html\"\n+    option_template_name = \"django/forms/widgets/radio_option.html\"\n \n     def id_for_label(self, id_, index=None):\n         \"\"\"\n@@ -769,15 +827,15 @@ class RadioSelect(ChoiceWidget):\n         the first input.\n         \"\"\"\n         if index is None:\n-            return ''\n+            return \"\"\n         return super().id_for_label(id_, index)\n \n \n class CheckboxSelectMultiple(RadioSelect):\n     allow_multiple_selected = True\n-    input_type = 'checkbox'\n-    template_name = 'django/forms/widgets/checkbox_select.html'\n-    option_template_name = 'django/forms/widgets/checkbox_option.html'\n+    input_type = \"checkbox\"\n+    template_name = \"django/forms/widgets/checkbox_select.html\"\n+    option_template_name = \"django/forms/widgets/checkbox_option.html\"\n \n     def use_required_attribute(self, initial):\n         # Don't use the 'required' attribute because browser validation would\n@@ -800,16 +858,15 @@ class MultiWidget(Widget):\n \n     You'll probably want to use this class with MultiValueField.\n     \"\"\"\n-    template_name = 'django/forms/widgets/multiwidget.html'\n+\n+    template_name = \"django/forms/widgets/multiwidget.html\"\n \n     def __init__(self, widgets, attrs=None):\n         if isinstance(widgets, dict):\n-            self.widgets_names = [\n-                ('_%s' % name) if name else '' for name in widgets\n-            ]\n+            self.widgets_names = [(\"_%s\" % name) if name else \"\" for name in widgets]\n             widgets = widgets.values()\n         else:\n-            self.widgets_names = ['_%s' % i for i in range(len(widgets))]\n+            self.widgets_names = [\"_%s\" % i for i in range(len(widgets))]\n         self.widgets = [w() if isinstance(w, type) else w for w in widgets]\n         super().__init__(attrs)\n \n@@ -827,11 +884,13 @@ class MultiWidget(Widget):\n         if not isinstance(value, list):\n             value = self.decompress(value)\n \n-        final_attrs = context['widget']['attrs']\n-        input_type = final_attrs.pop('type', None)\n-        id_ = final_attrs.get('id')\n+        final_attrs = context[\"widget\"][\"attrs\"]\n+        input_type = final_attrs.pop(\"type\", None)\n+        id_ = final_attrs.get(\"id\")\n         subwidgets = []\n-        for i, (widget_name, widget) in enumerate(zip(self.widgets_names, self.widgets)):\n+        for i, (widget_name, widget) in enumerate(\n+            zip(self.widgets_names, self.widgets)\n+        ):\n             if input_type is not None:\n                 widget.input_type = input_type\n             widget_name = name + widget_name\n@@ -841,18 +900,15 @@ class MultiWidget(Widget):\n                 widget_value = None\n             if id_:\n                 widget_attrs = final_attrs.copy()\n-                widget_attrs['id'] = '%s_%s' % (id_, i)\n+                widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)\n             else:\n                 widget_attrs = final_attrs\n-            subwidgets.append(widget.get_context(widget_name, widget_value, widget_attrs)['widget'])\n-        context['widget']['subwidgets'] = subwidgets\n+            subwidgets.append(\n+                widget.get_context(widget_name, widget_value, widget_attrs)[\"widget\"]\n+            )\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n-\n     def value_from_datadict(self, data, files, name):\n         return [\n             widget.value_from_datadict(data, files, name + widget_name)\n@@ -871,7 +927,7 @@ class MultiWidget(Widget):\n         The given value can be assumed to be valid, but not necessarily\n         non-empty.\n         \"\"\"\n-        raise NotImplementedError('Subclasses must implement this method.')\n+        raise NotImplementedError(\"Subclasses must implement this method.\")\n \n     def _get_media(self):\n         \"\"\"\n@@ -882,6 +938,7 @@ class MultiWidget(Widget):\n         for w in self.widgets:\n             media = media + w.media\n         return media\n+\n     media = property(_get_media)\n \n     def __deepcopy__(self, memo):\n@@ -898,10 +955,18 @@ class SplitDateTimeWidget(MultiWidget):\n     \"\"\"\n     A widget that splits datetime input into two <input type=\"text\"> boxes.\n     \"\"\"\n-    supports_microseconds = False\n-    template_name = 'django/forms/widgets/splitdatetime.html'\n \n-    def __init__(self, attrs=None, date_format=None, time_format=None, date_attrs=None, time_attrs=None):\n+    supports_microseconds = False\n+    template_name = \"django/forms/widgets/splitdatetime.html\"\n+\n+    def __init__(\n+        self,\n+        attrs=None,\n+        date_format=None,\n+        time_format=None,\n+        date_attrs=None,\n+        time_attrs=None,\n+    ):\n         widgets = (\n             DateInput(\n                 attrs=attrs if date_attrs is None else date_attrs,\n@@ -925,12 +990,20 @@ class SplitHiddenDateTimeWidget(SplitDateTimeWidget):\n     \"\"\"\n     A widget that splits datetime input into two <input type=\"hidden\"> inputs.\n     \"\"\"\n-    template_name = 'django/forms/widgets/splithiddendatetime.html'\n \n-    def __init__(self, attrs=None, date_format=None, time_format=None, date_attrs=None, time_attrs=None):\n+    template_name = \"django/forms/widgets/splithiddendatetime.html\"\n+\n+    def __init__(\n+        self,\n+        attrs=None,\n+        date_format=None,\n+        time_format=None,\n+        date_attrs=None,\n+        time_attrs=None,\n+    ):\n         super().__init__(attrs, date_format, time_format, date_attrs, time_attrs)\n         for widget in self.widgets:\n-            widget.input_type = 'hidden'\n+            widget.input_type = \"hidden\"\n \n \n class SelectDateWidget(Widget):\n@@ -940,14 +1013,15 @@ class SelectDateWidget(Widget):\n     This also serves as an example of a Widget that has more than one HTML\n     element and hence implements value_from_datadict.\n     \"\"\"\n-    none_value = ('', '---')\n-    month_field = '%s_month'\n-    day_field = '%s_day'\n-    year_field = '%s_year'\n-    template_name = 'django/forms/widgets/select_date.html'\n-    input_type = 'select'\n+\n+    none_value = (\"\", \"---\")\n+    month_field = \"%s_month\"\n+    day_field = \"%s_day\"\n+    year_field = \"%s_year\"\n+    template_name = \"django/forms/widgets/select_date.html\"\n+    input_type = \"select\"\n     select_widget = Select\n-    date_re = _lazy_re_compile(r'(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$')\n+    date_re = _lazy_re_compile(r\"(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$\")\n \n     def __init__(self, attrs=None, years=None, months=None, empty_label=None):\n         self.attrs = attrs or {}\n@@ -968,14 +1042,14 @@ class SelectDateWidget(Widget):\n         # Optional string, list, or tuple to use as empty_label.\n         if isinstance(empty_label, (list, tuple)):\n             if not len(empty_label) == 3:\n-                raise ValueError('empty_label list/tuple must have 3 elements.')\n+                raise ValueError(\"empty_label list/tuple must have 3 elements.\")\n \n-            self.year_none_value = ('', empty_label[0])\n-            self.month_none_value = ('', empty_label[1])\n-            self.day_none_value = ('', empty_label[2])\n+            self.year_none_value = (\"\", empty_label[0])\n+            self.month_none_value = (\"\", empty_label[1])\n+            self.day_none_value = (\"\", empty_label[2])\n         else:\n             if empty_label is not None:\n-                self.none_value = ('', empty_label)\n+                self.none_value = (\"\", empty_label)\n \n             self.year_none_value = self.none_value\n             self.month_none_value = self.none_value\n@@ -988,33 +1062,40 @@ class SelectDateWidget(Widget):\n         if not self.is_required:\n             year_choices.insert(0, self.year_none_value)\n         year_name = self.year_field % name\n-        date_context['year'] = self.select_widget(attrs, choices=year_choices).get_context(\n+        date_context[\"year\"] = self.select_widget(\n+            attrs, choices=year_choices\n+        ).get_context(\n             name=year_name,\n-            value=context['widget']['value']['year'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % year_name},\n+            value=context[\"widget\"][\"value\"][\"year\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % year_name},\n         )\n         month_choices = list(self.months.items())\n         if not self.is_required:\n             month_choices.insert(0, self.month_none_value)\n         month_name = self.month_field % name\n-        date_context['month'] = self.select_widget(attrs, choices=month_choices).get_context(\n+        date_context[\"month\"] = self.select_widget(\n+            attrs, choices=month_choices\n+        ).get_context(\n             name=month_name,\n-            value=context['widget']['value']['month'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % month_name},\n+            value=context[\"widget\"][\"value\"][\"month\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % month_name},\n         )\n         day_choices = [(i, i) for i in range(1, 32)]\n         if not self.is_required:\n             day_choices.insert(0, self.day_none_value)\n         day_name = self.day_field % name\n-        date_context['day'] = self.select_widget(attrs, choices=day_choices,).get_context(\n+        date_context[\"day\"] = self.select_widget(\n+            attrs,\n+            choices=day_choices,\n+        ).get_context(\n             name=day_name,\n-            value=context['widget']['value']['day'],\n-            attrs={**context['widget']['attrs'], 'id': 'id_%s' % day_name},\n+            value=context[\"widget\"][\"value\"][\"day\"],\n+            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % day_name},\n         )\n         subwidgets = []\n         for field in self._parse_date_fmt():\n-            subwidgets.append(date_context[field]['widget'])\n-        context['widget']['subwidgets'] = subwidgets\n+            subwidgets.append(date_context[field][\"widget\"])\n+        context[\"widget\"][\"subwidgets\"] = subwidgets\n         return context\n \n     def format_value(self, value):\n@@ -1031,58 +1112,58 @@ class SelectDateWidget(Widget):\n             if match:\n                 # Convert any zeros in the date to empty strings to match the\n                 # empty option value.\n-                year, month, day = [int(val) or '' for val in match.groups()]\n+                year, month, day = [int(val) or \"\" for val in match.groups()]\n             else:\n-                input_format = get_format('DATE_INPUT_FORMATS')[0]\n+                input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n                 try:\n                     d = datetime.datetime.strptime(value, input_format)\n                 except ValueError:\n                     pass\n                 else:\n                     year, month, day = d.year, d.month, d.day\n-        return {'year': year, 'month': month, 'day': day}\n+        return {\"year\": year, \"month\": month, \"day\": day}\n \n     @staticmethod\n     def _parse_date_fmt():\n-        fmt = get_format('DATE_FORMAT')\n+        fmt = get_format(\"DATE_FORMAT\")\n         escaped = False\n         for char in fmt:\n             if escaped:\n                 escaped = False\n-            elif char == '\\\\':\n+            elif char == \"\\\\\":\n                 escaped = True\n-            elif char in 'Yy':\n-                yield 'year'\n-            elif char in 'bEFMmNn':\n-                yield 'month'\n-            elif char in 'dj':\n-                yield 'day'\n+            elif char in \"Yy\":\n+                yield \"year\"\n+            elif char in \"bEFMmNn\":\n+                yield \"month\"\n+            elif char in \"dj\":\n+                yield \"day\"\n \n     def id_for_label(self, id_):\n         for first_select in self._parse_date_fmt():\n-            return '%s_%s' % (id_, first_select)\n-        return '%s_month' % id_\n+            return \"%s_%s\" % (id_, first_select)\n+        return \"%s_month\" % id_\n \n     def value_from_datadict(self, data, files, name):\n         y = data.get(self.year_field % name)\n         m = data.get(self.month_field % name)\n         d = data.get(self.day_field % name)\n-        if y == m == d == '':\n+        if y == m == d == \"\":\n             return None\n         if y is not None and m is not None and d is not None:\n-            input_format = get_format('DATE_INPUT_FORMATS')[0]\n+            input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n             input_format = formats.sanitize_strftime_format(input_format)\n             try:\n                 date_value = datetime.date(int(y), int(m), int(d))\n             except ValueError:\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n-                return '%s-%s-%s' % (y or 0, m or 0, d or 0)\n+                return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n             return date_value.strftime(input_format)\n         return data.get(name)\n \n     def value_omitted_from_data(self, data, files, name):\n         return not any(\n-            ('{}_{}'.format(name, interval) in data)\n-            for interval in ('year', 'month', 'day')\n+            (\"{}_{}\".format(name, interval) in data)\n+            for interval in (\"year\", \"month\", \"day\")\n         )\n"}
{"instance_id": "django__django-15202", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 72fbe15551..0e789eaf06 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -11,18 +11,20 @@ from django.utils.regex_helper import _lazy_re_compile\n from django.utils.translation import gettext_lazy as _, ngettext_lazy\n \n # These values, if given to validate(), will trigger the self.required check.\n-EMPTY_VALUES = (None, '', [], (), {})\n+EMPTY_VALUES = (None, \"\", [], (), {})\n \n \n @deconstructible\n class RegexValidator:\n-    regex = ''\n-    message = _('Enter a valid value.')\n-    code = 'invalid'\n+    regex = \"\"\n+    message = _(\"Enter a valid value.\")\n+    code = \"invalid\"\n     inverse_match = False\n     flags = 0\n \n-    def __init__(self, regex=None, message=None, code=None, inverse_match=None, flags=None):\n+    def __init__(\n+        self, regex=None, message=None, code=None, inverse_match=None, flags=None\n+    ):\n         if regex is not None:\n             self.regex = regex\n         if message is not None:\n@@ -34,7 +36,9 @@ class RegexValidator:\n         if flags is not None:\n             self.flags = flags\n         if self.flags and not isinstance(self.regex, str):\n-            raise TypeError(\"If the flags are set, regex must be a regular expression string.\")\n+            raise TypeError(\n+                \"If the flags are set, regex must be a regular expression string.\"\n+            )\n \n         self.regex = _lazy_re_compile(self.regex, self.flags)\n \n@@ -46,51 +50,55 @@ class RegexValidator:\n         regex_matches = self.regex.search(str(value))\n         invalid_input = regex_matches if self.inverse_match else not regex_matches\n         if invalid_input:\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n     def __eq__(self, other):\n         return (\n-            isinstance(other, RegexValidator) and\n-            self.regex.pattern == other.regex.pattern and\n-            self.regex.flags == other.regex.flags and\n-            (self.message == other.message) and\n-            (self.code == other.code) and\n-            (self.inverse_match == other.inverse_match)\n+            isinstance(other, RegexValidator)\n+            and self.regex.pattern == other.regex.pattern\n+            and self.regex.flags == other.regex.flags\n+            and (self.message == other.message)\n+            and (self.code == other.code)\n+            and (self.inverse_match == other.inverse_match)\n         )\n \n \n @deconstructible\n class URLValidator(RegexValidator):\n-    ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n+    ul = \"\\u00a1-\\uffff\"  # Unicode letters range (must not be a raw string).\n \n     # IP patterns\n-    ipv4_re = r'(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)(?:\\.(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)){3}'\n-    ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n+    ipv4_re = r\"(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)(?:\\.(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)){3}\"\n+    ipv6_re = r\"\\[[0-9a-f:.]+\\]\"  # (simple regex, validated later)\n \n     # Host patterns\n-    hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n+    hostname_re = (\n+        r\"[a-z\" + ul + r\"0-9](?:[a-z\" + ul + r\"0-9-]{0,61}[a-z\" + ul + r\"0-9])?\"\n+    )\n     # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1\n-    domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n+    domain_re = r\"(?:\\.(?!-)[a-z\" + ul + r\"0-9-]{1,63}(?<!-))*\"\n     tld_re = (\n-        r'\\.'                                # dot\n-        r'(?!-)'                             # can't start with a dash\n-        r'(?:[a-z' + ul + '-]{2,63}'         # domain label\n-        r'|xn--[a-z0-9]{1,59})'              # or punycode label\n-        r'(?<!-)'                            # can't end with a dash\n-        r'\\.?'                               # may have a trailing dot\n+        r\"\\.\"  # dot\n+        r\"(?!-)\"  # can't start with a dash\n+        r\"(?:[a-z\" + ul + \"-]{2,63}\"  # domain label\n+        r\"|xn--[a-z0-9]{1,59})\"  # or punycode label\n+        r\"(?<!-)\"  # can't end with a dash\n+        r\"\\.?\"  # may have a trailing dot\n     )\n-    host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n+    host_re = \"(\" + hostname_re + domain_re + tld_re + \"|localhost)\"\n \n     regex = _lazy_re_compile(\n-        r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n-        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n-        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n-        r'(?::\\d{1,5})?'  # port\n-        r'(?:[/?#][^\\s]*)?'  # resource path\n-        r'\\Z', re.IGNORECASE)\n-    message = _('Enter a valid URL.')\n-    schemes = ['http', 'https', 'ftp', 'ftps']\n-    unsafe_chars = frozenset('\\t\\r\\n')\n+        r\"^(?:[a-z0-9.+-]*)://\"  # scheme is validated separately\n+        r\"(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?\"  # user:pass authentication\n+        r\"(?:\" + ipv4_re + \"|\" + ipv6_re + \"|\" + host_re + \")\"\n+        r\"(?::\\d{1,5})?\"  # port\n+        r\"(?:[/?#][^\\s]*)?\"  # resource path\n+        r\"\\Z\",\n+        re.IGNORECASE,\n+    )\n+    message = _(\"Enter a valid URL.\")\n+    schemes = [\"http\", \"https\", \"ftp\", \"ftps\"]\n+    unsafe_chars = frozenset(\"\\t\\r\\n\")\n \n     def __init__(self, schemes=None, **kwargs):\n         super().__init__(**kwargs)\n@@ -99,13 +107,13 @@ class URLValidator(RegexValidator):\n \n     def __call__(self, value):\n         if not isinstance(value, str):\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n         if self.unsafe_chars.intersection(value):\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n         # Check if the scheme is valid.\n-        scheme = value.split('://')[0].lower()\n+        scheme = value.split(\"://\")[0].lower()\n         if scheme not in self.schemes:\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n         # Then check full URL\n         try:\n@@ -116,7 +124,9 @@ class URLValidator(RegexValidator):\n                 try:\n                     scheme, netloc, path, query, fragment = urlsplit(value)\n                 except ValueError:  # for example, \"Invalid IPv6 URL\"\n-                    raise ValidationError(self.message, code=self.code, params={'value': value})\n+                    raise ValidationError(\n+                        self.message, code=self.code, params={\"value\": value}\n+                    )\n                 try:\n                     netloc = punycode(netloc)  # IDN -> ACE\n                 except UnicodeError:  # invalid domain part\n@@ -127,26 +137,38 @@ class URLValidator(RegexValidator):\n                 raise\n         else:\n             # Now verify IPv6 in the netloc part\n-            host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', urlsplit(value).netloc)\n+            try:\n+                netloc = urlsplit(value).netloc\n+            except ValueError:\n+                raise ValidationError(\n+                    self.message, code=self.code, params={\"value\": value}\n+                )\n+            host_match = re.search(r\"^\\[(.+)\\](?::\\d{1,5})?$\", netloc)\n             if host_match:\n                 potential_ip = host_match[1]\n                 try:\n                     validate_ipv6_address(potential_ip)\n                 except ValidationError:\n-                    raise ValidationError(self.message, code=self.code, params={'value': value})\n+                    raise ValidationError(\n+                        self.message, code=self.code, params={\"value\": value}\n+                    )\n \n         # The maximum length of a full host name is 253 characters per RFC 1034\n         # section 3.1. It's defined to be 255 bytes or less, but this includes\n         # one byte for the length of the name and one byte for the trailing dot\n         # that's used to indicate absolute names in DNS.\n-        if len(urlsplit(value).hostname) > 253:\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+        try:\n+            hostname = urlsplit(value).hostname\n+        except ValueError:\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n+        if hostname and len(hostname) > 253:\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n \n integer_validator = RegexValidator(\n-    _lazy_re_compile(r'^-?\\d+\\Z'),\n-    message=_('Enter a valid integer.'),\n-    code='invalid',\n+    _lazy_re_compile(r\"^-?\\d+\\Z\"),\n+    message=_(\"Enter a valid integer.\"),\n+    code=\"invalid\",\n )\n \n \n@@ -156,21 +178,24 @@ def validate_integer(value):\n \n @deconstructible\n class EmailValidator:\n-    message = _('Enter a valid email address.')\n-    code = 'invalid'\n+    message = _(\"Enter a valid email address.\")\n+    code = \"invalid\"\n     user_regex = _lazy_re_compile(\n         r\"(^[-!#$%&'*+/=?^_`{}|~0-9A-Z]+(\\.[-!#$%&'*+/=?^_`{}|~0-9A-Z]+)*\\Z\"  # dot-atom\n         r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',  # quoted-string\n-        re.IGNORECASE)\n+        re.IGNORECASE,\n+    )\n     domain_regex = _lazy_re_compile(\n         # max length for domain name labels is 63 characters per RFC 1034\n-        r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z',\n-        re.IGNORECASE)\n+        r\"((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z\",\n+        re.IGNORECASE,\n+    )\n     literal_regex = _lazy_re_compile(\n         # literal form, ipv4 or ipv6 address (SMTP 4.1.3)\n-        r'\\[([A-F0-9:.]+)\\]\\Z',\n-        re.IGNORECASE)\n-    domain_allowlist = ['localhost']\n+        r\"\\[([A-F0-9:.]+)\\]\\Z\",\n+        re.IGNORECASE,\n+    )\n+    domain_allowlist = [\"localhost\"]\n \n     def __init__(self, message=None, code=None, allowlist=None):\n         if message is not None:\n@@ -181,16 +206,17 @@ class EmailValidator:\n             self.domain_allowlist = allowlist\n \n     def __call__(self, value):\n-        if not value or '@' not in value:\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+        if not value or \"@\" not in value:\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n-        user_part, domain_part = value.rsplit('@', 1)\n+        user_part, domain_part = value.rsplit(\"@\", 1)\n \n         if not self.user_regex.match(user_part):\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n-        if (domain_part not in self.domain_allowlist and\n-                not self.validate_domain_part(domain_part)):\n+        if domain_part not in self.domain_allowlist and not self.validate_domain_part(\n+            domain_part\n+        ):\n             # Try for possible IDN domain-part\n             try:\n                 domain_part = punycode(domain_part)\n@@ -199,7 +225,7 @@ class EmailValidator:\n             else:\n                 if self.validate_domain_part(domain_part):\n                     return\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n     def validate_domain_part(self, domain_part):\n         if self.domain_regex.match(domain_part):\n@@ -217,28 +243,30 @@ class EmailValidator:\n \n     def __eq__(self, other):\n         return (\n-            isinstance(other, EmailValidator) and\n-            (self.domain_allowlist == other.domain_allowlist) and\n-            (self.message == other.message) and\n-            (self.code == other.code)\n+            isinstance(other, EmailValidator)\n+            and (self.domain_allowlist == other.domain_allowlist)\n+            and (self.message == other.message)\n+            and (self.code == other.code)\n         )\n \n \n validate_email = EmailValidator()\n \n-slug_re = _lazy_re_compile(r'^[-a-zA-Z0-9_]+\\Z')\n+slug_re = _lazy_re_compile(r\"^[-a-zA-Z0-9_]+\\Z\")\n validate_slug = RegexValidator(\n     slug_re,\n     # Translators: \"letters\" means latin letters: a-z and A-Z.\n-    _('Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.'),\n-    'invalid'\n+    _(\"Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.\"),\n+    \"invalid\",\n )\n \n-slug_unicode_re = _lazy_re_compile(r'^[-\\w]+\\Z')\n+slug_unicode_re = _lazy_re_compile(r\"^[-\\w]+\\Z\")\n validate_unicode_slug = RegexValidator(\n     slug_unicode_re,\n-    _('Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.'),\n-    'invalid'\n+    _(\n+        \"Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.\"\n+    ),\n+    \"invalid\",\n )\n \n \n@@ -246,25 +274,26 @@ def validate_ipv4_address(value):\n     try:\n         ipaddress.IPv4Address(value)\n     except ValueError:\n-        raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n+        raise ValidationError(\n+            _(\"Enter a valid IPv4 address.\"), code=\"invalid\", params={\"value\": value}\n+        )\n     else:\n         # Leading zeros are forbidden to avoid ambiguity with the octal\n         # notation. This restriction is included in Python 3.9.5+.\n         # TODO: Remove when dropping support for PY39.\n-        if any(\n-            octet != '0' and octet[0] == '0'\n-            for octet in value.split('.')\n-        ):\n+        if any(octet != \"0\" and octet[0] == \"0\" for octet in value.split(\".\")):\n             raise ValidationError(\n-                _('Enter a valid IPv4 address.'),\n-                code='invalid',\n-                params={'value': value},\n+                _(\"Enter a valid IPv4 address.\"),\n+                code=\"invalid\",\n+                params={\"value\": value},\n             )\n \n \n def validate_ipv6_address(value):\n     if not is_valid_ipv6_address(value):\n-        raise ValidationError(_('Enter a valid IPv6 address.'), code='invalid', params={'value': value})\n+        raise ValidationError(\n+            _(\"Enter a valid IPv6 address.\"), code=\"invalid\", params={\"value\": value}\n+        )\n \n \n def validate_ipv46_address(value):\n@@ -274,13 +303,17 @@ def validate_ipv46_address(value):\n         try:\n             validate_ipv6_address(value)\n         except ValidationError:\n-            raise ValidationError(_('Enter a valid IPv4 or IPv6 address.'), code='invalid', params={'value': value})\n+            raise ValidationError(\n+                _(\"Enter a valid IPv4 or IPv6 address.\"),\n+                code=\"invalid\",\n+                params={\"value\": value},\n+            )\n \n \n ip_address_validator_map = {\n-    'both': ([validate_ipv46_address], _('Enter a valid IPv4 or IPv6 address.')),\n-    'ipv4': ([validate_ipv4_address], _('Enter a valid IPv4 address.')),\n-    'ipv6': ([validate_ipv6_address], _('Enter a valid IPv6 address.')),\n+    \"both\": ([validate_ipv46_address], _(\"Enter a valid IPv4 or IPv6 address.\")),\n+    \"ipv4\": ([validate_ipv4_address], _(\"Enter a valid IPv4 address.\")),\n+    \"ipv6\": ([validate_ipv6_address], _(\"Enter a valid IPv6 address.\")),\n }\n \n \n@@ -289,33 +322,39 @@ def ip_address_validators(protocol, unpack_ipv4):\n     Depending on the given parameters, return the appropriate validators for\n     the GenericIPAddressField.\n     \"\"\"\n-    if protocol != 'both' and unpack_ipv4:\n+    if protocol != \"both\" and unpack_ipv4:\n         raise ValueError(\n-            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\")\n+            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\"\n+        )\n     try:\n         return ip_address_validator_map[protocol.lower()]\n     except KeyError:\n-        raise ValueError(\"The protocol '%s' is unknown. Supported: %s\"\n-                         % (protocol, list(ip_address_validator_map)))\n+        raise ValueError(\n+            \"The protocol '%s' is unknown. Supported: %s\"\n+            % (protocol, list(ip_address_validator_map))\n+        )\n \n \n-def int_list_validator(sep=',', message=None, code='invalid', allow_negative=False):\n-    regexp = _lazy_re_compile(r'^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z' % {\n-        'neg': '(-)?' if allow_negative else '',\n-        'sep': re.escape(sep),\n-    })\n+def int_list_validator(sep=\",\", message=None, code=\"invalid\", allow_negative=False):\n+    regexp = _lazy_re_compile(\n+        r\"^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z\"\n+        % {\n+            \"neg\": \"(-)?\" if allow_negative else \"\",\n+            \"sep\": re.escape(sep),\n+        }\n+    )\n     return RegexValidator(regexp, message=message, code=code)\n \n \n validate_comma_separated_integer_list = int_list_validator(\n-    message=_('Enter only digits separated by commas.'),\n+    message=_(\"Enter only digits separated by commas.\"),\n )\n \n \n @deconstructible\n class BaseValidator:\n-    message = _('Ensure this value is %(limit_value)s (it is %(show_value)s).')\n-    code = 'limit_value'\n+    message = _(\"Ensure this value is %(limit_value)s (it is %(show_value)s).\")\n+    code = \"limit_value\"\n \n     def __init__(self, limit_value, message=None):\n         self.limit_value = limit_value\n@@ -324,8 +363,10 @@ class BaseValidator:\n \n     def __call__(self, value):\n         cleaned = self.clean(value)\n-        limit_value = self.limit_value() if callable(self.limit_value) else self.limit_value\n-        params = {'limit_value': limit_value, 'show_value': cleaned, 'value': value}\n+        limit_value = (\n+            self.limit_value() if callable(self.limit_value) else self.limit_value\n+        )\n+        params = {\"limit_value\": limit_value, \"show_value\": cleaned, \"value\": value}\n         if self.compare(cleaned, limit_value):\n             raise ValidationError(self.message, code=self.code, params=params)\n \n@@ -333,9 +374,9 @@ class BaseValidator:\n         if not isinstance(other, self.__class__):\n             return NotImplemented\n         return (\n-            self.limit_value == other.limit_value and\n-            self.message == other.message and\n-            self.code == other.code\n+            self.limit_value == other.limit_value\n+            and self.message == other.message\n+            and self.code == other.code\n         )\n \n     def compare(self, a, b):\n@@ -347,8 +388,8 @@ class BaseValidator:\n \n @deconstructible\n class MaxValueValidator(BaseValidator):\n-    message = _('Ensure this value is less than or equal to %(limit_value)s.')\n-    code = 'max_value'\n+    message = _(\"Ensure this value is less than or equal to %(limit_value)s.\")\n+    code = \"max_value\"\n \n     def compare(self, a, b):\n         return a > b\n@@ -356,8 +397,8 @@ class MaxValueValidator(BaseValidator):\n \n @deconstructible\n class MinValueValidator(BaseValidator):\n-    message = _('Ensure this value is greater than or equal to %(limit_value)s.')\n-    code = 'min_value'\n+    message = _(\"Ensure this value is greater than or equal to %(limit_value)s.\")\n+    code = \"min_value\"\n \n     def compare(self, a, b):\n         return a < b\n@@ -366,10 +407,11 @@ class MinValueValidator(BaseValidator):\n @deconstructible\n class MinLengthValidator(BaseValidator):\n     message = ngettext_lazy(\n-        'Ensure this value has at least %(limit_value)d character (it has %(show_value)d).',\n-        'Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).',\n-        'limit_value')\n-    code = 'min_length'\n+        \"Ensure this value has at least %(limit_value)d character (it has %(show_value)d).\",\n+        \"Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).\",\n+        \"limit_value\",\n+    )\n+    code = \"min_length\"\n \n     def compare(self, a, b):\n         return a < b\n@@ -381,10 +423,11 @@ class MinLengthValidator(BaseValidator):\n @deconstructible\n class MaxLengthValidator(BaseValidator):\n     message = ngettext_lazy(\n-        'Ensure this value has at most %(limit_value)d character (it has %(show_value)d).',\n-        'Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).',\n-        'limit_value')\n-    code = 'max_length'\n+        \"Ensure this value has at most %(limit_value)d character (it has %(show_value)d).\",\n+        \"Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).\",\n+        \"limit_value\",\n+    )\n+    code = \"max_length\"\n \n     def compare(self, a, b):\n         return a > b\n@@ -399,22 +442,23 @@ class DecimalValidator:\n     Validate that the input does not exceed the maximum number of digits\n     expected, otherwise raise ValidationError.\n     \"\"\"\n+\n     messages = {\n-        'invalid': _('Enter a number.'),\n-        'max_digits': ngettext_lazy(\n-            'Ensure that there are no more than %(max)s digit in total.',\n-            'Ensure that there are no more than %(max)s digits in total.',\n-            'max'\n+        \"invalid\": _(\"Enter a number.\"),\n+        \"max_digits\": ngettext_lazy(\n+            \"Ensure that there are no more than %(max)s digit in total.\",\n+            \"Ensure that there are no more than %(max)s digits in total.\",\n+            \"max\",\n         ),\n-        'max_decimal_places': ngettext_lazy(\n-            'Ensure that there are no more than %(max)s decimal place.',\n-            'Ensure that there are no more than %(max)s decimal places.',\n-            'max'\n+        \"max_decimal_places\": ngettext_lazy(\n+            \"Ensure that there are no more than %(max)s decimal place.\",\n+            \"Ensure that there are no more than %(max)s decimal places.\",\n+            \"max\",\n         ),\n-        'max_whole_digits': ngettext_lazy(\n-            'Ensure that there are no more than %(max)s digit before the decimal point.',\n-            'Ensure that there are no more than %(max)s digits before the decimal point.',\n-            'max'\n+        \"max_whole_digits\": ngettext_lazy(\n+            \"Ensure that there are no more than %(max)s digit before the decimal point.\",\n+            \"Ensure that there are no more than %(max)s digits before the decimal point.\",\n+            \"max\",\n         ),\n     }\n \n@@ -424,8 +468,10 @@ class DecimalValidator:\n \n     def __call__(self, value):\n         digit_tuple, exponent = value.as_tuple()[1:]\n-        if exponent in {'F', 'n', 'N'}:\n-            raise ValidationError(self.messages['invalid'], code='invalid', params={'value': value})\n+        if exponent in {\"F\", \"n\", \"N\"}:\n+            raise ValidationError(\n+                self.messages[\"invalid\"], code=\"invalid\", params={\"value\": value}\n+            )\n         if exponent >= 0:\n             # A positive exponent adds that many trailing zeros.\n             digits = len(digit_tuple) + exponent\n@@ -445,43 +491,48 @@ class DecimalValidator:\n \n         if self.max_digits is not None and digits > self.max_digits:\n             raise ValidationError(\n-                self.messages['max_digits'],\n-                code='max_digits',\n-                params={'max': self.max_digits, 'value': value},\n+                self.messages[\"max_digits\"],\n+                code=\"max_digits\",\n+                params={\"max\": self.max_digits, \"value\": value},\n             )\n         if self.decimal_places is not None and decimals > self.decimal_places:\n             raise ValidationError(\n-                self.messages['max_decimal_places'],\n-                code='max_decimal_places',\n-                params={'max': self.decimal_places, 'value': value},\n+                self.messages[\"max_decimal_places\"],\n+                code=\"max_decimal_places\",\n+                params={\"max\": self.decimal_places, \"value\": value},\n             )\n-        if (self.max_digits is not None and self.decimal_places is not None and\n-                whole_digits > (self.max_digits - self.decimal_places)):\n+        if (\n+            self.max_digits is not None\n+            and self.decimal_places is not None\n+            and whole_digits > (self.max_digits - self.decimal_places)\n+        ):\n             raise ValidationError(\n-                self.messages['max_whole_digits'],\n-                code='max_whole_digits',\n-                params={'max': (self.max_digits - self.decimal_places), 'value': value},\n+                self.messages[\"max_whole_digits\"],\n+                code=\"max_whole_digits\",\n+                params={\"max\": (self.max_digits - self.decimal_places), \"value\": value},\n             )\n \n     def __eq__(self, other):\n         return (\n-            isinstance(other, self.__class__) and\n-            self.max_digits == other.max_digits and\n-            self.decimal_places == other.decimal_places\n+            isinstance(other, self.__class__)\n+            and self.max_digits == other.max_digits\n+            and self.decimal_places == other.decimal_places\n         )\n \n \n @deconstructible\n class FileExtensionValidator:\n     message = _(\n-        'File extension \u201c%(extension)s\u201d is not allowed. '\n-        'Allowed extensions are: %(allowed_extensions)s.'\n+        \"File extension \u201c%(extension)s\u201d is not allowed. \"\n+        \"Allowed extensions are: %(allowed_extensions)s.\"\n     )\n-    code = 'invalid_extension'\n+    code = \"invalid_extension\"\n \n     def __init__(self, allowed_extensions=None, message=None, code=None):\n         if allowed_extensions is not None:\n-            allowed_extensions = [allowed_extension.lower() for allowed_extension in allowed_extensions]\n+            allowed_extensions = [\n+                allowed_extension.lower() for allowed_extension in allowed_extensions\n+            ]\n         self.allowed_extensions = allowed_extensions\n         if message is not None:\n             self.message = message\n@@ -490,23 +541,26 @@ class FileExtensionValidator:\n \n     def __call__(self, value):\n         extension = Path(value.name).suffix[1:].lower()\n-        if self.allowed_extensions is not None and extension not in self.allowed_extensions:\n+        if (\n+            self.allowed_extensions is not None\n+            and extension not in self.allowed_extensions\n+        ):\n             raise ValidationError(\n                 self.message,\n                 code=self.code,\n                 params={\n-                    'extension': extension,\n-                    'allowed_extensions': ', '.join(self.allowed_extensions),\n-                    'value': value,\n-                }\n+                    \"extension\": extension,\n+                    \"allowed_extensions\": \", \".join(self.allowed_extensions),\n+                    \"value\": value,\n+                },\n             )\n \n     def __eq__(self, other):\n         return (\n-            isinstance(other, self.__class__) and\n-            self.allowed_extensions == other.allowed_extensions and\n-            self.message == other.message and\n-            self.code == other.code\n+            isinstance(other, self.__class__)\n+            and self.allowed_extensions == other.allowed_extensions\n+            and self.message == other.message\n+            and self.code == other.code\n         )\n \n \n@@ -521,14 +575,17 @@ def get_available_image_extensions():\n \n \n def validate_image_file_extension(value):\n-    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(value)\n+    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(\n+        value\n+    )\n \n \n @deconstructible\n class ProhibitNullCharactersValidator:\n     \"\"\"Validate that the string doesn't contain the null character.\"\"\"\n-    message = _('Null characters are not allowed.')\n-    code = 'null_characters_not_allowed'\n+\n+    message = _(\"Null characters are not allowed.\")\n+    code = \"null_characters_not_allowed\"\n \n     def __init__(self, message=None, code=None):\n         if message is not None:\n@@ -537,12 +594,12 @@ class ProhibitNullCharactersValidator:\n             self.code = code\n \n     def __call__(self, value):\n-        if '\\x00' in str(value):\n-            raise ValidationError(self.message, code=self.code, params={'value': value})\n+        if \"\\x00\" in str(value):\n+            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n \n     def __eq__(self, other):\n         return (\n-            isinstance(other, self.__class__) and\n-            self.message == other.message and\n-            self.code == other.code\n+            isinstance(other, self.__class__)\n+            and self.message == other.message\n+            and self.code == other.code\n         )\n"}
{"instance_id": "django__django-15213", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..b93955e35d 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -20,11 +20,12 @@ class SQLiteNumericMixin:\n     Some expressions with output_field=DecimalField() must be cast to\n     numeric to be properly filtered.\n     \"\"\"\n+\n     def as_sqlite(self, compiler, connection, **extra_context):\n         sql, params = self.as_sql(compiler, connection, **extra_context)\n         try:\n-            if self.output_field.get_internal_type() == 'DecimalField':\n-                sql = 'CAST(%s AS NUMERIC)' % sql\n+            if self.output_field.get_internal_type() == \"DecimalField\":\n+                sql = \"CAST(%s AS NUMERIC)\" % sql\n         except FieldError:\n             pass\n         return sql, params\n@@ -37,26 +38,26 @@ class Combinable:\n     \"\"\"\n \n     # Arithmetic connectors\n-    ADD = '+'\n-    SUB = '-'\n-    MUL = '*'\n-    DIV = '/'\n-    POW = '^'\n+    ADD = \"+\"\n+    SUB = \"-\"\n+    MUL = \"*\"\n+    DIV = \"/\"\n+    POW = \"^\"\n     # The following is a quoted % operator - it is quoted because it can be\n     # used in strings that also have parameter substitution.\n-    MOD = '%%'\n+    MOD = \"%%\"\n \n     # Bitwise operators - note that these are generated by .bitand()\n     # and .bitor(), the '&' and '|' are reserved for boolean operator\n     # usage.\n-    BITAND = '&'\n-    BITOR = '|'\n-    BITLEFTSHIFT = '<<'\n-    BITRIGHTSHIFT = '>>'\n-    BITXOR = '#'\n+    BITAND = \"&\"\n+    BITOR = \"|\"\n+    BITLEFTSHIFT = \"<<\"\n+    BITRIGHTSHIFT = \">>\"\n+    BITXOR = \"#\"\n \n     def _combine(self, other, connector, reversed):\n-        if not hasattr(other, 'resolve_expression'):\n+        if not hasattr(other, \"resolve_expression\"):\n             # everything must be resolvable to an expression\n             other = Value(other)\n \n@@ -90,7 +91,7 @@ class Combinable:\n         return self._combine(other, self.POW, False)\n \n     def __and__(self, other):\n-        if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n+        if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):\n             return Q(self) & Q(other)\n         raise NotImplementedError(\n             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n@@ -109,7 +110,7 @@ class Combinable:\n         return self._combine(other, self.BITXOR, False)\n \n     def __or__(self, other):\n-        if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n+        if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):\n             return Q(self) | Q(other)\n         raise NotImplementedError(\n             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n@@ -165,14 +166,14 @@ class BaseExpression:\n \n     def __getstate__(self):\n         state = self.__dict__.copy()\n-        state.pop('convert_value', None)\n+        state.pop(\"convert_value\", None)\n         return state\n \n     def get_db_converters(self, connection):\n         return (\n             []\n-            if self.convert_value is self._convert_value_noop else\n-            [self.convert_value]\n+            if self.convert_value is self._convert_value_noop\n+            else [self.convert_value]\n         ) + self.output_field.get_db_converters(connection)\n \n     def get_source_expressions(self):\n@@ -183,9 +184,10 @@ class BaseExpression:\n \n     def _parse_expressions(self, *expressions):\n         return [\n-            arg if hasattr(arg, 'resolve_expression') else (\n-                F(arg) if isinstance(arg, str) else Value(arg)\n-            ) for arg in expressions\n+            arg\n+            if hasattr(arg, \"resolve_expression\")\n+            else (F(arg) if isinstance(arg, str) else Value(arg))\n+            for arg in expressions\n         ]\n \n     def as_sql(self, compiler, connection):\n@@ -218,17 +220,26 @@ class BaseExpression:\n \n     @cached_property\n     def contains_aggregate(self):\n-        return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_aggregate for expr in self.get_source_expressions()\n+        )\n \n     @cached_property\n     def contains_over_clause(self):\n-        return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_over_clause for expr in self.get_source_expressions()\n+        )\n \n     @cached_property\n     def contains_column_references(self):\n-        return any(expr and expr.contains_column_references for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_column_references\n+            for expr in self.get_source_expressions()\n+        )\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         \"\"\"\n         Provide the chance to do any preprocessing or validation before being\n         added to the query.\n@@ -245,11 +256,14 @@ class BaseExpression:\n         \"\"\"\n         c = self.copy()\n         c.is_summary = summarize\n-        c.set_source_expressions([\n-            expr.resolve_expression(query, allow_joins, reuse, summarize)\n-            if expr else None\n-            for expr in c.get_source_expressions()\n-        ])\n+        c.set_source_expressions(\n+            [\n+                expr.resolve_expression(query, allow_joins, reuse, summarize)\n+                if expr\n+                else None\n+                for expr in c.get_source_expressions()\n+            ]\n+        )\n         return c\n \n     @property\n@@ -266,7 +280,7 @@ class BaseExpression:\n         output_field = self._resolve_output_field()\n         if output_field is None:\n             self._output_field_resolved_to_none = True\n-            raise FieldError('Cannot resolve expression type, unknown output_field')\n+            raise FieldError(\"Cannot resolve expression type, unknown output_field\")\n         return output_field\n \n     @cached_property\n@@ -295,13 +309,16 @@ class BaseExpression:\n         If all sources are None, then an error is raised higher up the stack in\n         the output_field property.\n         \"\"\"\n-        sources_iter = (source for source in self.get_source_fields() if source is not None)\n+        sources_iter = (\n+            source for source in self.get_source_fields() if source is not None\n+        )\n         for output_field in sources_iter:\n             for source in sources_iter:\n                 if not isinstance(output_field, source.__class__):\n                     raise FieldError(\n-                        'Expression contains mixed types: %s, %s. You must '\n-                        'set output_field.' % (\n+                        \"Expression contains mixed types: %s, %s. You must \"\n+                        \"set output_field.\"\n+                        % (\n                             output_field.__class__.__name__,\n                             source.__class__.__name__,\n                         )\n@@ -321,12 +338,24 @@ class BaseExpression:\n         \"\"\"\n         field = self.output_field\n         internal_type = field.get_internal_type()\n-        if internal_type == 'FloatField':\n-            return lambda value, expression, connection: None if value is None else float(value)\n-        elif internal_type.endswith('IntegerField'):\n-            return lambda value, expression, connection: None if value is None else int(value)\n-        elif internal_type == 'DecimalField':\n-            return lambda value, expression, connection: None if value is None else Decimal(value)\n+        if internal_type == \"FloatField\":\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else float(value)\n+            )\n+        elif internal_type.endswith(\"IntegerField\"):\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else int(value)\n+            )\n+        elif internal_type == \"DecimalField\":\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else Decimal(value)\n+            )\n         return self._convert_value_noop\n \n     def get_lookup(self, lookup):\n@@ -337,10 +366,12 @@ class BaseExpression:\n \n     def relabeled_clone(self, change_map):\n         clone = self.copy()\n-        clone.set_source_expressions([\n-            e.relabeled_clone(change_map) if e is not None else None\n-            for e in self.get_source_expressions()\n-        ])\n+        clone.set_source_expressions(\n+            [\n+                e.relabeled_clone(change_map) if e is not None else None\n+                for e in self.get_source_expressions()\n+            ]\n+        )\n         return clone\n \n     def copy(self):\n@@ -375,7 +406,7 @@ class BaseExpression:\n         yield self\n         for expr in self.get_source_expressions():\n             if expr:\n-                if hasattr(expr, 'flatten'):\n+                if hasattr(expr, \"flatten\"):\n                     yield from expr.flatten()\n                 else:\n                     yield expr\n@@ -385,7 +416,7 @@ class BaseExpression:\n         Custom format for select clauses. For example, EXISTS expressions need\n         to be wrapped in CASE WHEN on Oracle.\n         \"\"\"\n-        if hasattr(self.output_field, 'select_format'):\n+        if hasattr(self.output_field, \"select_format\"):\n             return self.output_field.select_format(compiler, sql, params)\n         return sql, params\n \n@@ -438,12 +469,13 @@ _connector_combinators = {\n def _resolve_combined_type(connector, lhs_type, rhs_type):\n     combinators = _connector_combinators.get(connector, ())\n     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:\n-        if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):\n+        if issubclass(lhs_type, combinator_lhs_type) and issubclass(\n+            rhs_type, combinator_rhs_type\n+        ):\n             return combined_type\n \n \n class CombinedExpression(SQLiteNumericMixin, Expression):\n-\n     def __init__(self, lhs, connector, rhs, output_field=None):\n         super().__init__(output_field=output_field)\n         self.connector = connector\n@@ -485,13 +517,19 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n         expressions.append(sql)\n         expression_params.extend(params)\n         # order of precedence\n-        expression_wrapper = '(%s)'\n+        expression_wrapper = \"(%s)\"\n         sql = connection.ops.combine_expression(self.connector, expressions)\n         return expression_wrapper % sql, expression_params\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n-        lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n-        rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n+        lhs = self.lhs.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n+        rhs = self.rhs.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         if not isinstance(self, (DurationExpression, TemporalSubtraction)):\n             try:\n                 lhs_type = lhs.output_field.get_internal_type()\n@@ -501,14 +539,28 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n                 rhs_type = rhs.output_field.get_internal_type()\n             except (AttributeError, FieldError):\n                 rhs_type = None\n-            if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:\n-                return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(\n-                    query, allow_joins, reuse, summarize, for_save,\n+            if \"DurationField\" in {lhs_type, rhs_type} and lhs_type != rhs_type:\n+                return DurationExpression(\n+                    self.lhs, self.connector, self.rhs\n+                ).resolve_expression(\n+                    query,\n+                    allow_joins,\n+                    reuse,\n+                    summarize,\n+                    for_save,\n                 )\n-            datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}\n-            if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:\n+            datetime_fields = {\"DateField\", \"DateTimeField\", \"TimeField\"}\n+            if (\n+                self.connector == self.SUB\n+                and lhs_type in datetime_fields\n+                and lhs_type == rhs_type\n+            ):\n                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(\n-                    query, allow_joins, reuse, summarize, for_save,\n+                    query,\n+                    allow_joins,\n+                    reuse,\n+                    summarize,\n+                    for_save,\n                 )\n         c = self.copy()\n         c.is_summary = summarize\n@@ -524,7 +576,7 @@ class DurationExpression(CombinedExpression):\n         except FieldError:\n             pass\n         else:\n-            if output.get_internal_type() == 'DurationField':\n+            if output.get_internal_type() == \"DurationField\":\n                 sql, params = compiler.compile(side)\n                 return connection.ops.format_for_duration_arithmetic(sql), params\n         return compiler.compile(side)\n@@ -542,7 +594,7 @@ class DurationExpression(CombinedExpression):\n         expressions.append(sql)\n         expression_params.extend(params)\n         # order of precedence\n-        expression_wrapper = '(%s)'\n+        expression_wrapper = \"(%s)\"\n         sql = connection.ops.combine_duration_expression(self.connector, expressions)\n         return expression_wrapper % sql, expression_params\n \n@@ -556,11 +608,14 @@ class DurationExpression(CombinedExpression):\n                 pass\n             else:\n                 allowed_fields = {\n-                    'DecimalField', 'DurationField', 'FloatField', 'IntegerField',\n+                    \"DecimalField\",\n+                    \"DurationField\",\n+                    \"FloatField\",\n+                    \"IntegerField\",\n                 }\n                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:\n                     raise DatabaseError(\n-                        f'Invalid arguments for operator {self.connector}.'\n+                        f\"Invalid arguments for operator {self.connector}.\"\n                     )\n         return sql, params\n \n@@ -575,10 +630,12 @@ class TemporalSubtraction(CombinedExpression):\n         connection.ops.check_expression_support(self)\n         lhs = compiler.compile(self.lhs)\n         rhs = compiler.compile(self.rhs)\n-        return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)\n+        return connection.ops.subtract_temporals(\n+            self.lhs.output_field.get_internal_type(), lhs, rhs\n+        )\n \n \n-@deconstructible(path='django.db.models.F')\n+@deconstructible(path=\"django.db.models.F\")\n class F(Combinable):\n     \"\"\"An object capable of resolving references to existing query objects.\"\"\"\n \n@@ -592,8 +649,9 @@ class F(Combinable):\n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.name)\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None,\n-                           summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         return query.resolve_ref(self.name, allow_joins, reuse, summarize)\n \n     def asc(self, **kwargs):\n@@ -616,12 +674,13 @@ class ResolvedOuterRef(F):\n     In this case, the reference to the outer query has been resolved because\n     the inner query has been used as a subquery.\n     \"\"\"\n+\n     contains_aggregate = False\n \n     def as_sql(self, *args, **kwargs):\n         raise ValueError(\n-            'This queryset contains a reference to an outer query and may '\n-            'only be used in a subquery.'\n+            \"This queryset contains a reference to an outer query and may \"\n+            \"only be used in a subquery.\"\n         )\n \n     def resolve_expression(self, *args, **kwargs):\n@@ -653,15 +712,17 @@ class OuterRef(F):\n \n class Func(SQLiteNumericMixin, Expression):\n     \"\"\"An SQL function call.\"\"\"\n+\n     function = None\n-    template = '%(function)s(%(expressions)s)'\n-    arg_joiner = ', '\n+    template = \"%(function)s(%(expressions)s)\"\n+    arg_joiner = \", \"\n     arity = None  # The number of arguments the function accepts.\n \n     def __init__(self, *expressions, output_field=None, **extra):\n         if self.arity is not None and len(expressions) != self.arity:\n             raise TypeError(\n-                \"'%s' takes exactly %s %s (%s given)\" % (\n+                \"'%s' takes exactly %s %s (%s given)\"\n+                % (\n                     self.__class__.__name__,\n                     self.arity,\n                     \"argument\" if self.arity == 1 else \"arguments\",\n@@ -676,7 +737,9 @@ class Func(SQLiteNumericMixin, Expression):\n         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n         extra = {**self.extra, **self._get_repr_options()}\n         if extra:\n-            extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))\n+            extra = \", \".join(\n+                str(key) + \"=\" + str(val) for key, val in sorted(extra.items())\n+            )\n             return \"{}({}, {})\".format(self.__class__.__name__, args, extra)\n         return \"{}({})\".format(self.__class__.__name__, args)\n \n@@ -690,14 +753,26 @@ class Func(SQLiteNumericMixin, Expression):\n     def set_source_expressions(self, exprs):\n         self.source_expressions = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n         for pos, arg in enumerate(c.source_expressions):\n-            c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+            c.source_expressions[pos] = arg.resolve_expression(\n+                query, allow_joins, reuse, summarize, for_save\n+            )\n         return c\n \n-    def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):\n+    def as_sql(\n+        self,\n+        compiler,\n+        connection,\n+        function=None,\n+        template=None,\n+        arg_joiner=None,\n+        **extra_context,\n+    ):\n         connection.ops.check_expression_support(self)\n         sql_parts = []\n         params = []\n@@ -705,7 +780,9 @@ class Func(SQLiteNumericMixin, Expression):\n             try:\n                 arg_sql, arg_params = compiler.compile(arg)\n             except EmptyResultSet:\n-                empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented)\n+                empty_result_set_value = getattr(\n+                    arg, \"empty_result_set_value\", NotImplemented\n+                )\n                 if empty_result_set_value is NotImplemented:\n                     raise\n                 arg_sql, arg_params = compiler.compile(Value(empty_result_set_value))\n@@ -716,12 +793,12 @@ class Func(SQLiteNumericMixin, Expression):\n         # method, a value supplied in __init__()'s **extra (the value in\n         # `data`), or the value defined on the class.\n         if function is not None:\n-            data['function'] = function\n+            data[\"function\"] = function\n         else:\n-            data.setdefault('function', self.function)\n-        template = template or data.get('template', self.template)\n-        arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)\n-        data['expressions'] = data['field'] = arg_joiner.join(sql_parts)\n+            data.setdefault(\"function\", self.function)\n+        template = template or data.get(\"template\", self.template)\n+        arg_joiner = arg_joiner or data.get(\"arg_joiner\", self.arg_joiner)\n+        data[\"expressions\"] = data[\"field\"] = arg_joiner.join(sql_parts)\n         return template % data, params\n \n     def copy(self):\n@@ -733,6 +810,7 @@ class Func(SQLiteNumericMixin, Expression):\n \n class Value(SQLiteNumericMixin, Expression):\n     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n+\n     # Provide a default value for `for_save` in order to allow unresolved\n     # instances to be compiled until a decision is taken in #25425.\n     for_save = False\n@@ -750,7 +828,7 @@ class Value(SQLiteNumericMixin, Expression):\n         self.value = value\n \n     def __repr__(self):\n-        return f'{self.__class__.__name__}({self.value!r})'\n+        return f\"{self.__class__.__name__}({self.value!r})\"\n \n     def as_sql(self, compiler, connection):\n         connection.ops.check_expression_support(self)\n@@ -761,16 +839,18 @@ class Value(SQLiteNumericMixin, Expression):\n                 val = output_field.get_db_prep_save(val, connection=connection)\n             else:\n                 val = output_field.get_db_prep_value(val, connection=connection)\n-            if hasattr(output_field, 'get_placeholder'):\n+            if hasattr(output_field, \"get_placeholder\"):\n                 return output_field.get_placeholder(val, compiler, connection), [val]\n         if val is None:\n             # cx_Oracle does not always convert None to the appropriate\n             # NULL type (like in case expressions using numbers), so we\n             # use a literal SQL NULL\n-            return 'NULL', []\n-        return '%s', [val]\n+            return \"NULL\", []\n+        return \"%s\", [val]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n         c.for_save = for_save\n         return c\n@@ -818,12 +898,14 @@ class RawSQL(Expression):\n         return \"{}({}, {})\".format(self.__class__.__name__, self.sql, self.params)\n \n     def as_sql(self, compiler, connection):\n-        return '(%s)' % self.sql, self.params\n+        return \"(%s)\" % self.sql, self.params\n \n     def get_group_by_cols(self, alias=None):\n         return [self]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         # Resolve parents fields used in raw SQL.\n         for parent in query.model._meta.get_parent_list():\n             for parent_field in parent._meta.local_fields:\n@@ -831,7 +913,9 @@ class RawSQL(Expression):\n                 if column_name.lower() in self.sql.lower():\n                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)\n                     break\n-        return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        return super().resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n \n \n class Star(Expression):\n@@ -839,11 +923,10 @@ class Star(Expression):\n         return \"'*'\"\n \n     def as_sql(self, compiler, connection):\n-        return '*', []\n+        return \"*\", []\n \n \n class Col(Expression):\n-\n     contains_column_references = True\n     possibly_multivalued = False\n \n@@ -856,18 +939,20 @@ class Col(Expression):\n     def __repr__(self):\n         alias, target = self.alias, self.target\n         identifiers = (alias, str(target)) if alias else (str(target),)\n-        return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))\n+        return \"{}({})\".format(self.__class__.__name__, \", \".join(identifiers))\n \n     def as_sql(self, compiler, connection):\n         alias, column = self.alias, self.target.column\n         identifiers = (alias, column) if alias else (column,)\n-        sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))\n+        sql = \".\".join(map(compiler.quote_name_unless_alias, identifiers))\n         return sql, []\n \n     def relabeled_clone(self, relabels):\n         if self.alias is None:\n             return self\n-        return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)\n+        return self.__class__(\n+            relabels.get(self.alias, self.alias), self.target, self.output_field\n+        )\n \n     def get_group_by_cols(self, alias=None):\n         return [self]\n@@ -875,8 +960,9 @@ class Col(Expression):\n     def get_db_converters(self, connection):\n         if self.target == self.output_field:\n             return self.output_field.get_db_converters(connection)\n-        return (self.output_field.get_db_converters(connection) +\n-                self.target.get_db_converters(connection))\n+        return self.output_field.get_db_converters(\n+            connection\n+        ) + self.target.get_db_converters(connection)\n \n \n class Ref(Expression):\n@@ -884,6 +970,7 @@ class Ref(Expression):\n     Reference to column alias of the query. For example, Ref('sum_cost') in\n     qs.annotate(sum_cost=Sum('cost')) query.\n     \"\"\"\n+\n     def __init__(self, refs, source):\n         super().__init__()\n         self.refs, self.source = refs, source\n@@ -895,9 +982,11 @@ class Ref(Expression):\n         return [self.source]\n \n     def set_source_expressions(self, exprs):\n-        self.source, = exprs\n+        (self.source,) = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         # The sub-expression `source` has already been resolved, as this is\n         # just a reference to the name of `source`.\n         return self\n@@ -918,11 +1007,14 @@ class ExpressionList(Func):\n     list of expressions as an argument to another expression, like a partition\n     clause.\n     \"\"\"\n-    template = '%(expressions)s'\n+\n+    template = \"%(expressions)s\"\n \n     def __init__(self, *expressions, **extra):\n         if not expressions:\n-            raise ValueError('%s requires at least one expression.' % self.__class__.__name__)\n+            raise ValueError(\n+                \"%s requires at least one expression.\" % self.__class__.__name__\n+            )\n         super().__init__(*expressions, **extra)\n \n     def __str__(self):\n@@ -934,13 +1026,13 @@ class ExpressionList(Func):\n \n \n class OrderByList(Func):\n-    template = 'ORDER BY %(expressions)s'\n+    template = \"ORDER BY %(expressions)s\"\n \n     def __init__(self, *expressions, **extra):\n         expressions = (\n             (\n                 OrderBy(F(expr[1:]), descending=True)\n-                if isinstance(expr, str) and expr[0] == '-'\n+                if isinstance(expr, str) and expr[0] == \"-\"\n                 else expr\n             )\n             for expr in expressions\n@@ -949,7 +1041,7 @@ class OrderByList(Func):\n \n     def as_sql(self, *args, **kwargs):\n         if not self.source_expressions:\n-            return '', ()\n+            return \"\", ()\n         return super().as_sql(*args, **kwargs)\n \n \n@@ -979,14 +1071,18 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return super().get_group_by_cols()\n \n     def as_sql(self, compiler, connection):\n-        return compiler.compile(self.expression)\n+        expression_sql, expression_params = compiler.compile(self.expression)\n+        if not expression_sql:\n+            if self.output_field.get_internal_type() == \"BooleanField\":\n+                return \"1\", ()\n+        return expression_sql, expression_params\n \n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n \n \n class When(Expression):\n-    template = 'WHEN %(condition)s THEN %(result)s'\n+    template = \"WHEN %(condition)s THEN %(result)s\"\n     # This isn't a complete conditional expression, must be used in Case().\n     conditional = False\n \n@@ -994,12 +1090,12 @@ class When(Expression):\n         if lookups:\n             if condition is None:\n                 condition, lookups = Q(**lookups), None\n-            elif getattr(condition, 'conditional', False):\n+            elif getattr(condition, \"conditional\", False):\n                 condition, lookups = Q(condition, **lookups), None\n-        if condition is None or not getattr(condition, 'conditional', False) or lookups:\n+        if condition is None or not getattr(condition, \"conditional\", False) or lookups:\n             raise TypeError(\n-                'When() supports a Q object, a boolean expression, or lookups '\n-                'as a condition.'\n+                \"When() supports a Q object, a boolean expression, or lookups \"\n+                \"as a condition.\"\n             )\n         if isinstance(condition, Q) and not condition:\n             raise ValueError(\"An empty Q() can't be used as a When() condition.\")\n@@ -1023,12 +1119,18 @@ class When(Expression):\n         # We're only interested in the fields of the result expressions.\n         return [self.result._output_field_or_none]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n-        if hasattr(c.condition, 'resolve_expression'):\n-            c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)\n-        c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        if hasattr(c.condition, \"resolve_expression\"):\n+            c.condition = c.condition.resolve_expression(\n+                query, allow_joins, reuse, summarize, False\n+            )\n+        c.result = c.result.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         return c\n \n     def as_sql(self, compiler, connection, template=None, **extra_context):\n@@ -1036,10 +1138,10 @@ class When(Expression):\n         template_params = extra_context\n         sql_params = []\n         condition_sql, condition_params = compiler.compile(self.condition)\n-        template_params['condition'] = condition_sql\n+        template_params[\"condition\"] = condition_sql\n         sql_params.extend(condition_params)\n         result_sql, result_params = compiler.compile(self.result)\n-        template_params['result'] = result_sql\n+        template_params[\"result\"] = result_sql\n         sql_params.extend(result_params)\n         template = template or self.template\n         return template % template_params, sql_params\n@@ -1064,8 +1166,9 @@ class Case(SQLiteNumericMixin, Expression):\n             ELSE 'zero'\n         END\n     \"\"\"\n-    template = 'CASE %(cases)s ELSE %(default)s END'\n-    case_joiner = ' '\n+\n+    template = \"CASE %(cases)s ELSE %(default)s END\"\n+    case_joiner = \" \"\n \n     def __init__(self, *cases, default=None, output_field=None, **extra):\n         if not all(isinstance(case, When) for case in cases):\n@@ -1076,7 +1179,10 @@ class Case(SQLiteNumericMixin, Expression):\n         self.extra = extra\n \n     def __str__(self):\n-        return \"CASE %s, ELSE %r\" % (', '.join(str(c) for c in self.cases), self.default)\n+        return \"CASE %s, ELSE %r\" % (\n+            \", \".join(str(c) for c in self.cases),\n+            self.default,\n+        )\n \n     def __repr__(self):\n         return \"<%s: %s>\" % (self.__class__.__name__, self)\n@@ -1087,12 +1193,18 @@ class Case(SQLiteNumericMixin, Expression):\n     def set_source_expressions(self, exprs):\n         *self.cases, self.default = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n         for pos, case in enumerate(c.cases):\n-            c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n-        c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+            c.cases[pos] = case.resolve_expression(\n+                query, allow_joins, reuse, summarize, for_save\n+            )\n+        c.default = c.default.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         return c\n \n     def copy(self):\n@@ -1100,7 +1212,9 @@ class Case(SQLiteNumericMixin, Expression):\n         c.cases = c.cases[:]\n         return c\n \n-    def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):\n+    def as_sql(\n+        self, compiler, connection, template=None, case_joiner=None, **extra_context\n+    ):\n         connection.ops.check_expression_support(self)\n         if not self.cases:\n             return compiler.compile(self.default)\n@@ -1118,10 +1232,10 @@ class Case(SQLiteNumericMixin, Expression):\n         if not case_parts:\n             return default_sql, default_params\n         case_joiner = case_joiner or self.case_joiner\n-        template_params['cases'] = case_joiner.join(case_parts)\n-        template_params['default'] = default_sql\n+        template_params[\"cases\"] = case_joiner.join(case_parts)\n+        template_params[\"default\"] = default_sql\n         sql_params.extend(default_params)\n-        template = template or template_params.get('template', self.template)\n+        template = template or template_params.get(\"template\", self.template)\n         sql = template % template_params\n         if self._output_field_or_none is not None:\n             sql = connection.ops.unification_cast_sql(self.output_field) % sql\n@@ -1138,13 +1252,14 @@ class Subquery(BaseExpression, Combinable):\n     An explicit subquery. It may contain OuterRef() references to the outer\n     query which will be resolved when it is applied to that query.\n     \"\"\"\n-    template = '(%(subquery)s)'\n+\n+    template = \"(%(subquery)s)\"\n     contains_aggregate = False\n     empty_result_set_value = None\n \n     def __init__(self, queryset, output_field=None, **extra):\n         # Allow the usage of both QuerySet and sql.Query objects.\n-        self.query = getattr(queryset, 'query', queryset)\n+        self.query = getattr(queryset, \"query\", queryset)\n         self.extra = extra\n         super().__init__(output_field)\n \n@@ -1174,9 +1289,9 @@ class Subquery(BaseExpression, Combinable):\n         template_params = {**self.extra, **extra_context}\n         query = query or self.query\n         subquery_sql, sql_params = query.as_sql(compiler, connection)\n-        template_params['subquery'] = subquery_sql[1:-1]\n+        template_params[\"subquery\"] = subquery_sql[1:-1]\n \n-        template = template or template_params.get('template', self.template)\n+        template = template or template_params.get(\"template\", self.template)\n         sql = template % template_params\n         return sql, sql_params\n \n@@ -1191,7 +1306,7 @@ class Subquery(BaseExpression, Combinable):\n \n \n class Exists(Subquery):\n-    template = 'EXISTS(%(subquery)s)'\n+    template = \"EXISTS(%(subquery)s)\"\n     output_field = fields.BooleanField()\n \n     def __init__(self, queryset, negated=False, **kwargs):\n@@ -1213,7 +1328,7 @@ class Exists(Subquery):\n             **extra_context,\n         )\n         if self.negated:\n-            sql = 'NOT {}'.format(sql)\n+            sql = \"NOT {}\".format(sql)\n         return sql, params\n \n     def select_format(self, compiler, sql, params):\n@@ -1221,27 +1336,30 @@ class Exists(Subquery):\n         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP\n         # BY list.\n         if not compiler.connection.features.supports_boolean_expr_in_select_clause:\n-            sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)\n+            sql = \"CASE WHEN {} THEN 1 ELSE 0 END\".format(sql)\n         return sql, params\n \n \n class OrderBy(Expression):\n-    template = '%(expression)s %(ordering)s'\n+    template = \"%(expression)s %(ordering)s\"\n     conditional = False\n \n-    def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):\n+    def __init__(\n+        self, expression, descending=False, nulls_first=False, nulls_last=False\n+    ):\n         if nulls_first and nulls_last:\n-            raise ValueError('nulls_first and nulls_last are mutually exclusive')\n+            raise ValueError(\"nulls_first and nulls_last are mutually exclusive\")\n         self.nulls_first = nulls_first\n         self.nulls_last = nulls_last\n         self.descending = descending\n-        if not hasattr(expression, 'resolve_expression'):\n-            raise ValueError('expression must be an expression type')\n+        if not hasattr(expression, \"resolve_expression\"):\n+            raise ValueError(\"expression must be an expression type\")\n         self.expression = expression\n \n     def __repr__(self):\n         return \"{}({}, descending={})\".format(\n-            self.__class__.__name__, self.expression, self.descending)\n+            self.__class__.__name__, self.expression, self.descending\n+        )\n \n     def set_source_expressions(self, exprs):\n         self.expression = exprs[0]\n@@ -1253,32 +1371,34 @@ class OrderBy(Expression):\n         template = template or self.template\n         if connection.features.supports_order_by_nulls_modifier:\n             if self.nulls_last:\n-                template = '%s NULLS LAST' % template\n+                template = \"%s NULLS LAST\" % template\n             elif self.nulls_first:\n-                template = '%s NULLS FIRST' % template\n+                template = \"%s NULLS FIRST\" % template\n         else:\n             if self.nulls_last and not (\n                 self.descending and connection.features.order_by_nulls_first\n             ):\n-                template = '%%(expression)s IS NULL, %s' % template\n+                template = \"%%(expression)s IS NULL, %s\" % template\n             elif self.nulls_first and not (\n                 not self.descending and connection.features.order_by_nulls_first\n             ):\n-                template = '%%(expression)s IS NOT NULL, %s' % template\n+                template = \"%%(expression)s IS NOT NULL, %s\" % template\n         connection.ops.check_expression_support(self)\n         expression_sql, params = compiler.compile(self.expression)\n         placeholders = {\n-            'expression': expression_sql,\n-            'ordering': 'DESC' if self.descending else 'ASC',\n+            \"expression\": expression_sql,\n+            \"ordering\": \"DESC\" if self.descending else \"ASC\",\n             **extra_context,\n         }\n-        params *= template.count('%(expression)s')\n+        params *= template.count(\"%(expression)s\")\n         return (template % placeholders).rstrip(), params\n \n     def as_oracle(self, compiler, connection):\n         # Oracle doesn't allow ORDER BY EXISTS() or filters unless it's wrapped\n         # in a CASE WHEN.\n-        if connection.ops.conditional_expression_supported_in_where_clause(self.expression):\n+        if connection.ops.conditional_expression_supported_in_where_clause(\n+            self.expression\n+        ):\n             copy = self.copy()\n             copy.expression = Case(\n                 When(self.expression, then=True),\n@@ -1308,7 +1428,7 @@ class OrderBy(Expression):\n \n \n class Window(SQLiteNumericMixin, Expression):\n-    template = '%(expression)s OVER (%(window)s)'\n+    template = \"%(expression)s OVER (%(window)s)\"\n     # Although the main expression may either be an aggregate or an\n     # expression with an aggregate function, the GROUP BY that will\n     # be introduced in the query as a result is not desired.\n@@ -1316,15 +1436,22 @@ class Window(SQLiteNumericMixin, Expression):\n     contains_over_clause = True\n     filterable = False\n \n-    def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):\n+    def __init__(\n+        self,\n+        expression,\n+        partition_by=None,\n+        order_by=None,\n+        frame=None,\n+        output_field=None,\n+    ):\n         self.partition_by = partition_by\n         self.order_by = order_by\n         self.frame = frame\n \n-        if not getattr(expression, 'window_compatible', False):\n+        if not getattr(expression, \"window_compatible\", False):\n             raise ValueError(\n-                \"Expression '%s' isn't compatible with OVER clauses.\" %\n-                expression.__class__.__name__\n+                \"Expression '%s' isn't compatible with OVER clauses.\"\n+                % expression.__class__.__name__\n             )\n \n         if self.partition_by is not None:\n@@ -1339,8 +1466,8 @@ class Window(SQLiteNumericMixin, Expression):\n                 self.order_by = OrderByList(self.order_by)\n             else:\n                 raise ValueError(\n-                    'Window.order_by must be either a string reference to a '\n-                    'field, an expression, or a list or tuple of them.'\n+                    \"Window.order_by must be either a string reference to a \"\n+                    \"field, an expression, or a list or tuple of them.\"\n                 )\n         super().__init__(output_field=output_field)\n         self.source_expression = self._parse_expressions(expression)[0]\n@@ -1357,14 +1484,15 @@ class Window(SQLiteNumericMixin, Expression):\n     def as_sql(self, compiler, connection, template=None):\n         connection.ops.check_expression_support(self)\n         if not connection.features.supports_over_clause:\n-            raise NotSupportedError('This backend does not support window expressions.')\n+            raise NotSupportedError(\"This backend does not support window expressions.\")\n         expr_sql, params = compiler.compile(self.source_expression)\n         window_sql, window_params = [], []\n \n         if self.partition_by is not None:\n             sql_expr, sql_params = self.partition_by.as_sql(\n-                compiler=compiler, connection=connection,\n-                template='PARTITION BY %(expressions)s',\n+                compiler=compiler,\n+                connection=connection,\n+                template=\"PARTITION BY %(expressions)s\",\n             )\n             window_sql.append(sql_expr)\n             window_params.extend(sql_params)\n@@ -1383,8 +1511,8 @@ class Window(SQLiteNumericMixin, Expression):\n         template = template or self.template\n \n         return template % {\n-            'expression': expr_sql,\n-            'window': ' '.join(window_sql).strip()\n+            \"expression\": expr_sql,\n+            \"window\": \" \".join(window_sql).strip(),\n         }, params\n \n     def as_sqlite(self, compiler, connection):\n@@ -1398,15 +1526,15 @@ class Window(SQLiteNumericMixin, Expression):\n         return self.as_sql(compiler, connection)\n \n     def __str__(self):\n-        return '{} OVER ({}{}{})'.format(\n+        return \"{} OVER ({}{}{})\".format(\n             str(self.source_expression),\n-            'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',\n-            str(self.order_by or ''),\n-            str(self.frame or ''),\n+            \"PARTITION BY \" + str(self.partition_by) if self.partition_by else \"\",\n+            str(self.order_by or \"\"),\n+            str(self.frame or \"\"),\n         )\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def get_group_by_cols(self, alias=None):\n         return []\n@@ -1420,7 +1548,8 @@ class WindowFrame(Expression):\n     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last\n     row in the frame).\n     \"\"\"\n-    template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'\n+\n+    template = \"%(frame_type)s BETWEEN %(start)s AND %(end)s\"\n \n     def __init__(self, start=None, end=None):\n         self.start = Value(start)\n@@ -1434,52 +1563,54 @@ class WindowFrame(Expression):\n \n     def as_sql(self, compiler, connection):\n         connection.ops.check_expression_support(self)\n-        start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)\n+        start, end = self.window_frame_start_end(\n+            connection, self.start.value, self.end.value\n+        )\n         return self.template % {\n-            'frame_type': self.frame_type,\n-            'start': start,\n-            'end': end,\n+            \"frame_type\": self.frame_type,\n+            \"start\": start,\n+            \"end\": end,\n         }, []\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def get_group_by_cols(self, alias=None):\n         return []\n \n     def __str__(self):\n         if self.start.value is not None and self.start.value < 0:\n-            start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)\n+            start = \"%d %s\" % (abs(self.start.value), connection.ops.PRECEDING)\n         elif self.start.value is not None and self.start.value == 0:\n             start = connection.ops.CURRENT_ROW\n         else:\n             start = connection.ops.UNBOUNDED_PRECEDING\n \n         if self.end.value is not None and self.end.value > 0:\n-            end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)\n+            end = \"%d %s\" % (self.end.value, connection.ops.FOLLOWING)\n         elif self.end.value is not None and self.end.value == 0:\n             end = connection.ops.CURRENT_ROW\n         else:\n             end = connection.ops.UNBOUNDED_FOLLOWING\n         return self.template % {\n-            'frame_type': self.frame_type,\n-            'start': start,\n-            'end': end,\n+            \"frame_type\": self.frame_type,\n+            \"start\": start,\n+            \"end\": end,\n         }\n \n     def window_frame_start_end(self, connection, start, end):\n-        raise NotImplementedError('Subclasses must implement window_frame_start_end().')\n+        raise NotImplementedError(\"Subclasses must implement window_frame_start_end().\")\n \n \n class RowRange(WindowFrame):\n-    frame_type = 'ROWS'\n+    frame_type = \"ROWS\"\n \n     def window_frame_start_end(self, connection, start, end):\n         return connection.ops.window_frame_rows_start_end(start, end)\n \n \n class ValueRange(WindowFrame):\n-    frame_type = 'RANGE'\n+    frame_type = \"RANGE\"\n \n     def window_frame_start_end(self, connection, start, end):\n         return connection.ops.window_frame_range_start_end(start, end)\n"}
{"instance_id": "django__django-15252", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..953366f82b 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,5 @@\n from django.apps.registry import Apps\n-from django.db import DatabaseError, models\n+from django.db import DatabaseError, models, router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -18,6 +18,7 @@ class MigrationRecorder:\n     If a migration is unapplied its row is removed from the table. Having\n     a row in the table always means a migration is applied.\n     \"\"\"\n+\n     _migration_class = None\n \n     @classproperty\n@@ -27,6 +28,7 @@ class MigrationRecorder:\n         MigrationRecorder.\n         \"\"\"\n         if cls._migration_class is None:\n+\n             class Migration(models.Model):\n                 app = models.CharField(max_length=255)\n                 name = models.CharField(max_length=255)\n@@ -34,11 +36,11 @@ class MigrationRecorder:\n \n                 class Meta:\n                     apps = Apps()\n-                    app_label = 'migrations'\n-                    db_table = 'django_migrations'\n+                    app_label = \"migrations\"\n+                    db_table = \"django_migrations\"\n \n                 def __str__(self):\n-                    return 'Migration %s for %s' % (self.name, self.app)\n+                    return \"Migration %s for %s\" % (self.name, self.app)\n \n             cls._migration_class = Migration\n         return cls._migration_class\n@@ -62,12 +64,17 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n+        # Check if the router allows migrations on this database.\n+        if not router.allow_migrate(self.connection.alias, \"migrations\"):\n+            return\n         # Make the table\n         try:\n             with self.connection.schema_editor() as editor:\n                 editor.create_model(self.Migration)\n         except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+            raise MigrationSchemaMissing(\n+                \"Unable to create the django_migrations table (%s)\" % exc\n+            )\n \n     def applied_migrations(self):\n         \"\"\"\n@@ -75,7 +82,10 @@ class MigrationRecorder:\n         for all applied migrations.\n         \"\"\"\n         if self.has_table():\n-            return {(migration.app, migration.name): migration for migration in self.migration_qs}\n+            return {\n+                (migration.app, migration.name): migration\n+                for migration in self.migration_qs\n+            }\n         else:\n             # If the django_migrations table doesn't exist, then no migrations\n             # are applied.\n@@ -83,11 +93,15 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n+        if not router.allow_migrate(self.connection.alias, \"migrations\"):\n+            return\n         self.ensure_schema()\n         self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n+        if not router.allow_migrate(self.connection.alias, \"migrations\"):\n+            return\n         self.ensure_schema()\n         self.migration_qs.filter(app=app, name=name).delete()\n \n"}
{"instance_id": "django__django-15320", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 6f26dff0e0..dbe5147307 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -20,11 +20,12 @@ class SQLiteNumericMixin:\n     Some expressions with output_field=DecimalField() must be cast to\n     numeric to be properly filtered.\n     \"\"\"\n+\n     def as_sqlite(self, compiler, connection, **extra_context):\n         sql, params = self.as_sql(compiler, connection, **extra_context)\n         try:\n-            if self.output_field.get_internal_type() == 'DecimalField':\n-                sql = 'CAST(%s AS NUMERIC)' % sql\n+            if self.output_field.get_internal_type() == \"DecimalField\":\n+                sql = \"CAST(%s AS NUMERIC)\" % sql\n         except FieldError:\n             pass\n         return sql, params\n@@ -37,26 +38,26 @@ class Combinable:\n     \"\"\"\n \n     # Arithmetic connectors\n-    ADD = '+'\n-    SUB = '-'\n-    MUL = '*'\n-    DIV = '/'\n-    POW = '^'\n+    ADD = \"+\"\n+    SUB = \"-\"\n+    MUL = \"*\"\n+    DIV = \"/\"\n+    POW = \"^\"\n     # The following is a quoted % operator - it is quoted because it can be\n     # used in strings that also have parameter substitution.\n-    MOD = '%%'\n+    MOD = \"%%\"\n \n     # Bitwise operators - note that these are generated by .bitand()\n     # and .bitor(), the '&' and '|' are reserved for boolean operator\n     # usage.\n-    BITAND = '&'\n-    BITOR = '|'\n-    BITLEFTSHIFT = '<<'\n-    BITRIGHTSHIFT = '>>'\n-    BITXOR = '#'\n+    BITAND = \"&\"\n+    BITOR = \"|\"\n+    BITLEFTSHIFT = \"<<\"\n+    BITRIGHTSHIFT = \">>\"\n+    BITXOR = \"#\"\n \n     def _combine(self, other, connector, reversed):\n-        if not hasattr(other, 'resolve_expression'):\n+        if not hasattr(other, \"resolve_expression\"):\n             # everything must be resolvable to an expression\n             other = Value(other)\n \n@@ -90,7 +91,7 @@ class Combinable:\n         return self._combine(other, self.POW, False)\n \n     def __and__(self, other):\n-        if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n+        if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):\n             return Q(self) & Q(other)\n         raise NotImplementedError(\n             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n@@ -109,7 +110,7 @@ class Combinable:\n         return self._combine(other, self.BITXOR, False)\n \n     def __or__(self, other):\n-        if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n+        if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):\n             return Q(self) | Q(other)\n         raise NotImplementedError(\n             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n@@ -165,14 +166,14 @@ class BaseExpression:\n \n     def __getstate__(self):\n         state = self.__dict__.copy()\n-        state.pop('convert_value', None)\n+        state.pop(\"convert_value\", None)\n         return state\n \n     def get_db_converters(self, connection):\n         return (\n             []\n-            if self.convert_value is self._convert_value_noop else\n-            [self.convert_value]\n+            if self.convert_value is self._convert_value_noop\n+            else [self.convert_value]\n         ) + self.output_field.get_db_converters(connection)\n \n     def get_source_expressions(self):\n@@ -183,9 +184,10 @@ class BaseExpression:\n \n     def _parse_expressions(self, *expressions):\n         return [\n-            arg if hasattr(arg, 'resolve_expression') else (\n-                F(arg) if isinstance(arg, str) else Value(arg)\n-            ) for arg in expressions\n+            arg\n+            if hasattr(arg, \"resolve_expression\")\n+            else (F(arg) if isinstance(arg, str) else Value(arg))\n+            for arg in expressions\n         ]\n \n     def as_sql(self, compiler, connection):\n@@ -218,17 +220,26 @@ class BaseExpression:\n \n     @cached_property\n     def contains_aggregate(self):\n-        return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_aggregate for expr in self.get_source_expressions()\n+        )\n \n     @cached_property\n     def contains_over_clause(self):\n-        return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_over_clause for expr in self.get_source_expressions()\n+        )\n \n     @cached_property\n     def contains_column_references(self):\n-        return any(expr and expr.contains_column_references for expr in self.get_source_expressions())\n+        return any(\n+            expr and expr.contains_column_references\n+            for expr in self.get_source_expressions()\n+        )\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         \"\"\"\n         Provide the chance to do any preprocessing or validation before being\n         added to the query.\n@@ -245,11 +256,14 @@ class BaseExpression:\n         \"\"\"\n         c = self.copy()\n         c.is_summary = summarize\n-        c.set_source_expressions([\n-            expr.resolve_expression(query, allow_joins, reuse, summarize)\n-            if expr else None\n-            for expr in c.get_source_expressions()\n-        ])\n+        c.set_source_expressions(\n+            [\n+                expr.resolve_expression(query, allow_joins, reuse, summarize)\n+                if expr\n+                else None\n+                for expr in c.get_source_expressions()\n+            ]\n+        )\n         return c\n \n     @property\n@@ -266,7 +280,7 @@ class BaseExpression:\n         output_field = self._resolve_output_field()\n         if output_field is None:\n             self._output_field_resolved_to_none = True\n-            raise FieldError('Cannot resolve expression type, unknown output_field')\n+            raise FieldError(\"Cannot resolve expression type, unknown output_field\")\n         return output_field\n \n     @cached_property\n@@ -295,13 +309,16 @@ class BaseExpression:\n         If all sources are None, then an error is raised higher up the stack in\n         the output_field property.\n         \"\"\"\n-        sources_iter = (source for source in self.get_source_fields() if source is not None)\n+        sources_iter = (\n+            source for source in self.get_source_fields() if source is not None\n+        )\n         for output_field in sources_iter:\n             for source in sources_iter:\n                 if not isinstance(output_field, source.__class__):\n                     raise FieldError(\n-                        'Expression contains mixed types: %s, %s. You must '\n-                        'set output_field.' % (\n+                        \"Expression contains mixed types: %s, %s. You must \"\n+                        \"set output_field.\"\n+                        % (\n                             output_field.__class__.__name__,\n                             source.__class__.__name__,\n                         )\n@@ -321,12 +338,24 @@ class BaseExpression:\n         \"\"\"\n         field = self.output_field\n         internal_type = field.get_internal_type()\n-        if internal_type == 'FloatField':\n-            return lambda value, expression, connection: None if value is None else float(value)\n-        elif internal_type.endswith('IntegerField'):\n-            return lambda value, expression, connection: None if value is None else int(value)\n-        elif internal_type == 'DecimalField':\n-            return lambda value, expression, connection: None if value is None else Decimal(value)\n+        if internal_type == \"FloatField\":\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else float(value)\n+            )\n+        elif internal_type.endswith(\"IntegerField\"):\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else int(value)\n+            )\n+        elif internal_type == \"DecimalField\":\n+            return (\n+                lambda value, expression, connection: None\n+                if value is None\n+                else Decimal(value)\n+            )\n         return self._convert_value_noop\n \n     def get_lookup(self, lookup):\n@@ -337,10 +366,12 @@ class BaseExpression:\n \n     def relabeled_clone(self, change_map):\n         clone = self.copy()\n-        clone.set_source_expressions([\n-            e.relabeled_clone(change_map) if e is not None else None\n-            for e in self.get_source_expressions()\n-        ])\n+        clone.set_source_expressions(\n+            [\n+                e.relabeled_clone(change_map) if e is not None else None\n+                for e in self.get_source_expressions()\n+            ]\n+        )\n         return clone\n \n     def copy(self):\n@@ -375,7 +406,7 @@ class BaseExpression:\n         yield self\n         for expr in self.get_source_expressions():\n             if expr:\n-                if hasattr(expr, 'flatten'):\n+                if hasattr(expr, \"flatten\"):\n                     yield from expr.flatten()\n                 else:\n                     yield expr\n@@ -385,7 +416,7 @@ class BaseExpression:\n         Custom format for select clauses. For example, EXISTS expressions need\n         to be wrapped in CASE WHEN on Oracle.\n         \"\"\"\n-        if hasattr(self.output_field, 'select_format'):\n+        if hasattr(self.output_field, \"select_format\"):\n             return self.output_field.select_format(compiler, sql, params)\n         return sql, params\n \n@@ -438,12 +469,13 @@ _connector_combinators = {\n def _resolve_combined_type(connector, lhs_type, rhs_type):\n     combinators = _connector_combinators.get(connector, ())\n     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:\n-        if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):\n+        if issubclass(lhs_type, combinator_lhs_type) and issubclass(\n+            rhs_type, combinator_rhs_type\n+        ):\n             return combined_type\n \n \n class CombinedExpression(SQLiteNumericMixin, Expression):\n-\n     def __init__(self, lhs, connector, rhs, output_field=None):\n         super().__init__(output_field=output_field)\n         self.connector = connector\n@@ -485,13 +517,19 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n         expressions.append(sql)\n         expression_params.extend(params)\n         # order of precedence\n-        expression_wrapper = '(%s)'\n+        expression_wrapper = \"(%s)\"\n         sql = connection.ops.combine_expression(self.connector, expressions)\n         return expression_wrapper % sql, expression_params\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n-        lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n-        rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n+        lhs = self.lhs.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n+        rhs = self.rhs.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         if not isinstance(self, (DurationExpression, TemporalSubtraction)):\n             try:\n                 lhs_type = lhs.output_field.get_internal_type()\n@@ -501,14 +539,28 @@ class CombinedExpression(SQLiteNumericMixin, Expression):\n                 rhs_type = rhs.output_field.get_internal_type()\n             except (AttributeError, FieldError):\n                 rhs_type = None\n-            if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:\n-                return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(\n-                    query, allow_joins, reuse, summarize, for_save,\n+            if \"DurationField\" in {lhs_type, rhs_type} and lhs_type != rhs_type:\n+                return DurationExpression(\n+                    self.lhs, self.connector, self.rhs\n+                ).resolve_expression(\n+                    query,\n+                    allow_joins,\n+                    reuse,\n+                    summarize,\n+                    for_save,\n                 )\n-            datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}\n-            if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:\n+            datetime_fields = {\"DateField\", \"DateTimeField\", \"TimeField\"}\n+            if (\n+                self.connector == self.SUB\n+                and lhs_type in datetime_fields\n+                and lhs_type == rhs_type\n+            ):\n                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(\n-                    query, allow_joins, reuse, summarize, for_save,\n+                    query,\n+                    allow_joins,\n+                    reuse,\n+                    summarize,\n+                    for_save,\n                 )\n         c = self.copy()\n         c.is_summary = summarize\n@@ -524,7 +576,7 @@ class DurationExpression(CombinedExpression):\n         except FieldError:\n             pass\n         else:\n-            if output.get_internal_type() == 'DurationField':\n+            if output.get_internal_type() == \"DurationField\":\n                 sql, params = compiler.compile(side)\n                 return connection.ops.format_for_duration_arithmetic(sql), params\n         return compiler.compile(side)\n@@ -542,7 +594,7 @@ class DurationExpression(CombinedExpression):\n         expressions.append(sql)\n         expression_params.extend(params)\n         # order of precedence\n-        expression_wrapper = '(%s)'\n+        expression_wrapper = \"(%s)\"\n         sql = connection.ops.combine_duration_expression(self.connector, expressions)\n         return expression_wrapper % sql, expression_params\n \n@@ -556,11 +608,14 @@ class DurationExpression(CombinedExpression):\n                 pass\n             else:\n                 allowed_fields = {\n-                    'DecimalField', 'DurationField', 'FloatField', 'IntegerField',\n+                    \"DecimalField\",\n+                    \"DurationField\",\n+                    \"FloatField\",\n+                    \"IntegerField\",\n                 }\n                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:\n                     raise DatabaseError(\n-                        f'Invalid arguments for operator {self.connector}.'\n+                        f\"Invalid arguments for operator {self.connector}.\"\n                     )\n         return sql, params\n \n@@ -575,10 +630,12 @@ class TemporalSubtraction(CombinedExpression):\n         connection.ops.check_expression_support(self)\n         lhs = compiler.compile(self.lhs)\n         rhs = compiler.compile(self.rhs)\n-        return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)\n+        return connection.ops.subtract_temporals(\n+            self.lhs.output_field.get_internal_type(), lhs, rhs\n+        )\n \n \n-@deconstructible(path='django.db.models.F')\n+@deconstructible(path=\"django.db.models.F\")\n class F(Combinable):\n     \"\"\"An object capable of resolving references to existing query objects.\"\"\"\n \n@@ -592,8 +649,9 @@ class F(Combinable):\n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.name)\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None,\n-                           summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         return query.resolve_ref(self.name, allow_joins, reuse, summarize)\n \n     def asc(self, **kwargs):\n@@ -616,12 +674,13 @@ class ResolvedOuterRef(F):\n     In this case, the reference to the outer query has been resolved because\n     the inner query has been used as a subquery.\n     \"\"\"\n+\n     contains_aggregate = False\n \n     def as_sql(self, *args, **kwargs):\n         raise ValueError(\n-            'This queryset contains a reference to an outer query and may '\n-            'only be used in a subquery.'\n+            \"This queryset contains a reference to an outer query and may \"\n+            \"only be used in a subquery.\"\n         )\n \n     def resolve_expression(self, *args, **kwargs):\n@@ -651,18 +710,20 @@ class OuterRef(F):\n         return self\n \n \n-@deconstructible(path='django.db.models.Func')\n+@deconstructible(path=\"django.db.models.Func\")\n class Func(SQLiteNumericMixin, Expression):\n     \"\"\"An SQL function call.\"\"\"\n+\n     function = None\n-    template = '%(function)s(%(expressions)s)'\n-    arg_joiner = ', '\n+    template = \"%(function)s(%(expressions)s)\"\n+    arg_joiner = \", \"\n     arity = None  # The number of arguments the function accepts.\n \n     def __init__(self, *expressions, output_field=None, **extra):\n         if self.arity is not None and len(expressions) != self.arity:\n             raise TypeError(\n-                \"'%s' takes exactly %s %s (%s given)\" % (\n+                \"'%s' takes exactly %s %s (%s given)\"\n+                % (\n                     self.__class__.__name__,\n                     self.arity,\n                     \"argument\" if self.arity == 1 else \"arguments\",\n@@ -677,7 +738,9 @@ class Func(SQLiteNumericMixin, Expression):\n         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n         extra = {**self.extra, **self._get_repr_options()}\n         if extra:\n-            extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))\n+            extra = \", \".join(\n+                str(key) + \"=\" + str(val) for key, val in sorted(extra.items())\n+            )\n             return \"{}({}, {})\".format(self.__class__.__name__, args, extra)\n         return \"{}({})\".format(self.__class__.__name__, args)\n \n@@ -691,14 +754,26 @@ class Func(SQLiteNumericMixin, Expression):\n     def set_source_expressions(self, exprs):\n         self.source_expressions = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n         for pos, arg in enumerate(c.source_expressions):\n-            c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+            c.source_expressions[pos] = arg.resolve_expression(\n+                query, allow_joins, reuse, summarize, for_save\n+            )\n         return c\n \n-    def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):\n+    def as_sql(\n+        self,\n+        compiler,\n+        connection,\n+        function=None,\n+        template=None,\n+        arg_joiner=None,\n+        **extra_context,\n+    ):\n         connection.ops.check_expression_support(self)\n         sql_parts = []\n         params = []\n@@ -706,7 +781,9 @@ class Func(SQLiteNumericMixin, Expression):\n             try:\n                 arg_sql, arg_params = compiler.compile(arg)\n             except EmptyResultSet:\n-                empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented)\n+                empty_result_set_value = getattr(\n+                    arg, \"empty_result_set_value\", NotImplemented\n+                )\n                 if empty_result_set_value is NotImplemented:\n                     raise\n                 arg_sql, arg_params = compiler.compile(Value(empty_result_set_value))\n@@ -717,12 +794,12 @@ class Func(SQLiteNumericMixin, Expression):\n         # method, a value supplied in __init__()'s **extra (the value in\n         # `data`), or the value defined on the class.\n         if function is not None:\n-            data['function'] = function\n+            data[\"function\"] = function\n         else:\n-            data.setdefault('function', self.function)\n-        template = template or data.get('template', self.template)\n-        arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)\n-        data['expressions'] = data['field'] = arg_joiner.join(sql_parts)\n+            data.setdefault(\"function\", self.function)\n+        template = template or data.get(\"template\", self.template)\n+        arg_joiner = arg_joiner or data.get(\"arg_joiner\", self.arg_joiner)\n+        data[\"expressions\"] = data[\"field\"] = arg_joiner.join(sql_parts)\n         return template % data, params\n \n     def copy(self):\n@@ -732,9 +809,10 @@ class Func(SQLiteNumericMixin, Expression):\n         return copy\n \n \n-@deconstructible(path='django.db.models.Value')\n+@deconstructible(path=\"django.db.models.Value\")\n class Value(SQLiteNumericMixin, Expression):\n     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n+\n     # Provide a default value for `for_save` in order to allow unresolved\n     # instances to be compiled until a decision is taken in #25425.\n     for_save = False\n@@ -752,7 +830,7 @@ class Value(SQLiteNumericMixin, Expression):\n         self.value = value\n \n     def __repr__(self):\n-        return f'{self.__class__.__name__}({self.value!r})'\n+        return f\"{self.__class__.__name__}({self.value!r})\"\n \n     def as_sql(self, compiler, connection):\n         connection.ops.check_expression_support(self)\n@@ -763,16 +841,18 @@ class Value(SQLiteNumericMixin, Expression):\n                 val = output_field.get_db_prep_save(val, connection=connection)\n             else:\n                 val = output_field.get_db_prep_value(val, connection=connection)\n-            if hasattr(output_field, 'get_placeholder'):\n+            if hasattr(output_field, \"get_placeholder\"):\n                 return output_field.get_placeholder(val, compiler, connection), [val]\n         if val is None:\n             # cx_Oracle does not always convert None to the appropriate\n             # NULL type (like in case expressions using numbers), so we\n             # use a literal SQL NULL\n-            return 'NULL', []\n-        return '%s', [val]\n+            return \"NULL\", []\n+        return \"%s\", [val]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n         c.for_save = for_save\n         return c\n@@ -820,12 +900,14 @@ class RawSQL(Expression):\n         return \"{}({}, {})\".format(self.__class__.__name__, self.sql, self.params)\n \n     def as_sql(self, compiler, connection):\n-        return '(%s)' % self.sql, self.params\n+        return \"(%s)\" % self.sql, self.params\n \n     def get_group_by_cols(self, alias=None):\n         return [self]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         # Resolve parents fields used in raw SQL.\n         for parent in query.model._meta.get_parent_list():\n             for parent_field in parent._meta.local_fields:\n@@ -833,7 +915,9 @@ class RawSQL(Expression):\n                 if column_name.lower() in self.sql.lower():\n                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)\n                     break\n-        return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        return super().resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n \n \n class Star(Expression):\n@@ -841,11 +925,10 @@ class Star(Expression):\n         return \"'*'\"\n \n     def as_sql(self, compiler, connection):\n-        return '*', []\n+        return \"*\", []\n \n \n class Col(Expression):\n-\n     contains_column_references = True\n     possibly_multivalued = False\n \n@@ -858,18 +941,20 @@ class Col(Expression):\n     def __repr__(self):\n         alias, target = self.alias, self.target\n         identifiers = (alias, str(target)) if alias else (str(target),)\n-        return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))\n+        return \"{}({})\".format(self.__class__.__name__, \", \".join(identifiers))\n \n     def as_sql(self, compiler, connection):\n         alias, column = self.alias, self.target.column\n         identifiers = (alias, column) if alias else (column,)\n-        sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))\n+        sql = \".\".join(map(compiler.quote_name_unless_alias, identifiers))\n         return sql, []\n \n     def relabeled_clone(self, relabels):\n         if self.alias is None:\n             return self\n-        return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)\n+        return self.__class__(\n+            relabels.get(self.alias, self.alias), self.target, self.output_field\n+        )\n \n     def get_group_by_cols(self, alias=None):\n         return [self]\n@@ -877,8 +962,9 @@ class Col(Expression):\n     def get_db_converters(self, connection):\n         if self.target == self.output_field:\n             return self.output_field.get_db_converters(connection)\n-        return (self.output_field.get_db_converters(connection) +\n-                self.target.get_db_converters(connection))\n+        return self.output_field.get_db_converters(\n+            connection\n+        ) + self.target.get_db_converters(connection)\n \n \n class Ref(Expression):\n@@ -886,6 +972,7 @@ class Ref(Expression):\n     Reference to column alias of the query. For example, Ref('sum_cost') in\n     qs.annotate(sum_cost=Sum('cost')) query.\n     \"\"\"\n+\n     def __init__(self, refs, source):\n         super().__init__()\n         self.refs, self.source = refs, source\n@@ -897,9 +984,11 @@ class Ref(Expression):\n         return [self.source]\n \n     def set_source_expressions(self, exprs):\n-        self.source, = exprs\n+        (self.source,) = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         # The sub-expression `source` has already been resolved, as this is\n         # just a reference to the name of `source`.\n         return self\n@@ -920,11 +1009,14 @@ class ExpressionList(Func):\n     list of expressions as an argument to another expression, like a partition\n     clause.\n     \"\"\"\n-    template = '%(expressions)s'\n+\n+    template = \"%(expressions)s\"\n \n     def __init__(self, *expressions, **extra):\n         if not expressions:\n-            raise ValueError('%s requires at least one expression.' % self.__class__.__name__)\n+            raise ValueError(\n+                \"%s requires at least one expression.\" % self.__class__.__name__\n+            )\n         super().__init__(*expressions, **extra)\n \n     def __str__(self):\n@@ -936,13 +1028,13 @@ class ExpressionList(Func):\n \n \n class OrderByList(Func):\n-    template = 'ORDER BY %(expressions)s'\n+    template = \"ORDER BY %(expressions)s\"\n \n     def __init__(self, *expressions, **extra):\n         expressions = (\n             (\n                 OrderBy(F(expr[1:]), descending=True)\n-                if isinstance(expr, str) and expr[0] == '-'\n+                if isinstance(expr, str) and expr[0] == \"-\"\n                 else expr\n             )\n             for expr in expressions\n@@ -951,11 +1043,11 @@ class OrderByList(Func):\n \n     def as_sql(self, *args, **kwargs):\n         if not self.source_expressions:\n-            return '', ()\n+            return \"\", ()\n         return super().as_sql(*args, **kwargs)\n \n \n-@deconstructible(path='django.db.models.ExpressionWrapper')\n+@deconstructible(path=\"django.db.models.ExpressionWrapper\")\n class ExpressionWrapper(SQLiteNumericMixin, Expression):\n     \"\"\"\n     An expression that can wrap another expression so that it can provide\n@@ -988,9 +1080,9 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n \n \n-@deconstructible(path='django.db.models.When')\n+@deconstructible(path=\"django.db.models.When\")\n class When(Expression):\n-    template = 'WHEN %(condition)s THEN %(result)s'\n+    template = \"WHEN %(condition)s THEN %(result)s\"\n     # This isn't a complete conditional expression, must be used in Case().\n     conditional = False\n \n@@ -998,12 +1090,12 @@ class When(Expression):\n         if lookups:\n             if condition is None:\n                 condition, lookups = Q(**lookups), None\n-            elif getattr(condition, 'conditional', False):\n+            elif getattr(condition, \"conditional\", False):\n                 condition, lookups = Q(condition, **lookups), None\n-        if condition is None or not getattr(condition, 'conditional', False) or lookups:\n+        if condition is None or not getattr(condition, \"conditional\", False) or lookups:\n             raise TypeError(\n-                'When() supports a Q object, a boolean expression, or lookups '\n-                'as a condition.'\n+                \"When() supports a Q object, a boolean expression, or lookups \"\n+                \"as a condition.\"\n             )\n         if isinstance(condition, Q) and not condition:\n             raise ValueError(\"An empty Q() can't be used as a When() condition.\")\n@@ -1027,12 +1119,18 @@ class When(Expression):\n         # We're only interested in the fields of the result expressions.\n         return [self.result._output_field_or_none]\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n-        if hasattr(c.condition, 'resolve_expression'):\n-            c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)\n-        c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        if hasattr(c.condition, \"resolve_expression\"):\n+            c.condition = c.condition.resolve_expression(\n+                query, allow_joins, reuse, summarize, False\n+            )\n+        c.result = c.result.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         return c\n \n     def as_sql(self, compiler, connection, template=None, **extra_context):\n@@ -1040,10 +1138,10 @@ class When(Expression):\n         template_params = extra_context\n         sql_params = []\n         condition_sql, condition_params = compiler.compile(self.condition)\n-        template_params['condition'] = condition_sql\n+        template_params[\"condition\"] = condition_sql\n         sql_params.extend(condition_params)\n         result_sql, result_params = compiler.compile(self.result)\n-        template_params['result'] = result_sql\n+        template_params[\"result\"] = result_sql\n         sql_params.extend(result_params)\n         template = template or self.template\n         return template % template_params, sql_params\n@@ -1056,7 +1154,7 @@ class When(Expression):\n         return cols\n \n \n-@deconstructible(path='django.db.models.Case')\n+@deconstructible(path=\"django.db.models.Case\")\n class Case(SQLiteNumericMixin, Expression):\n     \"\"\"\n     An SQL searched CASE expression:\n@@ -1069,8 +1167,9 @@ class Case(SQLiteNumericMixin, Expression):\n             ELSE 'zero'\n         END\n     \"\"\"\n-    template = 'CASE %(cases)s ELSE %(default)s END'\n-    case_joiner = ' '\n+\n+    template = \"CASE %(cases)s ELSE %(default)s END\"\n+    case_joiner = \" \"\n \n     def __init__(self, *cases, default=None, output_field=None, **extra):\n         if not all(isinstance(case, When) for case in cases):\n@@ -1081,7 +1180,10 @@ class Case(SQLiteNumericMixin, Expression):\n         self.extra = extra\n \n     def __str__(self):\n-        return \"CASE %s, ELSE %r\" % (', '.join(str(c) for c in self.cases), self.default)\n+        return \"CASE %s, ELSE %r\" % (\n+            \", \".join(str(c) for c in self.cases),\n+            self.default,\n+        )\n \n     def __repr__(self):\n         return \"<%s: %s>\" % (self.__class__.__name__, self)\n@@ -1092,12 +1194,18 @@ class Case(SQLiteNumericMixin, Expression):\n     def set_source_expressions(self, exprs):\n         *self.cases, self.default = exprs\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n+    def resolve_expression(\n+        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+    ):\n         c = self.copy()\n         c.is_summary = summarize\n         for pos, case in enumerate(c.cases):\n-            c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n-        c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+            c.cases[pos] = case.resolve_expression(\n+                query, allow_joins, reuse, summarize, for_save\n+            )\n+        c.default = c.default.resolve_expression(\n+            query, allow_joins, reuse, summarize, for_save\n+        )\n         return c\n \n     def copy(self):\n@@ -1105,7 +1213,9 @@ class Case(SQLiteNumericMixin, Expression):\n         c.cases = c.cases[:]\n         return c\n \n-    def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):\n+    def as_sql(\n+        self, compiler, connection, template=None, case_joiner=None, **extra_context\n+    ):\n         connection.ops.check_expression_support(self)\n         if not self.cases:\n             return compiler.compile(self.default)\n@@ -1123,10 +1233,10 @@ class Case(SQLiteNumericMixin, Expression):\n         if not case_parts:\n             return default_sql, default_params\n         case_joiner = case_joiner or self.case_joiner\n-        template_params['cases'] = case_joiner.join(case_parts)\n-        template_params['default'] = default_sql\n+        template_params[\"cases\"] = case_joiner.join(case_parts)\n+        template_params[\"default\"] = default_sql\n         sql_params.extend(default_params)\n-        template = template or template_params.get('template', self.template)\n+        template = template or template_params.get(\"template\", self.template)\n         sql = template % template_params\n         if self._output_field_or_none is not None:\n             sql = connection.ops.unification_cast_sql(self.output_field) % sql\n@@ -1143,13 +1253,15 @@ class Subquery(BaseExpression, Combinable):\n     An explicit subquery. It may contain OuterRef() references to the outer\n     query which will be resolved when it is applied to that query.\n     \"\"\"\n-    template = '(%(subquery)s)'\n+\n+    template = \"(%(subquery)s)\"\n     contains_aggregate = False\n     empty_result_set_value = None\n \n     def __init__(self, queryset, output_field=None, **extra):\n         # Allow the usage of both QuerySet and sql.Query objects.\n-        self.query = getattr(queryset, 'query', queryset)\n+        self.query = getattr(queryset, \"query\", queryset)\n+        self.query.subquery = True\n         self.extra = extra\n         super().__init__(output_field)\n \n@@ -1179,9 +1291,9 @@ class Subquery(BaseExpression, Combinable):\n         template_params = {**self.extra, **extra_context}\n         query = query or self.query\n         subquery_sql, sql_params = query.as_sql(compiler, connection)\n-        template_params['subquery'] = subquery_sql[1:-1]\n+        template_params[\"subquery\"] = subquery_sql[1:-1]\n \n-        template = template or template_params.get('template', self.template)\n+        template = template or template_params.get(\"template\", self.template)\n         sql = template % template_params\n         return sql, sql_params\n \n@@ -1196,7 +1308,7 @@ class Subquery(BaseExpression, Combinable):\n \n \n class Exists(Subquery):\n-    template = 'EXISTS(%(subquery)s)'\n+    template = \"EXISTS(%(subquery)s)\"\n     output_field = fields.BooleanField()\n \n     def __init__(self, queryset, negated=False, **kwargs):\n@@ -1218,7 +1330,7 @@ class Exists(Subquery):\n             **extra_context,\n         )\n         if self.negated:\n-            sql = 'NOT {}'.format(sql)\n+            sql = \"NOT {}\".format(sql)\n         return sql, params\n \n     def select_format(self, compiler, sql, params):\n@@ -1226,28 +1338,31 @@ class Exists(Subquery):\n         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP\n         # BY list.\n         if not compiler.connection.features.supports_boolean_expr_in_select_clause:\n-            sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)\n+            sql = \"CASE WHEN {} THEN 1 ELSE 0 END\".format(sql)\n         return sql, params\n \n \n-@deconstructible(path='django.db.models.OrderBy')\n+@deconstructible(path=\"django.db.models.OrderBy\")\n class OrderBy(Expression):\n-    template = '%(expression)s %(ordering)s'\n+    template = \"%(expression)s %(ordering)s\"\n     conditional = False\n \n-    def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):\n+    def __init__(\n+        self, expression, descending=False, nulls_first=False, nulls_last=False\n+    ):\n         if nulls_first and nulls_last:\n-            raise ValueError('nulls_first and nulls_last are mutually exclusive')\n+            raise ValueError(\"nulls_first and nulls_last are mutually exclusive\")\n         self.nulls_first = nulls_first\n         self.nulls_last = nulls_last\n         self.descending = descending\n-        if not hasattr(expression, 'resolve_expression'):\n-            raise ValueError('expression must be an expression type')\n+        if not hasattr(expression, \"resolve_expression\"):\n+            raise ValueError(\"expression must be an expression type\")\n         self.expression = expression\n \n     def __repr__(self):\n         return \"{}({}, descending={})\".format(\n-            self.__class__.__name__, self.expression, self.descending)\n+            self.__class__.__name__, self.expression, self.descending\n+        )\n \n     def set_source_expressions(self, exprs):\n         self.expression = exprs[0]\n@@ -1259,32 +1374,34 @@ class OrderBy(Expression):\n         template = template or self.template\n         if connection.features.supports_order_by_nulls_modifier:\n             if self.nulls_last:\n-                template = '%s NULLS LAST' % template\n+                template = \"%s NULLS LAST\" % template\n             elif self.nulls_first:\n-                template = '%s NULLS FIRST' % template\n+                template = \"%s NULLS FIRST\" % template\n         else:\n             if self.nulls_last and not (\n                 self.descending and connection.features.order_by_nulls_first\n             ):\n-                template = '%%(expression)s IS NULL, %s' % template\n+                template = \"%%(expression)s IS NULL, %s\" % template\n             elif self.nulls_first and not (\n                 not self.descending and connection.features.order_by_nulls_first\n             ):\n-                template = '%%(expression)s IS NOT NULL, %s' % template\n+                template = \"%%(expression)s IS NOT NULL, %s\" % template\n         connection.ops.check_expression_support(self)\n         expression_sql, params = compiler.compile(self.expression)\n         placeholders = {\n-            'expression': expression_sql,\n-            'ordering': 'DESC' if self.descending else 'ASC',\n+            \"expression\": expression_sql,\n+            \"ordering\": \"DESC\" if self.descending else \"ASC\",\n             **extra_context,\n         }\n-        params *= template.count('%(expression)s')\n+        params *= template.count(\"%(expression)s\")\n         return (template % placeholders).rstrip(), params\n \n     def as_oracle(self, compiler, connection):\n         # Oracle doesn't allow ORDER BY EXISTS() or filters unless it's wrapped\n         # in a CASE WHEN.\n-        if connection.ops.conditional_expression_supported_in_where_clause(self.expression):\n+        if connection.ops.conditional_expression_supported_in_where_clause(\n+            self.expression\n+        ):\n             copy = self.copy()\n             copy.expression = Case(\n                 When(self.expression, then=True),\n@@ -1314,7 +1431,7 @@ class OrderBy(Expression):\n \n \n class Window(SQLiteNumericMixin, Expression):\n-    template = '%(expression)s OVER (%(window)s)'\n+    template = \"%(expression)s OVER (%(window)s)\"\n     # Although the main expression may either be an aggregate or an\n     # expression with an aggregate function, the GROUP BY that will\n     # be introduced in the query as a result is not desired.\n@@ -1322,15 +1439,22 @@ class Window(SQLiteNumericMixin, Expression):\n     contains_over_clause = True\n     filterable = False\n \n-    def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):\n+    def __init__(\n+        self,\n+        expression,\n+        partition_by=None,\n+        order_by=None,\n+        frame=None,\n+        output_field=None,\n+    ):\n         self.partition_by = partition_by\n         self.order_by = order_by\n         self.frame = frame\n \n-        if not getattr(expression, 'window_compatible', False):\n+        if not getattr(expression, \"window_compatible\", False):\n             raise ValueError(\n-                \"Expression '%s' isn't compatible with OVER clauses.\" %\n-                expression.__class__.__name__\n+                \"Expression '%s' isn't compatible with OVER clauses.\"\n+                % expression.__class__.__name__\n             )\n \n         if self.partition_by is not None:\n@@ -1345,8 +1469,8 @@ class Window(SQLiteNumericMixin, Expression):\n                 self.order_by = OrderByList(self.order_by)\n             else:\n                 raise ValueError(\n-                    'Window.order_by must be either a string reference to a '\n-                    'field, an expression, or a list or tuple of them.'\n+                    \"Window.order_by must be either a string reference to a \"\n+                    \"field, an expression, or a list or tuple of them.\"\n                 )\n         super().__init__(output_field=output_field)\n         self.source_expression = self._parse_expressions(expression)[0]\n@@ -1363,14 +1487,15 @@ class Window(SQLiteNumericMixin, Expression):\n     def as_sql(self, compiler, connection, template=None):\n         connection.ops.check_expression_support(self)\n         if not connection.features.supports_over_clause:\n-            raise NotSupportedError('This backend does not support window expressions.')\n+            raise NotSupportedError(\"This backend does not support window expressions.\")\n         expr_sql, params = compiler.compile(self.source_expression)\n         window_sql, window_params = [], []\n \n         if self.partition_by is not None:\n             sql_expr, sql_params = self.partition_by.as_sql(\n-                compiler=compiler, connection=connection,\n-                template='PARTITION BY %(expressions)s',\n+                compiler=compiler,\n+                connection=connection,\n+                template=\"PARTITION BY %(expressions)s\",\n             )\n             window_sql.append(sql_expr)\n             window_params.extend(sql_params)\n@@ -1389,8 +1514,8 @@ class Window(SQLiteNumericMixin, Expression):\n         template = template or self.template\n \n         return template % {\n-            'expression': expr_sql,\n-            'window': ' '.join(window_sql).strip()\n+            \"expression\": expr_sql,\n+            \"window\": \" \".join(window_sql).strip(),\n         }, params\n \n     def as_sqlite(self, compiler, connection):\n@@ -1404,15 +1529,15 @@ class Window(SQLiteNumericMixin, Expression):\n         return self.as_sql(compiler, connection)\n \n     def __str__(self):\n-        return '{} OVER ({}{}{})'.format(\n+        return \"{} OVER ({}{}{})\".format(\n             str(self.source_expression),\n-            'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',\n-            str(self.order_by or ''),\n-            str(self.frame or ''),\n+            \"PARTITION BY \" + str(self.partition_by) if self.partition_by else \"\",\n+            str(self.order_by or \"\"),\n+            str(self.frame or \"\"),\n         )\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def get_group_by_cols(self, alias=None):\n         return []\n@@ -1426,7 +1551,8 @@ class WindowFrame(Expression):\n     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last\n     row in the frame).\n     \"\"\"\n-    template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'\n+\n+    template = \"%(frame_type)s BETWEEN %(start)s AND %(end)s\"\n \n     def __init__(self, start=None, end=None):\n         self.start = Value(start)\n@@ -1440,52 +1566,54 @@ class WindowFrame(Expression):\n \n     def as_sql(self, compiler, connection):\n         connection.ops.check_expression_support(self)\n-        start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)\n+        start, end = self.window_frame_start_end(\n+            connection, self.start.value, self.end.value\n+        )\n         return self.template % {\n-            'frame_type': self.frame_type,\n-            'start': start,\n-            'end': end,\n+            \"frame_type\": self.frame_type,\n+            \"start\": start,\n+            \"end\": end,\n         }, []\n \n     def __repr__(self):\n-        return '<%s: %s>' % (self.__class__.__name__, self)\n+        return \"<%s: %s>\" % (self.__class__.__name__, self)\n \n     def get_group_by_cols(self, alias=None):\n         return []\n \n     def __str__(self):\n         if self.start.value is not None and self.start.value < 0:\n-            start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)\n+            start = \"%d %s\" % (abs(self.start.value), connection.ops.PRECEDING)\n         elif self.start.value is not None and self.start.value == 0:\n             start = connection.ops.CURRENT_ROW\n         else:\n             start = connection.ops.UNBOUNDED_PRECEDING\n \n         if self.end.value is not None and self.end.value > 0:\n-            end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)\n+            end = \"%d %s\" % (self.end.value, connection.ops.FOLLOWING)\n         elif self.end.value is not None and self.end.value == 0:\n             end = connection.ops.CURRENT_ROW\n         else:\n             end = connection.ops.UNBOUNDED_FOLLOWING\n         return self.template % {\n-            'frame_type': self.frame_type,\n-            'start': start,\n-            'end': end,\n+            \"frame_type\": self.frame_type,\n+            \"start\": start,\n+            \"end\": end,\n         }\n \n     def window_frame_start_end(self, connection, start, end):\n-        raise NotImplementedError('Subclasses must implement window_frame_start_end().')\n+        raise NotImplementedError(\"Subclasses must implement window_frame_start_end().\")\n \n \n class RowRange(WindowFrame):\n-    frame_type = 'ROWS'\n+    frame_type = \"ROWS\"\n \n     def window_frame_start_end(self, connection, start, end):\n         return connection.ops.window_frame_rows_start_end(start, end)\n \n \n class ValueRange(WindowFrame):\n-    frame_type = 'RANGE'\n+    frame_type = \"RANGE\"\n \n     def window_frame_start_end(self, connection, start, end):\n         return connection.ops.window_frame_range_start_end(start, end)\n"}
{"instance_id": "django__django-15347", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 1d390c71dd..0fd7ab60b6 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -12,14 +12,15 @@ class MessageEncoder(json.JSONEncoder):\n     \"\"\"\n     Compactly serialize instances of the ``Message`` class as JSON.\n     \"\"\"\n-    message_key = '__json_message'\n+\n+    message_key = \"__json_message\"\n \n     def default(self, obj):\n         if isinstance(obj, Message):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n@@ -38,8 +39,7 @@ class MessageDecoder(json.JSONDecoder):\n                 return Message(*obj[2:])\n             return [self.process_messages(item) for item in obj]\n         if isinstance(obj, dict):\n-            return {key: self.process_messages(value)\n-                    for key, value in obj.items()}\n+            return {key: self.process_messages(value) for key, value in obj.items()}\n         return obj\n \n     def decode(self, s, **kwargs):\n@@ -51,25 +51,26 @@ class MessageSerializer:\n     def dumps(self, obj):\n         return json.dumps(\n             obj,\n-            separators=(',', ':'),\n+            separators=(\",\", \":\"),\n             cls=MessageEncoder,\n-        ).encode('latin-1')\n+        ).encode(\"latin-1\")\n \n     def loads(self, data):\n-        return json.loads(data.decode('latin-1'), cls=MessageDecoder)\n+        return json.loads(data.decode(\"latin-1\"), cls=MessageDecoder)\n \n \n class CookieStorage(BaseStorage):\n     \"\"\"\n     Store messages in a cookie.\n     \"\"\"\n-    cookie_name = 'messages'\n+\n+    cookie_name = \"messages\"\n     # uwsgi's default configuration enforces a maximum size of 4kb for all the\n     # HTTP headers. In order to leave some room for other cookies and headers,\n     # restrict the session cookie to 1/2 of 4kb. See #18781.\n     max_cookie_size = 2048\n-    not_finished = '__messagesnotfinished__'\n-    key_salt = 'django.contrib.messages'\n+    not_finished = \"__messagesnotfinished__\"\n+    key_salt = \"django.contrib.messages\"\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n@@ -97,7 +98,8 @@ class CookieStorage(BaseStorage):\n         \"\"\"\n         if encoded_data:\n             response.set_cookie(\n-                self.cookie_name, encoded_data,\n+                self.cookie_name,\n+                encoded_data,\n                 domain=settings.SESSION_COOKIE_DOMAIN,\n                 secure=settings.SESSION_COOKIE_SECURE or None,\n                 httponly=settings.SESSION_COOKIE_HTTPONLY or None,\n@@ -134,8 +136,9 @@ class CookieStorage(BaseStorage):\n                     unstored_messages.append(messages.pop(0))\n                 else:\n                     unstored_messages.insert(0, messages.pop())\n-                encoded_data = self._encode(messages + [self.not_finished],\n-                                            encode_empty=unstored_messages)\n+                encoded_data = self._encode(\n+                    messages + [self.not_finished], encode_empty=unstored_messages\n+                )\n         self._update_cookie(encoded_data, response)\n         return unstored_messages\n \n@@ -148,7 +151,9 @@ class CookieStorage(BaseStorage):\n         also contains a hash to ensure that the data was not tampered with.\n         \"\"\"\n         if messages or encode_empty:\n-            return self.signer.sign_object(messages, serializer=MessageSerializer, compress=True)\n+            return self.signer.sign_object(\n+                messages, serializer=MessageSerializer, compress=True\n+            )\n \n     def _decode(self, data):\n         \"\"\"\n"}
{"instance_id": "django__django-15388", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/template/autoreload.py b/django/template/autoreload.py\nindex cf1b20ba95..81eb2a532e 100644\n--- a/django/template/autoreload.py\n+++ b/django/template/autoreload.py\n@@ -5,7 +5,9 @@ from django.template import engines\n from django.template.backends.django import DjangoTemplates\n from django.utils._os import to_path\n from django.utils.autoreload import (\n-    autoreload_started, file_changed, is_django_path,\n+    autoreload_started,\n+    file_changed,\n+    is_django_path,\n )\n \n \n@@ -22,14 +24,22 @@ def get_template_directories():\n         items.update(cwd / to_path(dir) for dir in backend.engine.dirs)\n \n         for loader in backend.engine.template_loaders:\n-            if not hasattr(loader, 'get_dirs'):\n+            if not hasattr(loader, \"get_dirs\"):\n                 continue\n             items.update(\n                 cwd / to_path(directory)\n                 for directory in loader.get_dirs()\n                 if not is_django_path(directory)\n             )\n-    return items\n+    # Filter out parent directories that contain other template directories.\n+    # This avoids unnecessarily watching the project root (BASE_DIR) when a\n+    # more specific template directory exists, which would cause all file\n+    # changes to be treated as template changes and prevent auto-reload.\n+    return {\n+        directory\n+        for directory in items\n+        if not any(directory in other.parents and directory != other for other in items)\n+    }\n \n \n def reset_loaders():\n@@ -40,13 +50,13 @@ def reset_loaders():\n             loader.reset()\n \n \n-@receiver(autoreload_started, dispatch_uid='template_loaders_watch_changes')\n+@receiver(autoreload_started, dispatch_uid=\"template_loaders_watch_changes\")\n def watch_for_template_changes(sender, **kwargs):\n     for directory in get_template_directories():\n-        sender.watch_dir(directory, '**/*')\n+        sender.watch_dir(directory, \"**/*\")\n \n \n-@receiver(file_changed, dispatch_uid='template_loaders_file_changed')\n+@receiver(file_changed, dispatch_uid=\"template_loaders_file_changed\")\n def template_changed(sender, file_path, **kwargs):\n     for template_dir in get_template_directories():\n         if template_dir in file_path.parents:\n"}
{"instance_id": "django__django-15400", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 9e1be0fe0f..bf6513a2c4 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -19,8 +19,7 @@ class cached_property:\n     @staticmethod\n     def func(instance):\n         raise TypeError(\n-            \"Cannot use cached_property instance without calling \"\n-            \"__set_name__() on it.\"\n+            \"Cannot use cached_property instance without calling __set_name__() on it.\"\n         )\n \n     def __init__(self, func, name=None):\n@@ -28,8 +27,7 @@ class cached_property:\n \n         if name is not None:\n             warnings.warn(\n-                \"The name argument is deprecated as it's unnecessary as of \"\n-                \"Python 3.6.\",\n+                \"The name argument is deprecated as it's unnecessary as of Python 3.6.\",\n                 RemovedInDjango50Warning,\n                 stacklevel=2,\n             )\n@@ -432,6 +430,11 @@ class SimpleLazyObject(LazyObject):\n             return result\n         return copy.deepcopy(self._wrapped, memo)\n \n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n \n def partition(predicate, values):\n     \"\"\"\n"}
{"instance_id": "django__django-15498", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/views/static.py b/django/views/static.py\nindex 1c558a53ff..734e7a90af 100644\n--- a/django/views/static.py\n+++ b/django/views/static.py\n@@ -2,6 +2,7 @@\n Views and functions for serving static files. These are only to be used\n during development, and SHOULD NOT be used in a production setting.\n \"\"\"\n+\n import mimetypes\n import posixpath\n import re\n@@ -116,8 +117,8 @@ def was_modified_since(header=None, mtime=0, size=0):\n     Was something modified since the user last downloaded it?\n \n     header\n-      This is the value of the If-Modified-Since header.  If this is None,\n-      I'll just return True.\n+      This is the value of the If-Modified-Since header.  If this is None\n+      or an empty string, I'll just return True.\n \n     mtime\n       This is the modification time of the item we're talking about.\n@@ -126,7 +127,7 @@ def was_modified_since(header=None, mtime=0, size=0):\n       This is the size of the item we're talking about.\n     \"\"\"\n     try:\n-        if header is None:\n+        if not header:\n             raise ValueError\n         matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header, re.IGNORECASE)\n         header_mtime = parse_http_date(matches[1])\n"}
{"instance_id": "django__django-15695", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..11a3786025 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -401,7 +401,7 @@ class RenameModel(ModelOperation):\n             fields = zip(\n                 old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n             )\n-            for (old_field, new_field) in fields:\n+            for old_field, new_field in fields:\n                 # Skip self-referential fields as these are renamed above.\n                 if (\n                     new_field.model == new_field.related_model\n@@ -506,7 +506,7 @@ class AlterModelTable(ModelOptionOperation):\n                 new_model._meta.db_table,\n             )\n             # Rename M2M fields whose name is based on this model's db_table\n-            for (old_field, new_field) in zip(\n+            for old_field, new_field in zip(\n                 old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n             ):\n                 if new_field.remote_field.through._meta.auto_created:\n@@ -942,7 +942,7 @@ class RenameIndex(IndexOperation):\n                 from_model._meta.get_field(field).column for field in self.old_fields\n             ]\n             matching_index_name = schema_editor._constraint_names(\n-                from_model, column_names=columns, index=True\n+                from_model, column_names=columns, index=True, exclude=[self.new_name]\n             )\n             if len(matching_index_name) != 1:\n                 raise ValueError(\n"}
{"instance_id": "django__django-15738", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 03f0f11507..07df9be2c3 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -517,7 +517,9 @@ class BaseDatabaseSchemaEditor:\n         if sql:\n             self.execute(sql)\n \n-    def alter_unique_together(self, model, old_unique_together, new_unique_together):\n+    def alter_unique_together(\n+        self, model, old_unique_together, new_unique_together, old_model=None\n+    ):\n         \"\"\"\n         Deal with a model changing its unique_together. The input\n         unique_togethers must be doubly-nested, not the single-nested\n@@ -532,13 +534,16 @@ class BaseDatabaseSchemaEditor:\n                 fields,\n                 {\"unique\": True, \"primary_key\": False},\n                 self.sql_delete_unique,\n+                old_model=old_model,\n             )\n         # Created uniques\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n             self.execute(self._create_unique_sql(model, fields))\n \n-    def alter_index_together(self, model, old_index_together, new_index_together):\n+    def alter_index_together(\n+        self, model, old_index_together, new_index_together, old_model=None\n+    ):\n         \"\"\"\n         Deal with a model changing its index_together. The input\n         index_togethers must be doubly-nested, not the single-nested\n@@ -553,18 +558,23 @@ class BaseDatabaseSchemaEditor:\n                 fields,\n                 {\"index\": True, \"unique\": False},\n                 self.sql_delete_index,\n+                old_model=old_model,\n             )\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n             self.execute(self._create_index_sql(model, fields=fields, suffix=\"_idx\"))\n \n-    def _delete_composed_index(self, model, fields, constraint_kwargs, sql):\n+    def _delete_composed_index(\n+        self, model, fields, constraint_kwargs, sql, old_model=None\n+    ):\n         meta_constraint_names = {\n             constraint.name for constraint in model._meta.constraints\n         }\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n-        columns = [model._meta.get_field(field).column for field in fields]\n+        columns = [\n+            (old_model or model)._meta.get_field(field).column for field in fields\n+        ]\n         constraint_names = self._constraint_names(\n             model,\n             columns,\ndiff --git a/django/db/backends/mysql/schema.py b/django/db/backends/mysql/schema.py\nindex d6d303f0f0..df314058d8 100644\n--- a/django/db/backends/mysql/schema.py\n+++ b/django/db/backends/mysql/schema.py\n@@ -3,7 +3,6 @@ from django.db.models import NOT_PROVIDED\n \n \n class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n-\n     sql_rename_table = \"RENAME TABLE %(old_table)s TO %(new_table)s\"\n \n     sql_alter_column_null = \"MODIFY %(column)s %(type)s NULL\"\n@@ -135,7 +134,9 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             return False\n         return not self._is_limited_data_type(field)\n \n-    def _delete_composed_index(self, model, fields, *args):\n+    def _delete_composed_index(\n+        self, model, fields, constraint_kwargs, sql, old_model=None\n+    ):\n         \"\"\"\n         MySQL can remove an implicit FK index on a field when that field is\n         covered by another index like a unique_together. \"covered\" here means\n@@ -144,7 +145,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         We check here before removing the [unique|index]_together if we have to\n         recreate a FK index.\n         \"\"\"\n-        first_field = model._meta.get_field(fields[0])\n+        first_field = (old_model or model)._meta.get_field(fields[0])\n         if first_field.get_internal_type() == \"ForeignKey\":\n             constraint_names = self._constraint_names(\n                 model, [first_field.column], index=True\n@@ -153,7 +154,9 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n                 self.execute(\n                     self._create_index_sql(model, fields=[first_field], suffix=\"\")\n                 )\n-        return super()._delete_composed_index(model, fields, *args)\n+        return super()._delete_composed_index(\n+            model, fields, constraint_kwargs, sql, old_model=old_model\n+        )\n \n     def _set_field_new_type_null_status(self, field, new_type):\n         \"\"\"\ndiff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 75a3b8b030..5017132bd7 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -401,7 +401,7 @@ class RenameModel(ModelOperation):\n             fields = zip(\n                 old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n             )\n-            for (old_field, new_field) in fields:\n+            for old_field, new_field in fields:\n                 # Skip self-referential fields as these are renamed above.\n                 if (\n                     new_field.model == new_field.related_model\n@@ -506,7 +506,7 @@ class AlterModelTable(ModelOptionOperation):\n                 new_model._meta.db_table,\n             )\n             # Rename M2M fields whose name is based on this model's db_table\n-            for (old_field, new_field) in zip(\n+            for old_field, new_field in zip(\n                 old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n             ):\n                 if new_field.remote_field.through._meta.auto_created:\n@@ -566,6 +566,7 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n                 new_model,\n                 getattr(old_model._meta, self.option_name, set()),\n                 getattr(new_model._meta, self.option_name, set()),\n+                old_model=old_model,\n             )\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n"}
{"instance_id": "django__django-15781", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex d37d43d5c5..e8ffbce533 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -2,10 +2,11 @@\n Base classes for writing management commands (named commands which can\n be executed through ``django-admin`` or ``manage.py``).\n \"\"\"\n+\n import argparse\n import os\n import sys\n-from argparse import ArgumentParser, HelpFormatter\n+from argparse import ArgumentParser, HelpFormatter, RawTextHelpFormatter\n from io import TextIOBase\n \n import django\n@@ -102,7 +103,7 @@ def no_translations(handle_func):\n     return wrapper\n \n \n-class DjangoHelpFormatter(HelpFormatter):\n+class DjangoHelpFormatter(RawTextHelpFormatter):\n     \"\"\"\n     Customized formatter so that command-specific arguments appear in the\n     --help output before arguments common to all commands.\n"}
{"instance_id": "django__django-15789", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d0bc97be80..007602a14a 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -59,7 +59,7 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=None):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -67,7 +67,9 @@ def json_script(value, element_id=None):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n \n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    json_str = json.dumps(value, cls=encoder or DjangoJSONEncoder).translate(\n+        _json_script_escapes\n+    )\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n"}
{"instance_id": "django__django-15790", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/default_1.sqlite3 b/default_1.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/default_2.sqlite3 b/default_2.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/default_3.sqlite3 b/default_3.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/django/core/checks/templates.py b/django/core/checks/templates.py\nindex 5214276987..23304e99ee 100644\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -57,8 +57,17 @@ def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n         for module_name, module_path in custom_libraries.items():\n             libraries[module_name].append(module_path)\n \n+    # Autodiscovery adds libraries from installed apps. Skip libraries\n+    # that are already defined in custom_libraries to avoid false positives.\n+    autodiscover_libraries = {\n+        module_name\n+        for conf in settings.TEMPLATES\n+        for module_name in conf.get(\"OPTIONS\", {}).get(\"libraries\", {})\n+    }\n+\n     for module_name, module_path in get_template_tag_modules():\n-        libraries[module_name].append(module_path)\n+        if module_name not in autodiscover_libraries:\n+            libraries[module_name].append(module_path)\n \n     for library_name, items in libraries.items():\n         if len(items) > 1:\ndiff --git a/other_1.sqlite3 b/other_1.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/other_2.sqlite3 b/other_2.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/other_3.sqlite3 b/other_3.sqlite3\nnew file mode 100644\nindex 0000000000..e69de29bb2\n"}
{"instance_id": "django__django-15814", "model_name_or_path": "opencode-minimax-m2.5", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..66a67590e3 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -6,6 +6,7 @@ themselves do not have to (and could be backed by things other than SQL\n databases). The abstraction barrier only works one way: this module has to know\n all about the internals of models in order to get the information it needs.\n \"\"\"\n+\n import copy\n import difflib\n import functools\n@@ -748,7 +749,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n@@ -1266,8 +1267,7 @@ class Query(BaseExpression):\n             expression, \"filterable\", True\n         ):\n             raise NotSupportedError(\n-                expression.__class__.__name__ + \" is disallowed in the filter \"\n-                \"clause.\"\n+                expression.__class__.__name__ + \" is disallowed in the filter clause.\"\n             )\n         if hasattr(expression, \"get_source_expressions\"):\n             for expr in expression.get_source_expressions():\n@@ -2162,8 +2162,7 @@ class Query(BaseExpression):\n                 raise\n             elif name in self.annotations:\n                 raise FieldError(\n-                    \"Cannot select the '%s' alias. Use annotate() to promote \"\n-                    \"it.\" % name\n+                    \"Cannot select the '%s' alias. Use annotate() to promote it.\" % name\n                 )\n             else:\n                 names = sorted(\n"}
